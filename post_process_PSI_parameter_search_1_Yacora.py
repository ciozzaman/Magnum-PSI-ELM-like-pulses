
# echo 'running batch'

import os,sys
# os.environ["MKL_NUM_THREADS"] = "1"
# os.environ["NUMEXPR_NUM_THREADS"] = "1"
# os.environ["OMP_NUM_THREADS"] = "1"
import mkl
# mkl.set_num_threads(1)
import numpy as np
exec(open("/home/ffederic/work/analysis_scripts/scripts/preamble_import_pc.py").read())
# exec(open("/home/ffederic/work/analysis_scripts/scripts/preamble_import_batch.py").read())
# import matplotlib.pyplot as plt
#import .functions
os.chdir('/home/ffederic/work/Collaboratory/test/experimental_data')
from functions.fabio_add import find_index_of_file, examine_current_trace, shift_between_TS_and_power_source
from generate_merge88_TS import generate_merge88_TS
import collections

from adas import read_adf15,read_adf11
from PIL import Image
import xarray as xr
import pandas as pd
import copy
from scipy.optimize import curve_fit,least_squares
from scipy import interpolate
from scipy.signal import find_peaks, peak_prominences as get_proms
from sklearn.linear_model import LinearRegression
import time as tm
import pickle
from multiprocessing import Pool,cpu_count,current_process,set_start_method,get_context,Semaphore
from multiprocessing.dummy import Pool as ThreadPool
from functools import partial
import traceback
# set_start_method('spawn')
number_cpu_available = 10	#cpu_count()
# pool = get_context('spawn').Pool(number_cpu_available)
print('Number of cores available: '+str(number_cpu_available))
# number_cpu_available = 10
# print('Number of cores available: '+str(number_cpu_available))
# print('Number of cores available: '+str(len(os.sched_getaffinitymy_r_pos(0))))
# import psutil
# print('Number of cores available: '+str(psutil.cpu_count(logical = False)))



# n = np.arange(10, 20)
# waveLengths = [656.45377,486.13615,434.0462,410.174,397.0072,388.9049,383.5384] + list((364.6*(n*n)/(n*n-4)))
waveLengths = [486.13615,434.0462,410.174,397.0072,388.9049,383.5384]
waveLengths_interp = interpolate.interp1d(waveLengths[:2], [1.39146712e+03,8.83761543e+02],fill_value='extrapolate')
#pathfiles = '/home/ff645/GoogleDrive/ff645/YPI - Fabio/Collaboratory/Experimental data/tests/2019-04-25/final_test/Untitled_1/Pos0'
# pathfiles = '/home/ff645/GoogleDrive/ff645/YPI - Fabio/Collaboratory/Experimental data/tests/temp - Desktop pc/Untitled_11/Pos0'
# pathfiles = '/home/ff645/GoogleDrive/ff645/YPI - Fabio/Collaboratory/Experimental data/tests/test_data_folder/2019-04-25/01/Untitled_1/Pos0'

fdir = '/home/ffederic/work/Collaboratory/test/experimental_data'
df_log = pd.read_csv('/home/ffederic/work/Collaboratory/test/experimental_data/functions/Log/shots_3.csv', index_col=0)
df_settings = pd.read_csv('/home/ffederic/work/Collaboratory/test/experimental_data/functions/Log/settings_3.csv',index_col=0)

exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/import_PECs_FF_2.py").read())

pecfile = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/pec12#h_balmer#h0.dat'
pecfile_2 = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/pec12#h_pju#h0.dat'
scdfile = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/scd12_h.dat'
acdfile = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/acd12_h.dat'
pltfile = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/plt12_h.dat'
prbfile = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/prb12_h.dat'
ccdfile = '/home/ffederic/work/Collaboratory/test/experimental_data/functions/ccd96_h.dat'

if False:

	solutions=[]
	for merge_ID_target in [85,89,93]:
		for high_line in [7,8,9,10]:
			# high_line = 7
			low_line = 4
			time_shift_factor = -0.05
			spatial_factor = 1.35
			nH_ne = 1
			OES_multiplier = 1

			# merge_ID_target = 85


			figure_index = 0

			# calculate_geometry = False
			# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
			for i in range(10):
				print('.')
			print('Starting to work on merge number'+str(merge_ID_target))
			for i in range(10):
				print('.')


			time_resolution_scan = False
			time_resolution_scan_improved = True
			time_resolution_extra_skip = 0




			started=0
			rows_range_for_interp = 25/3 # rows that I use for interpolation (box with twice this side length, not sphere)
			# if merge_ID_target>=66:
			# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
			if time_resolution_scan:
				conventional_time_step = 0.01	# ms
			else:
				conventional_time_step = 0.05	# ms
			# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
			grade_of_interpolation = 3	#this is the exponent used for the weights of the interpolation for image resampling
			type_of_image = '12bit'	# '12bit' or '16bit'
			# if type_of_image=='12bit':
			row_shift=2*10280/1000000	# ms
			# elif type_of_image=='16bit':
			# 	print('Row shift to be checked')
			# 	exit()
			# time_range_for_interp = rows_range_for_interp*row_shift
			# merge_time_window=[-1,4]
			merge_time_window=[-10,10]
			overexposed_treshold = 3600
			path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(merge_ID_target)



			new_timesteps = np.linspace(merge_time_window[0]+0.5, merge_time_window[1]-0.5,int((merge_time_window[1]-0.5-(merge_time_window[0]+0.5))/conventional_time_step+1))
			dt=np.nanmedian(np.diff(new_timesteps))



			# first_time = np.min(new_timesteps)
			# last_time = np.max(new_timesteps)


			# Data from wikipedia
			energy_difference = np.array([1.89,2.55,2.86,3.03,3.13,3.19,3.23,3.26, 3.29 ])	#eV
			# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
			statistical_weigth = np.array([32,50,72,98,128,162,200,242,288])	#gi-gk
			einstein_coeff = np.array([8.4193e-2,2.53044e-2,9.7320e-3,4.3889e-3,2.2148e-3,1.2156e-3,7.1225e-4,4.3972e-4,2.8337e-4])*1e8	#1/s
			J_to_eV = 6.242e18
			au_to_kg = 1.66053906660e-27
			# Used formula 2.3 in Rion Barrois thesys, 2017
			color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']

			inverted_profiles_original = 4*np.pi*np.load(path_where_to_save_everything+'/inverted_profiles.npy')		# in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
			all_fits = np.load(path_where_to_save_everything +'/merge'+str(merge_ID_target)+'_all_fits.npy')	# in W m^-2 sr^-1
			merge_Te_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_Te_prof_multipulse']
			merge_dTe_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dTe_multipulse']
			merge_ne_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_ne_prof_multipulse']
			merge_dne_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dne_multipulse']
			merge_time_original = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_time']
			TS_dt=np.nanmedian(np.diff(merge_time_original))


			TS_size=[-4.149230769230769056e+01,4.416923076923076508e+01]
			TS_r=TS_size[0] + np.linspace(0,1,65)*(TS_size[1]- TS_size[0])
			TS_dr = np.median(np.diff(TS_r))/1000
			gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
			profile_centres = []
			profile_centres_score = []
			for index in range(np.shape(merge_Te_prof_multipulse)[0]):
				yy = merge_Te_prof_multipulse[index]
				p0 = [np.max(yy),10,0]
				bds = [[0,-40,np.min(TS_r)],[np.inf,40,np.max(TS_r)]]
				fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
				profile_centres.append(fit[0][-1])
				profile_centres_score.append(fit[1][-1,-1])
				# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
			profile_centres = np.array(profile_centres)
			profile_centres_score = np.array(profile_centres_score)
			centre = np.nanmean(profile_centres[profile_centres_score<1])
			TS_r_new = np.abs(TS_r-centre)/1000


			def residual_ext(nH_ne,high_line,merge_time_original,merge_Te_prof_multipulse,inverted_profiles_original,merge_ne_prof_multipulse,new_timesteps,TS_dt,TS_dr,dt ):
				# def residual(input):
				def residual(input):
					import numpy as np
					spatial_factor, time_shift_factor, OES_multiplier = *input,1
					print('spatial_factor,time_shift_factor,OES_multiplier')
					print(spatial_factor,time_shift_factor,OES_multiplier)
					# spatial_factor = input[0]
					# time_shift_factor = input[1]
					# OES_multiplier = input[2]


					merge_time = time_shift_factor + merge_time_original
					inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3

					dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
					xx = np.arange(40) * dx  # m
					xn = np.linspace(0, max(xx), 1000)
					r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
					r = r[::10]
					dr = np.median(np.diff(r))

					temp1 = np.zeros_like(inverted_profiles[:, 0])
					temp3 = np.zeros_like(inverted_profiles[:, 0])
					interp_range_t = max(dt / 2, TS_dt) * 1
					interp_range_r = max(dx / 2, TS_dr) * 1
					for i_t, value_t in enumerate(new_timesteps):
						if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
							continue
						for i_r, value_r in enumerate(np.abs(r)):
							if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
								continue
							temp1[i_t, i_r] = np.mean(merge_Te_prof_multipulse[np.abs(merge_time - value_t) < interp_range_t][:,np.abs(TS_r_new - value_r) < interp_range_r])
							temp3[i_t, i_r] = np.mean(merge_ne_prof_multipulse[np.abs(merge_time - value_t) < interp_range_t][:,np.abs(TS_r_new - value_r) < interp_range_r])

					merge_Te_prof_multipulse_interp = np.array(temp1)
					merge_ne_prof_multipulse_interp = np.array(temp3)

					# I crop to the usefull stuff
					start_time = np.abs(new_timesteps - 0).argmin()
					end_time = np.abs(new_timesteps - 1.5).argmin() + 1
					time_crop = new_timesteps[start_time:end_time]
					start_r = np.abs(r - 0).argmin()
					end_r = np.abs(r - 5).argmin() + 1
					r_crop = r[start_r:end_r]
					temp_r, temp_t = np.meshgrid(r_crop, time_crop)
					merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time, start_r:end_r]
					merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
					inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
					inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
					# all_fits_crop = all_fits[start_time:end_time]

					merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
					merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop_limited < 0.2] = 0
					merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
					merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop_limited < 5e-07] = 0
					# excitation = []
					# for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
					isel =high_line - 4 +2
					temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
					temp[np.isnan(temp)] = 0
					excitation = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
					# excitation.append(temp)
					excitation = np.array(excitation)  # in # photons cm^-3 s^-1
					excitation = (excitation.T * (10 ** -6) * (energy_difference[high_line - 4] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

					# recombination = []
					# for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
					isel =high_line - 4 + 20
					temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
					temp[np.isnan(temp)] = 0
					recombination = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
					# recombination.append(temp)
					recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
					recombination = (recombination.T * (10 ** -6) * (energy_difference[high_line - 4] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

					recombination_emissivity = (recombination * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) ** 2)).astype('float')
					difference = inverted_profiles_crop[:, high_line - 4] * OES_multiplier - recombination_emissivity
					h_atomic_density = difference / (excitation * (merge_ne_prof_multipulse_interp_crop * (10 ** 20))).astype('float')
					h_atomic_density[np.logical_not(np.isfinite(h_atomic_density))] = 0
					h_atomic_density[h_atomic_density < 0] = 0
					excitation_emissivity = (excitation * (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) * (h_atomic_density)).astype('float')

					if True:
						isel =low_line - 4 +2
						temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
						temp[np.isnan(temp)] = 0
						excitation = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
						# excitation.append(temp)
						excitation = np.array(excitation)  # in # photons cm^-3 s^-1
						excitation = (excitation.T * (10 ** -6) * (energy_difference[low_line - 4] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2
						excitation_emissivity = (excitation * (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) * (h_atomic_density)).astype('float')

						# recombination = []
						# for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
						isel =low_line - 4 + 20
						temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
						temp[np.isnan(temp)] = 0
						recombination = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
						# recombination.append(temp)
						recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
						recombination = (recombination.T * (10 ** -6) * (energy_difference[low_line - 4] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2
						recombination_emissivity = (recombination * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) ** 2)).astype('float')


						# residual_emission = []
						# for index in range(len(recombination_emissivity)):
						index=low_line - 4
						residual_emission=(inverted_profiles_crop[:, index] * OES_multiplier - recombination_emissivity -excitation_emissivity)
						residual_emission = np.array(residual_emission)
					elif False:
						index=high_line - 4
						residual_emission=(inverted_profiles_crop[:, index] * OES_multiplier - recombination_emissivity -excitation_emissivity)
						residual_emission = np.array(residual_emission)


					# print(np.sum(residual_emission[0][residual_emission[0]<0]))
					return residual_emission.flatten()
				return residual

			# # bds=[[1,-0.2,1],[2,0.1,4]]
			# # guess = [1,0,1]
			# # curve_fit(residual_ext(nH_ne,high_line,merge_time_original,merge_Te_prof_multipulse,inverted_profiles_original,merge_ne_prof_multipulse,new_timesteps,TS_dt,TS_dr,dt ),0,0,p0=guess,bounds=bds)
			# #
			# # guess = [spatial_factor,time_shift_factor,OES_multiplier]
			# # sol = newton_krylov(residual_ext(nH_ne,high_line,merge_time_original,merge_Te_prof_multipulse,inverted_profiles_original,merge_ne_prof_multipulse,new_timesteps,TS_dt,TS_dr,dt ), guess,method='lgmres', verbose=1,iter=30)
			# # print('Residual: %g' % abs(residual_ext(hx,hy,ht,P_left, P_right,P_top, P_bottom, P_init, conductivity,thickness,emissivity,diffusivity,sigmaSB,T_reference,Power_in,d2x,d2y,dt)(sol)).max())
			#
			# bds=[[1,-0.2,0.5],[2,0.1,4]]
			# guess = [1.3, -0.09      ,  1.9]
			# guess = np.array(guess).astype('float').flatten()
			# sol = least_squares(residual_ext(nH_ne,high_line,merge_time_original,merge_Te_prof_multipulse,inverted_profiles_original,merge_ne_prof_multipulse,new_timesteps,TS_dt,TS_dr,dt ), guess,bounds = bds,ftol=1-5,xtol=1e-16, max_nfev = 60,verbose=2,diff_step=[0.05,0.05,0.01],tr_solver='lsmr',x_scale='jac')

			bds=[[1,-0.2],[2,0.1]]
			guess = [1, 0 ]
			guess = np.array(guess).astype('float').flatten()
			sol = least_squares(residual_ext(nH_ne,high_line,merge_time_original,merge_Te_prof_multipulse,inverted_profiles_original,merge_ne_prof_multipulse,new_timesteps,TS_dt,TS_dr,dt ), guess,bounds = bds,ftol=1-5,xtol=1e-8, max_nfev = 6,verbose=2,diff_step=[-0.05,-0.06],tr_solver='lsmr',x_scale='jac')
			for index in range(5):
				sol = least_squares(residual_ext(nH_ne,high_line,merge_time_original,merge_Te_prof_multipulse,inverted_profiles_original,merge_ne_prof_multipulse,new_timesteps,TS_dt,TS_dr,dt ), sol.x,bounds = bds,ftol=1-5,xtol=1e-8, max_nfev = 10,verbose=2,diff_step=[-0.05,-0.06],tr_solver='lsmr',x_scale='jac')
			solutions.append(sol.x)

	solution=[]
	# high_line = 7
	solution .append( [1.26030977, -0.09      ,  1.88243027])
	# high_line = 8
	solution .append([1.26007684, -0.09      ,  1.9137136])
	# high_line = 9
	solution .append( [1.25725712, -0.08995191,  1.90669528])
	spatial_factor, time_shift_factor, OES_multiplier = np.mean(solution,axis=0)

	solutions = np.array([[ 1.48296984, -0.04946108],
		   [ 1.51064555, -0.04680084],
		   [ 1.32579228, -0.02394259],
		   [ 1.24151298, -0.00740485],
		   [ 1.61002045, -0.09527693],
		   [ 1.99950828, -0.02437629],
		   [ 1.55462026, -0.06259724],
		   [ 1.56731445, -0.02995821],
		   [ 1.2821108 , -0.01490611],
		   [ 1.39634897, -0.04119113],
		   [ 1.01181224, -0.00750937],
		   [ 1.01936835, -0.03175309]])

	np.median(solutions,axis=0)
	spatial_factor, time_shift_factor = np.median(solutions,axis=0)
elif False:

	make_plots = True



	for merge_ID_target in [85,86,87,88,89,92,93,94]:

		# merge_ID_target = 85


		figure_index = 0

		# calculate_geometry = False
		# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
		for i in range(10):
			print('.')
		print('Starting to work on merge number'+str(merge_ID_target))
		for i in range(10):
			print('.')


		time_resolution_scan = False
		time_resolution_scan_improved = True
		time_resolution_extra_skip = 0


		n_list = np.array([5,6,7, 9, 10, 11, 12])
		n_list_1 = np.array([4])
		n_weights = [1,1,1, 1, 1, 1, 1, 1000]
		for index in (n_list_1-4):
			n_weights[index]=3
		n_weights[np.max(n_list_1)-3]=2
		min_nH_ne = 0.999
		max_nH_ne = 0.1

		mod = '/min_nH_ne'+str(min_nH_ne)+'/n_dummy_'+str(len(n_list_1))

		print('dummy')
		print(n_list_1)
		print('min_nH_ne')
		print(min_nH_ne)
		print('max_nH_ne')
		print(max_nH_ne)
		print('n_weights')
		print(n_weights)

		started=0
		rows_range_for_interp = 25/3 # rows that I use for interpolation (box with twice this side length, not sphere)
		# if merge_ID_target>=66:
		# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
		if time_resolution_scan:
			conventional_time_step = 0.01	# ms
		else:
			conventional_time_step = 0.05	# ms
		# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
		grade_of_interpolation = 3	#this is the exponent used for the weights of the interpolation for image resampling
		type_of_image = '12bit'	# '12bit' or '16bit'
		# if type_of_image=='12bit':
		row_shift=2*10280/1000000	# ms
		# elif type_of_image=='16bit':
		# 	print('Row shift to be checked')
		# 	exit()
		# time_range_for_interp = rows_range_for_interp*row_shift
		# merge_time_window=[-1,4]
		merge_time_window=[-10,10]
		overexposed_treshold = 3600
		path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(merge_ID_target)

		if not os.path.exists(path_where_to_save_everything + mod):
			os.makedirs(path_where_to_save_everything + mod)


		new_timesteps = np.linspace(merge_time_window[0]+0.5, merge_time_window[1]-0.5,int((merge_time_window[1]-0.5-(merge_time_window[0]+0.5))/conventional_time_step+1))
		dt=np.nanmedian(np.diff(new_timesteps))

		# for spatial_factor in spatial_factor_all:
		#
		# 	mod = '/spatial_factor' + str(spatial_factor)
		# 	if not os.path.exists(path_where_to_save_everything + mod):
		# 		os.makedirs(path_where_to_save_everything + mod)

		# dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
		# xx = np.arange(40) * dx  # m
		# xn = np.linspace(0, max(xx), 1000)
		# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
		# r=r[::10]
		# dr=np.median(np.diff(r))



		# first_time = np.min(new_timesteps)
		# last_time = np.max(new_timesteps)


		# Data from wikipedia
		energy_difference = np.array([1.89,2.55,2.86,3.03,3.13,3.19,3.23,3.26, 3.29 ])	#eV
		# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
		statistical_weigth = np.array([32,50,72,98,128,162,200,242,288])	#gi-gk
		einstein_coeff = np.array([8.4193e-2,2.53044e-2,9.7320e-3,4.3889e-3,2.2148e-3,1.2156e-3,7.1225e-4,4.3972e-4,2.8337e-4])*1e8	#1/s
		J_to_eV = 6.242e18
		# Used formula 2.3 in Rion Barrois thesys, 2017
		color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']

		inverted_profiles_original = 4*np.pi*np.load(path_where_to_save_everything+'/inverted_profiles.npy')		# in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
		all_fits = np.load(path_where_to_save_everything +'/merge'+str(merge_ID_target)+'_all_fits.npy')	# in W m^-2 sr^-1
		merge_Te_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_Te_prof_multipulse']
		merge_dTe_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dTe_multipulse']
		merge_ne_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_ne_prof_multipulse']
		merge_dne_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dne_multipulse']
		merge_time_original = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_time']

		# for time_shift_factor in time_shift_factor_all:
		#
		# 	mod = '/spatial_factor' + str(spatial_factor)+'/time_shift_factor' + str(time_shift_factor)
		# 	if not os.path.exists(path_where_to_save_everything + mod):
		# 		os.makedirs(path_where_to_save_everything + mod)

		def residual_ext(inverted_profiles_original,merge_Te_prof_multipulse,merge_ne_prof_multipulse,merge_time_original):
			def residuals(input):
				spatial_factor=input[0]
				time_shift_factor = input[1]
				print('spatial_factor,time_shift_factor  '+str([spatial_factor,time_shift_factor]))


				dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
				xx = np.arange(40) * dx  # m
				xn = np.linspace(0, max(xx), 1000)
				r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
				r=r[::10]
				dr=np.median(np.diff(r))


				merge_time = time_shift_factor + merge_time_original
				inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				TS_dt=np.nanmedian(np.diff(merge_time))


				if np.max(merge_Te_prof_multipulse)<=0:
					print('merge'+str(merge_ID_target)+" has no recorded temperature")
					# continue

				TS_size=[-4.149230769230769056e+01,4.416923076923076508e+01]
				TS_r=TS_size[0] + np.linspace(0,1,65)*(TS_size[1]- TS_size[0])
				TS_dr = np.median(np.diff(TS_r))/1000
				gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
				profile_centres = []
				profile_centres_score = []
				for index in range(np.shape(merge_Te_prof_multipulse)[0]):
					yy = merge_Te_prof_multipulse[index]
					p0 = [np.max(yy),10,0]
					bds = [[0,-40,np.min(TS_r)],[np.inf,40,np.max(TS_r)]]
					fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
					profile_centres.append(fit[0][-1])
					profile_centres_score.append(fit[1][-1,-1])
					# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
				profile_centres = np.array(profile_centres)
				profile_centres_score = np.array(profile_centres_score)
				centre = np.nanmean(profile_centres[profile_centres_score<1])
				TS_r_new = np.abs(TS_r-centre)/1000
				# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
				# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
				# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)


				temp1=np.zeros_like(inverted_profiles[:,0])
				temp3=np.zeros_like(inverted_profiles[:,0])
				interp_range_t = max(dt/2,TS_dt)*1
				interp_range_r = max(dx/2,TS_dr)*1
				for i_t,value_t in enumerate(new_timesteps):
					if np.sum(np.abs(merge_time-value_t) < interp_range_t) == 0:
						continue
					for i_r,value_r in enumerate(np.abs(r)):
						if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
							continue
						temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[np.abs(merge_time-value_t)<interp_range_t][:,np.abs(TS_r_new-value_r)<interp_range_r])
						temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[np.abs(merge_time-value_t)<interp_range_t][:,np.abs(TS_r_new-value_r)<interp_range_r])

				merge_Te_prof_multipulse_interp=np.array(temp1)
				merge_ne_prof_multipulse_interp=np.array(temp3)
				temp_r, temp_t = np.meshgrid(r, new_timesteps)


				# I crop to the usefull stuff
				start_time = np.abs(new_timesteps-0).argmin()
				end_time = np.abs(new_timesteps-1.5).argmin()+1
				time_crop = new_timesteps[start_time:end_time]
				start_r = np.abs(r-0).argmin()
				end_r = np.abs(r-5).argmin()+1
				r_crop = r[start_r:end_r]
				temp_r, temp_t = np.meshgrid(r_crop, time_crop)
				merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,start_r:end_r]
				merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,start_r:end_r]
				inverted_profiles_crop = inverted_profiles[start_time:end_time,:,start_r:end_r]
				inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
				all_fits_crop = all_fits[start_time:end_time]
				# inverted_profiles_crop[inverted_profiles_crop<0] = 0

				x_local = xx - spatial_factor * 17.4 / 1000
				dr_crop = np.median(np.diff(r_crop))

				merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
				merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop_limited<0.2]=0
				merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
				merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop_limited<5e-07]=0
				excitation = []
				for isel in [2,3,4,5,6,7,8,9,10]:
					temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(), (merge_ne_prof_multipulse_interp_crop_limited*10**(20-6)).flatten())[0]	# ADAS database is in cm^3   # photons s^-1 cm^-3
					temp[np.isnan(temp)] = 0
					temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
					excitation.append(temp)
				excitation = np.array(excitation)	# in # photons cm^-3 s^-1
				excitation = (excitation.T*(10**-6)*(energy_difference/J_to_eV)).T	# in W m^-3 / (# / m^3)**2

				recombination = []
				for isel in [20,21,22,23,24,25,26,27,28]:
					temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(), (merge_ne_prof_multipulse_interp_crop_limited*10**(20-6)).flatten())[0]	# ADAS database is in cm^3   # photons s^-1 cm^-3
					temp[np.isnan(temp)] = 0
					temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
					recombination.append(temp)
				recombination = np.array(recombination)	# in # photons cm^-3 s^-1 / (# cm^-3)**2
				recombination = (recombination.T*(10**-6)*(energy_difference/J_to_eV)).T	# in W m^-3 / (# / m^3)**2




				def residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation):
					def residuals1(input):
						OES_multiplier=input
						print(OES_multiplier)

						n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
						# OES_multiplier = 0.81414701
						# nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						for my_time_pos in range(len(time_crop)):
							for my_r_pos in range(len(r_crop)):
								inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all-4, my_r_pos].flatten()
								recombination_restrict=recombination[n_list_all-4,my_time_pos, my_r_pos].flatten()
								merge_ne_prof_multipulse_interp_crop_limited_restrict=merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
								merge_Te_prof_multipulse_interp_crop_limited_restrict=merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
								excitation_restrict=excitation[n_list_all-4,my_time_pos, my_r_pos].flatten()

								if (merge_ne_prof_multipulse_interp_crop_limited_restrict==0 and merge_Te_prof_multipulse_interp_crop_limited_restrict==0):
									continue

								dummy = np.zeros((len(n_list_1), len(n_list_all)))
								for value in n_list_1:
									dummy[value - 4][value - 4] = 1

								if len(n_list_1) == 3:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2,dummy3):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
											return recombination_emissivity + excitation_emissivity + dummy_emissivity
										return calculated_emission

									bds = [[min_nH_ne, 0, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
									guess = [max_nH_ne, 10, 1000, 1000, 1000]
								elif len(n_list_1) == 2:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
											return recombination_emissivity + excitation_emissivity + dummy_emissivity
										return calculated_emission

									bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
									guess = [max_nH_ne, 10, 1000, 1000]
								elif len(n_list_1) == 1:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
											return recombination_emissivity + excitation_emissivity + dummy_emissivity
										return calculated_emission

									bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
									guess = [max_nH_ne, 10, 1000]

								fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict * OES_multiplier, p0=guess, bounds=bds,sigma=n_weights, maxfev=10000000)

								# nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
								# h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
								# dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
								# dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
								# dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
								residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict * OES_multiplier - fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict, excitation_restrict)(n_list, *fit[0]))) ** 2)
						return residuals_all.flatten()
					return residuals1


				guess = [1]
				bds = [[0.4],[5]]
				sol = least_squares(residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation), guess, bounds=bds, max_nfev=60,	verbose=2, gtol=1e-20, xtol=1e-5, ftol=1e-16, diff_step=0.01, x_scale='jac')
				OES_multiplier=sol.x
				return residual_ext1(n_list,n_list_1, n_weights, time_crop, r_crop, inverted_profiles_crop, recombination,merge_ne_prof_multipulse_interp_crop_limited, merge_Te_prof_multipulse_interp_crop_limited,excitation)(OES_multiplier)
			return residuals


		guess = [1,0]
		bds = [[1,-0.1], [2,0.1]]
		sol = least_squares(residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse, merge_time_original), guess, bounds=bds,max_nfev=60, verbose=2, gtol=1e-20, xtol=1e-12, ftol=1e-16, diff_step=[0.05,0.05], x_scale='jac')
		print(sol.x)

		spatial_factor = sol.x[0]
		time_shift_factor = sol.x[1]

		print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

		dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
		xx = np.arange(40) * dx  # m
		xn = np.linspace(0, max(xx), 1000)
		r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
		r = r[::10]
		dr = np.median(np.diff(r))

		merge_time = time_shift_factor + merge_time_original
		inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
		TS_dt = np.nanmedian(np.diff(merge_time))

		if np.max(merge_Te_prof_multipulse) <= 0:
			print('merge' + str(merge_ID_target) + " has no recorded temperature")
		# continue

		TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
		TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
		TS_dr = np.median(np.diff(TS_r)) / 1000
		gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
		profile_centres = []
		profile_centres_score = []
		for index in range(np.shape(merge_Te_prof_multipulse)[0]):
			yy = merge_Te_prof_multipulse[index]
			p0 = [np.max(yy), 10, 0]
			bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
			fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
			profile_centres.append(fit[0][-1])
			profile_centres_score.append(fit[1][-1, -1])
		# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
		profile_centres = np.array(profile_centres)
		profile_centres_score = np.array(profile_centres_score)
		centre = np.nanmean(profile_centres[profile_centres_score < 1])
		TS_r_new = np.abs(TS_r - centre) / 1000
		# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
		# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
		# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

		temp1 = np.zeros_like(inverted_profiles[:, 0])
		temp3 = np.zeros_like(inverted_profiles[:, 0])
		interp_range_t = max(dt / 2, TS_dt) * 1
		interp_range_r = max(dx / 2, TS_dr) * 1
		for i_t, value_t in enumerate(new_timesteps):
			if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
				continue
			for i_r, value_r in enumerate(np.abs(r)):
				if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
					continue
				temp1[i_t, i_r] = np.mean(merge_Te_prof_multipulse[np.abs(merge_time - value_t) < interp_range_t][:,np.abs(TS_r_new - value_r) < interp_range_r])
				temp3[i_t, i_r] = np.mean(merge_ne_prof_multipulse[np.abs(merge_time - value_t) < interp_range_t][:,np.abs(TS_r_new - value_r) < interp_range_r])

		merge_Te_prof_multipulse_interp = np.array(temp1)
		merge_ne_prof_multipulse_interp = np.array(temp3)
		temp_r, temp_t = np.meshgrid(r, new_timesteps)

		# I crop to the usefull stuff
		start_time = np.abs(new_timesteps - 0).argmin()
		end_time = np.abs(new_timesteps - 1.5).argmin() + 1
		time_crop = new_timesteps[start_time:end_time]
		start_r = np.abs(r - 0).argmin()
		end_r = np.abs(r - 5).argmin() + 1
		r_crop = r[start_r:end_r]
		temp_r, temp_t = np.meshgrid(r_crop, time_crop)
		merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time, start_r:end_r]
		merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
		inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
		inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
		all_fits_crop = all_fits[start_time:end_time]
		# inverted_profiles_crop[inverted_profiles_crop<0] = 0

		x_local = xx - spatial_factor * 17.4 / 1000
		dr_crop = np.median(np.diff(r_crop))

		merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
		merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop_limited < 0.2] = 0
		merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
		merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop_limited < 5e-07] = 0
		excitation = []
		for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
			temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
			temp[np.isnan(temp)] = 0
			temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
			excitation.append(temp)
		excitation = np.array(excitation)  # in # photons cm^-3 s^-1
		excitation = (excitation.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

		recombination = []
		for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
			temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
			temp[np.isnan(temp)] = 0
			temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
			recombination.append(temp)
		recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
		recombination = (recombination.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2



		def residual_ext1(n_list, n_list_1, n_weights, time_crop, r_crop, inverted_profiles_crop, recombination,merge_ne_prof_multipulse_interp_crop_limited, merge_Te_prof_multipulse_interp_crop_limited,excitation):
			def residuals1(input):
				OES_multiplier = input
				print(OES_multiplier)

				n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
				# OES_multiplier = 0.81414701
				# nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
				# h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
				# dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
				# dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
				# dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
				residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
				for my_time_pos in range(len(time_crop)):
					for my_r_pos in range(len(r_crop)):
						inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
						recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
						merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
						merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
						excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

						if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 and merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
							continue

						dummy = np.zeros((len(n_list_1), len(n_list_all)))
						for value in n_list_1:
							dummy[value - 4][value - 4] = 1

						if len(n_list_1) == 3:
							def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
								def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2, dummy3):
									recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
									excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
									dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
									return recombination_emissivity + excitation_emissivity + dummy_emissivity
								return calculated_emission

							bds = [[min_nH_ne, 0, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
							guess = [max_nH_ne, 10, 1000, 1000, 1000]
						elif len(n_list_1) == 2:
							def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
								def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
									recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
									excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
									dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
									return recombination_emissivity + excitation_emissivity + dummy_emissivity
								return calculated_emission

							bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
							guess = [max_nH_ne, 10, 1000, 1000]
						elif len(n_list_1) == 1:
							def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
								def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
									recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
									excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
									dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
									return recombination_emissivity + excitation_emissivity + dummy_emissivity
								return calculated_emission

							bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
							guess = [max_nH_ne, 10, 1000]

						fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict * OES_multiplier, p0=guess, bounds=bds,sigma=n_weights, maxfev=10000000)

						# nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
						# h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
						# dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
						# dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
						# dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
						residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict * OES_multiplier - fit_nH_ne_h_atomic_density(dummy,recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))) ** 2)
				return residuals_all.flatten()
			return residuals1


		guess = [1]
		bds = [[0.4], [5]]
		sol = least_squares(residual_ext1(n_list, n_list_1, n_weights, time_crop, r_crop, inverted_profiles_crop, recombination,merge_ne_prof_multipulse_interp_crop_limited, merge_Te_prof_multipulse_interp_crop_limited,excitation), guess, bounds=bds, max_nfev=60, verbose=2, gtol=1e-20, xtol=1e-5, ftol=1e-16,diff_step=0.01, x_scale='jac')
		OES_multiplier = sol.x

		print('OES_multiplier')
		print(OES_multiplier)


		n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
		# OES_multiplier = 0.81414701
		# Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		# ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
		for my_time_pos in range(len(time_crop)):
			for my_r_pos in range(len(r_crop)):
				inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
				recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
				merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
				merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
				excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

				if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 and merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
					continue
				# if np.sum(inverted_profiles_crop_restrict == 0)>2:
				# 	continue

				dummy = np.zeros((len(n_list_1), len(n_list_all)))
				for value in n_list_1:
					dummy[value - 4][value - 4] = 1

				if len(n_list_1)==3:
					def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
						def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2, dummy3):
							recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
							excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
							dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
							return recombination_emissivity + excitation_emissivity + dummy_emissivity
						return calculated_emission

					bds = [[min_nH_ne, 0, 0,0,0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
					guess = [max_nH_ne, 10, 1000,1000,1000]
				elif len(n_list_1)==2:
					def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
						def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
							recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
							excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
							dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
							return recombination_emissivity + excitation_emissivity + dummy_emissivity
						return calculated_emission

					bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
					guess = [max_nH_ne, 10, 1000, 1000]
				elif len(n_list_1)==1:
					def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
						def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
							recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
							excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
							dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
							return recombination_emissivity + excitation_emissivity + dummy_emissivity
						return calculated_emission

					bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
					guess = [max_nH_ne, 10, 1000]

				fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict*OES_multiplier, p0=guess, bounds=bds, sigma=n_weights,maxfev=10000000)

				# plt.figure()
				# plt.plot(n_list_all,inverted_profiles_crop_restrict * OES_multiplier)
				# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
				# # plt.plot(n_list_all,np.ones_like(inverted_profiles_crop_restrict) * OES_multiplier)
				# # plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict,inverted_profiles_crop_restrict)(n_list, *fit[0]))
				# plt.semilogy()
				# plt.title(str(fit[0])+'\n'+str(n_weights))
				# plt.pause(0.01)

				nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
				h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
				if len(n_list_1)>=1:
					dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
				if len(n_list_1)>=2:
					dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
				if len(n_list_1)>=3:
					dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
				# Te_all[my_time_pos, my_r_pos]=fit[0][3]
				# ne_all[my_time_pos, my_r_pos]=fit[0][4]
				residuals_all[my_time_pos, my_r_pos] = np.nansum(((inverted_profiles_crop_restrict * OES_multiplier - fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))/(n_weights*inverted_profiles_crop_restrict * OES_multiplier)) ** 2)

		# plt.figure()
		# plt.title('ne,Te,nH_ne,h_atomic_density,OES_multiplier\n'+str([*merge_ne_prof_multipulse_interp_crop_limited_restrict,*merge_Te_prof_multipulse_interp_crop_limited_restrict,*fit[0],OES_multiplier]))
		# plt.plot(n_list,inverted_profiles_crop_restrict*OES_multiplier)
		# plt.plot(n_list,fit_nH_ne_h_atomic_density(recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list,*fit[0]))
		# plt.pause(0.01)

		temp_r, temp_t = np.meshgrid(r_crop, time_crop)
		plt.figure();
		plt.pcolor(temp_t, temp_r, nH_ne_all, cmap='rainbow');
		plt.colorbar().set_label('nH/ne [au]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([OES_multiplier,spatial_factor,time_shift_factor]))
		figure_index += 1
		plt.savefig(path_where_to_save_everything +mod+ '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, h_atomic_density_all, cmap='rainbow');
		plt.colorbar().set_label('neutral atomic hydrogen density [# m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([OES_multiplier,spatial_factor,time_shift_factor]))
		figure_index += 1
		plt.savefig(path_where_to_save_everything +mod + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, residuals_all, cmap='rainbow');
		plt.colorbar().set_label('relative residual unaccounted line emission [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([OES_multiplier,spatial_factor,time_shift_factor]))
		figure_index += 1
		plt.savefig(path_where_to_save_everything +mod + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, dummy1_all, cmap='rainbow');
		plt.colorbar().set_label('extra emissivity n=4 [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([OES_multiplier,spatial_factor,time_shift_factor]))
		figure_index += 1
		plt.savefig(path_where_to_save_everything +mod + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, dummy2_all, cmap='rainbow');
		plt.colorbar().set_label('extra emissivity n=5 [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([OES_multiplier,spatial_factor,time_shift_factor]))
		figure_index += 1
		plt.savefig(path_where_to_save_everything +mod + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, dummy3_all, cmap='rainbow');
		plt.colorbar().set_label('extra emissivity n=6 [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([OES_multiplier,spatial_factor,time_shift_factor]))
		figure_index += 1
		plt.savefig(path_where_to_save_everything +mod + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
		plt.close()

		# figure_index += 1
		# plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
		# plt.close()

		recombination_emissivity = (recombination * nH_ne_all * ((merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) ** 2)).astype('float')
		excitation_emissivity = (excitation * (merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) * (h_atomic_density_all * (10 ** 20))).astype('float')

		residual_emission = []
		for index in range(len(recombination_emissivity)):
			residual_emission.append(inverted_profiles_crop[:, index] * OES_multiplier - recombination_emissivity[index] - excitation_emissivity[index])
		residual_emission = np.array(residual_emission)


		plt.figure();
		plt.pcolor(temp_t, temp_r, residual_emission[0], cmap='rainbow', vmin=np.min(
			residual_emission[0][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
		plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('residual emissivity, attribuited to MAR, line4\nnH_ne='  + ' , OES_multiplier=' + str(
			OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		temp = residual_emission[0] / recombination_emissivity[0]
		temp[np.logical_not(np.isfinite(temp))] = 0
		plt.figure();
		plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',
				   vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),
				   vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
		plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title(
			'relative residual emissivity, attribuited to MAR, line4\nnH_ne='  + ' , OES_multiplier=' + str(
				OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, residual_emission[1], cmap='rainbow', vmin=np.min(
			residual_emission[1][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
		plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('residual emissivity, attribuited to MAR, line5\nnH_ne='  + ' , OES_multiplier=' + str(
			OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		temp = residual_emission[1] / recombination_emissivity[1]
		temp[np.logical_not(np.isfinite(temp))] = 0
		plt.figure();
		plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',
				   vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),
				   vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
		plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title(
			'relative residual emissivity, attribuited to MAR, line5\nnH_ne='  + ' , OES_multiplier=' + str(
				OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		plt.figure();
		plt.pcolor(temp_t, temp_r, residual_emission[2], cmap='rainbow', vmin=np.min(
			residual_emission[2][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
		plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('residual emissivity, attribuited to MAR, line6\nnH_ne='  + ' , OES_multiplier=' + str(
			OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		temp = residual_emission[2] / recombination_emissivity[2]
		temp[np.logical_not(np.isfinite(temp))] = 0
		plt.figure();
		plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',
				   vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),
				   vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
		plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title(
			'relative residual emissivity, attribuited to MAR, line6\nnH_ne='  + ' , OES_multiplier=' + str(
				OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		temp = read_adf11(scdfile, 'scd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
						  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
		temp[np.isnan(temp)] = 0
		effective_ionisation_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (10 ** -6)  # in ionisations m^-3 s-1 / (# / m^3)**2
		effective_ionisation_rates = (effective_ionisation_rates * (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) * h_atomic_density).astype('float')
		plt.figure();
		plt.pcolor(temp_t, temp_r, effective_ionisation_rates, cmap='rainbow');
		plt.colorbar().set_label('effective_ionisation_rates [# m^-3 s-1]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('effective_ionisation_rates\nnH_ne='  + ' , OES_multiplier=' + str(OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()

		temp = read_adf11(acdfile, 'acd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
						  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
		temp[np.isnan(temp)] = 0
		effective_recombination_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (
					10 ** -6)  # in recombinations m^-3 s-1 / (# / m^3)**2
		effective_recombination_rates = (
					effective_recombination_rates * (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) ** 2).astype(
			'float')
		plt.figure();
		plt.pcolor(temp_t, temp_r, effective_recombination_rates, cmap='rainbow');
		plt.colorbar().set_label('effective_recombination_rates [# m^-3 s-1]')  # ;plt.pause(0.01)
		plt.axes().set_aspect(20)
		plt.xlabel('time [ms]')
		plt.ylabel('radial location [m]')
		plt.title('effective_recombination_rates (three body plus radiative)\nnH_ne=' + ' , OES_multiplier=' + str(OES_multiplier))
		figure_index += 1
		plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',
					bbox_inches='tight')
		plt.close()
elif False:	#relative intensity fit




	make_plots = True

	for merge_ID_target in [85,86,87,88,89,92,93,94]:

		# merge_ID_target = 85

		for min_nH_ne in [0.3,0.01,0.1,0.6,0.999]:


			figure_index = 0

			# calculate_geometry = False
			# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
			for i in range(10):
				print('.')
			print('Starting to work on merge number'+str(merge_ID_target))
			for i in range(10):
				print('.')


			time_resolution_scan = False
			time_resolution_scan_improved = True
			time_resolution_extra_skip = 0


			n_list = np.array([5,6,7,8 , 9])#, 10, 11, 12])
			n_list_1 = np.array([4])
			n_weights = [1,1,1, 1,3, 1]#, 1, 1, 1000]
			for index in (n_list_1-4):
				n_weights[index]=4
			n_weights[np.max(n_list_1)-3]=2
			# min_nH_ne = 0.6
			max_nH_ne = 1

			mod = '/relative/min_nH_ne'+str(min_nH_ne)+'/n_dummy_'+str(len(n_list_1))

			print('dummy')
			print(n_list_1)
			print('min_nH_ne')
			print(min_nH_ne)
			print('max_nH_ne')
			print(max_nH_ne)
			print('n_weights')
			print(n_weights)

			started=0
			rows_range_for_interp = 25/3 # rows that I use for interpolation (box with twice this side length, not sphere)
			# if merge_ID_target>=66:
			# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
			if time_resolution_scan:
				conventional_time_step = 0.01	# ms
			else:
				conventional_time_step = 0.05	# ms
			# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
			grade_of_interpolation = 3	#this is the exponent used for the weights of the interpolation for image resampling
			type_of_image = '12bit'	# '12bit' or '16bit'
			# if type_of_image=='12bit':
			row_shift=2*10280/1000000	# ms
			# elif type_of_image=='16bit':
			# 	print('Row shift to be checked')
			# 	exit()
			# time_range_for_interp = rows_range_for_interp*row_shift
			# merge_time_window=[-1,4]
			merge_time_window=[-10,10]
			overexposed_treshold = 3600
			path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(merge_ID_target)+'_back'

			if not os.path.exists(path_where_to_save_everything + mod):
				os.makedirs(path_where_to_save_everything + mod)


			new_timesteps = np.linspace(merge_time_window[0]+0.5, merge_time_window[1]-0.5,int((merge_time_window[1]-0.5-(merge_time_window[0]+0.5))/conventional_time_step+1))
			dt=np.nanmedian(np.diff(new_timesteps))

			# for spatial_factor in spatial_factor_all:
			#
			# 	mod = '/spatial_factor' + str(spatial_factor)
			# 	if not os.path.exists(path_where_to_save_everything + mod):
			# 		os.makedirs(path_where_to_save_everything + mod)

			# dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
			# xx = np.arange(40) * dx  # m
			# xn = np.linspace(0, max(xx), 1000)
			# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
			# r=r[::10]
			# dr=np.median(np.diff(r))



			# first_time = np.min(new_timesteps)
			# last_time = np.max(new_timesteps)


			# Data from wikipedia
			energy_difference = np.array([1.89,2.55,2.86,3.03,3.13,3.19,3.23,3.26, 3.29 ])	#eV
			# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
			statistical_weigth = np.array([32,50,72,98,128,162,200,242,288])	#gi-gk
			einstein_coeff = np.array([8.4193e-2,2.53044e-2,9.7320e-3,4.3889e-3,2.2148e-3,1.2156e-3,7.1225e-4,4.3972e-4,2.8337e-4])*1e8	#1/s
			J_to_eV = 6.242e18
			# Used formula 2.3 in Rion Barrois thesys, 2017
			color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']

			inverted_profiles_original = 4*np.pi*np.load(path_where_to_save_everything+'/inverted_profiles.npy')		# in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
			all_fits = np.load(path_where_to_save_everything +'/merge'+str(merge_ID_target)+'_all_fits.npy')	# in W m^-2 sr^-1
			merge_Te_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_Te_prof_multipulse']
			merge_dTe_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dTe_multipulse']
			merge_ne_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_ne_prof_multipulse']
			merge_dne_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dne_multipulse']
			merge_time_original = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_time']

			# for time_shift_factor in time_shift_factor_all:
			#
			# 	mod = '/spatial_factor' + str(spatial_factor)+'/time_shift_factor' + str(time_shift_factor)
			# 	if not os.path.exists(path_where_to_save_everything + mod):
			# 		os.makedirs(path_where_to_save_everything + mod)

			if False:
				def residual_ext(inverted_profiles_original,merge_Te_prof_multipulse,merge_ne_prof_multipulse,merge_time_original):
					def residuals(input):
						spatial_factor=input[0]
						time_shift_factor = input[1]
						print('spatial_factor,time_shift_factor  '+str([spatial_factor,time_shift_factor]))


						dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
						xx = np.arange(40) * dx  # m
						xn = np.linspace(0, max(xx), 1000)
						r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
						r=r[::10]
						dr=np.median(np.diff(r))


						merge_time = time_shift_factor + merge_time_original
						inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
						TS_dt=np.nanmedian(np.diff(merge_time))


						if np.max(merge_Te_prof_multipulse)<=0:
							print('merge'+str(merge_ID_target)+" has no recorded temperature")
							# continue

						TS_size=[-4.149230769230769056e+01,4.416923076923076508e+01]
						TS_r=TS_size[0] + np.linspace(0,1,65)*(TS_size[1]- TS_size[0])
						TS_dr = np.median(np.diff(TS_r))/1000
						gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
						profile_centres = []
						profile_centres_score = []
						for index in range(np.shape(merge_Te_prof_multipulse)[0]):
							yy = merge_Te_prof_multipulse[index]
							p0 = [np.max(yy),10,0]
							bds = [[0,-40,np.min(TS_r)],[np.inf,40,np.max(TS_r)]]
							fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
							profile_centres.append(fit[0][-1])
							profile_centres_score.append(fit[1][-1,-1])
							# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
						profile_centres = np.array(profile_centres)
						profile_centres_score = np.array(profile_centres_score)
						centre = np.nanmean(profile_centres[profile_centres_score<1])
						TS_r_new = np.abs(TS_r-centre)/1000
						# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
						# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
						# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)


						temp1=np.zeros_like(inverted_profiles[:,0])
						temp3=np.zeros_like(inverted_profiles[:,0])
						interp_range_t = max(dt/2,TS_dt)*1
						interp_range_r = max(dx/2,TS_dr)*1
						for i_t,value_t in enumerate(new_timesteps):
							if np.sum(np.abs(merge_time-value_t) < interp_range_t) == 0:
								continue
							for i_r,value_r in enumerate(np.abs(r)):
								if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
									continue
								temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[np.abs(merge_time-value_t)<interp_range_t][:,np.abs(TS_r_new-value_r)<interp_range_r])
								temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[np.abs(merge_time-value_t)<interp_range_t][:,np.abs(TS_r_new-value_r)<interp_range_r])

						merge_Te_prof_multipulse_interp=np.array(temp1)
						merge_ne_prof_multipulse_interp=np.array(temp3)
						temp_r, temp_t = np.meshgrid(r, new_timesteps)


						# I crop to the usefull stuff
						start_time = np.abs(new_timesteps-0).argmin()
						end_time = np.abs(new_timesteps-1.5).argmin()+1
						time_crop = new_timesteps[start_time:end_time]
						start_r = np.abs(r-0).argmin()
						end_r = np.abs(r-5).argmin()+1
						r_crop = r[start_r:end_r]
						temp_r, temp_t = np.meshgrid(r_crop, time_crop)
						merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,start_r:end_r]
						merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,start_r:end_r]
						inverted_profiles_crop = inverted_profiles[start_time:end_time,:,start_r:end_r]
						inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
						all_fits_crop = all_fits[start_time:end_time]
						# inverted_profiles_crop[inverted_profiles_crop<0] = 0

						x_local = xx - spatial_factor * 17.4 / 1000
						dr_crop = np.median(np.diff(r_crop))

						merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
						merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop_limited<0.2]=0
						merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
						merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop_limited<5e-07]=0
						excitation = []
						for isel in [2,3,4,5,6,7,8,9,10]:
							temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(), (merge_ne_prof_multipulse_interp_crop_limited*10**(20-6)).flatten())[0]	# ADAS database is in cm^3   # photons s^-1 cm^-3
							temp[np.isnan(temp)] = 0
							temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
							excitation.append(temp)
						excitation = np.array(excitation)	# in # photons cm^-3 s^-1
						excitation = (excitation.T*(10**-6)*(energy_difference/J_to_eV)).T	# in W m^-3 / (# / m^3)**2

						recombination = []
						for isel in [20,21,22,23,24,25,26,27,28]:
							temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(), (merge_ne_prof_multipulse_interp_crop_limited*10**(20-6)).flatten())[0]	# ADAS database is in cm^3   # photons s^-1 cm^-3
							temp[np.isnan(temp)] = 0
							temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
							recombination.append(temp)
						recombination = np.array(recombination)	# in # photons cm^-3 s^-1 / (# cm^-3)**2
						recombination = (recombination.T*(10**-6)*(energy_difference/J_to_eV)).T	# in W m^-3 / (# / m^3)**2




						# def residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation):
						# 	def residuals1(input):
						# 		OES_multiplier=input
						# 		print(OES_multiplier)

						n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
						# OES_multiplier = 0.81414701
						# nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						for my_time_pos in range(len(time_crop)):
							for my_r_pos in range(len(r_crop)):
								inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all-4, my_r_pos].flatten()
								recombination_restrict=recombination[n_list_all-4,my_time_pos, my_r_pos].flatten()
								merge_ne_prof_multipulse_interp_crop_limited_restrict=merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
								merge_Te_prof_multipulse_interp_crop_limited_restrict=merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
								excitation_restrict=excitation[n_list_all-4,my_time_pos, my_r_pos].flatten()

								if (merge_ne_prof_multipulse_interp_crop_limited_restrict==0 or merge_Te_prof_multipulse_interp_crop_limited_restrict==0):
									continue

								dummy = np.zeros((len(n_list_1), len(n_list_all)))
								for value in n_list_1:
									dummy[value - 4][value - 4] = 1

								if len(n_list_1) == 3:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2,dummy3):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
											total = recombination_emissivity + excitation_emissivity + dummy_emissivity
											return total/(total[0])
										return calculated_emission

									bds = [[min_nH_ne, 0, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
									guess = [max_nH_ne, 10, 1000, 1000, 1000]
								elif len(n_list_1) == 2:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
											total = recombination_emissivity + excitation_emissivity + dummy_emissivity
											return total/(total[0])
										return calculated_emission

									bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
									guess = [max_nH_ne, 10, 1000, 1000]
								elif len(n_list_1) == 1:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
											total = recombination_emissivity + excitation_emissivity + dummy_emissivity
											return total/(total[0])
										return calculated_emission

									bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
									guess = [max_nH_ne, 10, 1000]

								fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]), p0=guess, bounds=bds,sigma=n_weights, maxfev=10000000)

								# if np.sum(fit[1] == 0) > 0:
								# 	continue

								# plt.figure()
								# plt.plot(n_list_all,inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]))
								# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
								# # plt.plot(n_list_all,np.ones_like(inverted_profiles_crop_restrict) * OES_multiplier)
								# # plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict,inverted_profiles_crop_restrict)(n_list, *fit[0]))
								# plt.semilogy()
								# plt.title(str(fit[0])+'\n'+str(n_weights))
								# plt.pause(0.01)

								# nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
								# h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
								# dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
								# dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
								# dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
								if np.sum(fit[1]==0)>0:
									residuals_all[my_time_pos, my_r_pos] =np.sum(fit[1]==0)
								else:
									residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]) - fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict, excitation_restrict)(n_list, *fit[0]))) ** 2)
								# if residuals_all[my_time_pos, my_r_pos]>1:
								# 	print([my_time_pos, my_r_pos])
							# 	return residuals_all.flatten()
							# return residuals1


						# guess = [1]
						# bds = [[0.4],[5]]
						# sol = least_squares(residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation), guess, bounds=bds, max_nfev=60,	verbose=2, gtol=1e-20, xtol=1e-5, ftol=1e-16, diff_step=0.01, x_scale='jac')
						# OES_multiplier=sol.x
						return residuals_all.flatten()
					return residuals


				guess = [1.3,-0.05]
				bds = [[1,-0.1], [2,0.1]]
				sol = least_squares(residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse, merge_time_original), guess, bounds=bds,max_nfev=60, verbose=2, gtol=1e-20, xtol=1e-12, ftol=1e-16, diff_step=[0.05,0.05], x_scale='jac')

				spatial_factor = sol.x[0]
				time_shift_factor = sol.x[1]

				print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

			else:
				for spatial_factor in [1,1.1,1.2,1.3,1.4,1.5]:
					for time_shift_factor in [-0.1,-0.05,0,0.05]:
						mod2=mod + '/spatial_factor_'+str(spatial_factor)+'/time_shift_factor_'+str(time_shift_factor)

						if not os.path.exists(path_where_to_save_everything + mod2):
							os.makedirs(path_where_to_save_everything + mod2)

						dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
						xx = np.arange(40) * dx  # m
						xn = np.linspace(0, max(xx), 1000)
						r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
						r = r[::10]
						dr = np.median(np.diff(r))

						merge_time = time_shift_factor + merge_time_original
						inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
						TS_dt = np.nanmedian(np.diff(merge_time))

						if np.max(merge_Te_prof_multipulse) <= 0:
							print('merge' + str(merge_ID_target) + " has no recorded temperature")
						# continue

						TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
						TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
						TS_dr = np.median(np.diff(TS_r)) / 1000
						gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
						profile_centres = []
						profile_centres_score = []
						for index in range(np.shape(merge_Te_prof_multipulse)[0]):
							yy = merge_Te_prof_multipulse[index]
							p0 = [np.max(yy), 10, 0]
							bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
							fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
							profile_centres.append(fit[0][-1])
							profile_centres_score.append(fit[1][-1, -1])
						# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
						profile_centres = np.array(profile_centres)
						profile_centres_score = np.array(profile_centres_score)
						centre = np.nanmean(profile_centres[profile_centres_score < 1])
						TS_r_new = np.abs(TS_r - centre) / 1000
						# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
						# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
						# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

						temp1 = np.zeros_like(inverted_profiles[:, 0])
						temp3 = np.zeros_like(inverted_profiles[:, 0])
						interp_range_t = max(dt / 2, TS_dt) * 1
						interp_range_r = max(dx / 2, TS_dr) * 1
						for i_t, value_t in enumerate(new_timesteps):
							if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
								continue
							for i_r, value_r in enumerate(np.abs(r)):
								if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
									continue
								temp1[i_t, i_r] = np.mean(merge_Te_prof_multipulse[np.abs(merge_time - value_t) < interp_range_t][:,np.abs(TS_r_new - value_r) < interp_range_r])
								temp3[i_t, i_r] = np.mean(merge_ne_prof_multipulse[np.abs(merge_time - value_t) < interp_range_t][:,np.abs(TS_r_new - value_r) < interp_range_r])

						merge_Te_prof_multipulse_interp = np.array(temp1)
						merge_ne_prof_multipulse_interp = np.array(temp3)
						temp_r, temp_t = np.meshgrid(r, new_timesteps)

						# I crop to the usefull stuff
						start_time = np.abs(new_timesteps - 0).argmin()
						end_time = np.abs(new_timesteps - 1.5).argmin() + 1
						time_crop = new_timesteps[start_time:end_time]
						start_r = np.abs(r - 0).argmin()
						end_r = np.abs(r - 5).argmin() + 1
						r_crop = r[start_r:end_r]
						temp_r, temp_t = np.meshgrid(r_crop, time_crop)
						merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time, start_r:end_r]
						merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
						inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
						inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
						all_fits_crop = all_fits[start_time:end_time]
						# inverted_profiles_crop[inverted_profiles_crop<0] = 0

						x_local = xx - spatial_factor * 17.4 / 1000
						dr_crop = np.median(np.diff(r_crop))

						merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
						merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop_limited < 0.2] = 0
						merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
						merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop_limited < 5e-07] = 0
						excitation = []
						for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
							temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
							temp[np.isnan(temp)] = 0
							temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
							excitation.append(temp)
						excitation = np.array(excitation)  # in # photons cm^-3 s^-1
						excitation = (excitation.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

						recombination = []
						for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
							temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
							temp[np.isnan(temp)] = 0
							temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
							recombination.append(temp)
						recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
						recombination = (recombination.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2



						n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
						# OES_multiplier = 0.81414701
						# Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						for my_time_pos in range(len(time_crop)):
							for my_r_pos in range(len(r_crop)):
								inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
								merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
								merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
								excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

								if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
									continue
								# if np.sum(inverted_profiles_crop_restrict == 0)>2:
								# 	continue

								dummy = np.zeros((len(n_list_1), len(n_list_all)))
								for value in n_list_1:
									dummy[value - 4][value - 4] = 1

								if len(n_list_1)==3:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2, dummy3):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
											total = recombination_emissivity + excitation_emissivity + dummy_emissivity
											return total / (total[0])
										return calculated_emission

									bds = [[min_nH_ne, 0, 0,0,0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
									guess = [max_nH_ne, 10, 1000,1000,1000]
								elif len(n_list_1)==2:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
											total = recombination_emissivity + excitation_emissivity + dummy_emissivity
											return total / (total[0])
										return calculated_emission

									bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
									guess = [max_nH_ne, 10, 1000, 1000]
								elif len(n_list_1)==1:
									def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
										def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
											recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
											excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
											dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
											total = recombination_emissivity + excitation_emissivity + dummy_emissivity
											return total / (total[0])
										return calculated_emission

									bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
									guess = [max_nH_ne, 1, 0]

								fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]), p0=guess, bounds=bds, sigma=n_weights,maxfev=10000000)

								# if np.sum(fit[1] == 0)>0:
								# 	continue

								# plt.figure()
								# plt.plot(n_list_all,inverted_profiles_crop_restrict/inverted_profiles_crop_restrict[0])
								# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
								# # plt.plot(n_list_all,np.ones_like(inverted_profiles_crop_restrict) * OES_multiplier)
								# # plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict,inverted_profiles_crop_restrict)(n_list, *fit[0]))
								# plt.semilogy()
								# plt.title(str(fit[0])+'\n'+str(n_weights))
								# plt.pause(0.01)

								nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
								h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
								if len(n_list_1)>=1:
									dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
								if len(n_list_1)>=2:
									dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
								if len(n_list_1)>=3:
									dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
								# Te_all[my_time_pos, my_r_pos]=fit[0][3]
								# ne_all[my_time_pos, my_r_pos]=fit[0][4]
								# if np.sum(fit[1] == 0) == len(fit[0]) ** 2:
								# 	residuals_all[my_time_pos, my_r_pos] = 0
								# else:
								residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict / (inverted_profiles_crop_restrict[0]) - fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))) ** 2)

						# plt.figure()
						# plt.title('ne,Te,nH_ne,h_atomic_density,OES_multiplier\n'+str([*merge_ne_prof_multipulse_interp_crop_limited_restrict,*merge_Te_prof_multipulse_interp_crop_limited_restrict,*fit[0],OES_multiplier]))
						# plt.plot(n_list,inverted_profiles_crop_restrict*OES_multiplier)
						# plt.plot(n_list,fit_nH_ne_h_atomic_density(recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list,*fit[0]))
						# plt.pause(0.01)

						figure_index = 0

						temp_r, temp_t = np.meshgrid(r_crop, time_crop)
						plt.figure();
						plt.pcolor(temp_t, temp_r, nH_ne_all, cmap='rainbow');
						plt.colorbar().set_label('nH/ne [au]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor]))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2+ '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, h_atomic_density_all, cmap='rainbow');
						plt.colorbar().set_label('neutral atomic hydrogen density [# m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor]))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, residuals_all, cmap='rainbow',vmax=np.max(residuals_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('relative residual unaccounted line emission [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor])+'\nsum = '+str(np.sum(residuals_all)))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, dummy1_all, cmap='rainbow',vmax=np.max(dummy1_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(dummy1_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('extra emissivity n=4 [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor]))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, dummy2_all, cmap='rainbow');
						plt.colorbar().set_label('extra emissivity n=5 [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor]))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, dummy3_all, cmap='rainbow');
						plt.colorbar().set_label('extra emissivity n=6 [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('OES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor]))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()

						# figure_index += 1
						# plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
						# plt.close()

						recombination_emissivity = (recombination * nH_ne_all * ((merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) ** 2)).astype('float')
						excitation_emissivity = (excitation * (merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) * (h_atomic_density_all * (10 ** 20))).astype('float')

						residual_emission = []
						for index in range(len(recombination_emissivity)):
							residual_emission.append(inverted_profiles_crop[:, index] - recombination_emissivity[index] - excitation_emissivity[index])
						residual_emission = np.array(residual_emission)

						to_print = inverted_profiles_crop[:, 0]*dummy1_all/(recombination_emissivity[0]+excitation_emissivity[0]+ dummy1_all)
						plt.figure();
						plt.pcolor(temp_t, temp_r, to_print, cmap='rainbow',vmax=np.max(to_print[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(dummy1_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('extra emissivity n=4 [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('extra emissivity using only the ratio from the fitting\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([np.nan,spatial_factor,time_shift_factor]))
						figure_index += 1
						plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
						plt.close()
						figure_index -= 1


						plt.figure();
						plt.pcolor(temp_t, temp_r, residual_emission[0], cmap='rainbow', vmin=np.min(
							residual_emission[0][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('residual emissivity, attribuited to MAR, line4\nOES_multiplier=' + str(
							np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						temp = residual_emission[0] / recombination_emissivity[0]
						temp[np.logical_not(np.isfinite(temp))] = 0
						plt.figure();
						plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',
								   vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),
								   vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title(
							'relative residual emissivity, attribuited to MAR, line4\nOES_multiplier=' + str(
								np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, residual_emission[0]-dummy1_all, cmap='rainbow', vmin=np.min(
							residual_emission[0][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('residual emissivity not included in the fitting, line4\nOES_multiplier=' + str(
							np.nan)+'\nsum = '+str(np.sum(np.abs(residual_emission[0]-dummy1_all))))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()


						plt.figure();
						plt.pcolor(temp_t, temp_r, residual_emission[1], cmap='rainbow', vmin=np.min(
							residual_emission[1][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('residual emissivity, attribuited to MAR, line5\nOES_multiplier=' + str(
							np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						temp = residual_emission[1] / recombination_emissivity[1]
						temp[np.logical_not(np.isfinite(temp))] = 0
						plt.figure();
						plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',
								   vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),
								   vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title(
							'relative residual emissivity, attribuited to MAR, line5\nOES_multiplier=' + str(
								np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						if len(n_list_1)>1:
							plt.figure();
							plt.pcolor(temp_t, temp_r, residual_emission[1]-dummy2_all, cmap='rainbow', vmin=np.min(
								residual_emission[1][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('residual emissivity not included in the fitting, line5\nOES_multiplier=' + str(
								np.nan)+'\nsum = '+str(np.sum(np.abs(residual_emission[1]-dummy1_all))))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
										bbox_inches='tight')
							plt.close()


						plt.figure();
						plt.pcolor(temp_t, temp_r, residual_emission[2], cmap='rainbow', vmin=np.min(
							residual_emission[2][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('residual emissivity, attribuited to MAR, line6\nOES_multiplier=' + str(
							np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						temp = residual_emission[2] / recombination_emissivity[2]
						temp[np.logical_not(np.isfinite(temp))] = 0
						plt.figure();
						plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',
								   vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),
								   vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
						plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title(
							'relative residual emissivity, attribuited to MAR, line6\nOES_multiplier=' + str(
								np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						if len(n_list_1)>2:
							plt.figure();
							plt.pcolor(temp_t, temp_r, residual_emission[2]-dummy3_all, cmap='rainbow', vmin=np.min(
								residual_emission[2][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('residual emissivity not included in the fitting, line6\nOES_multiplier=' + str(
								np.nan)+'\nsum = '+str(np.sum(np.abs(residual_emission[2]-dummy1_all))))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
										bbox_inches='tight')
							plt.close()


						temp = read_adf11(scdfile, 'scd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
										  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
						temp[np.isnan(temp)] = 0
						effective_ionisation_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (
									10 ** -6)  # in ionisations m^-3 s-1 / (# / m^3)**2
						effective_ionisation_rates = (effective_ionisation_rates * (
									merge_ne_prof_multipulse_interp_crop * (10 ** 20)) * h_atomic_density_all).astype('float')
						plt.figure();
						plt.pcolor(temp_t, temp_r, effective_ionisation_rates, cmap='rainbow');
						plt.colorbar().set_label('effective_ionisation_rates [# m^-3 s-1]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('effective_ionisation_rates\nOES_multiplier=' + str(np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						temp = read_adf11(acdfile, 'acd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
										  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
						temp[np.isnan(temp)] = 0
						effective_recombination_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (
									10 ** -6)  # in recombinations m^-3 s-1 / (# / m^3)**2
						effective_recombination_rates = (
									effective_recombination_rates *nH_ne_all* (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) ** 2).astype(
							'float')
						plt.figure();
						plt.pcolor(temp_t, temp_r, effective_recombination_rates, cmap='rainbow');
						plt.colorbar().set_label('effective_recombination_rates [# m^-3 s-1]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('effective_recombination_rates (three body plus radiative)\nOES_multiplier=' + str(np.nan))
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()


						plt.figure();
						plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited, cmap='rainbow');
						plt.colorbar().set_label('electron density [# m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('Scaled electron density')
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, merge_Te_prof_multipulse_interp_crop_limited, cmap='rainbow');
						plt.colorbar().set_label('electron temperature [eV]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('Scaled electron temperature')
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, inverted_profiles_crop[:, 0], cmap='rainbow');
						plt.colorbar().set_label('line emission n=4 [w m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('Scaled OES line emissivity')
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()

						plt.figure();
						plt.pcolor(temp_t, temp_r, inverted_profiles_crop[:, 3], cmap='rainbow');
						plt.colorbar().set_label('line emission n=7 [w m^-3]')  # ;plt.pause(0.01)
						plt.axes().set_aspect(20)
						plt.xlabel('time [ms]')
						plt.ylabel('radial location [m]')
						plt.title('Scaled OES line emissivity')
						figure_index += 1
						plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
									bbox_inches='tight')
						plt.close()
elif False:	#absolute intensity fit




	make_plots = True

	# for merge_ID_target in np.flip([85,86,87,89,92,93,94],axis=0):	# 88 excluded because I don't have a temperature profile
	for merge_ID_target in np.flip([92,93,94],axis=0):	# 88 excluded because I don't have a temperature profile

		# merge_ID_target = 85

		# for min_nH_ne in [0.3,0.01,0.1,0.6,0.999,0.9999]:	#0.9999 is for the case when I relax this boundary if nH<0.001
		for min_nH_ne in [0.999]:
			# for max_h_atomic_density in [300,np.inf]:
			for max_h_atomic_density in [np.inf]:


				figure_index = 0

				# calculate_geometry = False
				# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
				for i in range(10):
					print('.')
				print('Starting to work on merge number'+str(merge_ID_target))
				for i in range(10):
					print('.')


				time_resolution_scan = False
				time_resolution_scan_improved = True
				time_resolution_extra_skip = 0


				n_list = np.array([5,6,7,8 , 9])#, 10, 11, 12])
				n_list_1 = np.array([4])
				n_weights = [1,1,1, 1,4, 1]#, 1, 1, 1000]
				for index in (n_list_1-4):
					n_weights[index]=4
				n_weights[np.max(n_list_1)-3]=2
				# min_nH_ne = 0.6
				max_nH_ne = 1

				mod = '/absolute/min_nH_ne'+str(min_nH_ne)+'/max_h_atomic_density'+str(max_h_atomic_density)+'/n_dummy_'+str(len(n_list_1))

				print('dummy')
				print(n_list_1)
				print('min_nH_ne')
				print(min_nH_ne)
				print('max_h_atomic_density')
				print(max_h_atomic_density)
				print('max_nH_ne')
				print(max_nH_ne)
				print('n_weights')
				print(n_weights)

				started=0
				rows_range_for_interp = 25/3 # rows that I use for interpolation (box with twice this side length, not sphere)
				# if merge_ID_target>=66:
				# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
				if time_resolution_scan:
					conventional_time_step = 0.01	# ms
				else:
					conventional_time_step = 0.05	# ms
				# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
				grade_of_interpolation = 3	#this is the exponent used for the weights of the interpolation for image resampling
				type_of_image = '12bit'	# '12bit' or '16bit'
				# if type_of_image=='12bit':
				row_shift=2*10280/1000000	# ms
				# elif type_of_image=='16bit':
				# 	print('Row shift to be checked')
				# 	exit()
				# time_range_for_interp = rows_range_for_interp*row_shift
				# merge_time_window=[-1,4]
				merge_time_window=[-10,10]
				overexposed_treshold = 3600
				path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(merge_ID_target)+'_back'

				if not os.path.exists(path_where_to_save_everything + mod):
					os.makedirs(path_where_to_save_everything + mod)


				new_timesteps = np.linspace(merge_time_window[0]+0.5, merge_time_window[1]-0.5,int((merge_time_window[1]-0.5-(merge_time_window[0]+0.5))/conventional_time_step+1))
				dt=np.nanmedian(np.diff(new_timesteps))

				# for spatial_factor in spatial_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				# dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
				# xx = np.arange(40) * dx  # m
				# xn = np.linspace(0, max(xx), 1000)
				# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
				# r=r[::10]
				# dr=np.median(np.diff(r))



				# first_time = np.min(new_timesteps)
				# last_time = np.max(new_timesteps)


				# Data from wikipedia
				energy_difference = np.array([1.89,2.55,2.86,3.03,3.13,3.19,3.23,3.26, 3.29 ])	#eV
				# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
				statistical_weigth = np.array([32,50,72,98,128,162,200,242,288])	#gi-gk
				einstein_coeff = np.array([8.4193e-2,2.53044e-2,9.7320e-3,4.3889e-3,2.2148e-3,1.2156e-3,7.1225e-4,4.3972e-4,2.8337e-4])*1e8	#1/s
				J_to_eV = 6.242e18
				# Used formula 2.3 in Rion Barrois thesys, 2017
				color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']

				inverted_profiles_original = 4*np.pi*np.load(path_where_to_save_everything+'/inverted_profiles.npy')		# in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				all_fits = np.load(path_where_to_save_everything +'/merge'+str(merge_ID_target)+'_all_fits.npy')	# in W m^-2 sr^-1
				merge_Te_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_Te_prof_multipulse']
				merge_dTe_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dTe_multipulse']
				merge_ne_prof_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_ne_prof_multipulse']
				merge_dne_multipulse = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_dne_multipulse']
				merge_time_original = np.load(path_where_to_save_everything+'/TS_data_merge_' + str(merge_ID_target) +'.npz')['merge_time']

				# for time_shift_factor in time_shift_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)+'/time_shift_factor' + str(time_shift_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				if False:
					def residual_ext(inverted_profiles_original,merge_Te_prof_multipulse,merge_ne_prof_multipulse,merge_time_original):
						def residuals(input):
							spatial_factor=input[0]
							time_shift_factor = input[1]
							print('spatial_factor,time_shift_factor  '+str([spatial_factor,time_shift_factor]))


							dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
							xx = np.arange(40) * dx  # m
							xn = np.linspace(0, max(xx), 1000)
							r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
							r=r[::10]
							dr=np.median(np.diff(r))


							merge_time = time_shift_factor + merge_time_original
							inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
							TS_dt=np.nanmedian(np.diff(merge_time))


							if np.max(merge_Te_prof_multipulse)<=0:
								print('merge'+str(merge_ID_target)+" has no recorded temperature")
								# continue

							TS_size=[-4.149230769230769056e+01,4.416923076923076508e+01]
							TS_r=TS_size[0] + np.linspace(0,1,65)*(TS_size[1]- TS_size[0])
							TS_dr = np.median(np.diff(TS_r))/1000
							gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
							profile_centres = []
							profile_centres_score = []
							for index in range(np.shape(merge_Te_prof_multipulse)[0]):
								yy = merge_Te_prof_multipulse[index]
								p0 = [np.max(yy),10,0]
								bds = [[0,-40,np.min(TS_r)],[np.inf,40,np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
								profile_centres.append(fit[0][-1])
								profile_centres_score.append(fit[1][-1,-1])
								# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
							profile_centres = np.array(profile_centres)
							profile_centres_score = np.array(profile_centres_score)
							centre = np.nanmean(profile_centres[profile_centres_score<1])
							TS_r_new = np.abs(TS_r-centre)/1000
							# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)


							temp1=np.zeros_like(inverted_profiles[:,0])
							temp3=np.zeros_like(inverted_profiles[:,0])
							interp_range_t = max(dt/2,TS_dt)*1
							interp_range_r = max(dx/2,TS_dr)*1
							for i_t,value_t in enumerate(new_timesteps):
								if np.sum(np.abs(merge_time-value_t) < interp_range_t) == 0:
									continue
								for i_r,value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
										continue
									if np.sum(np.logical_and(np.abs(merge_time-value_t)<interp_range_t,np.sum(merge_Te_prof_multipulse,axis=1)>0))==0:
										continue
									temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[np.logical_and(np.abs(merge_time-value_t)<interp_range_t,np.sum(merge_Te_prof_multipulse,axis=1)>0)][:,np.abs(TS_r_new-value_r)<interp_range_r])
									temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[np.logical_and(np.abs(merge_time-value_t)<interp_range_t,np.sum(merge_Te_prof_multipulse,axis=1)>0)][:,np.abs(TS_r_new-value_r)<interp_range_r])

							merge_Te_prof_multipulse_interp=np.array(temp1)
							merge_ne_prof_multipulse_interp=np.array(temp3)
							temp_r, temp_t = np.meshgrid(r, new_timesteps)


							# I crop to the usefull stuff
							start_time = np.abs(new_timesteps-0).argmin()
							end_time = np.abs(new_timesteps-1.5).argmin()+1
							time_crop = new_timesteps[start_time:end_time]
							start_r = np.abs(r-0).argmin()
							end_r = np.abs(r-5).argmin()+1
							r_crop = r[start_r:end_r]
							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,start_r:end_r]
							merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,start_r:end_r]
							inverted_profiles_crop = inverted_profiles[start_time:end_time,:,start_r:end_r]
							inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
							all_fits_crop = all_fits[start_time:end_time]
							# inverted_profiles_crop[inverted_profiles_crop<0] = 0

							x_local = xx - spatial_factor * 17.4 / 1000
							dr_crop = np.median(np.diff(r_crop))

							merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
							merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop_limited<0.2]=0
							merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
							merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop_limited<5e-07]=0
							excitation = []
							for isel in [2,3,4,5,6,7,8,9,10]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(), (merge_ne_prof_multipulse_interp_crop_limited*10**(20-6)).flatten())[0]	# ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								excitation.append(temp)
							excitation = np.array(excitation)	# in # photons cm^-3 s^-1
							excitation = (excitation.T*(10**-6)*(energy_difference/J_to_eV)).T	# in W m^-3 / (# / m^3)**2

							recombination = []
							for isel in [20,21,22,23,24,25,26,27,28]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(), (merge_ne_prof_multipulse_interp_crop_limited*10**(20-6)).flatten())[0]	# ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								recombination.append(temp)
							recombination = np.array(recombination)	# in # photons cm^-3 s^-1 / (# cm^-3)**2
							recombination = (recombination.T*(10**-6)*(energy_difference/J_to_eV)).T	# in W m^-3 / (# / m^3)**2




							# def residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation):
							# 	def residuals1(input):
							# 		OES_multiplier=input
							# 		print(OES_multiplier)

							n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
							# OES_multiplier = 0.81414701
							# nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all-4, my_r_pos].flatten()
									recombination_restrict=recombination[n_list_all-4,my_time_pos, my_r_pos].flatten()
									merge_ne_prof_multipulse_interp_crop_limited_restrict=merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									merge_Te_prof_multipulse_interp_crop_limited_restrict=merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									excitation_restrict=excitation[n_list_all-4,my_time_pos, my_r_pos].flatten()

									if (merge_ne_prof_multipulse_interp_crop_limited_restrict==0 or merge_Te_prof_multipulse_interp_crop_limited_restrict==0):
										continue

									dummy = np.zeros((len(n_list_1), len(n_list_all)))
									for value in n_list_1:
										dummy[value - 4][value - 4] = 1

									if len(n_list_1) == 3:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2,dummy3):
												recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
												excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total
											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000, 1000]
									elif len(n_list_1) == 2:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
												recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
												excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total
											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000]
									elif len(n_list_1) == 1:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
												recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
												excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
												dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total
											return calculated_emission

										bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
										guess = [max_nH_ne, 10, 1000]

									fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict, p0=guess, bounds=bds,sigma=n_weights, maxfev=10000000)

									# if np.sum(fit[1] == 0) > 0:
									# 	continue

									# plt.figure()
									# plt.plot(n_list_all,inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]))
									# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
									# # plt.plot(n_list_all,np.ones_like(inverted_profiles_crop_restrict) * OES_multiplier)
									# # plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict,inverted_profiles_crop_restrict)(n_list, *fit[0]))
									# plt.semilogy()
									# plt.title(str(fit[0])+'\n'+str(n_weights))
									# plt.pause(0.01)

									# nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
									# h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
									# dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
									# dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
									# dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
									if np.sum(fit[1]==0)>0:
										residuals_all[my_time_pos, my_r_pos] =np.sum(fit[1]==0)
									else:
										residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict - fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict, excitation_restrict)(n_list, *fit[0]))) ** 2)
									# if residuals_all[my_time_pos, my_r_pos]>1:
									# 	print([my_time_pos, my_r_pos])
								# 	return residuals_all.flatten()
								# return residuals1


							# guess = [1]
							# bds = [[0.4],[5]]
							# sol = least_squares(residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation), guess, bounds=bds, max_nfev=60,	verbose=2, gtol=1e-20, xtol=1e-5, ftol=1e-16, diff_step=0.01, x_scale='jac')
							# OES_multiplier=sol.x
							return residuals_all.flatten()
						return residuals


					guess = [1.3,-0.05]
					bds = [[1,-0.1], [2,0.1]]
					sol = least_squares(residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse, merge_time_original), guess, bounds=bds,max_nfev=60, verbose=2, gtol=1e-20, xtol=1e-12, ftol=1e-16, diff_step=[0.05,0.05], x_scale='jac')

					spatial_factor = sol.x[0]
					time_shift_factor = sol.x[1]

					print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

				else:
					# for spatial_factor in [1,1.1,1.2,1.3,1.4,1.5]:
					for spatial_factor in [1]:
						# for time_shift_factor in [-0.1,-0.05,0,0.05]:
						for time_shift_factor in [0]:
							mod2=mod + '/spatial_factor_'+str(spatial_factor)+'/time_shift_factor_'+str(time_shift_factor)

							if not os.path.exists(path_where_to_save_everything + mod2):
								os.makedirs(path_where_to_save_everything + mod2)

							dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
							xx = np.arange(40) * dx  # m
							xn = np.linspace(0, max(xx), 1000)
							r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
							r = r[::10]
							dr = np.median(np.diff(r))

							merge_time = time_shift_factor + merge_time_original
							inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
							TS_dt = np.nanmedian(np.diff(merge_time))

							if np.max(merge_Te_prof_multipulse) <= 0:
								print('merge' + str(merge_ID_target) + " has no recorded temperature")
							# continue

							TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
							TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
							TS_dr = np.median(np.diff(TS_r)) / 1000
							gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
							profile_centres = []
							profile_centres_score = []
							for index in range(np.shape(merge_Te_prof_multipulse)[0]):
								yy = merge_Te_prof_multipulse[index]
								p0 = [np.max(yy), 10, 0]
								bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
								profile_centres.append(fit[0][-1])
								profile_centres_score.append(fit[1][-1, -1])
							# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
							profile_centres = np.array(profile_centres)
							profile_centres_score = np.array(profile_centres_score)
							centre = np.nanmean(profile_centres[profile_centres_score < 1])
							TS_r_new = np.abs(TS_r - centre) / 1000
							# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

							temp1 = np.zeros_like(inverted_profiles[:, 0])
							temp2 = np.zeros_like(inverted_profiles[:, 0])
							temp3 = np.zeros_like(inverted_profiles[:, 0])
							temp4 = np.zeros_like(inverted_profiles[:, 0])
							interp_range_t = max(dt / 2, TS_dt) * 1
							interp_range_r = max(dx / 2, TS_dr) * 1
							for i_t, value_t in enumerate(new_timesteps):
								if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
									continue
								for i_r, value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
										continue
									elif np.sum(np.logical_and(np.abs(merge_time-value_t)<interp_range_t,np.sum(merge_Te_prof_multipulse,axis=1)>0))==0:
										continue
									selected_values_t = np.logical_and(np.abs(merge_time-value_t)<interp_range_t,np.sum(merge_Te_prof_multipulse,axis=1)>0)
									selected_values_r = np.abs(TS_r_new-value_r)<interp_range_r
									selected_values = (np.array([selected_values_t])).T*selected_values_r
									selected_values[merge_Te_prof_multipulse==0]=False
									if np.sum(selected_values)==0:
										continue
									# temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[selected_values_t][:,selected_values_r])
									# temp2[i_t, i_r] = np.max(merge_dTe_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dTe_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
									temp1[i_t,i_r] = np.sum(merge_Te_prof_multipulse[selected_values]/merge_dTe_multipulse[selected_values])/np.sum(1/merge_dTe_multipulse[selected_values])
									temp2[i_t, i_r] = (np.sum(selected_values)/(np.sum(1/merge_dTe_multipulse[selected_values]) ** 2))**0.5
									# temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[selected_values_t][:,selected_values_r])
									# temp4[i_t, i_r] = np.max(merge_dne_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dne_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
									temp3[i_t,i_r] = np.sum(merge_ne_prof_multipulse[selected_values]/merge_dne_multipulse[selected_values])/np.sum(1/merge_dne_multipulse[selected_values])
									temp4[i_t, i_r] = (np.sum(selected_values)/(np.sum(1/merge_dne_multipulse[selected_values]) ** 2))**0.5

							merge_Te_prof_multipulse_interp = np.array(temp1)
							merge_dTe_prof_multipulse_interp = np.array(temp2)
							merge_ne_prof_multipulse_interp = np.array(temp3)
							merge_dne_prof_multipulse_interp = np.array(temp4)
							temp_r, temp_t = np.meshgrid(r, new_timesteps)

							# I crop to the usefull stuff
							start_time = np.abs(new_timesteps - 0).argmin()
							end_time = np.abs(new_timesteps - 1.5).argmin() + 1
							time_crop = new_timesteps[start_time:end_time]
							start_r = np.abs(r - 0).argmin()
							end_r = np.abs(r - 5).argmin() + 1
							r_crop = r[start_r:end_r]
							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time, start_r:end_r]
							merge_dTe_prof_multipulse_interp_crop = merge_dTe_prof_multipulse_interp[start_time:end_time, start_r:end_r]
							merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
							merge_dne_prof_multipulse_interp_crop = merge_dne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
							inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
							inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
							all_fits_crop = all_fits[start_time:end_time]
							# inverted_profiles_crop[inverted_profiles_crop<0] = 0

							x_local = xx - spatial_factor * 17.4 / 1000
							dr_crop = np.median(np.diff(r_crop))

							merge_dTe_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_dTe_prof_multipulse_interp_crop)
							merge_dTe_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.2] = 0
							merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
							merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.2] = 0
							merge_dne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_dne_prof_multipulse_interp_crop)
							merge_dne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop < 5e-07] = 0
							merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
							merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop < 5e-07] = 0
							excitation = []
							for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								excitation.append(temp)
							excitation = np.array(excitation)  # in # photons cm^-3 s^-1
							excitation = (excitation.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							recombination = []
							for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								recombination.append(temp)
							recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
							recombination = (recombination.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2



							n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
							# OES_multiplier = 0.81414701
							# Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
									recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
									merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

									if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										continue
									# if np.sum(inverted_profiles_crop_restrict == 0)>2:
									# 	continue

									dummy = np.zeros((len(n_list_1), len(n_list_all)))
									for value in n_list_1:
										dummy[value - 4][value - 4] = 1

									if len(n_list_1)==3:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2, dummy3):
												recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
												excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total
											return calculated_emission

										bds = [[min_nH_ne, 0, 0,0,0], [max_nH_ne, max_h_atomic_density, np.inf, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000,1000,1000]
									elif len(n_list_1)==2:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
												recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
												excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total
											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, max_h_atomic_density, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000]
									elif len(n_list_1)==1:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
												recombination_emissivity = (recombination_restrict * nH_ne * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
												excitation_emissivity = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (h_atomic_density * (10 ** 20))).astype('float')
												dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total
											return calculated_emission

										bds = [[min_nH_ne, 0, 0], [max_nH_ne, max_h_atomic_density, np.inf]]
										guess = [max_nH_ne, 10, 1000]

									fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict, p0=guess, bounds=bds, sigma=n_weights,maxfev=10000000,ftol=1e-5)
									if (fit[0][1] < 0.01 and min_nH_ne==0.9999):
										bds[0][0]=0
										fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict), n_list,inverted_profiles_crop_restrict, p0=guess, bounds=bds, sigma=n_weights,maxfev=10000000,ftol=1e-5)


									# # if np.sum(fit[1] == 0)>0:
									# # 	continue
									# if int(time_crop[my_time_pos]*100) in np.array([0.2,0.4,0.6,0.8])*100:
									# 	if r_crop[my_r_pos] in r_crop[[0,10,20,30]]:
									# 		plt.figure()
									# 		# plt.plot(n_list_all,inverted_profiles_crop_restrict/inverted_profiles_crop_restrict[0])
									# 		# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
									# 		recombination_emissivity_local = (recombination_restrict * fit[0][0] * ((merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) ** 2)).astype('float')
									# 		excitation_emissivity_local = (excitation_restrict * (merge_ne_prof_multipulse_interp_crop_limited_restrict * (10 ** 20)) * (fit[0][1] * (10 ** 20))).astype('float')
									# 		dummy_emissivity_local = np.sum((dummy.T * [fit[0][2:]]).T, axis=0)
									# 		plt.plot(n_list_all,inverted_profiles_crop_restrict,label='OES')
									# 		plt.plot(n_list_all,recombination_emissivity_local,label='recombination')
									# 		plt.plot(n_list_all,excitation_emissivity_local,label='excitation')
									# 		plt.plot(n_list_all,dummy_emissivity_local,'*',label='extra radiation')
									# 		plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]),'--',label='total fit')
									# 		plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy*0, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]),'+',label='excitation + recombination')
									# 		plt.semilogy()
									# 		plt.legend(loc='best')
									# 		plt.ylim(np.min(inverted_profiles_crop_restrict)/2,np.max(inverted_profiles_crop_restrict)*2)
									# 		plt.title('location [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g eV, ' % merge_Te_prof_multipulse_interp_crop_limited_restrict + '%.3g #/m^3]' % merge_ne_prof_multipulse_interp_crop_limited_restrict +'\nfit [nH/ne, H_atomic_density, extra rad] , '+ '[%.3g, ' % fit[0][0] + '%.3g, ' % fit[0][1]+ '%.3g]' % fit[0][2])# +'\nweights '+str(n_weights))
									# 		plt.xlabel('Exctited state n')
									# 		plt.ylabel('Line emissivity n->2 [W m^-3]')
									# 		# plt.pause(0.01)
									# 		plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
									# 		plt.close()

									nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
									h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
									if len(n_list_1)>=1:
										dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
									if len(n_list_1)>=2:
										dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
									if len(n_list_1)>=3:
										dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
									# Te_all[my_time_pos, my_r_pos]=fit[0][3]
									# ne_all[my_time_pos, my_r_pos]=fit[0][4]
									# if np.sum(fit[1] == 0) == len(fit[0]) ** 2:
									# 	residuals_all[my_time_pos, my_r_pos] = 0
									# else:
									residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict - fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))) ** 2)

							# plt.figure()
							# plt.title('ne,Te,nH_ne,h_atomic_density,OES_multiplier\n'+str([*merge_ne_prof_multipulse_interp_crop_limited_restrict,*merge_Te_prof_multipulse_interp_crop_limited_restrict,*fit[0],OES_multiplier]))
							# plt.plot(n_list,inverted_profiles_crop_restrict*OES_multiplier)
							# plt.plot(n_list,fit_nH_ne_h_atomic_density(recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list,*fit[0]))
							# plt.pause(0.01)

							figure_index = 0

							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							plt.figure();
							plt.pcolor(temp_t, temp_r, nH_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[au]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('hydrogen ion density / electron density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2+ '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited*nH_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('hydrogen ion density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2+ '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							if np.mean(np.sort(h_atomic_density_all.flatten())[-100:-10])>0:
								plt.pcolor(temp_t, temp_r, h_atomic_density_all, cmap='rainbow',norm=LogNorm(),vmin=0.1,vmax=np.mean(np.sort(h_atomic_density_all.flatten())[-100:-10]));
							else:
								plt.pcolor(temp_t, temp_r, h_atomic_density_all, cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('neutral atomic hydrogen density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, residuals_all, cmap='rainbow',vmax=np.max(residuals_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('[W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('relative residual unaccounted line emission\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor])+'\nsum = '+str(np.sum(residuals_all)))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, dummy1_all, cmap='rainbow',vmax=np.max(dummy1_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(dummy1_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('[W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('extra emissivity n=4\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, dummy2_all, cmap='rainbow');
							plt.colorbar().set_label('[W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('extra emissivity n=5\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, dummy3_all, cmap='rainbow');
							plt.colorbar().set_label('[W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('extra emissivity n=6\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							# figure_index += 1
							# plt.savefig(path_where_to_save_everything + mod + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							# plt.close()

							recombination_emissivity = (recombination * nH_ne_all * ((merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) ** 2)).astype('float')
							excitation_emissivity = (excitation * (merge_ne_prof_multipulse_interp_crop_limited * (10 ** 20)) * (h_atomic_density_all * (10 ** 20))).astype('float')

							residual_emission = []
							for index in range(len(recombination_emissivity)):
								residual_emission.append(inverted_profiles_crop[:, index] - recombination_emissivity[index] - excitation_emissivity[index])
							residual_emission = np.array(residual_emission)

							to_print = inverted_profiles_crop[:, 0]*dummy1_all/(recombination_emissivity[0]+excitation_emissivity[0]+ dummy1_all)
							plt.figure();
							plt.pcolor(temp_t, temp_r, to_print, cmap='rainbow',vmax=np.max(to_print[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(dummy1_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('[W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('extra emissivity using only the ratio from the fitting on n=4\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything +mod2 + '/post_process_mega_global_fit' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()
							figure_index -= 1


							plt.figure();
							plt.pcolor(temp_t, temp_r, residual_emission[0], cmap='rainbow', vmin=np.min(residual_emission[0][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('residual emissivity, attribuited to MAR, line4\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							temp = residual_emission[0] / recombination_emissivity[0]
							temp[np.logical_not(np.isfinite(temp))] = 0
							plt.figure();
							plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('relative residual emissivity, attribuited to MAR, line4\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, residual_emission[0]-dummy1_all, cmap='rainbow', vmin=np.min(residual_emission[0][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('residual emissivity not included in the fitting, line4\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor])+'\nsum = '+str(np.sum(np.abs(residual_emission[0]-dummy1_all))))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()


							plt.figure();
							plt.pcolor(temp_t, temp_r, residual_emission[1], cmap='rainbow', vmin=np.min(residual_emission[1][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('residual emissivity, attribuited to MAR, line5\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							temp = residual_emission[1] / recombination_emissivity[1]
							temp[np.logical_not(np.isfinite(temp))] = 0
							plt.figure();
							plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('relative residual emissivity, attribuited to MAR, line5\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							if len(n_list_1)>1:
								plt.figure();
								plt.pcolor(temp_t, temp_r, residual_emission[1]-dummy2_all, cmap='rainbow', vmin=np.min(residual_emission[1][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
								plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
								plt.axes().set_aspect(20)
								plt.xlabel('time [ms]')
								plt.ylabel('radial location [m]')
								plt.title('residual emissivity not included in the fitting, line5\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor])+'\nsum = '+str(np.sum(np.abs(residual_emission[1]-dummy1_all))))
								figure_index += 1
								plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
								plt.close()


							plt.figure();
							plt.pcolor(temp_t, temp_r, residual_emission[2], cmap='rainbow', vmin=np.min(residual_emission[2][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('residual emissivity, attribuited to MAR, line6\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							temp = residual_emission[2] / recombination_emissivity[2]
							temp[np.logical_not(np.isfinite(temp))] = 0
							plt.figure();
							plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',vmax=np.max(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]),vmin=np.min(temp[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label(' relative line emission [au]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('relative residual emissivity, attribuited to MAR, line6\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							if len(n_list_1)>2:
								plt.figure();
								plt.pcolor(temp_t, temp_r, residual_emission[2]-dummy3_all, cmap='rainbow', vmin=np.min(residual_emission[2][np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
								plt.colorbar().set_label('line emission [W m^-3]')  # ;plt.pause(0.01)
								plt.axes().set_aspect(20)
								plt.xlabel('time [ms]')
								plt.ylabel('radial location [m]')
								plt.title('residual emissivity not included in the fitting, line6\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor])+'\nsum = '+str(np.sum(np.abs(residual_emission[2]-dummy1_all))))
								figure_index += 1
								plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
								plt.close()


							temp = read_adf11(scdfile, 'scd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
							temp[np.isnan(temp)] = 0
							effective_ionisation_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (10 ** -6)  # in ionisations m^-3 s-1 / (# / m^3)**2
							effective_ionisation_rates = (effective_ionisation_rates * (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) * h_atomic_density_all).astype('float')

							plt.figure();
							plt.pcolor(temp_t, temp_r, effective_ionisation_rates, cmap='rainbow');
							plt.colorbar().set_label('effective_ionisation_rates [# m^-3 s-1]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('effective_ionisation_rates\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							# plt.title('effective_ionisation_rates')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							temp = read_adf11(acdfile, 'acd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
							temp[np.isnan(temp)] = 0
							effective_recombination_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (10 ** -6)  # in recombinations m^-3 s-1 / (# / m^3)**2
							effective_recombination_rates = (effective_recombination_rates *nH_ne_all* (merge_ne_prof_multipulse_interp_crop * (10 ** 20)) ** 2).astype('float')

							plt.figure();
							plt.pcolor(temp_t, temp_r, effective_recombination_rates, cmap='rainbow');
							plt.colorbar().set_label('effective_recombination_rates [# m^-3 s-1]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('effective_recombination_rates (three body plus radiative)\nOES_multiplier,spatial_factor,time_shift_factor \n' + str([1,spatial_factor,time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()


							plt.figure();
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited, cmap='rainbow');
							plt.colorbar().set_label('electron density [10^20 # m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Scaled electron density')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							temp = 100*merge_dne_prof_multipulse_interp_crop_limited / merge_ne_prof_multipulse_interp_crop_limited
							temp[np.logical_not(np.isfinite(temp))] = 0
							plt.figure();
							plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',norm=LogNorm());
							plt.colorbar().set_label('uncertainty [%]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Scaled electron density relative uncertainty')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, merge_Te_prof_multipulse_interp_crop_limited, cmap='rainbow');
							plt.colorbar().set_label('electron temperature [eV]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Scaled electron temperature')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							temp = 100*merge_dTe_prof_multipulse_interp_crop_limited / merge_Te_prof_multipulse_interp_crop_limited
							temp[np.logical_not(np.isfinite(temp))] = 0
							plt.figure();
							plt.pcolor(temp_t, temp_r, temp, cmap='rainbow',norm=LogNorm());
							plt.colorbar().set_label('uncertainty [%]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Scaled electron temperature relative uncertainty')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
										bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, inverted_profiles_crop[:, 0], cmap='rainbow');
							plt.colorbar().set_label('line emission n=4 [Wm^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Scaled OES line emissivity')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, inverted_profiles_crop[:, 3], cmap='rainbow');
							plt.colorbar().set_label('line emission n=7 [W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Scaled OES line emissivity')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()

							to_print = 100*dummy1_all/inverted_profiles_crop[:, 0]
							to_print[np.logical_not(np.isfinite(to_print))] = 0
							plt.figure();
							plt.pcolor(temp_t, temp_r, to_print, cmap='rainbow');
							plt.colorbar().set_label('emissivity ratio [%]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('Ratio of emissivity attributed to MAR\nover total OEs measurement')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()


							fig = plt.figure()
							# fig=plt.figure(merge_ID_target * 100 + 2)
							ax = fig.add_subplot(1, 5, 1)
							im = ax.pcolor(1000*temp_r.T,temp_t.T,merge_Te_prof_multipulse_interp_crop_limited.T,cmap='rainbow')
							# plt.set_sketch_params(scale=2)
							ax.set_aspect(40)
							plt.title('TS\nelectron temperature')
							plt.xlabel('radial location [mm]')
							plt.ylabel('time [ms]')
							fig.colorbar(im, ax=ax).set_label('[eV]')
							# plt.axes().set_aspect(0.1)


							ax=fig.add_subplot(1, 5, 2)
							im=ax.pcolor(1000*temp_r.T,temp_t.T,merge_ne_prof_multipulse_interp_crop_limited.T,cmap='rainbow')
							ax.set_aspect(40)
							plt.title('TS\nelectron density')
							plt.xlabel('radial location [mm]')
							plt.yticks([])
							# plt.ylabel('time [ms]')
							fig.colorbar(im, ax=ax).set_label('[10^20 # m^-3]')

							ax=fig.add_subplot(1, 5, 3)
							im = ax.pcolor(1000*temp_r.T,temp_t.T,effective_ionisation_rates.T,cmap='rainbow')
							ax.set_aspect(40)
							plt.title('effective ionisation\nrates')
							plt.xlabel('radial location [mm]')
							# plt.ylabel('time [ms]')
							plt.yticks([])
							fig.colorbar(im, ax=ax).set_label('effective ionisation rates [# m^-3 s-1]')

							ax=fig.add_subplot(1, 5, 4)
							im = ax.pcolor(1000*temp_r.T,temp_t.T,effective_recombination_rates.T, cmap='rainbow')
							ax.set_aspect(40)
							plt.title('effective recombination\nrates')
							plt.xlabel('radial location [mm]')
							# plt.ylabel('time [ms]')
							plt.yticks([])
							fig.colorbar(im, ax=ax).set_label('effective recombination rates [# m^-3 s-1]')

							ax=fig.add_subplot(1, 5, 5)
							im = ax.pcolor(1000*temp_r.T,temp_t.T,dummy1_all.T, cmap='rainbow')
							ax.set_aspect(40)
							plt.title('extra emissivity\nn=4')
							plt.xlabel('radial location [mm]')
							# plt.ylabel('time [ms]')
							plt.yticks([])
							fig.colorbar(im, ax=ax).set_label('emissivity [W m^-3]')

							# plt.pause(0.001)
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',
										bbox_inches='tight')
							plt.close()


							fig = plt.figure()
							ax = fig.add_subplot(1, 3, 1)
							im = ax.pcolor(1000 * temp_r.T, temp_t.T, effective_ionisation_rates.T, cmap='rainbow')
							ax.set_aspect(40)
							plt.title('effective ionisation\nrates')
							plt.xlabel('radial location [mm]')
							plt.ylabel('time [ms]')
							# plt.yticks([])
							fig.colorbar(im, ax=ax).set_label('effective ionisation rates [# m^-3 s-1]')

							ax = fig.add_subplot(1, 3, 2)
							im = ax.pcolor(1000 * temp_r.T, temp_t.T, effective_recombination_rates.T, cmap='rainbow')
							ax.set_aspect(40)
							plt.title('effective recombination\nrates')
							plt.xlabel('radial location [mm]')
							# plt.ylabel('time [ms]')
							plt.yticks([])
							fig.colorbar(im, ax=ax).set_label('effective recombination rates [# m^-3 s-1]')

							ax = fig.add_subplot(1, 3, 3)
							im = ax.pcolor(1000 * temp_r.T, temp_t.T, dummy1_all.T, cmap='rainbow')
							ax.set_aspect(40)
							plt.title('extra emissivity\nn=4')
							plt.xlabel('radial location [mm]')
							# plt.ylabel('time [ms]')
							plt.yticks([])
							fig.colorbar(im, ax=ax).set_label('emissivity [W m^-3]')

							# plt.pause(0.001)
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()


							plt.figure();
							threshold_radious = 0.005
							plt.plot(time_crop, np.mean(effective_ionisation_rates[:,r_crop<threshold_radious],axis=1)/np.max(np.mean(effective_ionisation_rates[:,r_crop<threshold_radious],axis=1)), label='ionisation rate\n(max='+'%.3g # m^-3 s-1)' % (np.max(np.mean(effective_ionisation_rates[:,r_crop<threshold_radious],axis=1))));
							plt.plot(time_crop, np.mean(effective_recombination_rates[:,r_crop<threshold_radious],axis=1)/np.max(np.mean(effective_recombination_rates[:,r_crop<threshold_radious],axis=1)), label='recombination rate\n(max='+'%.3g # m^-3 s-1)' % (np.max(np.mean(effective_recombination_rates[:,r_crop<threshold_radious],axis=1))));
							plt.plot(time_crop, np.mean(dummy1_all[:,r_crop<threshold_radious],axis=1)/np.max(np.mean(dummy1_all[:,r_crop<threshold_radious],axis=1)), label='additional H- emissivity\n(max='+'%.3g W m^-3)' % (np.max(np.mean(dummy1_all[:,r_crop<threshold_radious],axis=1))));
							plt.plot(time_crop, np.mean(merge_Te_prof_multipulse_interp_crop_limited[:,r_crop<threshold_radious],axis=1)/np.max(np.mean(merge_Te_prof_multipulse_interp_crop_limited[:,r_crop<threshold_radious],axis=1)),'--', label='Te TS\n(max='+'%.3g eV)' % (np.max(np.mean(merge_Te_prof_multipulse_interp_crop_limited[:,r_crop<threshold_radious],axis=1))));
							plt.plot(time_crop, np.mean(merge_ne_prof_multipulse_interp_crop_limited[:,r_crop<threshold_radious],axis=1)/np.max(np.mean(merge_ne_prof_multipulse_interp_crop_limited[:,r_crop<threshold_radious],axis=1)),'--', label='ne TS\n(max='+'%.3g 10^20 # m^-3)' % (np.max(np.mean(merge_ne_prof_multipulse_interp_crop_limited[:,r_crop<threshold_radious],axis=1))));
							plt.legend(loc='best')
							plt.xlabel('time from beginning of pulse [ms]')
							plt.ylabel('relative radial average [au]')
							plt.title('Time evolution of the radial average, 0>r>'+  '%.3g' % (1000*threshold_radious) +' mm, 21.2mm from the target')
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_' + str(figure_index) + '.eps',bbox_inches='tight')
							plt.close()
elif False:  # absolute intensity fit with Yacora coefficients




	for merge_ID_target in [85,86,87,89,92,93,94]:	# 88 excluded because I don't have a temperature profile
	# for merge_ID_target in np.flip([85, 94, 89], axis=0):  # 88 excluded because I don't have a temperature profile

		# merge_ID_target = 85

		for min_nHp_ne in [0.999,0.3,0,0.1,0.6]:	#0.9999 is for the case when I relax this boundary if nH<0.001
		# for min_nH_ne in [0.999]:
			for max_n_neutrals_ne in [1,np.inf]:
			# for max_h_atomic_density in [np.inf]:

				figure_index = 0

				# calculate_geometry = False
				# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
				for i in range(10):
					print('.')
				print('Starting to work on merge number' + str(merge_ID_target))
				for i in range(10):
					print('.')

				time_resolution_scan = False
				time_resolution_scan_improved = True
				time_resolution_extra_skip = 0

				if False:
					n_list = np.array([5, 6, 7, 9,10,11])
					n_list_1 = np.array([4])
					n_weights = [1, 1, 1, 1, 1,10,10]
				else:
					n_list = np.array([5, 6, 7,8, 9])
					n_list_1 = np.array([4])
					n_weights = [1, 1, 1, 1,10, 1]
				# for index in (n_list_1 - 4):
				# 	n_weights[index] = 4
				# n_weights[np.max(n_list_1) - 3] = 2
				# min_nH_ne = 0.6
				max_nHp_ne = 1

				mod = '/Yacora/absolute/lines_fitted'+str(len(n_list)+len(n_list_1))+'/min_nHp_ne' + str(min_nHp_ne) + '/max_n_neutrals_ne' + str(
					max_n_neutrals_ne)

				print('dummy')
				print(n_list_1)
				print('min_nHp_ne')
				print(min_nHp_ne)
				print('max_n_neutrals_ne')
				print(max_n_neutrals_ne)
				print('max_nHp_ne')
				print(max_nHp_ne)
				print('n_weights')
				print(n_weights)

				started = 0
				rows_range_for_interp = 25 / 3  # rows that I use for interpolation (box with twice this side length, not sphere)
				# if merge_ID_target>=66:
				# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
				if time_resolution_scan:
					conventional_time_step = 0.01  # ms
				else:
					conventional_time_step = 0.05  # ms
				# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
				grade_of_interpolation = 3  # this is the exponent used for the weights of the interpolation for image resampling
				type_of_image = '12bit'  # '12bit' or '16bit'
				# if type_of_image=='12bit':
				row_shift = 2 * 10280 / 1000000  # ms
				# elif type_of_image=='16bit':
				# 	print('Row shift to be checked')
				# 	exit()
				# time_range_for_interp = rows_range_for_interp*row_shift
				# merge_time_window=[-1,4]
				merge_time_window = [-10, 10]
				overexposed_treshold = 3600
				path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(
					merge_ID_target) + '_back'

				if not os.path.exists(path_where_to_save_everything + mod):
					os.makedirs(path_where_to_save_everything + mod)

				new_timesteps = np.linspace(merge_time_window[0] + 0.5, merge_time_window[1] - 0.5, int(
					(merge_time_window[1] - 0.5 - (merge_time_window[0] + 0.5)) / conventional_time_step + 1))
				dt = np.nanmedian(np.diff(new_timesteps))

				# for spatial_factor in spatial_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				# dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
				# xx = np.arange(40) * dx  # m
				# xn = np.linspace(0, max(xx), 1000)
				# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
				# r=r[::10]
				# dr=np.median(np.diff(r))

				# first_time = np.min(new_timesteps)
				# last_time = np.max(new_timesteps)

				# Data from wikipedia
				energy_difference = np.array([1.89, 2.55, 2.86, 3.03, 3.13, 3.19, 3.23, 3.26, 3.29])  # eV
				# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
				statistical_weigth = np.array([32, 50, 72, 98, 128, 162, 200, 242, 288])  # gi-gk
				einstein_coeff = np.array(
					[8.4193e-2, 2.53044e-2, 9.7320e-3, 4.3889e-3, 2.2148e-3, 1.2156e-3, 7.1225e-4, 4.3972e-4,
					 2.8337e-4]) * 1e8  # 1/s
				J_to_eV = 6.242e18
				# Used formula 2.3 in Rion Barrois thesys, 2017
				color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro',
						 'paleturquoise']

				inverted_profiles_original = 4 * np.pi * np.load(
					path_where_to_save_everything + '/inverted_profiles.npy')  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				all_fits = np.load(path_where_to_save_everything + '/merge' + str(
					merge_ID_target) + '_all_fits.npy')  # in W m^-2 sr^-1
				merge_Te_prof_multipulse = \
				np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')[
					'merge_Te_prof_multipulse']
				merge_dTe_multipulse = \
				np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')[
					'merge_dTe_multipulse']
				merge_ne_prof_multipulse = \
				np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')[
					'merge_ne_prof_multipulse']
				merge_dne_multipulse = \
				np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')[
					'merge_dne_multipulse']
				merge_time_original = \
				np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_time']

				# for time_shift_factor in time_shift_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)+'/time_shift_factor' + str(time_shift_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				if False:
					def residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse,
									 merge_time_original):
						def residuals(input):
							spatial_factor = input[0]
							time_shift_factor = input[1]
							print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

							dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
							xx = np.arange(40) * dx  # m
							xn = np.linspace(0, max(xx), 1000)
							r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
							r = r[::10]
							dr = np.median(np.diff(r))

							merge_time = time_shift_factor + merge_time_original
							inverted_profiles = (
															1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
							TS_dt = np.nanmedian(np.diff(merge_time))

							if np.max(merge_Te_prof_multipulse) <= 0:
								print('merge' + str(merge_ID_target) + " has no recorded temperature")
							# continue

							TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
							TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
							TS_dr = np.median(np.diff(TS_r)) / 1000
							gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
							profile_centres = []
							profile_centres_score = []
							for index in range(np.shape(merge_Te_prof_multipulse)[0]):
								yy = merge_Te_prof_multipulse[index]
								p0 = [np.max(yy), 10, 0]
								bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
								profile_centres.append(fit[0][-1])
								profile_centres_score.append(fit[1][-1, -1])
							# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
							profile_centres = np.array(profile_centres)
							profile_centres_score = np.array(profile_centres_score)
							centre = np.nanmean(profile_centres[profile_centres_score < 1])
							TS_r_new = np.abs(TS_r - centre) / 1000
							# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

							temp1 = np.zeros_like(inverted_profiles[:, 0])
							temp3 = np.zeros_like(inverted_profiles[:, 0])
							interp_range_t = max(dt / 2, TS_dt) * 1
							interp_range_r = max(dx / 2, TS_dr) * 1
							for i_t, value_t in enumerate(new_timesteps):
								if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
									continue
								for i_r, value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
										continue
									if np.sum(np.logical_and(np.abs(merge_time - value_t) < interp_range_t,
															 np.sum(merge_Te_prof_multipulse, axis=1) > 0)) == 0:
										continue
									temp1[i_t, i_r] = np.mean(merge_Te_prof_multipulse[np.logical_and(
										np.abs(merge_time - value_t) < interp_range_t,
										np.sum(merge_Te_prof_multipulse, axis=1) > 0)][:,
															  np.abs(TS_r_new - value_r) < interp_range_r])
									temp3[i_t, i_r] = np.mean(merge_ne_prof_multipulse[np.logical_and(
										np.abs(merge_time - value_t) < interp_range_t,
										np.sum(merge_Te_prof_multipulse, axis=1) > 0)][:,
															  np.abs(TS_r_new - value_r) < interp_range_r])

							merge_Te_prof_multipulse_interp = np.array(temp1)
							merge_ne_prof_multipulse_interp = np.array(temp3)
							temp_r, temp_t = np.meshgrid(r, new_timesteps)

							# I crop to the usefull stuff
							start_time = np.abs(new_timesteps - 0).argmin()
							end_time = np.abs(new_timesteps - 1.5).argmin() + 1
							time_crop = new_timesteps[start_time:end_time]
							start_r = np.abs(r - 0).argmin()
							end_r = np.abs(r - 5).argmin() + 1
							r_crop = r[start_r:end_r]
							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,
																   start_r:end_r]
							merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,
																   start_r:end_r]
							inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
							inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
							all_fits_crop = all_fits[start_time:end_time]
							# inverted_profiles_crop[inverted_profiles_crop<0] = 0

							x_local = xx - spatial_factor * 17.4 / 1000
							dr_crop = np.median(np.diff(r_crop))

							merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_Te_prof_multipulse_interp_crop)
							merge_Te_prof_multipulse_interp_crop_limited[
								merge_Te_prof_multipulse_interp_crop_limited < 0.2] = 0
							merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_ne_prof_multipulse_interp_crop)
							merge_ne_prof_multipulse_interp_crop_limited[
								merge_ne_prof_multipulse_interp_crop_limited < 5e-07] = 0
							excitation = []
							for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
												  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (
															  20 - 6)).flatten())[
									0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								excitation.append(temp)
							excitation = np.array(excitation)  # in # photons cm^-3 s^-1
							excitation = (excitation.T * (10 ** -6) * (
										energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							recombination = []
							for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
												  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (
															  20 - 6)).flatten())[
									0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								recombination.append(temp)
							recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
							recombination = (recombination.T * (10 ** -6) * (
										energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							# def residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation):
							# 	def residuals1(input):
							# 		OES_multiplier=input
							# 		print(OES_multiplier)

							n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
							# OES_multiplier = 0.81414701
							# nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									inverted_profiles_crop_restrict = inverted_profiles_crop[
										my_time_pos, n_list_all - 4, my_r_pos].flatten()
									recombination_restrict = recombination[
										n_list_all - 4, my_time_pos, my_r_pos].flatten()
									merge_ne_prof_multipulse_interp_crop_limited_restrict = \
									merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									merge_Te_prof_multipulse_interp_crop_limited_restrict = \
									merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

									if (
											merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										continue

									dummy = np.zeros((len(n_list_1), len(n_list_all)))
									for value in n_list_1:
										dummy[value - 4][value - 4] = 1

									if len(n_list_1) == 3:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																	   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																	   excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2,
																	dummy3):
												recombination_emissivity = (recombination_restrict * nH_ne * ((
																														  merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																															  10 ** 20)) ** 2)).astype(
													'float')
												excitation_emissivity = (excitation_restrict * (
															merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																10 ** 20)) * (h_atomic_density * (10 ** 20))).astype(
													'float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T,
																		  axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total

											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000, 1000]
									elif len(n_list_1) == 2:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																	   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																	   excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
												recombination_emissivity = (recombination_restrict * nH_ne * ((
																														  merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																															  10 ** 20)) ** 2)).astype(
													'float')
												excitation_emissivity = (excitation_restrict * (
															merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																10 ** 20)) * (h_atomic_density * (10 ** 20))).astype(
													'float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total

											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000]
									elif len(n_list_1) == 1:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																	   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																	   excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
												recombination_emissivity = (recombination_restrict * nH_ne * ((
																														  merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																															  10 ** 20)) ** 2)).astype(
													'float')
												excitation_emissivity = (excitation_restrict * (
															merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																10 ** 20)) * (h_atomic_density * (10 ** 20))).astype(
													'float')
												dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total

											return calculated_emission

										bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
										guess = [max_nH_ne, 10, 1000]

									fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																			   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																			   excitation_restrict), n_list,
													inverted_profiles_crop_restrict, p0=guess, bounds=bds,
													sigma=n_weights, maxfev=10000000)

									# if np.sum(fit[1] == 0) > 0:
									# 	continue

									# plt.figure()
									# plt.plot(n_list_all,inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]))
									# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
									# # plt.plot(n_list_all,np.ones_like(inverted_profiles_crop_restrict) * OES_multiplier)
									# # plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict,inverted_profiles_crop_restrict)(n_list, *fit[0]))
									# plt.semilogy()
									# plt.title(str(fit[0])+'\n'+str(n_weights))
									# plt.pause(0.01)

									# nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
									# h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
									# dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
									# dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
									# dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
									if np.sum(fit[1] == 0) > 0:
										residuals_all[my_time_pos, my_r_pos] = np.sum(fit[1] == 0)
									else:
										residuals_all[my_time_pos, my_r_pos] = np.sum(((
													inverted_profiles_crop_restrict - fit_nH_ne_h_atomic_density(dummy,
																												 recombination_restrict,
																												 merge_ne_prof_multipulse_interp_crop_limited_restrict,
																												 excitation_restrict)(
												n_list, *fit[0]))) ** 2)
							# if residuals_all[my_time_pos, my_r_pos]>1:
							# 	print([my_time_pos, my_r_pos])
							# 	return residuals_all.flatten()
							# return residuals1

							# guess = [1]
							# bds = [[0.4],[5]]
							# sol = least_squares(residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation), guess, bounds=bds, max_nfev=60,	verbose=2, gtol=1e-20, xtol=1e-5, ftol=1e-16, diff_step=0.01, x_scale='jac')
							# OES_multiplier=sol.x
							return residuals_all.flatten()

						return residuals


					guess = [1.3, -0.05]
					bds = [[1, -0.1], [2, 0.1]]
					sol = least_squares(
						residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse,
									 merge_time_original), guess, bounds=bds, max_nfev=60, verbose=2, gtol=1e-20,
						xtol=1e-12, ftol=1e-16, diff_step=[0.05, 0.05], x_scale='jac')

					spatial_factor = sol.x[0]
					time_shift_factor = sol.x[1]

					print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

				else:
					# for spatial_factor in [1,1.1,1.2,1.3,1.4,1.5]:
					for spatial_factor in [1]:
						# for time_shift_factor in [-0.1,-0.05,0,0.05]:
						for time_shift_factor in [0]:
							mod2 = mod + '/spatial_factor_' + str(spatial_factor) + '/time_shift_factor_' + str(
								time_shift_factor)

							if not os.path.exists(path_where_to_save_everything + mod2):
								os.makedirs(path_where_to_save_everything + mod2)

							dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
							xx = np.arange(40) * dx  # m
							xn = np.linspace(0, max(xx), 1000)
							r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
							r = r[::10]
							dr = np.median(np.diff(r))

							merge_time = time_shift_factor + merge_time_original
							inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
							TS_dt = np.nanmedian(np.diff(merge_time))

							if np.max(merge_Te_prof_multipulse) <= 0:
								print('merge' + str(merge_ID_target) + " has no recorded temperature")
							# continue

							TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
							TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
							TS_dr = np.median(np.diff(TS_r)) / 1000
							gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
							profile_centres = []
							profile_centres_score = []
							for index in range(np.shape(merge_Te_prof_multipulse)[0]):
								yy = merge_Te_prof_multipulse[index]
								p0 = [np.max(yy), 10, 0]
								bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
								profile_centres.append(fit[0][-1])
								profile_centres_score.append(fit[1][-1, -1])
							# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
							profile_centres = np.array(profile_centres)
							profile_centres_score = np.array(profile_centres_score)
							centre = np.nanmean(profile_centres[profile_centres_score < 1])
							TS_r_new = np.abs(TS_r - centre) / 1000
							# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

							temp1 = np.zeros_like(inverted_profiles[:, 0])
							temp2 = np.zeros_like(inverted_profiles[:, 0])
							temp3 = np.zeros_like(inverted_profiles[:, 0])
							temp4 = np.zeros_like(inverted_profiles[:, 0])
							interp_range_t = max(dt / 2, TS_dt) * 1
							interp_range_r = max(dx / 2, TS_dr) * 1
							for i_t, value_t in enumerate(new_timesteps):
								if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
									continue
								for i_r, value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
										continue
									elif np.sum(np.logical_and(np.abs(merge_time - value_t) < interp_range_t,
															   np.sum(merge_Te_prof_multipulse, axis=1) > 0)) == 0:
										continue
									selected_values_t = np.logical_and(np.abs(merge_time - value_t) < interp_range_t,
																	   np.sum(merge_Te_prof_multipulse, axis=1) > 0)
									selected_values_r = np.abs(TS_r_new - value_r) < interp_range_r
									selected_values = (np.array([selected_values_t])).T * selected_values_r
									selected_values[merge_Te_prof_multipulse == 0] = False
									if np.sum(selected_values) == 0:
										continue
									# temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[selected_values_t][:,selected_values_r])
									# temp2[i_t, i_r] = np.max(merge_dTe_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dTe_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
									temp1[i_t, i_r] = np.sum(
										merge_Te_prof_multipulse[selected_values] / merge_dTe_multipulse[
											selected_values]) / np.sum(1 / merge_dTe_multipulse[selected_values])
									temp2[i_t, i_r] = (np.sum(selected_values) / (
												np.sum(1 / merge_dTe_multipulse[selected_values]) ** 2)) ** 0.5
									# temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[selected_values_t][:,selected_values_r])
									# temp4[i_t, i_r] = np.max(merge_dne_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dne_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
									temp3[i_t, i_r] = np.sum(
										merge_ne_prof_multipulse[selected_values] / merge_dne_multipulse[
											selected_values]) / np.sum(1 / merge_dne_multipulse[selected_values])
									temp4[i_t, i_r] = (np.sum(selected_values) / (
												np.sum(1 / merge_dne_multipulse[selected_values]) ** 2)) ** 0.5

							merge_Te_prof_multipulse_interp = np.array(temp1)
							merge_dTe_prof_multipulse_interp = np.array(temp2)
							merge_ne_prof_multipulse_interp = np.array(temp3)
							merge_dne_prof_multipulse_interp = np.array(temp4)
							temp_r, temp_t = np.meshgrid(r, new_timesteps)

							# I crop to the usefull stuff
							start_time = np.abs(new_timesteps - 0).argmin()
							end_time = np.abs(new_timesteps - 1.5).argmin() + 1
							time_crop = new_timesteps[start_time:end_time]
							start_r = np.abs(r - 0).argmin()
							end_r = np.abs(r - 5).argmin() + 1
							r_crop = r[start_r:end_r]
							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,
																   start_r:end_r]
							merge_dTe_prof_multipulse_interp_crop = merge_dTe_prof_multipulse_interp[
																	start_time:end_time, start_r:end_r]
							merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,
																   start_r:end_r]
							merge_dne_prof_multipulse_interp_crop = merge_dne_prof_multipulse_interp[
																	start_time:end_time, start_r:end_r]
							inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
							inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
							all_fits_crop = all_fits[start_time:end_time]
							# inverted_profiles_crop[inverted_profiles_crop<0] = 0

							x_local = xx - spatial_factor * 17.4 / 1000
							dr_crop = np.median(np.diff(r_crop))

							merge_dTe_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_dTe_prof_multipulse_interp_crop)
							merge_dTe_prof_multipulse_interp_crop_limited[
								merge_Te_prof_multipulse_interp_crop < 0.1] = 0
							merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_Te_prof_multipulse_interp_crop)
							merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.1] = 0
							merge_dne_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_dne_prof_multipulse_interp_crop)
							merge_dne_prof_multipulse_interp_crop_limited[
								merge_ne_prof_multipulse_interp_crop < 5e-07] = 0
							merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_ne_prof_multipulse_interp_crop)
							merge_ne_prof_multipulse_interp_crop_limited[
								merge_ne_prof_multipulse_interp_crop < 5e-07] = 0

							n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
							# OES_multiplier = 0.81414701
							# Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nHp_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nHm_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nH2_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nH2p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							nH3p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)

							residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
									merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()

									if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										continue
									# if np.sum(inverted_profiles_crop_restrict == 0)>2:
									# 	continue

									T_Hp = 12000	# K
									T_Hm = 12000	# K
									T_H2p = 5000	# K
									ne = merge_ne_prof_multipulse_interp_crop_limited_restrict * 1e20
									multiplicative_factor = energy_difference[n_list_all - 4] * einstein_coeff[n_list_all - 4] / J_to_eV

									if True:
										def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
											def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
												# nHp_ne=1+nHm_ne-nH2p_ne
												total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
												total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
												total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												total = total[0]*(ne ** 2)*multiplicative_factor
												# print(total)
												return total
											return calculated_emission
										bds = [[0, min_nHp_ne, 0, 0, 0, 0],
											   [max_n_neutrals_ne, max_nHp_ne, 1, max_n_neutrals_ne, 1, 1]]
										guess = [0.1, 1, 0.01, 0.1, 0.0001, 0.0001]
										n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict / inverted_profiles_crop_restrict[0]
										fit = curve_fit(
											fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
																 merge_Te_prof_multipulse_interp_crop_limited_restrict,
																 T_Hp, T_Hm, T_H2p, ne, multiplicative_factor),
											n_list_all, inverted_profiles_crop_restrict, p0=guess, bounds=bds,
											sigma=n_weights_actual, maxfev=10000000)


									elif False:
										def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
											def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne):
												# nHp_ne=1+nHm_ne-nH2p_ne
												total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
												total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
												# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
												total = total[0]*(ne ** 2)*multiplicative_factor
												# print(total)
												return total
											return calculated_emission
										bds = [[0, min_nHp_ne, 0],
											   [max_n_neutrals_ne, max_nHp_ne, 1]]
										guess = [0.1, 1, 0.01]
										n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict / inverted_profiles_crop_restrict[0]
										fit = curve_fit(
											fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
																 merge_Te_prof_multipulse_interp_crop_limited_restrict,
																 T_Hp, T_Hm, T_H2p, ne, multiplicative_factor),
											n_list_all, inverted_profiles_crop_restrict, p0=guess, bounds=bds,
											sigma=n_weights_actual, maxfev=10000000)

									# bds = [[0, min_nHp_ne, 0, 0, 0,0],
									# 	   [max_n_neutrals_ne, max_nHp_ne, 1, max_n_neutrals_ne, 1,1]]
									# guess = [0.1, 1, 0.01, 0.1, 0.0001, 0.0001]
									# n_weights_actual = np.array(n_weights)*inverted_profiles_crop_restrict/inverted_profiles_crop_restrict[0]
									# fit = curve_fit(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor), n_list_all,inverted_profiles_crop_restrict, p0=guess, bounds=bds,sigma=n_weights_actual, maxfev=10000000)
									# if (fit[0][1] < 0.01 and min_nH_ne == 0.9999):
									# 	bds[0][0] = 0
									# 	fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
									# 											   merge_ne_prof_multipulse_interp_crop_limited_restrict,
									# 											   excitation_restrict), n_list,
									# 					inverted_profiles_crop_restrict, p0=guess, bounds=bds,
									# 					sigma=n_weights, maxfev=10000000, ftol=1e-5)

									# # if np.sum(fit[1] == 0)>0:
									# # 	continue
									if int(time_crop[my_time_pos]*100) in np.array([0.2,0.4,0.6,0.8])*100:
										if r_crop[my_r_pos] in r_crop[[0,10,20,30]]:
											plt.figure()
											# nH_ne, nHp_ne,nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = fit[0]
											nH_ne, nHp_ne, nH2p_ne = fit[0]
											# nHp_ne = 1 + nHm_ne - nH2p_ne
											plt.plot(n_list_all,inverted_profiles_crop_restrict,label='OES')
											plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
											plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
											plt.plot(n_list_all,nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )[0]*(ne ** 2)*multiplicative_factor,label='mutual neutralisation\nH+ + H-  H(p) + H\nH2+ + H-  H(p) + H2')
											plt.plot(n_list_all,nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
											plt.plot(n_list_all,nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
											plt.plot(n_list_all,nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
											plt.plot(n_list_all,fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, *fit[0]),'--',label='total fit')
											plt.plot(n_list_all,fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, nH_ne,nHp_ne, *np.zeros_like(fit[0][2:])),'+',label='excitation + recombination')
											plt.semilogy()
											plt.legend(loc='best', fontsize='x-small')
											# plt.ylim(np.min(inverted_profiles_crop_restrict)/2,np.max(inverted_profiles_crop_restrict)*2)
											plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g eV, ' % merge_Te_prof_multipulse_interp_crop_limited_restrict + '%.3g #10^20/m^3]' % merge_ne_prof_multipulse_interp_crop_limited_restrict +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH+/ne, nH+/ne] , '+ '[%.3g, ' % nH_ne + '%.3g, ' % nHp_ne+ '%.3g, ' % nHm_ne+ '%.3g, ' % nH2_ne+ '%.3g, ' % nH2p_ne+ '%.3g]' % nH3p_ne)# +'\nweights '+str(n_weights))
											plt.xlabel('Exctited state n')
											plt.ylabel('Line emissivity n->2 [W m^-3]')
											# plt.pause(0.01)
											plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
											plt.close()

									nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
									# nHp_ne_all[my_time_pos, my_r_pos] = 1 + fit[0][1] - fit[0][3]
									nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
									nHm_ne_all[my_time_pos, my_r_pos] = fit[0][2]
									nH2_ne_all[my_time_pos, my_r_pos] = fit[0][3]
									nH2p_ne_all[my_time_pos, my_r_pos] = fit[0][4]
									nH3p_ne_all[my_time_pos, my_r_pos] = fit[0][5]
									# if np.sum(fit[1] == 0) == len(fit[0]) ** 2:
									# 	residuals_all[my_time_pos, my_r_pos] = 0
									# else:
									residuals_all[my_time_pos, my_r_pos] = np.sum(((inverted_profiles_crop_restrict - fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, *fit[0]))) ** 2)

							# plt.figure()
							# plt.title('ne,Te,nH_ne,h_atomic_density,OES_multiplier\n'+str([*merge_ne_prof_multipulse_interp_crop_limited_restrict,*merge_Te_prof_multipulse_interp_crop_limited_restrict,*fit[0],OES_multiplier]))
							# plt.plot(n_list,inverted_profiles_crop_restrict*OES_multiplier)
							# plt.plot(n_list,fit_nH_ne_h_atomic_density(recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list,*fit[0]))
							# plt.pause(0.01)

							figure_index = 0

							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							plt.figure();
							plt.pcolor(temp_t, temp_r, nHp_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[au]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'hydrogen ion density / electron density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nHp_ne_all,
									   cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title('hydrogen ion density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
								[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							plt.figure();
							# if np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]) > 0:
							# 	plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all, cmap='rainbow', norm=LogNorm(),
							# 			   vmin=0.1, vmax=np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]));
							# else:
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'neutral atomic hydrogen density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							plt.figure();
							# if np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]) > 0:
							# 	plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all, cmap='rainbow', norm=LogNorm(),
							# 			   vmin=0.1, vmax=np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]));
							# else:
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nHm_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'H- density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							plt.figure();
							# if np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]) > 0:
							# 	plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all, cmap='rainbow', norm=LogNorm(),
							# 			   vmin=0.1, vmax=np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]));
							# else:
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH2_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'H2 density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							plt.figure();
							# if np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]) > 0:
							# 	plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all, cmap='rainbow', norm=LogNorm(),
							# 			   vmin=0.1, vmax=np.mean(np.sort((merge_ne_prof_multipulse_interp_crop_limited * nH_ne_all).flatten())[-100:-10]));
							# else:
							plt.pcolor(temp_t, temp_r, merge_ne_prof_multipulse_interp_crop_limited * nH2p_ne_all, cmap='rainbow');
							plt.colorbar().set_label('[# m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'H2+ density\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							charge_unbalance = -np.ones_like(merge_ne_prof_multipulse_interp_crop_limited) + nHp_ne_all - nHm_ne_all + nH2p_ne_all
							plt.figure();
							plt.pcolor(temp_t, temp_r, charge_unbalance, cmap='rainbow');
							plt.colorbar().set_label('[au]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'Fractional charge unbalance\n(0=neutral, 1=positive charge = 2*negative, -1=positive charge = 0)\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()

							plt.figure();
							plt.pcolor(temp_t, temp_r, residuals_all, cmap='rainbow', vmax=np.max(
								residuals_all[np.logical_and(time_crop > 0.3, time_crop < 0.9)][:, r_crop < 0.007]));
							plt.colorbar().set_label('[W m^-3]')  # ;plt.pause(0.01)
							plt.axes().set_aspect(20)
							plt.xlabel('time [ms]')
							plt.ylabel('radial location [m]')
							plt.title(
								'relative residual unaccounted line emission\nOES_multiplier,spatial_factor,time_shift_factor \n' + str(
									[1, spatial_factor, time_shift_factor]) + '\nsum = ' + str(np.sum(residuals_all)))
							figure_index += 1
							plt.savefig(path_where_to_save_everything + mod2 + '/post_process_mega_global_fit' + str(
								figure_index) + '.eps', bbox_inches='tight')
							plt.close()
elif False:  # absolute intensity fit with Yacora coefficients, but divided per molecular reaction




	# for merge_ID_target in [851,86,87,89,92]:	# 88 excluded because I don't have a temperature profile
	# 	merge_time_window = [-10, 10]
	# for merge_ID_target in [ 93, 94]:  # 88 excluded because I don't have a temperature profile
	# 	merge_time_window = [-1,2]

	# merge_ID_target_multipulse = np.flip([851,86,87,89,92, 93, 94],axis=0)
	merge_ID_target_multipulse = [851,86,87,89,92, 93, 94]
	# merge_ID_target_multipulse = [851]

	for merge_ID_target in merge_ID_target_multipulse:  # 88 excluded because I don't have a temperature profile
		if (merge_ID_target>=93 and merge_ID_target<100):
			merge_time_window = [-1,2]
		else:
			merge_time_window = [-10,10]


		recorded_data_override = [False,False]
		# recorded_data_override = [True,True]

		# merge_ID_target = 85

		# for min_nHp_ne,atomic_restricted_high_n in [[0.999,False],[0.999,True],[0.3,False],[0,False]]:	#0.9999 is for the case when I relax this boundary if nH<0.001
		for min_nHp_ne,atomic_restricted_high_n in [[0.999,False],[0.8,False]]:

			for max_n_neutrals_ne in [1,2,10,100]:
			# for max_h_atomic_density in [np.inf]:

				figure_index = 0

				# calculate_geometry = False
				# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
				for i in range(10):
					print('.')
				print('Starting to work on merge number' + str(merge_ID_target))
				for i in range(10):
					print('.')

				time_resolution_scan = False
				time_resolution_scan_improved = True
				time_resolution_extra_skip = 0

				if False:
					n_list = np.array([5, 6, 7,8, 9,10,11])
					n_list_1 = np.array([4])
					n_weights = [1, 1, 1, 1, 1, 1,3,3]
				else:
					n_list = np.array([6,7,8, 9])
					n_list_1 = np.array([4,5])
					n_weights = [1, 1, 1, 1,1, 3]
				# for index in (n_list_1 - 4):
				# 	n_weights[index] = 4
				# n_weights[np.max(n_list_1) - 3] = 2
				# min_nH_ne = 0.6

				max_nHp_ne = 1
				min_nH_ne = 0

				mod_atomic_restricted_high_n = ''
				if atomic_restricted_high_n ==True:
					mod_atomic_restricted_high_n = '_atomic_restricted_high_n'
					print('calculus of nH and nH+ limited to lines >=8')

				mod = '/Yacora_partial/absolute/lines_fitted'+str(len(n_list)+len(n_list_1))+'/min_nHp_ne' + str(min_nHp_ne) + mod_atomic_restricted_high_n+'/max_n_neutrals_ne' + str(
					max_n_neutrals_ne)

				boltzmann_constant_J = 1.380649e-23	# J/K
				eV_to_K = 8.617333262145e-5	# eV/K
				avogadro_number = 6.02214076e23
				all_j=find_index_of_file(merge_ID_target,df_settings,df_log,only_OES=True)
				target_chamber_pressure = []
				target_OES_distance = []
				for j in all_j:
					target_chamber_pressure.append(df_log.loc[j,['p_n [Pa]']])
					target_OES_distance.append(df_log.loc[j,['T_axial']])
				target_chamber_pressure = np.nanmean(target_chamber_pressure)	# Pa
				target_OES_distance = np.nanmean(target_OES_distance)	# Pa
				# Ideal gas law
				max_nH2_from_pressure = target_chamber_pressure/(boltzmann_constant_J*300)	# [#/m^3] I suppose ambient temp is ~ 300K

				print('lines')
				print(str(n_list_1.tolist()+n_list.tolist()))
				print('min_nHp/ne')
				print(min_nHp_ne)
				print('max_nH/ne')
				print(max_n_neutrals_ne)
				print('steady state nH2 [#/m^3]')
				print(max_nH2_from_pressure)
				max_nH2_from_pressure = 10*max_nH2_from_pressure
				print("considering that it's a transient phenomena the istantaneous max_nH2 is set 10 times higher to [#/m^3]")
				print(max_nH2_from_pressure)
				print('max_nHp/ne')
				print(max_nHp_ne)
				print('n_weights')
				print(n_weights)
				print('recorded data override is '+str(recorded_data_override))

				started = 0
				rows_range_for_interp = 25 / 3  # rows that I use for interpolation (box with twice this side length, not sphere)
				# if merge_ID_target>=66:
				# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
				if time_resolution_scan:
					conventional_time_step = 0.01  # ms
				else:
					conventional_time_step = 0.05  # ms
				# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
				grade_of_interpolation = 3  # this is the exponent used for the weights of the interpolation for image resampling
				type_of_image = '12bit'  # '12bit' or '16bit'
				# if type_of_image=='12bit':
				row_shift = 2 * 10280 / 1000000  # ms
				# elif type_of_image=='16bit':
				# 	print('Row shift to be checked')
				# 	exit()
				# time_range_for_interp = rows_range_for_interp*row_shift
				# merge_time_window=[-1,4]
				overexposed_treshold = 3600
				path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(
					merge_ID_target) #+ '_back'

				if not os.path.exists(path_where_to_save_everything + mod):
					os.makedirs(path_where_to_save_everything + mod)

				new_timesteps = np.linspace(merge_time_window[0] + 0.5, merge_time_window[1] - 0.5, int(
					(merge_time_window[1] - 0.5 - (merge_time_window[0] + 0.5)) / conventional_time_step + 1))
				dt = np.nanmedian(np.diff(new_timesteps))

				# for spatial_factor in spatial_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				# dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
				# xx = np.arange(40) * dx  # m
				# xn = np.linspace(0, max(xx), 1000)
				# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
				# r=r[::10]
				# dr=np.median(np.diff(r))

				# first_time = np.min(new_timesteps)
				# last_time = np.max(new_timesteps)

				# Data from wikipedia
				energy_difference = np.array([1.89, 2.55, 2.86, 3.03, 3.13, 3.19, 3.23, 3.26, 3.29])  # eV
				# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
				statistical_weigth = np.array([32, 50, 72, 98, 128, 162, 200, 242, 288])  # gi-gk
				einstein_coeff = np.array([8.4193e-2, 2.53044e-2, 9.7320e-3, 4.3889e-3, 2.2148e-3, 1.2156e-3, 7.1225e-4, 4.3972e-4, 2.8337e-4]) * 1e8  # 1/s
				J_to_eV = 6.242e18
				au_to_kg = 1.66053906660e-27	# kg/au
				# Used formula 2.3 in Rion Barrois thesys, 2017
				color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro',
						 'paleturquoise']

				inverted_profiles_original = 4 * np.pi * np.load(path_where_to_save_everything + '/inverted_profiles.npy')  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				inverted_profiles_sigma_original = 4 * np.pi * np.load(path_where_to_save_everything + '/inverted_profiles_sigma.npy')  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				all_fits = np.load(path_where_to_save_everything + '/merge' + str(merge_ID_target) + '_all_fits.npy')  # in W m^-2 sr^-1
				merge_Te_prof_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_Te_prof_multipulse']
				merge_dTe_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_dTe_multipulse']
				merge_ne_prof_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_ne_prof_multipulse']
				merge_dne_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_dne_multipulse']
				merge_time_original = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_time']

				# for time_shift_factor in time_shift_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)+'/time_shift_factor' + str(time_shift_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				if False:
					def residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse,
									 merge_time_original):
						def residuals(input):
							spatial_factor = input[0]
							time_shift_factor = input[1]
							print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

							dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
							xx = np.arange(40) * dx  # m
							xn = np.linspace(0, max(xx), 1000)
							r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
							r = r[::10]
							dr = np.median(np.diff(r))

							merge_time = time_shift_factor + merge_time_original
							inverted_profiles = (
															1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
							TS_dt = np.nanmedian(np.diff(merge_time))

							if np.max(merge_Te_prof_multipulse) <= 0:
								print('merge' + str(merge_ID_target) + " has no recorded temperature")
							# continue

							TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
							TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
							TS_dr = np.median(np.diff(TS_r)) / 1000
							gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
							profile_centres = []
							profile_centres_score = []
							for index in range(np.shape(merge_Te_prof_multipulse)[0]):
								yy = merge_Te_prof_multipulse[index]
								p0 = [np.max(yy), 10, 0]
								bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
								profile_centres.append(fit[0][-1])
								profile_centres_score.append(fit[1][-1, -1])
							# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
							profile_centres = np.array(profile_centres)
							profile_centres_score = np.array(profile_centres_score)
							centre = np.nanmean(profile_centres[profile_centres_score < 1])
							TS_r_new = np.abs(TS_r - centre) / 1000
							# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

							temp1 = np.zeros_like(inverted_profiles[:, 0])
							temp3 = np.zeros_like(inverted_profiles[:, 0])
							interp_range_t = max(dt / 2, TS_dt) * 1
							interp_range_r = max(dx / 2, TS_dr) * 1
							for i_t, value_t in enumerate(new_timesteps):
								if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
									continue
								for i_r, value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
										continue
									if np.sum(np.logical_and(np.abs(merge_time - value_t) < interp_range_t,
															 np.sum(merge_Te_prof_multipulse, axis=1) > 0)) == 0:
										continue
									temp1[i_t, i_r] = np.mean(merge_Te_prof_multipulse[np.logical_and(
										np.abs(merge_time - value_t) < interp_range_t,
										np.sum(merge_Te_prof_multipulse, axis=1) > 0)][:,
															  np.abs(TS_r_new - value_r) < interp_range_r])
									temp3[i_t, i_r] = np.mean(merge_ne_prof_multipulse[np.logical_and(
										np.abs(merge_time - value_t) < interp_range_t,
										np.sum(merge_Te_prof_multipulse, axis=1) > 0)][:,
															  np.abs(TS_r_new - value_r) < interp_range_r])

							merge_Te_prof_multipulse_interp = np.array(temp1)
							merge_ne_prof_multipulse_interp = np.array(temp3)
							temp_r, temp_t = np.meshgrid(r, new_timesteps)

							# I crop to the usefull stuff
							start_time = np.abs(new_timesteps - 0).argmin()
							end_time = np.abs(new_timesteps - 1.5).argmin() + 1
							time_crop = new_timesteps[start_time:end_time]
							start_r = np.abs(r - 0).argmin()
							end_r = np.abs(r - 5).argmin() + 1
							r_crop = r[start_r:end_r]
							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,
																   start_r:end_r]
							merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,
																   start_r:end_r]
							inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
							inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
							all_fits_crop = all_fits[start_time:end_time]
							# inverted_profiles_crop[inverted_profiles_crop<0] = 0

							x_local = xx - spatial_factor * 17.4 / 1000
							dr_crop = np.median(np.diff(r_crop))

							merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_Te_prof_multipulse_interp_crop)
							merge_Te_prof_multipulse_interp_crop_limited[
								merge_Te_prof_multipulse_interp_crop_limited < 0.2] = 0
							merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(
								merge_ne_prof_multipulse_interp_crop)
							merge_ne_prof_multipulse_interp_crop_limited[
								merge_ne_prof_multipulse_interp_crop_limited < 5e-07] = 0
							excitation = []
							for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
												  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (
															  20 - 6)).flatten())[
									0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								excitation.append(temp)
							excitation = np.array(excitation)  # in # photons cm^-3 s^-1
							excitation = (excitation.T * (10 ** -6) * (
										energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							recombination = []
							for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),
												  (merge_ne_prof_multipulse_interp_crop_limited * 10 ** (
															  20 - 6)).flatten())[
									0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								recombination.append(temp)
							recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
							recombination = (recombination.T * (10 ** -6) * (
										energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							# def residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation):
							# 	def residuals1(input):
							# 		OES_multiplier=input
							# 		print(OES_multiplier)

							n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
							# OES_multiplier = 0.81414701
							# nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# h_atomic_density_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy1_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy2_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							# dummy3_all =  np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									inverted_profiles_crop_restrict = inverted_profiles_crop[
										my_time_pos, n_list_all - 4, my_r_pos].flatten()
									recombination_restrict = recombination[
										n_list_all - 4, my_time_pos, my_r_pos].flatten()
									merge_ne_prof_multipulse_interp_crop_limited_restrict = \
									merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									merge_Te_prof_multipulse_interp_crop_limited_restrict = \
									merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
									excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

									if (
											merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										continue

									dummy = np.zeros((len(n_list_1), len(n_list_all)))
									for value in n_list_1:
										dummy[value - 4][value - 4] = 1

									if len(n_list_1) == 3:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																	   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																	   excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2,
																	dummy3):
												recombination_emissivity = (recombination_restrict * nH_ne * ((
																														  merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																															  10 ** 20)) ** 2)).astype(
													'float')
												excitation_emissivity = (excitation_restrict * (
															merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																10 ** 20)) * (h_atomic_density * (10 ** 20))).astype(
													'float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2, dummy3]).T,
																		  axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total

											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000, 1000]
									elif len(n_list_1) == 2:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																	   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																	   excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1, dummy2):
												recombination_emissivity = (recombination_restrict * nH_ne * ((
																														  merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																															  10 ** 20)) ** 2)).astype(
													'float')
												excitation_emissivity = (excitation_restrict * (
															merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																10 ** 20)) * (h_atomic_density * (10 ** 20))).astype(
													'float')
												dummy_emissivity = np.sum((dummy.T * [dummy1, dummy2]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total

											return calculated_emission

										bds = [[min_nH_ne, 0, 0, 0], [max_nH_ne, 300, np.inf, np.inf]]
										guess = [max_nH_ne, 10, 1000, 1000]
									elif len(n_list_1) == 1:
										def fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																	   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																	   excitation_restrict):
											def calculated_emission(n_list, nH_ne, h_atomic_density, dummy1):
												recombination_emissivity = (recombination_restrict * nH_ne * ((
																														  merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																															  10 ** 20)) ** 2)).astype(
													'float')
												excitation_emissivity = (excitation_restrict * (
															merge_ne_prof_multipulse_interp_crop_limited_restrict * (
																10 ** 20)) * (h_atomic_density * (10 ** 20))).astype(
													'float')
												dummy_emissivity = np.sum((dummy.T * [dummy1]).T, axis=0)
												total = recombination_emissivity + excitation_emissivity + dummy_emissivity
												return total

											return calculated_emission

										bds = [[min_nH_ne, 0, 0], [max_nH_ne, 300, np.inf]]
										guess = [max_nH_ne, 10, 1000]

									fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
																			   merge_ne_prof_multipulse_interp_crop_limited_restrict,
																			   excitation_restrict), n_list,
													inverted_profiles_crop_restrict, p0=guess, bounds=bds,
													sigma=n_weights, maxfev=10000000)

									# if np.sum(fit[1] == 0) > 0:
									# 	continue

									# plt.figure()
									# plt.plot(n_list_all,inverted_profiles_crop_restrict/(inverted_profiles_crop_restrict[0]))
									# plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list, *fit[0]))
									# # plt.plot(n_list_all,np.ones_like(inverted_profiles_crop_restrict) * OES_multiplier)
									# # plt.plot(n_list_all,fit_nH_ne_h_atomic_density(dummy, recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict,inverted_profiles_crop_restrict)(n_list, *fit[0]))
									# plt.semilogy()
									# plt.title(str(fit[0])+'\n'+str(n_weights))
									# plt.pause(0.01)

									# nH_ne_all[my_time_pos, my_r_pos]=fit[0][0]
									# h_atomic_density_all[my_time_pos, my_r_pos]=fit[0][1]
									# dummy1_all[my_time_pos, my_r_pos]=fit[0][2]
									# dummy2_all[my_time_pos, my_r_pos]=fit[0][3]
									# dummy3_all[my_time_pos, my_r_pos]=fit[0][4]
									if np.sum(fit[1] == 0) > 0:
										residuals_all[my_time_pos, my_r_pos] = np.sum(fit[1] == 0)
									else:
										residuals_all[my_time_pos, my_r_pos] = np.sum(((
													inverted_profiles_crop_restrict - fit_nH_ne_h_atomic_density(dummy,
																												 recombination_restrict,
																												 merge_ne_prof_multipulse_interp_crop_limited_restrict,
																												 excitation_restrict)(
												n_list, *fit[0]))) ** 2)
							# if residuals_all[my_time_pos, my_r_pos]>1:
							# 	print([my_time_pos, my_r_pos])
							# 	return residuals_all.flatten()
							# return residuals1

							# guess = [1]
							# bds = [[0.4],[5]]
							# sol = least_squares(residual_ext1(n_list,n_list_1,n_weights,time_crop,r_crop,inverted_profiles_crop,recombination,merge_ne_prof_multipulse_interp_crop_limited,merge_Te_prof_multipulse_interp_crop_limited,excitation), guess, bounds=bds, max_nfev=60,	verbose=2, gtol=1e-20, xtol=1e-5, ftol=1e-16, diff_step=0.01, x_scale='jac')
							# OES_multiplier=sol.x
							return residuals_all.flatten()

						return residuals


					guess = [1.3, -0.05]
					bds = [[1, -0.1], [2, 0.1]]
					sol = least_squares(
						residual_ext(inverted_profiles_original, merge_Te_prof_multipulse, merge_ne_prof_multipulse,
									 merge_time_original), guess, bounds=bds, max_nfev=60, verbose=2, gtol=1e-20,
						xtol=1e-12, ftol=1e-16, diff_step=[0.05, 0.05], x_scale='jac')

					spatial_factor = sol.x[0]
					time_shift_factor = sol.x[1]

					print('spatial_factor,time_shift_factor  ' + str([spatial_factor, time_shift_factor]))

				else:
					# for spatial_factor in [1,1.1,1.2,1.3,1.4,1.5]:
					for spatial_factor in [1]:
						# for time_shift_factor in [-0.1,-0.05,0,0.05]:
						for time_shift_factor in [0]:
							mod2 = mod + '/spatial_factor_' + str(spatial_factor) + '/time_shift_factor_' + str(time_shift_factor)

							if not os.path.exists(path_where_to_save_everything + mod2):
								os.makedirs(path_where_to_save_everything + mod2)

							# dx = 18 / 40 * (50.5 / 27.4) / 1e3
							dx = 1.06478505470992 / 1e3	# 10/02/2020 from	Calculate magnification_FF.xlsx
							xx = np.arange(40) * dx  # m
							xn = np.linspace(0, max(xx), 1000)
							r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
							r = r[::10]
							dr = np.median(np.diff(r))

							merge_time = time_shift_factor + merge_time_original
							inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
							inverted_profiles_sigma = cp.deepcopy(inverted_profiles_sigma_original)
							TS_dt = np.nanmedian(np.diff(merge_time))

							if np.max(merge_Te_prof_multipulse) <= 0:
								print('merge' + str(merge_ID_target) + " has no recorded temperature")
								continue

							TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
							TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
							TS_dr = np.median(np.diff(TS_r)) / 1000
							gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
							profile_centres = []
							profile_centres_score = []
							for index in range(np.shape(merge_Te_prof_multipulse)[0]):
								yy = merge_Te_prof_multipulse[index]
								p0 = [np.max(yy), 10, 0]
								bds = [[0, -40, np.min(TS_r)], [np.inf, 40, np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, maxfev=100000, bounds=bds)
								profile_centres.append(fit[0][-1])
								profile_centres_score.append(fit[1][-1, -1])
							# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
							profile_centres = np.array(profile_centres)
							profile_centres_score = np.array(profile_centres_score)
							centre = np.nanmean(profile_centres[profile_centres_score < 1])
							TS_r_new = np.abs(TS_r - centre) / 1000
							print('TS profile centre at %.3gmm compared to the theoretical centre' %centre)
							# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
							# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

							# This is the mean of Te and ne weighted in their own uncertainties.
							temp1 = np.zeros_like(inverted_profiles[:, 0])
							temp2 = np.zeros_like(inverted_profiles[:, 0])
							temp3 = np.zeros_like(inverted_profiles[:, 0])
							temp4 = np.zeros_like(inverted_profiles[:, 0])
							interp_range_t = max(dt / 2, TS_dt) * 1
							interp_range_r = max(dx / 2, TS_dr) * 1
							for i_t, value_t in enumerate(new_timesteps):
								if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
									continue
								for i_r, value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(TS_r_new - value_r) < interp_range_r) == 0:
										continue
									elif np.sum(np.logical_and(np.abs(merge_time - value_t) < interp_range_t,
															   np.sum(merge_Te_prof_multipulse, axis=1) > 0)) == 0:
										continue
									selected_values_t = np.logical_and(np.abs(merge_time - value_t) < interp_range_t,
																	   np.sum(merge_Te_prof_multipulse, axis=1) > 0)
									selected_values_r = np.abs(TS_r_new - value_r) < interp_range_r
									selected_values = (np.array([selected_values_t])).T * selected_values_r
									selected_values[merge_Te_prof_multipulse == 0] = False
									if np.sum(selected_values) == 0:
										continue
									# temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[selected_values_t][:,selected_values_r])
									# temp2[i_t, i_r] = np.max(merge_dTe_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dTe_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
									temp1[i_t, i_r] = np.sum(
										merge_Te_prof_multipulse[selected_values] / merge_dTe_multipulse[
											selected_values]) / np.sum(1 / merge_dTe_multipulse[selected_values])
									temp2[i_t, i_r] = (np.sum(selected_values) / (
												np.sum(1 / merge_dTe_multipulse[selected_values]) ** 2)) ** 0.5
									# temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[selected_values_t][:,selected_values_r])
									# temp4[i_t, i_r] = np.max(merge_dne_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dne_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
									temp3[i_t, i_r] = np.sum(
										merge_ne_prof_multipulse[selected_values] / merge_dne_multipulse[
											selected_values]) / np.sum(1 / merge_dne_multipulse[selected_values])
									temp4[i_t, i_r] = (np.sum(selected_values) / (
												np.sum(1 / merge_dne_multipulse[selected_values]) ** 2)) ** 0.5

							merge_Te_prof_multipulse_interp = np.array(temp1)
							merge_dTe_prof_multipulse_interp = np.array(temp2)
							merge_ne_prof_multipulse_interp = np.array(temp3)
							merge_dne_prof_multipulse_interp = np.array(temp4)
							temp_r, temp_t = np.meshgrid(r, new_timesteps)

							# I crop to the usefull stuff
							start_time = np.abs(new_timesteps - 0).argmin()
							end_time = np.abs(new_timesteps - 1.5).argmin() + 1
							time_crop = new_timesteps[start_time:end_time]
							start_r = np.abs(r - 0).argmin()
							end_r = np.abs(r - 5).argmin() + 1
							r_crop = r[start_r:end_r]
							temp_r, temp_t = np.meshgrid(r_crop, time_crop)
							merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,start_r:end_r]
							merge_dTe_prof_multipulse_interp_crop = merge_dTe_prof_multipulse_interp[start_time:end_time, start_r:end_r]
							merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,start_r:end_r]
							merge_dne_prof_multipulse_interp_crop = merge_dne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
							inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
							inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
							inverted_profiles_sigma_crop = inverted_profiles_sigma[start_time:end_time, :, start_r:end_r]
							inverted_profiles_sigma_crop[np.isnan(inverted_profiles_sigma_crop)] = 0
							all_fits_crop = all_fits[start_time:end_time]
							# inverted_profiles_crop[inverted_profiles_crop<0] = 0

							# x_local = xx - spatial_factor * 17.4 / 1000
							dr_crop = np.median(np.diff(r_crop))

							merge_dTe_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_dTe_prof_multipulse_interp_crop)
							merge_dTe_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.1] = 0
							merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
							merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.1] = 0
							merge_dne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_dne_prof_multipulse_interp_crop)
							merge_dne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop < 5e-07] = 0
							merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
							merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop < 5e-07] = 0

							excitation = []
							for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								excitation.append(temp)
							excitation = np.array(excitation)  # in # photons cm^-3 s^-1
							excitation = (excitation.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							recombination = []
							for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
								temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
								temp[np.isnan(temp)] = 0
								temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
								recombination.append(temp)
							recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
							recombination = (recombination.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

							arbitrary_H_temp = 5000	# K, It is the same used for the fittings
							thermal_velocity_H = ( (arbitrary_H_temp*boltzmann_constant_J)/ au_to_kg)**0.5
							temp = read_adf11(scdfile, 'scd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
							temp[np.isnan(temp)] = 0
							effective_ionisation_rates = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (10 ** -6)  # in ionisations m^-3 s-1 / (# / m^3)**2
							ionization_length = thermal_velocity_H/(effective_ionisation_rates * merge_ne_prof_multipulse_interp_crop_limited * 1e20 )
							ionization_length = np.where(np.isnan(ionization_length), 0, ionization_length)
							ionization_length = np.where(np.isinf(ionization_length), np.nan, ionization_length)
							ionization_length = np.where(np.isnan(ionization_length), np.nanmax(ionization_length[np.isfinite(ionization_length)]), ionization_length)

							min_multiplier = 1e-10
							# for max_nHm_ne,max_nH2_ne,max_nH2p_ne,max_nH3p_ne,mod3 in [[min_multiplier,min_multiplier,min_multiplier,min_multiplier,'only_H'],[1,min_multiplier,min_multiplier,min_multiplier,'only_Hm'],[min_multiplier,1,min_multiplier,min_multiplier,'only_H2'],[min_multiplier,min_multiplier,1,min_multiplier,'only_H2p'],[min_multiplier,min_multiplier,min_multiplier,1,'only_H3p'],[min_multiplier,1,1,min_multiplier,'only_H2_H2p'],[1,1,min_multiplier,min_multiplier,'only_Hm_H2'],[1,1,1,min_multiplier,'only_Hm_H2_H2p'],[1,1,1,1,'all']]:
							for max_nHm_ne,max_nH2_ne,max_nH2p_ne,max_nH3p_ne,mod3 in [[1,min_multiplier,min_multiplier,min_multiplier,'only_Hm'],[min_multiplier,1,1,min_multiplier,'only_H2_H2p'],[1,1,min_multiplier,min_multiplier,'only_Hm_H2'],[1,1,1,min_multiplier,'only_Hm_H2_H2p'],[1,1,1,1,'all']]:

								mod4 = mod2 +'/' +mod3

								if not os.path.exists(path_where_to_save_everything + mod4):
									os.makedirs(path_where_to_save_everything + mod4)

								print('Starting '+mod3)

								n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
								# OES_multiplier = 0.81414701
								# Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								# ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								nHp_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								nHm_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								nH2_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								nH2p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								nH3p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)

								residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
								# guess = [0, 1, 0.01 * max_nHm_ne, 0.1 * max_nH2_ne, 0.0001 * max_nH2p_ne,0.0001 * max_nH3p_ne]
								if max_nHm_ne==1 and max_nH2_ne==1 and max_nH2p_ne==1 and max_nH3p_ne==1:
									guess = [0.5, 1, 0.0005,0.0005, 0.0001,0.0005]
								elif max_nHm_ne==1 and max_nH2_ne==1 and max_nH2p_ne==1:
									guess = [0.5, 1, 0.0005, 0.0005,0.0001]
								elif max_nH2_ne==1 and max_nH2p_ne==1:
									guess = [0.5, 1, 0.0005,0.0001]
								elif max_nHm_ne==1 and max_nH2_ne==1:
									guess = [0.5, 1, 0.0005,0.0005]
								elif (max_nHm_ne==1 or max_nH2_ne==1 or max_nH2p_ne==1 or max_nH3p_ne==1):
									guess = [0.5, 1, 0.0005]
								else:
									guess = [0.5, 1]

								if False:	# single core way
									for my_time_pos in range(len(time_crop)):
										for my_r_pos in range(len(r_crop)):
											inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
											merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
											merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()

											if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
												continue
											# if np.sum(inverted_profiles_crop_restrict == 0)>2:
											# 	continue

											if False:
												T_Hp = 12000	# K
												T_Hm = 12000	# K
												T_H2p = 5000	# K
											else:
												T_Hp = min(max(1000,merge_Te_prof_multipulse_interp_crop_limited_restrict/boltzmann_constant),12000)	# K
												T_Hm = 5000	# K
												T_H2p = 5000	# K
											ne = merge_ne_prof_multipulse_interp_crop_limited_restrict * 1e20
											multiplicative_factor = energy_difference[n_list_all - 4] * einstein_coeff[n_list_all - 4] / J_to_eV

											if False:
												def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
													def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
														# nHp_ne=1+nHm_ne-nH2p_ne
														total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
														total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
														total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														total = total[0]*(ne ** 2)*multiplicative_factor
														# print(total)
														return np.log(total)
													return calculated_emission
												bds = [[0, min_nHp_ne, 0, 0, 0, 0],
													   [max_n_neutrals_ne, max_nHp_ne, 1*max_nHm_ne, 1*max_nH2_ne, 1*max_nH2p_ne, 1*max_nH3p_ne]]
												# guess = [0.1, 1, 0.01, 0.1, 0.0001, 0.0001]
												# guess = [0.1, 1, 0.01*max_nHm_ne, 0.1*max_nH2_ne, 0.0001*max_nH2p_ne, 0.0001*max_nH3p_ne]
												n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict / inverted_profiles_crop_restrict[0]
												fit = curve_fit(
													fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
																		 merge_Te_prof_multipulse_interp_crop_limited_restrict,
																		 T_Hp, T_Hm, T_H2p, ne, multiplicative_factor),
													n_list_all, np.log(inverted_profiles_crop_restrict), p0=guess, bounds=bds,
													sigma=np.ones_like(n_weights_actual), maxfev=10000000)
												guess[1:] = fit[0][1:]

											elif True:
												if max_nHm_ne == 1 and max_nH2_ne==min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne==min_multiplier:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne):
															nH2p_ne=0
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission
													bds = [[0, min_nHp_ne, 0],
														   [max_n_neutrals_ne, max_nHp_ne, 1]]
												elif max_nHm_ne == min_multiplier and max_nH2_ne==1 and max_nH2p_ne == min_multiplier and max_nH3p_ne==min_multiplier:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nH2_ne):
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission

													bds = [[0, min_nHp_ne, 0],
													   	[max_n_neutrals_ne, max_nHp_ne, max_nH2_from_pressure/ne]]
												elif max_nHm_ne == min_multiplier and max_nH2_ne==min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne==min_multiplier:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nH2p_ne):
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission
													bds = [[0, min_nHp_ne, 0],
														   [max_n_neutrals_ne, max_nHp_ne, 1]]
												elif max_nHm_ne == min_multiplier and max_nH2_ne==min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne==1:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nH3p_ne):
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission
													bds = [[0, min_nHp_ne, 0],
														   [max_n_neutrals_ne, max_nHp_ne, 1]]
												elif max_nHm_ne == min_multiplier and max_nH2_ne==1 and max_nH2p_ne == 1 and max_nH3p_ne==min_multiplier:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nH2_ne,nH2p_ne):
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission
													bds = [[0, min_nHp_ne, 0,0],
														   [max_n_neutrals_ne, max_nHp_ne, max_nH2_from_pressure/ne,1]]
												elif max_nHm_ne == 1 and max_nH2_ne==1 and max_nH2p_ne == 1 and max_nH3p_ne==min_multiplier:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne):
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission
													bds = [[0, min_nHp_ne,0, 0,0],
														   [max_n_neutrals_ne, max_nHp_ne, 1, 1*max_n_neutrals_ne,1]]
												elif max_nHm_ne == 1 and max_nH2_ne==1 and max_nH2p_ne == 1 and max_nH3p_ne==1:
													def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
														def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
															# nHp_ne=1+nHm_ne-nH2p_ne
															total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
															total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
															total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
															total = total[0]*(ne ** 2)*multiplicative_factor
															# print(total)
															return np.log(total)
														return calculated_emission
													bds = [[0, min_nHp_ne,0, 0,0,0],
														   [max_n_neutrals_ne, max_nHp_ne, 1, max_nH2_from_pressure/ne,1,1]]
												# guess = [0.1, 1, 0.01, 0.1, 0.0001, 0.0001]
												# guess = [0.1, 1, 0.01*max_nHm_ne, 0.1*max_nH2_ne, 0.0001*max_nH2p_ne, 0.0001*max_nH3p_ne]
												# n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict / inverted_profiles_crop_restrict[0]
												n_weights_actual = np.array(n_weights)
												fit = curve_fit(
													fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
																		 merge_Te_prof_multipulse_interp_crop_limited_restrict,
																		 T_Hp, T_Hm, T_H2p, ne, multiplicative_factor),
													n_list_all, np.log(inverted_profiles_crop_restrict), p0=guess, bounds=bds,
													sigma=n_weights_actual, maxfev=10000000)
												guess = fit[0]

											elif False:
												def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor):
													def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne):
														# nHp_ne=1+nHm_ne-nH2p_ne
														total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
														total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
														# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
														total = total[0]*(ne ** 2)*multiplicative_factor
														# print(total)
														return total
													return calculated_emission
												bds = [[0, min_nHp_ne, 0],
													   [max_n_neutrals_ne, max_nHp_ne, 1]]
												guess = [0.1, 1, 0.01]
												# n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict / inverted_profiles_crop_restrict[0]
												n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict
												fit = curve_fit(
													fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
																		 merge_Te_prof_multipulse_interp_crop_limited_restrict,
																		 T_Hp, T_Hm, T_H2p, ne, multiplicative_factor),
													n_list_all, inverted_profiles_crop_restrict, p0=guess, bounds=bds,
													sigma=n_weights_actual, maxfev=10000000)

											# bds = [[0, min_nHp_ne, 0, 0, 0,0],
											# 	   [max_n_neutrals_ne, max_nHp_ne, 1, max_n_neutrals_ne, 1,1]]
											# guess = [0.1, 1, 0.01, 0.1, 0.0001, 0.0001]
											# n_weights_actual = np.array(n_weights)*inverted_profiles_crop_restrict/inverted_profiles_crop_restrict[0]
											# fit = curve_fit(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor), n_list_all,inverted_profiles_crop_restrict, p0=guess, bounds=bds,sigma=n_weights_actual, maxfev=10000000)
											# if (fit[0][1] < 0.01 and min_nH_ne == 0.9999):
											# 	bds[0][0] = 0
											# 	fit = curve_fit(fit_nH_ne_h_atomic_density(dummy, recombination_restrict,
											# 											   merge_ne_prof_multipulse_interp_crop_limited_restrict,
											# 											   excitation_restrict), n_list,
											# 					inverted_profiles_crop_restrict, p0=guess, bounds=bds,
											# 					sigma=n_weights, maxfev=10000000, ftol=1e-5)

											# # if np.sum(fit[1] == 0)>0:
											# # 	continue
											if int(time_crop[my_time_pos]*100) in np.array([0.2,0.4,0.6,0.8])*100:
												if r_crop[my_r_pos] in r_crop[[0,10,20,30]]:
													if False:
														plt.figure()
														nH_ne, nHp_ne,nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = fit[0]
														# nH_ne, nHp_ne, nH2p_ne = fit[0]
														# nHp_ne = 1 + nHm_ne - nH2p_ne
														plt.errorbar(n_list_all,inverted_profiles_crop_restrict,yerr=n_weights_actual,label='OES')
														plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
														plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
														plt.plot(n_list_all,nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )[0]*(ne ** 2)*multiplicative_factor,label='mutual neutralisation\nH+ + H-  H(p) + H\nH2+ + H-  H(p) + H2')
														plt.plot(n_list_all,nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
														plt.plot(n_list_all,nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
														plt.plot(n_list_all,nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
														plt.plot(n_list_all,np.exp(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, *fit[0])),'--',label='total fit')
														plt.plot(n_list_all,np.exp(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, nH_ne,nHp_ne, *np.zeros_like(fit[0][2:]))),'+',label='excitation + recombination')
														plt.semilogy()
														plt.legend(loc='best', fontsize='x-small')
														plt.ylim(np.min(inverted_profiles_crop_restrict)/2,np.max(inverted_profiles_crop_restrict)*2)
														plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g eV, ' % merge_Te_prof_multipulse_interp_crop_limited_restrict + '%.3g #10^20/m^3]' % merge_ne_prof_multipulse_interp_crop_limited_restrict +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH+/ne, nH+/ne] , '+ '[%.3g, ' % nH_ne + '%.3g, ' % nHp_ne+ '%.3g, ' % nHm_ne+ '%.3g, ' % nH2_ne+ '%.3g, ' % nH2p_ne+ '%.3g]' % nH3p_ne)# +'\nweights '+str(n_weights))
														plt.xlabel('Exctited state n')
														plt.ylabel('Line emissivity n->2 [W m^-3]')
														# plt.pause(0.01)
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
														plt.close()
													elif True:
														plt.figure()
														if max_nHm_ne == 1 and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
															nH_ne, nHp_ne,nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = [*fit[0],0,0,0]
														elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
															nH_ne, nHp_ne,nH2_ne, nHm_ne, nH2p_ne, nH3p_ne = [*fit[0],0,0,0]
														elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
															nH_ne, nHp_ne,nH2p_ne, nHm_ne, nH2_ne, nH3p_ne = [*fit[0],0,0,0]
														elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == 1:
															nH_ne, nHp_ne, nH3p_ne,nHm_ne, nH2_ne, nH2p_ne = [*fit[0],0,0,0]
														elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
															nH_ne, nHp_ne, nH2_ne, nH2p_ne,nHm_ne, nH3p_ne = [*fit[0],0,0]
														elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
															nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = [*fit[0],0]
														elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == 1:
															nH_ne, nHp_ne, nH2_ne, nHm_ne, nH2p_ne, nH3p_ne = fit[0]
														# nH_ne, nHp_ne, nH2p_ne = fit[0]
														# nHp_ne = 1 + nHm_ne - nH2p_ne
														plt.plot(n_list_all,inverted_profiles_crop_restrict,label='OES')
														plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
														plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
														plt.plot(n_list_all,nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )[0]*(ne ** 2)*multiplicative_factor,label='mutual neutralisation\nH+ + H-  H(p) + H\nH2+ + H-  H(p) + H2')
														plt.plot(n_list_all,nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
														plt.plot(n_list_all,nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
														plt.plot(n_list_all,nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
														plt.plot(n_list_all,np.exp(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, *fit[0])),'--',label='total fit')
														plt.plot(n_list_all,np.exp(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, nH_ne,nHp_ne, *np.zeros_like(fit[0][2:]))),'+',label='excitation + recombination')
														plt.semilogy()
														plt.legend(loc='best', fontsize='x-small')
														plt.ylim(np.min(inverted_profiles_crop_restrict)/2,np.max(inverted_profiles_crop_restrict)*2)
														plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g eV, ' % merge_Te_prof_multipulse_interp_crop_limited_restrict + '%.3g #10^20/m^3]' % merge_ne_prof_multipulse_interp_crop_limited_restrict +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2/ne, nH2+/ne] , '+ '[%.3g, ' % nH_ne + '%.3g, ' % nHp_ne+ '%.3g, ' % nHm_ne+ '%.3g, ' % nH2_ne+ '%.3g, ' % nH2p_ne+ '%.3g]' % nH3p_ne)# +'\nweights '+str(n_weights))
														plt.xlabel('Exctited state n')
														plt.ylabel('Line emissivity n->2 [W m^-3]')
														# plt.pause(0.01)
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
														plt.close()
											if False:
												nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
												# nHp_ne_all[my_time_pos, my_r_pos] = 1 + fit[0][1] - fit[0][3]
												nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
												nHm_ne_all[my_time_pos, my_r_pos] = fit[0][2]
												nH2_ne_all[my_time_pos, my_r_pos] = fit[0][3]
												nH2p_ne_all[my_time_pos, my_r_pos] = fit[0][4]
												nH3p_ne_all[my_time_pos, my_r_pos] = fit[0][5]
											elif True:
												if max_nHm_ne == 1 and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = fit[0][2]
													nH2_ne_all[my_time_pos, my_r_pos] = 0
													nH2p_ne_all[my_time_pos, my_r_pos] = 0
													nH3p_ne_all[my_time_pos, my_r_pos] = 0
												elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = 0
													nH2_ne_all[my_time_pos, my_r_pos] = fit[0][2]
													nH2p_ne_all[my_time_pos, my_r_pos] = 0
													nH3p_ne_all[my_time_pos, my_r_pos] = 0
												elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = 0
													nH2_ne_all[my_time_pos, my_r_pos] = 0
													nH2p_ne_all[my_time_pos, my_r_pos] = fit[0][2]
													nH3p_ne_all[my_time_pos, my_r_pos] = 0
												elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == 1:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = 0
													nH2_ne_all[my_time_pos, my_r_pos] = 0
													nH2p_ne_all[my_time_pos, my_r_pos] = 0
													nH3p_ne_all[my_time_pos, my_r_pos] = fit[0][2]
												elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = 0
													nH2_ne_all[my_time_pos, my_r_pos] = fit[0][2]
													nH2p_ne_all[my_time_pos, my_r_pos] = fit[0][3]
													nH3p_ne_all[my_time_pos, my_r_pos] = 0
												elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = fit[0][2]
													nH2_ne_all[my_time_pos, my_r_pos] = fit[0][3]
													nH2p_ne_all[my_time_pos, my_r_pos] = fit[0][4]
													nH3p_ne_all[my_time_pos, my_r_pos] = 0
												elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													nH_ne_all[my_time_pos, my_r_pos] = fit[0][0]
													nHp_ne_all[my_time_pos, my_r_pos] = fit[0][1]
													nHm_ne_all[my_time_pos, my_r_pos] = fit[0][2]
													nH2_ne_all[my_time_pos, my_r_pos] = fit[0][3]
													nH2p_ne_all[my_time_pos, my_r_pos] = fit[0][4]
													nH3p_ne_all[my_time_pos, my_r_pos] = fit[0][5]

											# if np.sum(fit[1] == 0) == len(fit[0]) ** 2:
											# 	residuals_all[my_time_pos, my_r_pos] = 0
											# else:
											residuals_all[my_time_pos, my_r_pos] = np.sum(((np.log(inverted_profiles_crop_restrict) - fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor)(n_list_all, *fit[0]))) ** 2)
								else:	# multiprocessor way

									class calc_stuff_output:
										def __init__(self, my_time_pos,my_r_pos, results):
											self.my_time_pos = my_time_pos
											self.my_r_pos = my_r_pos
											self.results = results


									def calc_stuff(arg):
										index = arg[0]
										my_time_pos = arg[1]
										my_r_pos = arg[2]
										pass_index = arg[3]
										guess = arg[4]

										inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
										inverted_profiles_crop_sigma_restrict = inverted_profiles_sigma_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
										merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
										merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop_limited[my_time_pos, my_r_pos].flatten()
										recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
										excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

										if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
											results = [0, 0, 0, 0, 0, 0,0]
											output = calc_stuff_output(my_time_pos,my_r_pos, results)
											return output

										# if np.sum(inverted_profiles_crop_restrict == 0)>2:
										# 	continue

										if False:
											T_Hp = 12000	# K
											T_Hm = 12000	# K
											T_H2p = 5000	# K
										else:
											T_Hp = min(max(1000,merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K),12000)	# K
											T_Hm = 5000	# K
											T_H2p = 5000	# K
										ne = merge_ne_prof_multipulse_interp_crop_limited_restrict * 1e20
										multiplicative_factor = energy_difference[n_list_all - 4] * einstein_coeff[n_list_all - 4] / J_to_eV

										if ionization_length[my_time_pos, my_r_pos]<=0.5:
											max_nmolecules_ne_low_ionisation_length = 0.0005
											max_nH2_from_pressure_int = ne/10
										else:
											max_nmolecules_ne_low_ionisation_length = 1
											max_nH2_from_pressure_int = max_nH2_from_pressure*1

										if atomic_restricted_high_n ==True:
											def fit_Yacora_pop_coeff_prelim(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne):
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													return np.log(total)
												return calculated_emission
											guess_prelim=[min_nH_ne,1]
											bds_prelim = [[min_nH_ne, min_nHp_ne],
												   [max_n_neutrals_ne, max_nHp_ne]]


										if max_nHm_ne == min_multiplier and max_nH2_ne==min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne],
												   [max_n_neutrals_ne, max_nHp_ne]]
										elif max_nHm_ne == 1 and max_nH2_ne==min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne):
													nH2p_ne=0
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne, 0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nmolecules_ne_low_ionisation_length]]
										elif max_nHm_ne == min_multiplier and max_nH2_ne==1 and max_nH2p_ne == min_multiplier and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nH2_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission

											bds = [[min_nH_ne, min_nHp_ne, 0],
											   	[max_n_neutrals_ne, max_nHp_ne, max_nH2_from_pressure_int/ne]]
										elif max_nHm_ne == min_multiplier and max_nH2_ne==min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nH2p_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne, 0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nmolecules_ne_low_ionisation_length]]
										elif max_nHm_ne == min_multiplier and max_nH2_ne==min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne==1:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nH3p_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													# total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne, 0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nmolecules_ne_low_ionisation_length]]
										elif max_nHm_ne == 1 and max_nH2_ne==1 and max_nH2p_ne == min_multiplier and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne):
													nH2p_ne=0
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne, 0, 0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nmolecules_ne_low_ionisation_length, max_nH2_from_pressure_int/ne]]
										elif max_nHm_ne == min_multiplier and max_nH2_ne==1 and max_nH2p_ne == 1 and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nH2_ne,nH2p_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne, 0,0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nH2_from_pressure_int/ne,max_nmolecules_ne_low_ionisation_length]]
										elif max_nHm_ne == 1 and max_nH2_ne==1 and max_nH2p_ne == 1 and max_nH3p_ne==min_multiplier:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													# total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne,0, 0,0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nmolecules_ne_low_ionisation_length, max_nH2_from_pressure_int/ne,max_nmolecules_ne_low_ionisation_length]]
										elif max_nHm_ne == 1 and max_nH2_ne==1 and max_nH2p_ne == 1 and max_nH3p_ne==1:
											def fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict):
												def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
													# nHp_ne=1+nHm_ne-nH2p_ne
													total = np.array([(excitation_restrict *  nH_ne /multiplicative_factor).astype('float')])
													total += np.array([(recombination_restrict * nHp_ne /multiplicative_factor).astype('float')])
													# total = nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
													# total += nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
													total += nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total += nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)
													total = total[0]*(ne ** 2)*multiplicative_factor
													# print(total)
													return np.log(total)
												return calculated_emission
											bds = [[min_nH_ne, min_nHp_ne,0, 0,0,0],
												   [max_n_neutrals_ne, max_nHp_ne, max_nmolecules_ne_low_ionisation_length, max_nH2_from_pressure_int/ne,max_nmolecules_ne_low_ionisation_length,max_nmolecules_ne_low_ionisation_length]]
										# guess = [0.1, 1, 0.01, 0.1, 0.0001, 0.0001]
										# guess = [0.1, 1, 0.01*max_nHm_ne, 0.1*max_nH2_ne, 0.0001*max_nH2p_ne, 0.0001*max_nH3p_ne]
										# n_weights_actual = np.array(n_weights) * inverted_profiles_crop_restrict / inverted_profiles_crop_restrict[0]

										for index in range(len(guess)):
											guess[index]=min(max(guess[index],bds[0][index]),bds[1][index])

										# n_weights_actual = np.array(n_weights) * np.log(inverted_profiles_crop_restrict)/10
										n_weights_actual = np.array(inverted_profiles_crop_sigma_restrict)*n_weights

										try:
											if atomic_restricted_high_n ==False:
												fit = curve_fit(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
													merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp, T_Hm, T_H2p, ne, multiplicative_factor,excitation_restrict,recombination_restrict),
													n_list_all, np.log(inverted_profiles_crop_restrict), p0=guess, bounds=bds,sigma=n_weights_actual, absolute_sigma=True, maxfev=1000000,x_scale = guess,xtol=1e-15)
											else:
												fit = curve_fit(fit_Yacora_pop_coeff_prelim(merge_ne_prof_multipulse_interp_crop_limited_restrict,
													merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp, T_Hm, T_H2p, ne, multiplicative_factor[n_list_all>=8],excitation_restrict[n_list_all>=8],recombination_restrict[n_list_all>=8]),
													n_list_all[n_list_all>=8], np.log(inverted_profiles_crop_restrict[n_list_all>=8]), p0=guess_prelim, bounds=bds_prelim,sigma=n_weights_actual[n_list_all>=8], maxfev=1000000)
												if fit[0][1]>=0.999:
													fit[0][1] = 1
												bds[0][:2] = fit[0][0]*0.9999999, fit[0][1]*0.9999999
												bds[1][:2] = fit[0][0]*1, fit[0][1]*1
												guess[:2] = fit[0][0]*1, fit[0][1]*1
												fit = curve_fit(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,
													merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp, T_Hm, T_H2p, ne, multiplicative_factor,excitation_restrict,recombination_restrict),
													n_list_all, np.log(inverted_profiles_crop_restrict), p0=guess, bounds=bds,sigma=n_weights_actual, absolute_sigma=True, maxfev=1000000)
										except Exception as e:
											print('fit at time index %.3g, radious index %.3g failed for reason %s' %(my_time_pos,my_r_pos,e))
											fit = [guess,np.ones((len(guess),len(guess)))]


										if max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne,nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = [*fit[0],0,0,0,0]
											nH_ne_sigma, nHp_ne_sigma,nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1,1,1]
										elif max_nHm_ne == 1 and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne,nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = [*fit[0],0,0,0]
											nH_ne_sigma, nHp_ne_sigma,nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1,1]
										elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne,nH2_ne, nHm_ne, nH2p_ne, nH3p_ne = [*fit[0],0,0,0]
											nH_ne_sigma, nHp_ne_sigma,nH2_ne_sigma, nHm_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1,1]
										elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne,nH2p_ne, nHm_ne, nH2_ne, nH3p_ne = [*fit[0],0,0,0]
											nH_ne_sigma, nHp_ne_sigma,nH2p_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1,1]
										elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == 1:
											nH_ne, nHp_ne, nH3p_ne,nHm_ne, nH2_ne, nH2p_ne = [*fit[0],0,0,0]
											nH_ne_sigma, nHp_ne_sigma, nH3p_ne_sigma,nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1,1]
										elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne, nH2_ne, nH2p_ne,nHm_ne, nH3p_ne = [*fit[0],0,0]
											nH_ne_sigma, nHp_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma,nHm_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1]
										elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = [*fit[0],0,0]
											nH_ne_sigma, nHp_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1,1]
										elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
											nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = [*fit[0],0]
											nH_ne_sigma, nHp_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = [*np.sqrt(np.diag(fit[1])),1]
										elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == 1:
											nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = fit[0]
											nH_ne_sigma, nHp_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = np.sqrt(np.diag(fit[1]))
										residuals = np.sum(((np.log(inverted_profiles_crop_restrict) - fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, *fit[0]))) ** 2)

										if int(time_crop[my_time_pos]*100) in np.array([0.2,0.4,0.6,0.8])*100:
											if r_crop[my_r_pos] in r_crop[[0,10,20,30]]:
												tm.sleep(np.random.random()*10)
												plt.figure()
												# nH_ne, nHp_ne, nH2p_ne = fit[0]
												# nHp_ne = 1 + nHm_ne - nH2p_ne
												plt.errorbar(n_list_all,inverted_profiles_crop_restrict,yerr=n_weights_actual,label='OES')
												plt.plot(n_list_all,(excitation_restrict *  nH_ne).astype('float')*(ne ** 2),label='direct excitation\nH(q) + e-  H(p>q) + e- (ADAS coeff)')
												plt.plot(n_list_all,(recombination_restrict * nHp_ne).astype('float')*(ne ** 2),label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e- (ADAS coeff)')
												# plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
												# plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
												plt.plot(n_list_all,nHm_ne*( From_Hn_with_Hp_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) )[0]*(ne ** 2)*multiplicative_factor,label='H+ mutual neutralisation\nH+ + H-  H(p) + H')
												plt.plot(n_list_all,nHm_ne*( From_Hn_with_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )[0]*(ne ** 2)*multiplicative_factor,label='H2+ mutual neutralisation\nH2+ + H-  H(p) + H2')
												plt.plot(n_list_all,nH2_ne*From_H2_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
												plt.plot(n_list_all,nH2p_ne*From_H2p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
												plt.plot(n_list_all,nH3p_ne*From_H3p_pop_coeff_full([[merge_Te_prof_multipulse_interp_crop_limited_restrict,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
												plt.plot(n_list_all,np.exp(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, *fit[0])),'--',label='total fit')
												plt.plot(n_list_all,np.exp(fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, nH_ne,nHp_ne, *np.zeros_like(fit[0][2:]))),'+',label='excitation + recombination')
												plt.semilogy()
												plt.legend(loc='best', fontsize='x-small')
												plt.ylim(np.min(inverted_profiles_crop_restrict)/2,np.max(inverted_profiles_crop_restrict)*2)
												plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g eV, ' % merge_Te_prof_multipulse_interp_crop_limited_restrict + '%.3g #10^20/m^3]' % merge_ne_prof_multipulse_interp_crop_limited_restrict +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % nH_ne + '%.3g, ' % nHp_ne+ '%.3g, ' % nHm_ne+ '%.3g, ' % nH2_ne+ '%.3g, ' % nH2p_ne+ '%.3g]' % nH3p_ne +'\nH ionization length %.3gm' % ionization_length[my_time_pos, my_r_pos])# +'\nweights '+str(n_weights))
												plt.xlabel('Exctited state n')
												plt.ylabel('Line emissivity n->2 [W m^-3]')
												# plt.pause(0.01)
												save_done = 0
												save_index=1
												try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
													plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
												except Exception as e:
													print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(1)+' failed. Reason %s' % e)
													while save_done==0 and save_index<100:
														try:
															tm.sleep(np.random.random()**2)
															plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
															print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' successfull')
															save_done=1
														except Exception as e:
															# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
															save_index+=1
												plt.close()

										results = [nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne,residuals]

										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output

									if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results.npz') ) or recorded_data_override[0] ):

										all_indexes = []
										global_index = 0
										for my_time_pos in range(len(time_crop)):
											for my_r_pos in range(len(r_crop)):
												all_indexes.append([global_index,my_time_pos,my_r_pos,1,guess])
												global_index+=1

										pool = Pool(number_cpu_available)
										all_results = [*pool.map(calc_stuff, all_indexes)]
										pool.close()
										pool.join()
										pool.terminate()
										del pool

										for i in range(len(all_results)):
											nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
											nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
											nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
											nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
											nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
											nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
											residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]


										np.savez_compressed(path_where_to_save_everything + mod4 +'/results',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all)
									else:
										nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH_ne_all']
										nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nHp_ne_all']
										nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nHm_ne_all']
										nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH2_ne_all']
										nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH2p_ne_all']
										nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH3p_ne_all']
										residuals_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['residuals_all']

									global_pass = 1
									exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())


									if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results_2.npz') ) or recorded_data_override[1] ):

										if False:
											nH_ne_all = medfilt(nH_ne_all,[3,15])
											nHp_ne_all = medfilt(nHp_ne_all,[3,7])
											nHm_ne_all = medfilt(nHm_ne_all,[3,5])
											nH2_ne_all = medfilt(nH2_ne_all,[3,7])
											nH2p_ne_all = medfilt(nH2p_ne_all,[3,5])
											nH3p_ne_all = medfilt(nH3p_ne_all,[3,5])
										else:
											nH_ne_all = convolve(nH_ne_all,np.ones((3,15))/np.sum(np.ones((3,15))),mode='constant', cval=0.0)
											nHp_ne_all = convolve(nHp_ne_all,np.ones((3,15))/np.sum(np.ones((3,15))),mode='constant', cval=0.0)
											nHm_ne_all = convolve(nHm_ne_all,np.ones((3,3))/np.sum(np.ones((3,3))),mode='constant', cval=0.0)
											nH2_ne_all = medfilt(nH2_ne_all,[3,7])
											nH2p_ne_all = convolve(nH2p_ne_all,np.ones((3,3))/np.sum(np.ones((3,3))),mode='constant', cval=0.0)
											nH3p_ne_all = convolve(nH3p_ne_all,np.ones((3,3))/np.sum(np.ones((3,3))),mode='constant', cval=0.0)

										global_pass = 2
										exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())


										all_indexes = []
										global_index = 0
										for my_time_pos in range(len(time_crop)):
											for my_r_pos in range(len(r_crop)):
												if max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												if max_nHm_ne == 1 and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == 1:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH3p_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1
												elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == 1:
													all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos],nH3p_ne_all[my_time_pos,my_r_pos]]])
													global_index+=1

										pool = Pool(number_cpu_available)
										all_results = [*pool.map(calc_stuff, all_indexes)]
										pool.close()
										pool.join()
										pool.terminate()
										del pool

										for i in range(len(all_results)):
											nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
											nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
											nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
											nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
											nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
											nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
											residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]


										np.savez_compressed(path_where_to_save_everything + mod4 +'/results_2',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all)
									else:
										nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH_ne_all']
										nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nHp_ne_all']
										nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nHm_ne_all']
										nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH2_ne_all']
										nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH2p_ne_all']
										nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH3p_ne_all']
										residuals_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['residuals_all']


								# plt.figure()
								# plt.title('ne,Te,nH_ne,h_atomic_density,OES_multiplier\n'+str([*merge_ne_prof_multipulse_interp_crop_limited_restrict,*merge_Te_prof_multipulse_interp_crop_limited_restrict,*fit[0],OES_multiplier]))
								# plt.plot(n_list,inverted_profiles_crop_restrict*OES_multiplier)
								# plt.plot(n_list,fit_nH_ne_h_atomic_density(recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list,*fit[0]))
								# plt.pause(0.01)

								global_pass = 3
								exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())
elif True:  # absolute intensity fit with Yacora coefficients, Bayesian aproach suggested by Kevin

	# for merge_ID_target in [851,86,87,89,92]:	# 88 excluded because I don't have a temperature profile
	# 	merge_time_window = [-10, 10]
	# for merge_ID_target in [ 93, 94]:  # 88 excluded because I don't have a temperature profile
	# 	merge_time_window = [-1,2]

	# merge_ID_target_multipulse = np.flip([851,86,87,89,92, 93, 94],axis=0)
	# merge_ID_target_multipulse = np.flip([73,77,78,79,85, 95, 86, 87, 88, 89, 92, 93, 94, 96, 97, 98, 99],axis=0)
	# merge_ID_target_multipulse = [85, 95, 86, 87, 88, 89, 92, 93, 94, 96, 97, 98, 99]
	# merge_ID_target_multipulse = np.flip([86, 87, 88, 89, 92, 93, 94, 96, 97, 98, 99],axis=0)
	# merge_ID_target_multipulse = np.flip([95, 86, 87, 88, 89, 92, 93, 94, 96, 97, 98, 88],axis=0)
	# merge_ID_target_multipulse = np.flip([95, 94, 93, 92, 89, 87, 86, 85],axis=0)
	# merge_ID_target_multipulse = [73,77,78,79]
	# merge_ID_target_multipulse = np.flip([99,85,97,89,92, 93,95],axis=0)
	merge_ID_target_multipulse = [89]

	for merge_ID_target in merge_ID_target_multipulse:  # 88 excluded because I don't have a temperature profile
		merge_time_window = [-1,2]
		# if (merge_ID_target>=93 and merge_ID_target<100):
		# 	merge_time_window = [-1,2]
		# else:
		# 	merge_time_window = [-10,10]


		# recorded_data_override = [True,True,True]
		recorded_data_override = [False,False,False]
		# recorded_data_override = [True,True]
		do_only_one_loop = True
		include_particles_limitation = True

		# merge_ID_target = 85

		# for min_nHp_ne,atomic_restricted_high_n in [[0.999,False],[0.8,False],[0.999,True],[0.3,False],[0,False]]:	#0.9999 is for the case when I relax this boundary if nH<0.001
		# for min_nHp_ne,atomic_restricted_high_n in [[0.999,False],[0.999,True],[0.01,True]]:
		for min_nHp_ne,atomic_restricted_high_n in [[0.01,True]]:

			# for max_n_neutrals_ne in [1,2,10,100]:
			for max_n_neutrals_ne in [1]:

				figure_index = 0

				# calculate_geometry = False
				# merge_ID_target = 17	#	THIS IS GIVEN BY THE LAUNCHER
				for i in range(10):
					print('.')
				print('Starting to work on merge number ' + str(merge_ID_target))
				print('of requested '+str(merge_ID_target_multipulse))
				for i in range(10):
					print('.')

				time_resolution_scan = False
				time_resolution_scan_improved = True
				time_resolution_extra_skip = 0

				if False:
					n_list = np.array([5, 6, 7,8, 9,10,11,12])
					n_list_1 = np.array([4])
					n_weights = [1, 1, 1, 1, 1, 1,3,1,1]
				elif False:
					n_list = np.array([5, 6, 7,8, 9,10])
					n_list_1 = np.array([4])
					n_weights = [1, 1, 1, 1, 1, 1,3]
				elif False:
					n_list = np.array([6,7,8,9])
					n_list_1 = np.array([4,5])
					n_weights = [1, 1, 1, 1,1, 3,3]
				else:
					n_list = np.array([6,7,8])
					n_list_1 = np.array([4,5])
					n_weights = [1, 1, 1, 1,1, 3]
				# for index in (n_list_1 - 4):
				# 	n_weights[index] = 4
				# n_weights[np.max(n_list_1) - 3] = 2
				# min_nH_ne = 0.6

				max_nHp_ne = 1
				min_nH_ne = 0

				mod_atomic_restricted_high_n = ''
				if atomic_restricted_high_n ==True:
					mod_atomic_restricted_high_n = '_atomic_restricted_high_n'
					print('calculus of nH and nH+ limited to lines >=8')

				mod = '/Yacora_Bayesian/absolute/lines_fitted'+str(len(n_list)+len(n_list_1))+'/fit_bounds_from_sims'

				boltzmann_constant_J = 1.380649e-23	# J/K
				eV_to_K = 8.617333262145e-5	# eV/K
				avogadro_number = 6.02214076e23
				hydrogen_mass = 1.008*1.660*1e-27	# kg
				electron_mass = 9.10938356* 1e-31	# kg
				ionisation_potential = 13.6	# eV
				dissociation_potential = 2.2	# eV

				# here I determine the standard time shift between TS and power source
				if merge_ID_target in [851,85,86,87,88,89,90,91,92,93,94,95]:
					shift_TS_to_power_source = shift_between_TS_and_power_source(95)
					print('standard time shift between TS and power source of %.3gms from %.5g' %(shift_TS_to_power_source,95))
				elif merge_ID_target in [37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,54,96,97,98,99]:
					shift_TS_to_power_source = shift_between_TS_and_power_source(99)
					print('standard time shift between TS and power source of %.3gms from %.5g' %(shift_TS_to_power_source,99))
				elif merge_ID_target in [74,75,76,77,78,79,80,81,82,83,84,101]:
					shift_TS_to_power_source = shift_between_TS_and_power_source(101)
					print('standard time shift between TS and power source of %.3gms from %.5g' %(shift_TS_to_power_source,101))
				elif merge_ID_target in [66,67,68,69,71,72,73,70]:
					shift_TS_to_power_source = shift_between_TS_and_power_source(70)
					print('standard time shift between TS and power source of %.3gms from %.5g' %(shift_TS_to_power_source,70))
				else:
					print('There is an error, the reference shot for TS/power source shift was not given')
					exit()

				all_j=find_index_of_file(merge_ID_target,df_settings,df_log,only_OES=True)
				target_chamber_pressure = []
				target_OES_distance = []
				feed_rate_SLM = []
				capacitor_voltage = []
				magnetic_field = []
				power_pulse_shape_time_dependent = []
				power_pulse_shape_time_dependent_std = []
				steady_state_power = []
				steady_state_power_std = []
				energy_delivered_good_pulses = []
				for j in all_j:
					target_chamber_pressure.append(df_log.loc[j,['p_n [Pa]']])
					target_OES_distance.append(df_log.loc[j,['T_axial']])
					feed_rate_SLM.append(df_log.loc[j,['Seed']])
					capacitor_voltage.append(df_log.loc[j,['Vc']])
					magnetic_field.append(df_log.loc[j,['B']])
					(merge_folder,sequence,fname_current_trace) = df_log.loc[j,['folder','sequence','current_trace_file']]
					sequence = int(sequence)
					bad_pulses,first_good_pulse,first_pulse,last_pulse,miss_pulses,double_pulses,good_pulses, time_of_pulses, energy_per_pulse,duration_per_pulse,median_energy_delivered_good_pulses,median_duration_good_pulses,mean_peak_shape,mean_peak_std,mean_steady_state_power,mean_steady_state_power_std,time_resolution = examine_current_trace(fdir+'/'+merge_folder+'/'+"{0:0=2d}".format(sequence)+'/', fname_current_trace, df_log.loc[j, ['number_of_pulses']][0],want_the_power_per_pulse=True,want_the_mean_power_profile=True)
					energy_delivered_good_pulses.append(median_energy_delivered_good_pulses)
					power_pulse_shape_time_dependent.append(mean_peak_shape)
					power_pulse_shape_time_dependent_std.append(mean_peak_std)
					steady_state_power.append(mean_steady_state_power)
					steady_state_power_std.append(mean_steady_state_power_std)
					target_material = df_log.loc[j,['Target']][0]
				target_chamber_pressure = np.nanmean(target_chamber_pressure)	# Pa
				target_OES_distance = np.nanmean(target_OES_distance)	# Pa
				feed_rate_SLM = np.nanmean(feed_rate_SLM)	# SLM
				capacitor_voltage = np.nanmean(capacitor_voltage)	# V
				magnetic_field = np.nanmean(magnetic_field)	# T
				energy_delivered_good_pulses = np.nanmean(energy_delivered_good_pulses)	# J
				# power_pulse_shape = np.sum(np.divide(power_pulse_shape,power_pulse_shape_std),axis=0)/np.sum(np.divide(1,power_pulse_shape_std),axis=0)
				power_pulse_shape_time_dependent = np.mean(power_pulse_shape_time_dependent,axis=0)
				power_pulse_shape_time_dependent_std = np.sum(0.25*np.array(power_pulse_shape_time_dependent_std)**2,axis=0)**0.5
				# steady_state_power = np.sum(np.divide(steady_state_power,steady_state_power_std),axis=0)/np.sum(np.divide(1,power_pulse_shape_std),axis=0)
				steady_state_power = np.mean(steady_state_power,axis=0)
				steady_state_power_std = np.sum(0.25*np.array(steady_state_power_std)**2,axis=0)**0.5
				power_pulse_shape =power_pulse_shape_time_dependent + steady_state_power
				power_pulse_shape_std = (power_pulse_shape_time_dependent_std**2+steady_state_power_std**2)**0.5
				# time_source_power = np.arange(len(power_pulse_shape))*time_resolution*1000 - 49.945	# 49.945 comes from TS-current trace comparison.py using merge 75 and 95
				time_source_power = np.arange(len(power_pulse_shape))*time_resolution*1000 - shift_TS_to_power_source	# this way because the time vary with magnetic field, probably because resulting in different sound speed
				interpolated_power_pulse_shape = interp1d(time_source_power,power_pulse_shape)
				interpolated_power_pulse_shape_std = interp1d(time_source_power,power_pulse_shape_std)
				# Ideal gas law
				nH2_from_pressure = target_chamber_pressure/(boltzmann_constant_J*300)	# [#/m^3] I suppose ambient temp is ~ 300K

				print('lines')
				print(str(n_list_1.tolist()+n_list.tolist()))
				print('min_nHp/ne')
				print(min_nHp_ne)
				print('max_nH/ne')
				print(max_n_neutrals_ne)
				print('steady state nH2 [#/m^3]')
				print(nH2_from_pressure)
				print("considering that it's a transient phenomena the istantaneous max_nH2 bound is *10/*0.1 times that")
				if False:	# I cannot assume a constant temperature, so I use a simple model in the target chamber heating to estimate the max H2 density.
					max_nH2_from_pressure = 10*max_nH2_from_pressure
					print("considering that it's a transient phenomena the istantaneous max_nH2 is set 10 times higher to [#/m^3]")
					print(max_nH2_from_pressure)
				print('max_nHp/ne')
				print(max_nHp_ne)
				print('n_weights')
				print(n_weights)
				print('recorded data override is '+str(recorded_data_override))
				fixed_fractions_nHm_H2p = [1/4,1,4]
				max_frac_acceptable_deviation_ext = 0.08	#0.07
				print('the fixed values of nH-/nH2+ tested are '+str(fixed_fractions_nHm_H2p)+' +/-'+str(max_frac_acceptable_deviation_ext*100)+'%')
				min_mol_fraction_ext = 1e-6
				print('minimum molecular fraction to give significant effect on emission taken as '+str(min_mol_fraction_ext))
				collect_power_PDF = True
				print('Will power PDF be collected? '+str(collect_power_PDF))
				print('Will particles banace be included? '+str(include_particles_limitation))
				timeout_bayesian_search = 60*60	# time in seconds
				print('Timeout for bayesian search of a single point %.3g min' %(timeout_bayesian_search/60))
				power_molecular_precision,power_atomic_precision,power_budget_precision = 0.5,0.2,0.5
				print('precision (sigma) for molecular elements of power balance %.3g%%, for atomic elements %.3g%%, for the budget %.3g%%' %(power_molecular_precision*100,power_atomic_precision*100,power_budget_precision*100))
				particle_molecular_precision,particle_atomic_precision,particle_molecular_budget_precision,particle_atomic_budget_precision = 0.5,0.2,0.2,0.5
				if include_particles_limitation:
					print('precision (sigma) for molecular elements of particle balance %.3g%%, for atomic elements %.3g%%, for the molecular budget %.3g%%, for the atomic budget %.3g%%' %(particle_molecular_precision*100,particle_atomic_precision*100,particle_molecular_budget_precision*100,particle_atomic_budget_precision*100))

				started = 0
				rows_range_for_interp = 25 / 3  # rows that I use for interpolation (box with twice this side length, not sphere)
				# if merge_ID_target>=66:
				# 	rows_range_for_interp = geom_store['binInterv'][0] / 6
				if time_resolution_scan:
					conventional_time_step = 0.01  # ms
				else:
					conventional_time_step = 0.05  # ms
				# interpolation_type = 'quadratic'	# 'linear' or 'quadratic'
				grade_of_interpolation = 3  # this is the exponent used for the weights of the interpolation for image resampling
				type_of_image = '12bit'  # '12bit' or '16bit'
				# if type_of_image=='12bit':
				row_shift = 2 * 10280 / 1000000  # ms
				# elif type_of_image=='16bit':
				# 	print('Row shift to be checked')
				# 	exit()
				# time_range_for_interp = rows_range_for_interp*row_shift
				# merge_time_window=[-1,4]
				overexposed_treshold = 3600
				path_where_to_save_everything = '/home/ffederic/work/Collaboratory/test/experimental_data/merge' + str(merge_ID_target) #+ '_back'

				if not os.path.exists(path_where_to_save_everything + mod):
					os.makedirs(path_where_to_save_everything + mod)

				# new_timesteps = np.linspace(merge_time_window[0] + 0.5, merge_time_window[1] - 0.5, int(
				# 	(merge_time_window[1] - 0.5 - (merge_time_window[0] + 0.5)) / conventional_time_step + 1))
				# dt = np.nanmedian(np.diff(new_timesteps))

				# for spatial_factor in spatial_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				# dx = (18 / 40 * (50.5 / 27.4) / 1e3) * spatial_factor
				# xx = np.arange(40) * dx  # m
				# xn = np.linspace(0, max(xx), 1000)
				# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
				# r=r[::10]
				# dr=np.median(np.diff(r))

				# first_time = np.min(new_timesteps)
				# last_time = np.max(new_timesteps)

				# Data from wikipedia
				energy_difference = np.array([2.54970, 2.85567, 3.02187, 3.12208, 3.18716, 3.23175, 3.26365, 3.28725, 3.30520])  # eV
				energy_difference_full = np.array([10.1988,1.88867, 2.54970, 2.85567, 3.02187, 3.12208, 3.18716, 3.23175, 3.26365, 3.28725, 3.30520, 3.31917])  # eV
				# Data from "Accurate Atomic Transition Probabilities for Hydrogen, Helium, and Lithium", W. L. Wiese and J. R. Fuhr 2009
				statistical_weigth = np.array([32, 50, 72, 98, 128, 162, 200, 242, 288])  # gi-gk
				einstein_coeff = np.array([8.4193e-2, 2.53044e-2, 9.7320e-3, 4.3889e-3, 2.2148e-3, 1.2156e-3, 7.1225e-4, 4.3972e-4, 2.8337e-4]) * 1e8  # 1/s
				einstein_coeff_full = np.array([4.6986e+00, 4.4101e-01, 8.4193e-2, 2.53044e-2, 9.7320e-3, 4.3889e-3, 2.2148e-3, 1.2156e-3, 7.1225e-4, 4.3972e-4, 2.8337e-4, 1.8927e-04]) * 1e8  # 1/s
				einstein_coeff_full_full = np.array([[4.6986,5.5751e-01,1.2785e-01,4.1250e-02,1.6440e-02,7.5684e-03,3.8694e-03,2.1425e-03,1.2631e-03,7.8340e-04,5.0659e-04,3.3927e-04],[0,0.44101,0.084193,0.0253044,0.009732,0.0043889,0.0022148,0.0012156,0.00071225,0.00043972,0.00028337,0.00018927],[0,0,8.9860e-02,2.2008e-02,7.7829e-03,3.3585e-03,1.6506e-03,8.9050e-04,5.1558e-04,3.1558e-04,2.0207e-04,1.3431e-04],[0,0,0,2.6993e-02,7.7110e-03,3.0415e-03,1.4242e-03,7.4593e-04,4.2347e-04,2.5565e-04,1.6205e-04,1.0689e-04],[0,0,0,0,1.0254e-02,3.2528e-03,1.3877e-03,6.9078e-04,3.7999e-04,2.2460e-04,1.4024e-04,9.1481e-05],[0,0,0,0,0,4.5608e-03,1.5609e-03,7.0652e-04,3.6881e-04,2.1096e-04,1.2884e-04,8.2716e-05],[0,0,0,0,0,0,2.2720e-03,8.2370e-04,3.9049e-04,2.1174e-04,1.2503e-04,7.8457e-05],[0,0,0,0,0,0,0,1.2328e-03,4.6762e-04,2.3007e-04,1.2870e-04,7.8037e-05],[0,0,0,0,0,0,0,0,7.1514e-04,2.8131e-04,1.4269e-04,8.1919e-05],[0,0,0,0,0,0,0,0,0,4.3766e-04,1.7740e-04,9.2309e-05],[0,0,0,0,0,0,0,0,0,0,2.7989e-04,1.1633e-04],[0,0,0,0,0,0,0,0,0,0,0,1.8569e-04]]) * 1e8  # 1/s
				level_1 = (np.ones((13,13))*np.arange(1,14)).T
				level_2 = (np.ones((13,13))*np.arange(1,14))
				energy_difference_full_full = 1/level_1**2-1/level_2**2
				energy_difference_full_full = 13.6*energy_difference_full_full[:-1,1:]
				energy_difference_full_full[energy_difference_full_full<0]=0
				J_to_eV = 6.242e18
				multiplicative_factor_full_full = np.sum(energy_difference_full_full * einstein_coeff_full_full / J_to_eV,axis=0)
				au_to_kg = 1.66053906660e-27	# kg/au
				# Used formula 2.3 in Rion Barrois thesys, 2017
				color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro','paleturquoise']

				inverted_profiles_original = 4 * np.pi * np.load(path_where_to_save_everything + '/inverted_profiles.npy')  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				inverted_profiles_sigma_original = 4 * np.pi * np.load(path_where_to_save_everything + '/inverted_profiles_sigma.npy')  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
				all_fits = np.load(path_where_to_save_everything + '/merge' + str(merge_ID_target) + '_all_fits.npy')  # in W m^-2 sr^-1
				merge_Te_prof_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_Te_prof_multipulse']
				merge_dTe_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_dTe_multipulse']
				merge_ne_prof_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_ne_prof_multipulse']
				merge_dne_multipulse = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_dne_multipulse']
				merge_time_original = np.load(path_where_to_save_everything + '/TS_data_merge_' + str(merge_ID_target) + '.npz')['merge_time']
				# new_timesteps = np.load(path_where_to_save_everything + '/merge' + str(merge_ID_target) + '_new_timesteps.npy')
				new_timesteps = np.linspace(-0.5,1.5,num=41)
				dt = np.nanmedian(np.diff(new_timesteps))

				# for time_shift_factor in time_shift_factor_all:
				#
				# 	mod = '/spatial_factor' + str(spatial_factor)+'/time_shift_factor' + str(time_shift_factor)
				# 	if not os.path.exists(path_where_to_save_everything + mod):
				# 		os.makedirs(path_where_to_save_everything + mod)

				# for spatial_factor in [1,1.1,1.2,1.3,1.4,1.5]:
				for spatial_factor in [1]:
					# for time_shift_factor in [-0.1,-0.05,0,0.05]:
					for time_shift_factor in [0]:
						mod2 = mod + '/spatial_factor_' + str(spatial_factor) + '/time_shift_factor_' + str(time_shift_factor)

						if not os.path.exists(path_where_to_save_everything + mod2):
							os.makedirs(path_where_to_save_everything + mod2)

						# dx = 18 / 40 * (50.5 / 27.4) / 1e3
						dx = 1.06478505470992 / 1e3	# 10/02/2020 from	Calculate magnification_FF.xlsx
						xx = np.arange(40) * dx  # m
						xn = np.linspace(0, max(xx), 1000)
						# r = np.linspace(-max(xx) / 2, max(xx) / 2, 1000)
						# r = r[::10]
						# dr = np.median(np.diff(r))
						number_of_radial_divisions = np.shape(inverted_profiles_original)[-1]
						r = np.arange(number_of_radial_divisions)*dx
						dr = np.median(np.diff(r))

						merge_time = time_shift_factor + merge_time_original
						inverted_profiles = (1 / spatial_factor) * inverted_profiles_original  # in W m^-3 sr^-1  *  4*pi sr  =  W m^-3
						inverted_profiles_sigma = cp.deepcopy(inverted_profiles_sigma_original)
						TS_dt = np.nanmedian(np.diff(merge_time))

						if (np.max(merge_Te_prof_multipulse) <= 0) and merge_ID_target!=88 :
							print('merge' + str(merge_ID_target) + " has no recorded temperature")
							continue

						TS_size = [-4.149230769230769056e+01, 4.416923076923076508e+01]
						TS_r = TS_size[0] + np.linspace(0, 1, 65) * (TS_size[1] - TS_size[0])
						TS_dr = np.median(np.diff(TS_r)) / 1000
						gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
						profile_centres = []
						profile_sigma = []
						profile_centres_score = []
						for index in range(np.shape(merge_ne_prof_multipulse)[0]):
							yy = merge_ne_prof_multipulse[index]
							yy_sigma = merge_dne_multipulse[index]
							yy_sigma[np.isnan(yy_sigma)]=np.nanmax(yy_sigma)
							if np.sum(yy>0)<5:
								profile_centres.append(0)
								profile_sigma.append(10)
								profile_centres_score.append(np.max(TS_r))
								continue
							yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
							p0 = [np.max(yy), 10, 0]
							bds = [[0, 0, np.min(TS_r)], [np.inf, TS_size[1], np.max(TS_r)]]
							fit = curve_fit(gauss, TS_r, yy, p0, sigma=yy_sigma, maxfev=100000, bounds=bds)
							profile_centres.append(fit[0][-1])
							profile_sigma.append(fit[0][-2])
							profile_centres_score.append(fit[1][-1, -1])
						# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
						profile_centres = np.array(profile_centres)
						profile_sigma = np.array(profile_sigma)
						profile_centres_score = np.array(profile_centres_score)
						# centre = np.nanmean(profile_centres[profile_centres_score < 1])
						centre = np.nansum(profile_centres/(profile_centres_score**1))/np.sum(1/profile_centres_score**1)
						TS_r_new = (TS_r - centre) / 1000
						print('TS profile centre at %.3gmm compared to the theoretical centre' %centre)
						# temp_r, temp_t = np.meshgrid(TS_r_new, merge_time)
						# plt.figure();plt.pcolor(temp_t,temp_r,merge_Te_prof_multipulse,vmin=0);plt.colorbar().set_label('Te [eV]');plt.pause(0.01)
						# plt.figure();plt.pcolor(temp_t,temp_r,merge_ne_prof_multipulse,vmin=0);plt.colorbar().set_label('ne [10^20 #/m^3]');plt.pause(0.01)

						if os.path.exists(path_where_to_save_everything + '/TS_SS_data_merge_' + str(merge_ID_target) + '.npz'):
							merge_Te_prof_multipulse_SS = np.load(path_where_to_save_everything + '/TS_SS_data_merge_' + str(merge_ID_target) + '.npz')['merge_Te_prof_multipulse']
							merge_dTe_multipulse_SS = np.load(path_where_to_save_everything + '/TS_SS_data_merge_' + str(merge_ID_target) + '.npz')['merge_dTe_multipulse']
							merge_ne_prof_multipulse_SS = np.load(path_where_to_save_everything + '/TS_SS_data_merge_' + str(merge_ID_target) + '.npz')['merge_ne_prof_multipulse']
							merge_dne_multipulse_SS = np.load(path_where_to_save_everything + '/TS_SS_data_merge_' + str(merge_ID_target) + '.npz')['merge_dne_multipulse']

							if False:	# I don't think I need this part, I use the SS info to replace directly the original time dependent data
								gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
								yy = merge_ne_prof_multipulse_SS
								yy_sigma = merge_dne_multipulse_SS
								if np.sum(np.isfinite(yy_sigma))>0:
									yy_sigma[np.isnan(yy_sigma)]=np.nanmax(yy_sigma)
									yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
								else:
									yy_sigma = np.ones_like(yy)*np.nanmin([np.nanmax(yy),1])
								p0 = [np.max(yy), 10, 0]
								bds = [[0, 0, np.min(TS_r)], [np.inf, TS_size[1], np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, sigma=yy_sigma, maxfev=100000, bounds=bds)
								SS_profile_centres=[fit[0][-1]]
								SS_profile_sigma=[fit[0][-2]]
								SS_profile_centres_score=[fit[1][-1, -1]]
								# plt.figure();plt.plot(TS_r,merge_ne_prof_multipulse,label='ne')
								# plt.plot([fit[0][-1],fit[0][-1]],[np.max(merge_ne_prof_multipulse),np.min(merge_ne_prof_multipulse)],'--',label='ne')
								yy = merge_Te_prof_multipulse_SS
								yy_sigma = merge_dTe_multipulse_SS
								if np.sum(np.isfinite(yy_sigma))>0:
									yy_sigma[np.isnan(yy_sigma)]=np.nanmax(yy_sigma)
									yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
								else:
									yy_sigma = np.ones_like(yy)*np.nanmin([np.nanmax(yy),1])
								p0 = [np.max(yy), 10, 0]
								bds = [[0, 0, np.min(TS_r)], [np.inf, TS_size[1], np.max(TS_r)]]
								fit = curve_fit(gauss, TS_r, yy, p0, sigma=yy_sigma, maxfev=100000, bounds=bds)
								SS_profile_centres = np.append(SS_profile_centres,[fit[0][-1]],axis=0)
								SS_profile_sigma = np.append(SS_profile_sigma,[fit[0][-2]],axis=0)
								SS_profile_centres_score = np.append(SS_profile_centres_score,[fit[1][-1, -1]],axis=0)
								SS_centre = np.nanmean(SS_profile_centres)
								SS_TS_r_new = (TS_r - SS_centre) / 1000
								print('TS profile SS_centre at %.3gmm compared to the theoretical centre' %centre)

								# This is the mean of Te and ne weighted in their own uncertainties.
								interp_range_r = max(dx, TS_dr) * 1.5
								# weights_r = TS_r_new/interp_range_r
								weights_r = SS_TS_r_new
								merge_Te_prof_multipulse_SS_interp = np.zeros_like(merge_Te_prof_multipulse_interp[ 0])
								merge_dTe_prof_multipulse_SS_interp = np.zeros_like(merge_Te_prof_multipulse_interp[ 0])
								merge_ne_prof_multipulse_SS_interp = np.zeros_like(merge_Te_prof_multipulse_interp[ 0])
								merge_dne_prof_multipulse_SS_interp = np.zeros_like(merge_Te_prof_multipulse_interp[ 0])
								for i_r, value_r in enumerate(np.abs(r)):
									if np.sum(np.abs(np.abs(SS_TS_r_new) - value_r) < interp_range_r) == 0:
										continue
									selected_values = np.abs(np.abs(SS_TS_r_new) - value_r) < interp_range_r
									selected_values[merge_Te_prof_multipulse_SS == 0] = False
									# weights = 1/np.abs(weights_r[selected_values]+1e-5)
									weights = 1/((weights_r[selected_values]-value_r)/interp_range_r)**2
									# weights = np.ones((np.sum(selected_values)))
									if np.sum(selected_values) == 0:
										continue
									merge_Te_prof_multipulse_SS_interp[i_r] = np.sum(merge_Te_prof_multipulse_SS[selected_values]*weights / merge_dTe_multipulse_SS[selected_values]) / np.sum(weights / merge_dTe_multipulse_SS[selected_values])
									merge_ne_prof_multipulse_SS_interp[i_r] = np.sum(merge_ne_prof_multipulse_SS[selected_values]*weights / merge_dne_multipulse_SS[selected_values]) / np.sum(weights / merge_dne_multipulse_SS[selected_values])
									if False: 	# suggestion from Daljeet: use the "worst case scenario" in therms of uncertainty
										merge_dTe_prof_multipulse_SS_interp[i_r] = 1/(np.sum(1 / merge_dTe_multipulse_SS[selected_values]))*(np.sum( ((merge_Te_prof_multipulse_SS_interp[i_r]-merge_Te_prof_multipulse_SS[selected_values])/merge_dTe_multipulse_SS[selected_values])**2 )**0.5)
										merge_dne_prof_multipulse_SS_interp[i_r] = 1/(np.sum(1 / merge_dne_multipulse_SS[selected_values]))*(np.sum( ((merge_ne_prof_multipulse_SS_interp[i_r]-merge_ne_prof_multipulse_SS[selected_values])/merge_dne_multipulse_SS[selected_values])**2 )**0.5)
									else:
										merge_dTe_prof_multipulse_SS_interp_temp = 1/(np.sum(1 / merge_dTe_multipulse_SS[selected_values]))*(np.sum( ((merge_Te_prof_multipulse_SS_interp[i_r]-merge_Te_prof_multipulse_SS[selected_values])/merge_dTe_multipulse_SS[selected_values])**2 )**0.5)
										merge_dne_prof_multipulse_SS_interp_temp = 1/(np.sum(1 / merge_dne_multipulse_SS[selected_values]))*(np.sum( ((merge_ne_prof_multipulse_SS_interp[i_r]-merge_ne_prof_multipulse_SS[selected_values])/merge_dne_multipulse_SS[selected_values])**2 )**0.5)
										merge_dTe_prof_multipulse_SS_interp[i_r] = max(merge_dTe_prof_multipulse_SS_interp_temp,(np.max(merge_Te_prof_multipulse_SS[selected_values])-np.min(merge_Te_prof_multipulse_SS[selected_values]))/2/2 )	# I enlarged the integration range by 1.5, so I reduce the sigma in the second calculation mechanism to compensate for that and get reasonables uncertainties
										merge_dne_prof_multipulse_SS_interp[i_r] = max(merge_dne_prof_multipulse_SS_interp_temp,(np.max(merge_ne_prof_multipulse_SS[selected_values])-np.min(merge_ne_prof_multipulse_SS[selected_values]))/2/2 )	# I enlarged the integration range by 1.5, so I reduce the sigma in the second calculation mechanism to compensate for that and get reasonables uncertainties
								temp_r, temp_t = np.meshgrid(r, new_timesteps)

								start_r = np.abs(r - 0).argmin()
								end_r = np.abs(r - 5).argmin() + 1
								r_crop = r[start_r:end_r]
								merge_Te_prof_multipulse_SS_interp_crop = merge_Te_prof_multipulse_SS_interp[start_r:end_r]
								merge_dTe_prof_multipulse_SS_interp_crop = merge_dTe_prof_multipulse_SS_interp[start_r:end_r]
								merge_ne_prof_multipulse_SS_interp_crop = merge_ne_prof_multipulse_SS_interp[start_r:end_r]
								merge_dne_prof_multipulse_SS_interp_crop = merge_dne_prof_multipulse_SS_interp[start_r:end_r]

								gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
								yy = merge_ne_prof_multipulse_SS_interp_crop
								yy_sigma = merge_dne_prof_multipulse_SS_interp_crop
								yy_sigma[np.isnan(yy_sigma)]=np.nanmax(yy_sigma)
								yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
								p0 = [np.max(yy), np.max(r_crop)/2, np.min(r_crop)]
								bds = [[0, 0, np.min(r_crop)], [np.inf, np.max(r_crop), np.max(r_crop)]]
								fit = curve_fit(gauss, r_crop, yy, p0, maxfev=100000, bounds=bds, sigma=yy_sigma,absolute_sigma=True)
								SS_averaged_profile_sigma=fit[0][-2]
								# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)

								for i_t in range(len(time_crop)):	# the 2e20 limit in density comes from VanDerMeiden2012a
									merge_Te_prof_multipulse_interp_crop[i_t,merge_ne_prof_multipulse_interp_crop[i_t]<2] = np.max([merge_Te_prof_multipulse_SS_interp_crop[merge_ne_prof_multipulse_interp_crop[i_t]<2],merge_Te_prof_multipulse_interp_crop[i_t,merge_ne_prof_multipulse_interp_crop[i_t]<2]],axis=0)
									merge_dTe_prof_multipulse_interp_crop[i_t,merge_ne_prof_multipulse_interp_crop[i_t]<2] = np.max([merge_Te_prof_multipulse_SS_interp_crop[merge_ne_prof_multipulse_interp_crop[i_t]<2],merge_dTe_prof_multipulse_SS_interp_crop[merge_ne_prof_multipulse_interp_crop[i_t]<2]],axis=0)
									merge_ne_prof_multipulse_interp_crop[i_t,merge_ne_prof_multipulse_interp_crop[i_t]<2] = np.max([merge_ne_prof_multipulse_SS_interp_crop[merge_ne_prof_multipulse_interp_crop[i_t]<2],merge_ne_prof_multipulse_interp_crop[i_t,merge_ne_prof_multipulse_interp_crop[i_t]<2]],axis=0)
									merge_dne_prof_multipulse_interp_crop[i_t,merge_ne_prof_multipulse_interp_crop[i_t]<2] = np.max([merge_ne_prof_multipulse_SS_interp_crop[merge_ne_prof_multipulse_interp_crop[i_t]<2],merge_dne_prof_multipulse_SS_interp_crop[merge_ne_prof_multipulse_interp_crop[i_t]<2]],axis=0)

							else:
								temp = np.mean(merge_ne_prof_multipulse,axis=1)
								start = (temp>np.mean(merge_ne_prof_multipulse_SS)).argmax()
								end = (np.flip(temp,axis=0)>np.mean(merge_ne_prof_multipulse_SS)).argmax()
								merge_Te_prof_multipulse[:start] = merge_Te_prof_multipulse_SS
								merge_dTe_multipulse[:start] = 2*merge_Te_prof_multipulse_SS
								merge_ne_prof_multipulse[:start] = merge_ne_prof_multipulse_SS
								merge_dne_multipulse[:start] = merge_ne_prof_multipulse_SS
								merge_Te_prof_multipulse[-end:] = merge_Te_prof_multipulse_SS
								merge_dTe_multipulse[-end:] = 2*merge_Te_prof_multipulse_SS
								merge_ne_prof_multipulse[-end:] = merge_ne_prof_multipulse_SS
								merge_dne_multipulse[-end:] = merge_ne_prof_multipulse_SS


						# This is the mean of Te and ne weighted in their own uncertainties.
						temp1 = np.zeros_like(inverted_profiles[:, 0])
						temp2 = np.zeros_like(inverted_profiles[:, 0])
						temp3 = np.zeros_like(inverted_profiles[:, 0])
						temp4 = np.zeros_like(inverted_profiles[:, 0])
						interp_range_t = max(dt, TS_dt) * 1.5
						interp_range_r = max(dx, TS_dr) * 1.5
						weights_r = (np.zeros_like(merge_Te_prof_multipulse) + TS_r_new)
						weights_t = (((np.zeros_like(merge_Te_prof_multipulse)).T + merge_time).T)
						for i_t, value_t in enumerate(new_timesteps):
							if np.sum(np.abs(merge_time - value_t) < interp_range_t) == 0:
								continue
							for i_r, value_r in enumerate(np.abs(r)):
								if np.sum(np.abs(np.abs(TS_r_new) - value_r) < interp_range_r) == 0:
									continue
								elif np.sum(np.logical_and(np.abs(merge_time - value_t) < interp_range_t,np.sum(merge_Te_prof_multipulse, axis=1) > 0)) == 0:
									continue
								selected_values_t = np.logical_and(np.abs(merge_time - value_t) < interp_range_t,np.sum(merge_Te_prof_multipulse, axis=1) > 0)
								selected_values_r = np.abs(np.abs(TS_r_new) - value_r) < interp_range_r
								selected_values = (np.array([selected_values_t])).T * selected_values_r
								selected_values[merge_Te_prof_multipulse == 0] = False
								# weights = 1/(weights_r[selected_values]-value_r)**2 + 1/(weights_t[selected_values]-value_t)**2
								weights = 1/((weights_t[selected_values]-value_t)/interp_range_t)**2 + 1/((weights_r[selected_values]-value_r)/interp_range_r)**2
								if np.sum(selected_values) == 0:
									continue
								# temp1[i_t,i_r] = np.mean(merge_Te_prof_multipulse[selected_values_t][:,selected_values_r])
								# temp2[i_t, i_r] = np.max(merge_dTe_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dTe_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
								temp1[i_t, i_r] = np.sum(merge_Te_prof_multipulse[selected_values]*weights / merge_dTe_multipulse[selected_values]) / np.sum(weights / merge_dTe_multipulse[selected_values])
								# temp3[i_t,i_r] = np.mean(merge_ne_prof_multipulse[selected_values_t][:,selected_values_r])
								# temp4[i_t, i_r] = np.max(merge_dne_multipulse[selected_values_t][:,selected_values_r]) / (np.sum(np.isfinite(merge_dne_multipulse[selected_values_t][:,selected_values_r])) ** 0.5)
								temp3[i_t, i_r] = np.sum(merge_ne_prof_multipulse[selected_values]*weights / merge_dne_multipulse[selected_values]) / np.sum(weights / merge_dne_multipulse[selected_values])
								if False: 	# suggestion from Daljeet: use the "worst case scenario" in therms of uncertainty
									# temp2[i_t, i_r] = (np.sum(selected_values) / (np.sum(1 / merge_dTe_multipulse[selected_values]) ** 2)) ** 0.5
									# temp4[i_t, i_r] = (np.sum(selected_values) / (np.sum(1 / merge_dne_multipulse[selected_values]) ** 2)) ** 0.5
									temp2[i_t, i_r] = 1/(np.sum(1 / merge_dTe_multipulse[selected_values]))*(np.sum( ((temp1[i_t, i_r]-merge_Te_prof_multipulse[selected_values])/merge_dTe_multipulse[selected_values])**2 )**0.5)
									temp4[i_t, i_r] = 1/(np.sum(1 / merge_dne_multipulse[selected_values]))*(np.sum( ((temp3[i_t, i_r]-merge_ne_prof_multipulse[selected_values])/merge_dne_multipulse[selected_values])**2 )**0.5)
								else:
									# temp2_temp = 1/(np.sum(1 / merge_dTe_multipulse[selected_values]))*(np.sum( ((temp1[i_t, i_r]-merge_Te_prof_multipulse[selected_values])/merge_dTe_multipulse[selected_values])**2 )**0.5)
									# temp4_temp = 1/(np.sum(1 / merge_dne_multipulse[selected_values]))*(np.sum( ((temp3[i_t, i_r]-merge_ne_prof_multipulse[selected_values])/merge_dne_multipulse[selected_values])**2 )**0.5)
									temp2[i_t, i_r] = max(np.sqrt(np.sum(weights**2))/np.sum(weights / merge_dTe_multipulse[selected_values]),(np.max(merge_Te_prof_multipulse[selected_values])-np.min(merge_Te_prof_multipulse[selected_values]))/2/2 )	# I enlarged the integration range by 1.5, so I reduce the sigma in the second calculation mechanism to compensate for that and get reasonables uncertainties
									temp4[i_t, i_r] = max(np.sqrt(np.sum(weights**2))/np.sum(weights / merge_dne_multipulse[selected_values]),(np.max(merge_ne_prof_multipulse[selected_values])-np.min(merge_ne_prof_multipulse[selected_values]))/2/2 )	# I enlarged the integration range by 1.5, so I reduce the sigma in the second calculation mechanism to compensate for that and get reasonables uncertainties

						merge_Te_prof_multipulse_interp = np.array(temp1)
						merge_dTe_prof_multipulse_interp = np.array(temp2)
						merge_ne_prof_multipulse_interp = np.array(temp3)
						merge_dne_prof_multipulse_interp = np.array(temp4)
						temp_r, temp_t = np.meshgrid(r, new_timesteps)

						# I crop to the usefull stuff
						start_time = np.abs(new_timesteps - 0).argmin()
						end_time = np.abs(new_timesteps - 1.5).argmin() + 1
						time_crop = new_timesteps[start_time:end_time]
						start_r = np.abs(r - 0).argmin()
						end_r = np.abs(r - 5).argmin() + 1
						r_crop = r[start_r:end_r]
						temp_r, temp_t = np.meshgrid(r_crop, time_crop)
						merge_Te_prof_multipulse_interp_crop = merge_Te_prof_multipulse_interp[start_time:end_time,start_r:end_r]
						merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop<0]=0
						merge_dTe_prof_multipulse_interp_crop = merge_dTe_prof_multipulse_interp[start_time:end_time, start_r:end_r]
						merge_ne_prof_multipulse_interp_crop = merge_ne_prof_multipulse_interp[start_time:end_time,start_r:end_r]
						merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop<0]=0
						merge_dne_prof_multipulse_interp_crop = merge_dne_prof_multipulse_interp[start_time:end_time, start_r:end_r]
						inverted_profiles_crop = inverted_profiles[start_time:end_time, :, start_r:end_r]
						inverted_profiles_crop[np.isnan(inverted_profiles_crop)] = 0
						inverted_profiles_sigma_crop = inverted_profiles_sigma[start_time:end_time, :, start_r:end_r]
						inverted_profiles_sigma_crop[np.isnan(inverted_profiles_sigma_crop)] = 0
						all_fits_crop = all_fits[start_time:end_time]
						# inverted_profiles_crop[inverted_profiles_crop<0] = 0

						if merge_ID_target == 88:
							merge_Te_prof_multipulse_interp_crop,merge_dTe_prof_multipulse_interp_crop,merge_ne_prof_multipulse_interp_crop,merge_dne_prof_multipulse_interp_crop = generate_merge88_TS()
							print(merge_Te_prof_multipulse_interp_crop)
							print(merge_dTe_prof_multipulse_interp_crop)
							print(merge_ne_prof_multipulse_interp_crop)
							print(merge_dne_prof_multipulse_interp_crop)

						gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
						averaged_profile_sigma = []
						averaged_profile_sigma_sigma = []
						for index in range(np.shape(merge_ne_prof_multipulse_interp_crop)[0]):
							yy = merge_ne_prof_multipulse_interp_crop[index]
							yy_sigma = merge_dne_prof_multipulse_interp_crop[index]
							yy_sigma[np.isnan(yy_sigma)]=np.nanmax(yy_sigma)
							if (np.sum(yy>0)==0 or np.sum(yy_sigma>0)==0):
								averaged_profile_sigma.append(0)
								averaged_profile_sigma_sigma.append(1)
								continue
							yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
							yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
							p0 = [np.max(yy), np.max(r_crop)/2, 0]
							bds = [[0, 0, -interp_range_r/1000], [np.inf, np.max(r_crop), interp_range_r/1000]]
							fit = curve_fit(gauss, r_crop, yy, p0, maxfev=100000, bounds=bds, sigma=yy_sigma,absolute_sigma=True)
							averaged_profile_sigma.append(fit[0][-2])
							averaged_profile_sigma_sigma.append(fit[1][-2,-2])
						# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
						averaged_profile_sigma = np.array(averaged_profile_sigma)
						averaged_profile_sigma_sigma = np.array(averaged_profile_sigma_sigma)**0.5
						mean_plasma_radius = np.sum(averaged_profile_sigma/averaged_profile_sigma_sigma)/np.sum(1/averaged_profile_sigma_sigma)
						averaged_profile_sigma_2 = []
						averaged_profile_sigma_2_sigma = []
						for index in range(np.shape(merge_ne_prof_multipulse_interp_crop)[0]):
							yy = merge_Te_prof_multipulse_interp_crop[index]
							yy_sigma = merge_dTe_prof_multipulse_interp_crop[index]
							yy_sigma[np.isnan(yy_sigma)]=np.nanmax(yy_sigma)
							if (np.sum(yy>0)==0 or np.sum(yy_sigma>0)==0):
								averaged_profile_sigma_2.append(0)
								averaged_profile_sigma_2_sigma.append(1)
								continue
							yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
							yy_sigma[yy_sigma==0]=np.nanmax(yy_sigma[yy_sigma!=0])
							p0 = [np.max(yy), mean_plasma_radius, 0]
							bds = [[0, 0, -interp_range_r/1000], [np.inf, np.max(r_crop), interp_range_r/1000]]
							fit = curve_fit(gauss, r_crop, yy, p0, maxfev=100000, bounds=bds, sigma=yy_sigma,absolute_sigma=True)
							averaged_profile_sigma_2.append(fit[0][-2])
							averaged_profile_sigma_2_sigma.append(fit[1][-2,-2])
						# plt.figure();plt.plot(TS_r,merge_Te_prof_multipulse[index]);plt.plot(TS_r,gauss(TS_r,*fit[0]));plt.pause(0.01)
						averaged_profile_sigma_2 = np.array(averaged_profile_sigma_2)
						averaged_profile_sigma_2_sigma = np.array(averaged_profile_sigma_2_sigma)**0.5
						mean_plasma_radius_2 = np.sum(averaged_profile_sigma_2/averaged_profile_sigma_2_sigma)/np.sum(1/averaged_profile_sigma_2_sigma)
						source_power_spread = (mean_plasma_radius+mean_plasma_radius_2)*1000/4


						# x_local = xx - spatial_factor * 17.4 / 1000
						dr_crop = np.median(np.diff(r_crop))

						merge_dTe_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_dTe_prof_multipulse_interp_crop)
						merge_dTe_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.1] = 0
						merge_Te_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_Te_prof_multipulse_interp_crop)
						merge_Te_prof_multipulse_interp_crop_limited[merge_Te_prof_multipulse_interp_crop < 0.1] = 0
						merge_dne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_dne_prof_multipulse_interp_crop)
						merge_dne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop < 5e-07] = 0
						merge_ne_prof_multipulse_interp_crop_limited = cp.deepcopy(merge_ne_prof_multipulse_interp_crop)
						merge_ne_prof_multipulse_interp_crop_limited[merge_ne_prof_multipulse_interp_crop < 5e-07] = 0

						excitation = []
						for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
							temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
							temp[np.isnan(temp)] = 0
							temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
							excitation.append(temp)
						excitation = np.array(excitation)  # in # photons cm^-3 s^-1
						excitation = (excitation.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

						recombination = []
						for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
							temp = read_adf15(pecfile, isel, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
							temp[np.isnan(temp)] = 0
							temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
							recombination.append(temp)
						recombination = np.array(recombination)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
						recombination = (recombination.T * (10 ** -6) * (energy_difference / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

						arbitrary_H_temp = 5000	# K, It is the same used for the fittings
						thermal_velocity_H = ( (arbitrary_H_temp*boltzmann_constant_J)/ au_to_kg)**0.5
						temp = read_adf11(scdfile, 'scd', 1, 1, 1, merge_Te_prof_multipulse_interp_crop_limited.flatten(),(merge_ne_prof_multipulse_interp_crop_limited * 10 ** (20 - 6)).flatten())
						temp[np.isnan(temp)] = 0
						temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop))) * (10 ** -6)  # in ionisations m^-3 s-1 / (# / m^3)**2
						ionization_length_H = thermal_velocity_H/(temp * merge_ne_prof_multipulse_interp_crop_limited * 1e20 )
						ionization_length_H = np.where(np.isnan(ionization_length_H), 0, ionization_length_H)
						ionization_length_H = np.where(np.isinf(ionization_length_H), np.nan, ionization_length_H)
						ionization_length_H = np.where(np.isnan(ionization_length_H), np.nanmax(ionization_length_H[np.isfinite(ionization_length_H)]), ionization_length_H)
						ionization_length_Hm = np.ones_like(ionization_length_H)
						ionization_length_H2 = np.ones_like(ionization_length_H)
						ionization_length_H2p = np.ones_like(ionization_length_H)

						min_multiplier = 1e-10
						# # for max_nHm_ne,max_nH2_ne,max_nH2p_ne,max_nH3p_ne,mod3 in [[min_multiplier,min_multiplier,min_multiplier,min_multiplier,'only_H'],[1,min_multiplier,min_multiplier,min_multiplier,'only_Hm'],[min_multiplier,1,min_multiplier,min_multiplier,'only_H2'],[min_multiplier,min_multiplier,1,min_multiplier,'only_H2p'],[min_multiplier,min_multiplier,min_multiplier,1,'only_H3p'],[min_multiplier,1,1,min_multiplier,'only_H2_H2p'],[1,1,min_multiplier,min_multiplier,'only_Hm_H2'],[1,1,1,min_multiplier,'only_Hm_H2_H2p'],[1,1,1,1,'all']]:
						# for max_nHm_ne,max_nH2_ne,max_nH2p_ne,max_nH3p_ne,mod3 in [[1,min_multiplier,min_multiplier,min_multiplier,'only_Hm'],[min_multiplier,1,1,min_multiplier,'only_H2_H2p'],[1,1,min_multiplier,min_multiplier,'only_Hm_H2'],[1,1,1,min_multiplier,'only_Hm_H2_H2p'],[1,1,1,1,'all']]:
						if include_particles_limitation:
							mod3 = 'only_Hm_H2_H2p_mol_lim'
						else:
							mod3 = 'only_Hm_H2_H2p'
						mod4 = mod2 +'/' +mod3

						if not os.path.exists(path_where_to_save_everything + mod4):
							os.makedirs(path_where_to_save_everything + mod4)

						print('Starting '+mod3)

						n_list_all = np.sort(np.concatenate((n_list, n_list_1)))
						# OES_multiplier = 0.81414701
						# Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						nHp_ne_all = np.ones_like(merge_ne_prof_multipulse_interp_crop_limited)
						nHm_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						nH2_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						nH2p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						nH3p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						Te_all = cp.deepcopy(merge_Te_prof_multipulse_interp_crop_limited)
						ne_all = cp.deepcopy(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_Te_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_nH_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_nHp_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_nHm_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_nH2_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_nH2p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						sigma_nH3p_ne_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						power_balance_data = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited).flatten().tolist()

						residuals_all = np.zeros_like(merge_ne_prof_multipulse_interp_crop_limited)
						# guess = [0, 1, 0.01 * max_nHm_ne, 0.1 * max_nH2_ne, 0.0001 * max_nH2p_ne,0.0001 * max_nH3p_ne]
						guess = [0.5, 1, 0.0005,0.0005, 0.0001,0.0005]


						# this is to estimate better the background max H2 density
						# I assume the flow velocity from CTS (Jonathan) of 10km/s
						T_Hp = np.min([np.max([1000*np.ones_like(merge_Te_prof_multipulse_interp_crop_limited),merge_Te_prof_multipulse_interp_crop_limited/eV_to_K],axis=0),12000*np.ones_like(merge_Te_prof_multipulse_interp_crop_limited)],axis=0)	# K
						area = 2*np.pi*(r_crop + np.median(np.diff(r_crop))/2) * np.median(np.diff(r_crop))	# m^2
						ionisation_potential = 13.6	# eV
						heat_inflow_upstream = np.sum(area * merge_ne_prof_multipulse_interp_crop_limited * 10000*(ionisation_potential+ T_Hp*eV_to_K +merge_Te_prof_multipulse_interp_crop_limited)/J_to_eV,axis=1)* 1e20	# W
						sound_speed = (merge_Te_prof_multipulse_interp_crop_limited/eV_to_K*boltzmann_constant_J/(hydrogen_mass))**0.5	# m/s
						sheat_transmission_factor = 7.7	# from T W Morgan et al 2014
						heat_flux_target = np.sum(area *merge_ne_prof_multipulse_interp_crop_limited*1e20*sound_speed *(ionisation_potential/J_to_eV+sheat_transmission_factor*merge_Te_prof_multipulse_interp_crop_limited/eV_to_K*boltzmann_constant_J),axis=1)	# W
						neat_background_heating = heat_inflow_upstream - heat_flux_target
						neat_background_heating[neat_background_heating<0] = 0
						net_power_in = neat_background_heating*np.median(np.diff(time_crop))/1000	# J
						volume = (0.38+target_OES_distance/1000)*np.pi*(0.4**2)	# m^2
						H2_mass = target_chamber_pressure*2*hydrogen_mass/(boltzmann_constant_J*300)*volume	# kg
						heat_capacity_H2 = 14.5	# kJ/(kg K)
						temp_increase = net_power_in/(heat_capacity_H2*H2_mass)
						temp_H2 = np.ones_like(net_power_in)*300
						# feed_H2 = 19.8	# SLM
						feed_H2_kg = feed_rate_SLM/1000*101325/(boltzmann_constant_J*300)*2*hydrogen_mass/60	# kg/s
						for index in range(len(net_power_in)):
							if index==0:
								H2_mass = target_chamber_pressure*2*hydrogen_mass/(boltzmann_constant_J*300)*volume	# kg
							else:
								H2_mass = target_chamber_pressure*2*hydrogen_mass/(boltzmann_constant_J*temp_H2[index-1])*volume	# kg
							# flow_out = ( feed_H2_kg + np.sum(area * merge_ne_prof_multipulse_interp_crop_limited[index] * 10000)* 1e20*hydrogen_mass )*np.median(np.diff(time_crop))/1000	# kg
							flow_out = ( feed_rate_SLM /1000/60 + np.sum(area * 10000) )*np.median(np.diff(time_crop))/1000 *target_chamber_pressure/(boltzmann_constant_J*temp_H2[index-1])*2*hydrogen_mass	# kg
							power_balance = net_power_in[index] + feed_H2_kg*np.median(np.diff(time_crop))/1000*300*heat_capacity_H2 - flow_out*heat_capacity_H2*temp_H2[index-1]
							temp_H2[index]=min(max(temp_H2[index-1]+power_balance/(heat_capacity_H2*H2_mass),300),1/eV_to_K)
							# print([power_balance,flow_out,temp_H2[index]])
						max_nH2_from_pressure_all = target_chamber_pressure/(boltzmann_constant_J*temp_H2)
						max_nH2_from_pressure_all = 10*max_nH2_from_pressure_all	# as a safety factor

						if False:	# I define this in the import_PECs_FF_2.py file
							if False:	# this is excluding the first mm close to the target
								limit_H_up = interpolate.interp1d(np.log([0.1,0.5,1.1,4]),np.log([7,5,0.3,0.3]),fill_value='extrapolate')
								limit_H_down = interpolate.interp1d(np.log([0.1,0.5,2,4]),np.log([0.2,0.006,0.003,0.003]),fill_value='extrapolate')
								nH_ne_fit_from_simulations = lambda Te: np.exp(np.polyval([0.47363853,-0.673271,-3.96789346],np.log(Te)))
							else:	# this considers even that
								limit_H_up = interpolate.interp1d(np.log([0.1,4]),np.log([20,20]),fill_value='extrapolate')
								limit_H_down = interpolate.interp1d(np.log([0.1,0.5,2,4]),np.log([0.2,0.006,0.003,0.003]),fill_value='extrapolate')
								nH_ne_fit_from_simulations = lambda Te: np.nanmin([np.exp(np.polyval([0.52425878,-0.7291866,-3.82342784],np.log(Te))),np.ones_like(Te)*10],axis=0)
							TH_fit_from_simulations = interpolate.interp1d(np.log([0.1,1.6,4]),np.log([0.1,1.1,1.1]),fill_value='extrapolate')
							nH2_ne_fit_from_simulations = lambda Te: np.exp(np.polyval([0.22332556,-1.33762069,-1.11738361],np.log(Te)))
							TH2_fit_from_simulations = interpolate.interp1d(np.log([0.1,4]),np.log([0.12,0.3]),fill_value='extrapolate')

						# net_rate_Hp_destruction = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['net_rate_Hp_destruction']
						# net_rate_e_destruction = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['net_rate_e_destruction']
						# net_rate_Hm_destruction = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['net_rate_Hm_destruction']
						# net_rate_H2p_destruction = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['net_rate_H2p_destruction']
						# # log_net_rate_Hp_destruction = np.log(np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['net_rate_Hp_destruction'])
						# # log_net_rate_e_destruction = np.log(np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['net_rate_e_destruction'])
						# # log_sum_nH_excited_states = np.log(np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['sum_nH_excited_states'])
						# # log_net_rate_Hp_destruction[net_rate_Hp_destruction<0]=-np.inf
						# # log_net_rate_e_destruction[net_rate_e_destruction<0]=-np.inf
						# sum_nH_excited_states = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['sum_nH_excited_states']
						# samples_nH_ne_array = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['samples_nH_ne_array']
						# samples_nHm_nH2_array = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['samples_nHm_nH2_array']
						# samples_nH2_ne_array = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['samples_nH2_ne_array']
						# samples_nH2p_nH2_array = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['samples_nH2p_nH2_array']
						# samples_ne_array = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['samples_ne_array']
						# samples_Te_array = np.load('/home/ffederic/work/Collaboratory/test/experimental_data/functions/MolRad_Yacora/Yacora_FF/' +'interpolator_particle_balance.npz')['samples_Te_array']
						# # out = np.exp(interpolate.interpn((np.log(coord_1),np.log(coord_2),np.log(coord_3),np.log(coord_4),np.log(excited_states)),np.log(parameters_orig_simple),np.log(x_full), bounds_error=False,fill_value=None))

						initial_conditions = True
						global_pass = 1
						exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())
						initial_conditions = False

						class calc_stuff_output:
							def __init__(self, my_time_pos,my_r_pos, results):
								self.my_time_pos = my_time_pos
								self.my_r_pos = my_r_pos
								self.results = results

						sample_time_step = []
						for time in [0.1, 0.2, 0.4, 0.6, 0.7, 0.8, 1, 1.4]:	#times in ms that I want to take a better look at
							sample_time_step.append(int((np.abs(time_crop - time)).argmin()))
						sample_time_step = np.unique(sample_time_step)
						sample_radious=[]
						for radious in [0, 0.004, 0.008, 0.012,0.018]:	#radious in m that I want to take a better look at
							sample_radious.append(int((np.abs(r_crop - radious)).argmin()))
						sample_radious = np.unique(sample_radious)

						def calc_power_balance_elements(Te_int,ne_int,nH_ne_int,nHm_ne_int,nH2p_ne_int,nH2_ne_int,T_Hp,T_Hm,T_H2p,T_Hp_prop_Te=True,T_Hm_prop_Te=True,T_H2p_prop_Te=True):
							# This is to calculate the power balance only

							if np.shape(Te_int)!=np.shape(ne_int):
								print('ERROR, shape of Te and ne must be same')
								exit()

							final_number_data = 1
							if not np.shape(Te_int)==():
								final_number_data = max(final_number_data,len(Te_int))
							# 	Te_int = Te_int * np.ones_like(nH_ne_int)
							# if np.shape(ne_int)==():
							# 	ne_int = ne_int * np.ones_like(nH_ne_int)
							# if np.shape(T_Hp)==():
							# 	T_Hp = T_Hp * np.ones_like(nH_ne_int)
							# if np.shape(T_Hm)==():
							# 	T_Hm = T_Hm * np.ones_like(nH_ne_int)
							# if np.shape(T_H2p)==():
							# 	T_H2p = T_H2p * np.ones_like(nH_ne_int)
							if not np.shape(nH_ne_int)==():
								final_number_data = max(final_number_data,len(nH_ne_int))
							if not np.shape(nHm_ne_int)==():
								final_number_data = max(final_number_data,len(nHm_ne_int))
							if not np.shape(nH2p_ne_int)==():
								final_number_data = max(final_number_data,len(nH2p_ne_int))
							if not np.shape(nH2_ne_int)==():
								final_number_data = max(final_number_data,len(nH2_ne_int))

							if np.shape(Te_int)==():
								excitation_full = []
								for isel in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:
									if isel==0:
										temp = read_adf15(pecfile_2, 1, Te_int,ne_int * 10 ** (0 - 6))[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									else:
										temp = read_adf15(pecfile, isel, Te_int,ne_int * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^
									excitation_full.append(temp)
								excitation_full = np.array(excitation_full)  # in # photons cm^-3 s^-1
								excitation_full = (excitation_full.T * (10 ** -6) * (energy_difference_full / J_to_eV)).T  # in W m^-3 / (# / m^3)**2
								# excitation_full = (np.ones((len(nH_ne_int),len(excitation_full)))*excitation_full).T

								recombination_full = []
								for isel in [0, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]:
									if isel==0:
										temp = read_adf15(pecfile_2, 67, Te_int,ne_int * 10 ** (0 - 6))[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									else:
										temp = read_adf15(pecfile, isel, Te_int,ne_int * 10 ** (0 - 6))[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									recombination_full.append(temp)
								recombination_full = np.array(recombination_full)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
								recombination_full = (recombination_full.T * (10 ** -6) * (energy_difference_full / J_to_eV)).T  # in W m^-3 / (# / m^3)**2
								# recombination_full = (np.ones((len(nH_ne_int),len(recombination_full)))*recombination_full).T
							else:
								unique_Te = np.unique(Te_int)
								unique_ne = np.unique(ne_int)
								sample_Te = (np.ones((len(unique_Te),len(unique_ne))).T*unique_Te).T
								sample_ne = np.ones((len(unique_Te),len(unique_ne)))*unique_ne

								excitation_full = []
								for isel in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:
									if isel==0:
										temp = read_adf15(pecfile_2, 1, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									else:
										temp = read_adf15(pecfile, isel, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^
									excitation_full.append(temp)
								excitation_full = np.array(excitation_full)  # in # photons cm^-3 s^-1
								excitation_full = (excitation_full.T * (10 ** -6) * (energy_difference_full / J_to_eV)).T  # in W m^-3 / (# / m^3)**2
								# excitation_full = (np.ones((len(nH_ne_int),len(excitation_full)))*excitation_full).T
								excitation_full = excitation_full.reshape((len(excitation_full),*np.shape(sample_Te)))

								temp = np.zeros((len(excitation_full),len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[:,np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[:,np.logical_and(Te_int==Te,ne_int==ne)]).T*excitation_full[:,i_Te,i_ne]).T
								excitation_full = cp.deepcopy(temp)

								recombination_full = []
								for isel in [0, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]:
									if isel==0:
										temp = read_adf15(pecfile_2, 67, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									else:
										temp = read_adf15(pecfile, isel, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									recombination_full.append(temp)
								recombination_full = np.array(recombination_full)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
								recombination_full = (recombination_full.T * (10 ** -6) * (energy_difference_full / J_to_eV)).T  # in W m^-3 / (# / m^3)**2
								# recombination_full = (np.ones((len(nH_ne_int),len(recombination_full)))*recombination_full).T
								recombination_full = recombination_full.reshape((len(recombination_full),*np.shape(sample_Te)))

								temp = np.zeros((len(recombination_full),len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[:,np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[:,np.logical_and(Te_int==Te,ne_int==ne)]).T*recombination_full[:,i_Te,i_ne]).T
								recombination_full = cp.deepcopy(temp)


							multiplicative_factor_full = energy_difference_full * einstein_coeff_full / J_to_eV
							nHp_ne_int = 1 + nHm_ne_int - nH2p_ne_int
							if (np.shape(Te_int)==()) and (not np.shape(nH_ne_int)==()):
								population_coefficients = (((np.ones((len(nH_ne_int),len(excitation_full)))*excitation_full.flatten()).T *  nH_ne_int).T /multiplicative_factor_full).T
							else:
								population_coefficients = ((excitation_full *  nH_ne_int).T /multiplicative_factor_full).T

							if (np.shape(Te_int)==()) and (not np.shape(nHp_ne_int)==()):
								temp = (((np.ones((len(nHp_ne_int),len(recombination_full)))*recombination_full.flatten()).T * nHp_ne_int).T /multiplicative_factor_full).T
							else:
								temp = ((recombination_full * nHp_ne_int).T /multiplicative_factor_full).T

							if np.shape(population_coefficients)[-1]>np.shape(temp)[-1]:
								population_coefficients += (np.ones_like(population_coefficients).T * (temp.flatten())).T
							elif np.shape(population_coefficients)[-1]<np.shape(temp)[-1]:
								population_coefficients = (np.ones_like(temp).T * (population_coefficients.flatten())).T + temp
							else:
								population_coefficients += temp

							if np.shape(population_coefficients)[-1]<final_number_data:
								population_coefficients = (np.ones((final_number_data,len(population_coefficients)))* (population_coefficients.flatten())).T
							population_states_atoms = population_coefficients* ne_int**2

							if np.shape(Te_int)==() and final_number_data>1:
								Te_int = Te_int * np.ones((final_number_data))
							if np.shape(ne_int)==() and final_number_data>1:
								ne_int = ne_int * np.ones((final_number_data))
							if np.shape(T_Hp)==() and final_number_data>1:
								T_Hp = T_Hp * np.ones((final_number_data))
							if np.shape(T_Hm)==() and final_number_data>1:
								T_Hm = T_Hm * np.ones((final_number_data))
							if np.shape(T_H2p)==() and final_number_data>1:
								T_H2p = T_H2p * np.ones((final_number_data))
							if np.shape(nH_ne_int)==() and final_number_data>1:
								nH_ne_int = nH_ne_int * np.ones((final_number_data))
							if np.shape(nHm_ne_int)==() and final_number_data>1:
								nHm_ne_int = nHm_ne_int * np.ones((final_number_data))
							if np.shape(nH2p_ne_int)==() and final_number_data>1:
								nH2p_ne_int = nH2p_ne_int * np.ones((final_number_data))
							if np.shape(nH2_ne_int)==() and final_number_data>1:
								nH2_ne_int = nH2_ne_int * np.ones((final_number_data))

							if final_number_data==1:
								temp1 = From_Hn_with_Hp_pop_coeff_full_extra(np.array([[Te_int,T_Hp,T_Hm,ne_int,nHp_ne_int*ne_int]]),np.unique(excited_states_From_Hn_with_Hp))
								temp2 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([[Te_int,T_H2p,T_Hm,ne_int,nH2p_ne_int*ne_int]]),np.unique(excited_states_From_Hn_with_H2p))
								population_coefficients_Hm = (nHm_ne_int*( temp1 + temp2 ).T).reshape((np.shape(population_coefficients)))
								population_coefficients += (nHm_ne_int*( temp1 + temp2 ).T).reshape((np.shape(population_coefficients)))
								temp = From_H2_pop_coeff_full_extra(np.array([[Te_int,ne_int]]),np.unique(excited_states_From_H2))
								population_coefficients_H2 = (nH2_ne_int*temp.T).reshape((np.shape(population_coefficients)))
								population_coefficients += (nH2_ne_int*temp.T).reshape((np.shape(population_coefficients)))
								temp = From_H2p_pop_coeff_full_extra(np.array([[Te_int,ne_int]]),np.unique(excited_states_From_H2p))
								population_coefficients_H2p = (nH2p_ne_int*temp.T).reshape((np.shape(population_coefficients)))
								population_coefficients += (nH2p_ne_int*temp.T).reshape((np.shape(population_coefficients)))
								# temp = From_H3p_pop_coeff_full_extra(np.array([[Te_int,ne_int]]),np.unique(excited_states_From_H3p))
								# population_coefficients += (nH3p_ne_all.flatten()*temp.T).reshape((np.shape(population_coefficients)))
							else:
								unique_Te = np.unique(Te_int)
								unique_T_Hp = np.unique(T_Hp)
								unique_T_Hm = np.unique(T_Hm)
								unique_T_H2p = np.unique(T_H2p)
								unique_ne = np.unique(ne_int)
								unique_nHp_ne = np.unique(nHp_ne_int)
								unique_nH2p_ne = np.unique(nH2p_ne_int)
								if (T_Hp_prop_Te==True and T_Hm_prop_Te==True and T_H2p_prop_Te==True):
									sample = []
									for Te in unique_Te:
										select1 = Te_int==Te
										nHp_ne_int_mod = nHp_ne_int[select1]
										ne_int_mod = ne_int[select1]
										T_Hp_mod = T_Hp[Te_int==Te][0]
										T_Hm_mod = T_Hm[Te_int==Te][0]
										for ne in unique_ne:
											select2 = ne_int_mod==ne
											if np.sum(select2)==0:
												continue
											nHp_ne_int_mod_mod = nHp_ne_int_mod[select2]
											for nHp_ne in unique_nHp_ne:
												if np.sum(nHp_ne_int_mod_mod==nHp_ne)>0:
													sample.append([Te,T_Hp_mod,T_Hm_mod,ne,nHp_ne])
									sample_orig=np.array(sample)
									sample = cp.deepcopy(sample_orig)
									sample[:,-1] = sample[:,-1]*sample[:,-2]
									# sample_Te,sample_ne,sample_nHp_ne = np.meshgrid(unique_Te,unique_ne,unique_nHp_ne,indexing='ij')
									# sample_T_Hp = np.zeros_like(sample_Te)
									# sample_T_Hm = np.zeros_like(sample_Te)
									# for values in unique_Te:
									# 	sample_T_Hp[sample_Te==values]=T_Hp[Te_int==values][0]
									# 	sample_T_Hm[sample_Te==values]=T_Hm[Te_int==values][0]
									# temp1 = From_Hn_with_Hp_pop_coeff_full_extra(np.array([sample_Te.flatten(),sample_T_Hp.flatten(),sample_T_Hm.flatten(),sample_ne.flatten(),sample_nHp_ne.flatten()*sample_ne.flatten()]).T,np.unique(excited_states_From_Hn_with_Hp))
									temp1 = From_Hn_with_Hp_pop_coeff_full_extra(sample,np.unique(excited_states_From_Hn_with_Hp))
									temp1 = temp1.T
									# temp1 = temp1.reshape((len(temp1),*np.shape(sample_Te)))
									temp = np.zeros((len(temp1),len(Te_int)))
									Te_mod = 0
									ne_mod = 0
									for index in range(len(sample_orig)):
										if Te_mod!=sample_orig[index][0]:
											Te_mod = sample_orig[index][0]
											# print(Te_mod)
											select1 = Te_int==Te_mod
											# ne_int_mod = ne_int[select1]
										if ne_mod!=sample_orig[index][3]:
											ne_mod = sample_orig[index][3]
											# print(ne_mod)
											# select2 = cp.deepcopy(select1)
											# select2[select2] = ne_int_mod==ne_mod
											select2 = np.logical_and(select1,ne_int==ne_mod)
											# nHp_ne_int_mod = nHp_ne_int[select2]
										# select3 = cp.deepcopy(select2)
										# select3[select3] = nHp_ne_int_mod==sample_orig[index][4]
										# temp[:,select3] = (np.ones((len(temp1),np.sum(select3))).T*temp1[:,index]).T
										select3 = nHp_ne_int==sample_orig[index][4]
										select = np.logical_and(select3,select2)
										temp[:,select] = (np.ones((len(temp1),np.sum(select))).T*temp1[:,index]).T

									# temp = np.zeros((len(temp1),len(Te_int)))
									# for Te in unique_Te:
									# 	select1 = Te_int==Te
									# 	# nHp_ne_int_mod = nHp_ne_int[select1]
									# 	# ne_int_mod = ne_int[select1]
									# 	temp1_1 = temp1[:,sample_orig[:,0]==Te]
									# 	sample_orig_1 = sample_orig[sample_orig[:,0]==Te]
									# 	for ne in unique_ne:
									# 		select2 = np.logical_and(ne_int==ne,select1)
									# 		if np.sum(select2)>0:
									# 		# if np.sum(ne_int_mod==ne)>0:
									# 			# select2 = cp.deepcopy(select1)
									# 			# select2[select2] = select3 = ne_int_mod==ne
									# 			temp1_2 = temp1_1[:,sample_orig_1[:,3]==ne]
									# 			sample_orig_2 = sample_orig_1[sample_orig_1[:,3]==ne]
									# 			# nHp_ne_int_mod_mod = nHp_ne_int_mod[select3]
									# 			for nHp_ne in unique_nHp_ne:
									# 				select4 = np.logical_and(nHp_ne_int==nHp_ne,select2)
									# 				if np.sum(select4)>0:
									# 				# if np.sum(nHp_ne_int_mod_mod==nHp_ne)>0:
									# 					# select4 = cp.deepcopy(select2)
									# 					# select4[select4] = nHp_ne_int_mod_mod==nHp_ne
									# 					temp[:,select4] = (np.ones((len(temp1),np.sum(select4))).T*(temp1_2[:,sample_orig_2[:,4]==nHp_ne].flatten())).T
										#
										# for i_Te,Te in enumerate(unique_Te):
										# 	select1 = nHp_ne_int==value3
										# 	for i_ne,ne in enumerate(unique_ne):
										# 		# temp[:,np.logical_and(np.logical_and(Te_int==Te,ne_int==ne),nHp_ne_int==nHp_ne)]=(np.ones_like(temp[:,np.logical_and(np.logical_and(Te_int==Te,ne_int==ne),nHp_ne_int==nHp_ne)]).T*temp1[:,i_Te,i_ne,i_nHp_ne]).T
										# 		temp[:,np.logical_and(np.logical_and(Te_int==Te,ne_int==ne),nHp_ne_int==nHp_ne)]=(np.ones_like(temp[:,np.logical_and(np.logical_and(Te_int==Te,ne_int==ne),nHp_ne_int==nHp_ne)]).T*temp1[:,np.logical_and(np.logical_and(sample[:,0]==Te,sample[:,3]==ne),sample[:,4]==nHp_ne*ne)]).T
									population_coefficients += (nHm_ne_int*( temp )).reshape((np.shape(population_coefficients)))
									population_coefficients_Hm = (nHm_ne_int*( temp )).reshape((np.shape(population_coefficients)))

									sample = []
									for Te in unique_Te:
										select1 = Te_int==Te
										nH2p_ne_int_mod = nH2p_ne_int[select1]
										ne_int_mod = ne_int[select1]
										T_H2p_mod = T_H2p[Te_int==Te][0]
										T_Hm_mod = T_Hm[Te_int==Te][0]
										for ne in unique_ne:
											select2 = ne_int_mod==ne
											if np.sum(select2)==0:
												continue
											nH2p_ne_int_mod_mod = nH2p_ne_int_mod[select2]
											for nH2p_ne in unique_nH2p_ne:
												if np.sum(nH2p_ne_int_mod_mod==nH2p_ne)>0:
													sample.append([Te,T_H2p_mod,T_Hm_mod,ne,nH2p_ne])
									sample_orig=np.array(sample)
									sample = cp.deepcopy(sample_orig)
									sample[:,-1] = sample[:,-1]*sample[:,-2]
									# sample_Te,sample_ne,sample_nH2p_ne = np.meshgrid(unique_Te,unique_ne,unique_nH2p_ne,indexing='ij')
									# sample_T_Hm = np.zeros_like(sample_Te)
									# sample_T_H2p = np.zeros_like(sample_Te)
									# for values in unique_Te:
									# 	sample_T_Hm[sample_Te==values]=T_Hm[Te_int==values][0]
									# 	sample_T_H2p[sample_Te==values]=T_H2p[Te_int==values][0]
									# temp1 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([sample_Te.flatten(),sample_T_H2p.flatten(),sample_T_Hm.flatten(),sample_ne.flatten(),sample_nH2p_ne.flatten()*sample_ne.flatten()]).T,np.unique(excited_states_From_Hn_with_H2p))
									temp1 = From_Hn_with_H2p_pop_coeff_full_extra(sample,np.unique(excited_states_From_Hn_with_H2p))
									temp1 = temp1.T
									# temp1 = temp1.reshape((len(temp1),*np.shape(sample_Te)))
									temp = np.zeros((len(temp1),len(Te_int)))
									Te_mod = 0
									ne_mod = 0
									for index in range(len(sample_orig)):
										if Te_mod!=sample_orig[index][0]:
											Te_mod = sample_orig[index][0]
											select1 = Te_int==Te_mod
											# ne_int_mod = ne_int[select1]
										if ne_mod!=sample_orig[index][3]:
											ne_mod = sample_orig[index][3]
											# select2 = cp.deepcopy(select1)
											# select2[select2] = ne_int_mod==ne_mod
											select2 = np.logical_and(select1,ne_int==ne_mod)
											# nHp_ne_int_mod = nHp_ne_int[select2]
										# select3 = cp.deepcopy(select2)
										# select3[select3] = nHp_ne_int_mod==sample_orig[index][4]
										# temp[:,select3] = (np.ones((len(temp1),np.sum(select3))).T*temp1[:,index]).T
										select3 = nH2p_ne_int==sample_orig[index][4]
										select = np.logical_and(select3,select2)
										temp[:,select] = (np.ones((len(temp1),np.sum(select))).T*temp1[:,index]).T

									# temp = np.zeros((len(temp1),len(Te_int)))
									# for Te in unique_Te:
									# 	select1 = Te_int==Te
									# 	nH2p_ne_int_mod = nH2p_ne_int[select1]
									# 	ne_int_mod = ne_int[select1]
									# 	temp1_1 = temp1[:,sample_orig[:,0]==Te]
									# 	sample_orig_1 = sample_orig[sample_orig[:,0]==Te]
									# 	for ne in unique_ne:
									# 		if np.sum(ne_int_mod==ne)>0:
									# 			select2 = cp.deepcopy(select1)
									# 			select2[select2] = select3 = ne_int_mod==ne
									# 			temp1_2 = temp1_1[:,sample_orig_1[:,3]==ne]
									# 			sample_orig_2 = sample_orig_1[sample_orig_1[:,3]==ne]
									# 			nH2p_ne_int_mod_mod = nH2p_ne_int_mod[select3]
									# 			for nH2p_ne in unique_nH2p_ne:
									# 				if np.sum(nH2p_ne_int_mod_mod==nH2p_ne)>0:
									# 					select4 = cp.deepcopy(select2)
									# 					select4[select4] = nH2p_ne_int_mod_mod==nH2p_ne
									# 					temp[:,select4] = (np.ones_like(temp[:,select4]).T*(temp1_2[:,sample_orig_2[:,4]==nH2p_ne].flatten())).T
									# for index,Te,trash1,trash2,ne,nH2p_ne in enumerate(sample_orig):
									# 	select1 = nH2p_ne_int==nH2p_ne
									# 	select2 = Te_int==Te
									# 	select3 = ne_int==ne
									# 	select = np.sum([select1,select2,select3],axis=0)
									# 	temp[:,select==3] = (np.ones_like(temp[:,select==3]).T*temp1[:,index]).T
									# for i_Te,Te in enumerate(unique_Te):
									# 	for i_ne,ne in enumerate(unique_ne):
									# 		for i_nH2p_ne,nH2p_ne in enumerate(unique_nH2p_ne):
									# 			temp[:,np.logical_and(np.logical_and(Te_int==Te,ne_int==ne),nH2p_ne_int==nH2p_ne)]=(np.ones_like(temp[:,np.logical_and(np.logical_and(Te_int==Te,ne_int==ne),nH2p_ne_int==nH2p_ne)]).T*temp1[:,i_Te,i_ne,i_nH2p_ne]).T
									population_coefficients += (nHm_ne_int*( temp )).reshape((np.shape(population_coefficients)))
									population_coefficients_Hm += (nHm_ne_int*( temp )).reshape((np.shape(population_coefficients)))
								else:
									print('calculating Hn_with_Hp and Hn_with_H2p for each input value, it can be extremely slow and simply not work')
									temp1 = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_int,T_Hp,T_Hm,ne_int,nHp_ne_int*ne_int]).T,np.unique(excited_states_From_Hn_with_Hp))
									temp2 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_int,T_H2p,T_Hm,ne_int,nH2p_ne_int*ne_int]).T,np.unique(excited_states_From_Hn_with_H2p))
									population_coefficients += (nHm_ne_int*( temp1 + temp2 )).reshape((np.shape(population_coefficients)))
									population_coefficients_Hm = (nHm_ne_int*( temp1 + temp2 )).reshape((np.shape(population_coefficients)))

								unique_Te = np.unique(Te_int)
								unique_ne = np.unique(ne_int)
								sample_Te = (np.ones((len(unique_Te),len(unique_ne))).T*unique_Te).T
								sample_ne = np.ones((len(unique_Te),len(unique_ne)))*unique_ne

								temp1 = From_H2_pop_coeff_full_extra(np.array([sample_Te.flatten(),sample_ne.flatten()]).T,np.unique(excited_states_From_H2))
								temp1 = temp1.T
								temp1 = temp1.reshape((len(temp1),*np.shape(sample_Te)))
								temp = np.zeros((len(temp1),len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[:,np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[:,np.logical_and(Te_int==Te,ne_int==ne)]).T*temp1[:,i_Te,i_ne]).T
								population_coefficients += (nH2_ne_int*temp).reshape((np.shape(population_coefficients)))
								population_coefficients_H2 = (nH2_ne_int*temp).reshape((np.shape(population_coefficients)))

								temp1 = From_H2p_pop_coeff_full_extra(np.array([sample_Te.flatten(),sample_ne.flatten()]).T,np.unique(excited_states_From_H2p))
								temp1 = temp1.T
								temp1 = temp1.reshape((len(temp1),*np.shape(sample_Te)))
								temp = np.zeros((len(temp1),len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[:,np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[:,np.logical_and(Te_int==Te,ne_int==ne)]).T*temp1[:,i_Te,i_ne]).T
								population_coefficients += (nH2p_ne_int*temp).reshape((np.shape(population_coefficients)))
								population_coefficients_H2p = (nH2p_ne_int*temp).reshape((np.shape(population_coefficients)))

								# temp1 = From_H3p_pop_coeff_full_extra(np.array([sample_Te.flatten(),sample_ne.flatten()]).T,np.unique(excited_states_From_H3p))
								# temp1 = temp1.T
								# temp1 = temp1.reshape((len(temp1),*np.shape(sample_Te)))
								# temp = np.zeros((len(temp1),len(Te_int)))
								# for i_Te,Te in enumerate(unique_Te):
								# 	for i_ne,ne in enumerate(unique_ne):
								# 		temp[:,np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[:,np.logical_and(Te_int==Te,ne_int==ne)]).T*temp1[:,i_Te,i_ne]).T
								# population_coefficients += (nH3p_ne_int*temp).reshape((np.shape(population_coefficients)))
							population_states = population_coefficients * (ne_int**2)
							population_states_molecules = population_states - population_states_atoms
							power_rad_mol = np.sum((population_states_molecules.T * multiplicative_factor_full_full).T,axis=0)
							temp = population_coefficients_Hm * (ne_int**2)
							power_rad_Hm = np.sum((temp.T * multiplicative_factor_full_full).T,axis=0)
							temp = population_coefficients_H2 * (ne_int**2)
							power_rad_H2 = np.sum((temp.T * multiplicative_factor_full_full).T,axis=0)
							temp = population_coefficients_H2p * (ne_int**2)
							power_rad_H2p = np.sum((temp.T * multiplicative_factor_full_full).T,axis=0)

							if np.shape(Te_int)==():
								temp = read_adf11(pltfile, 'plt', 1, 1, 1, Te_int,ne_int * 10 ** (0 - 6))
								power_rad_excit = temp * (ne_int**2) *nH_ne_int * (10 ** -6)
							else:
								unique_Te = np.unique(Te_int)
								unique_ne = np.unique(ne_int)
								sample_Te = (np.ones((len(unique_Te),len(unique_ne))).T*unique_Te).T
								sample_ne = np.ones((len(unique_Te),len(unique_ne)))*unique_ne
								temp1 = read_adf11(pltfile, 'plt', 1, 1, 1, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))
								temp1 = temp1.reshape(np.shape(sample_Te))

								temp = np.zeros((len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[np.logical_and(Te_int==Te,ne_int==ne)])*temp1[i_Te,i_ne]).T
								temp1 = cp.deepcopy(temp)
								power_rad_excit = temp1 * (ne_int**2) *nH_ne_int * (10 ** -6)

							if np.shape(Te_int)==():
								temp = read_adf11(prbfile, 'prb', 1, 1, 1, Te_int,ne_int * 10 ** (0 - 6))
								power_rad_rec_bremm = temp * (ne_int**2) *nHp_ne_int * (10 ** -6)
							else:
								unique_Te = np.unique(Te_int)
								unique_ne = np.unique(ne_int)
								sample_Te = (np.ones((len(unique_Te),len(unique_ne))).T*unique_Te).T
								sample_ne = np.ones((len(unique_Te),len(unique_ne)))*unique_ne
								temp1 = read_adf11(prbfile, 'prb', 1, 1, 1, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))
								temp1 = temp1.reshape(np.shape(sample_Te))

								temp = np.zeros((len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[np.logical_and(Te_int==Te,ne_int==ne)])*temp1[i_Te,i_ne]).T
								temp1 = cp.deepcopy(temp)
								power_rad_rec_bremm = temp1 * (ne_int**2) *nHp_ne_int * (10 ** -6)

							if np.shape(Te_int)==():
								temp = read_adf11(scdfile, 'scd', 1, 1, 1, Te_int,ne_int * 10 ** (0 - 6))
								effective_ionisation_rates = temp * (ne_int**2) * nH_ne_int  * (10 ** -6)
								power_via_ionisation = effective_ionisation_rates*13.6/J_to_eV
							else:
								unique_Te = np.unique(Te_int)
								unique_ne = np.unique(ne_int)
								sample_Te = (np.ones((len(unique_Te),len(unique_ne))).T*unique_Te).T
								sample_ne = np.ones((len(unique_Te),len(unique_ne)))*unique_ne
								temp1 = read_adf11(scdfile, 'scd', 1, 1, 1, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))
								temp1 = temp1.reshape(np.shape(sample_Te))

								temp = np.zeros((len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[np.logical_and(Te_int==Te,ne_int==ne)])*temp1[i_Te,i_ne]).T
								temp1 = cp.deepcopy(temp)
								effective_ionisation_rates = temp1 * (ne_int**2) * nH_ne_int  * (10 ** -6)
								power_via_ionisation = effective_ionisation_rates*13.6/J_to_eV

							if np.shape(Te_int)==():
								temp = read_adf11(acdfile, 'acd', 1, 1, 1, Te_int,ne_int * 10 ** (0 - 6))
								effective_recombination_rates = temp *nHp_ne_int* (ne_int**2)* (10 ** -6)
								power_via_recombination = effective_recombination_rates*13.6/J_to_eV
							else:
								unique_Te = np.unique(Te_int)
								unique_ne = np.unique(ne_int)
								sample_Te = (np.ones((len(unique_Te),len(unique_ne))).T*unique_Te).T
								sample_ne = np.ones((len(unique_Te),len(unique_ne)))*unique_ne
								temp1 = read_adf11(acdfile, 'acd', 1, 1, 1, sample_Te.flatten(),sample_ne.flatten() * 10 ** (0 - 6))
								temp1 = temp1.reshape(np.shape(sample_Te))

								temp = np.zeros((len(Te_int)))
								for i_Te,Te in enumerate(unique_Te):
									for i_ne,ne in enumerate(unique_ne):
										temp[np.logical_and(Te_int==Te,ne_int==ne)]=(np.ones_like(temp[np.logical_and(Te_int==Te,ne_int==ne)])*temp1[i_Te,i_ne]).T
								temp1 = cp.deepcopy(temp)
								effective_recombination_rates = temp1 *nHp_ne_int* (ne_int**2)* (10 ** -6)
								power_via_recombination = effective_recombination_rates*13.6/J_to_eV

							if final_number_data==1:
								return np.array([power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination,power_rad_Hm,power_rad_H2,power_rad_H2p]).flatten()
							else:
								return power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination,power_rad_Hm,power_rad_H2,power_rad_H2p

						def calc_power_balance_elements_simplified(nH_ne_values,nHm_ne_values,nH2_ne_values,nH2p_ne_values,ne_values_array,Te_values_array,Te_values,ne_values,T_Hm_values,T_H2p_values,T_Hp_values):
							TS_Te_steps = len(Te_values_array)
							TS_ne_steps = len(ne_values_array)
							total_wavelengths = np.unique(excited_states_From_Hn_with_Hp)
							population_states_Hm = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps,len(total_wavelengths)))	# H, Hm, H2, H2p, ne, Te
							population_states_H2 = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps,len(total_wavelengths)))	# H, Hm, H2, H2p, ne, Te
							population_states_H2p = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps,len(total_wavelengths)))	# H, Hm, H2, H2p, ne, Te
							power_rad_excit = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							power_rad_rec_bremm = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							power_via_ionisation = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							power_via_recombination = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							coeff_1 = (((From_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)).T * (ne_values.flatten()**2)).T).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
							# coeff_1 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2p))))
							coeff_2 = (((From_H2_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)).T * (ne_values.flatten()**2)).T).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
							# coeff_2 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2))))
							total_power_rad_excit = (read_adf11(pltfile, 'plt', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
							power_rad_excit += total_power_rad_excit
							power_rad_excit = (power_rad_excit.T * nH_ne_values).T
							total_power_rad_rec_bremm = (read_adf11(prbfile, 'prb', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
							total_power_via_ionisation = (read_adf11(scdfile, 'scd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
							power_via_ionisation += total_power_via_ionisation
							power_via_ionisation = (power_via_ionisation.T * nH_ne_values).T
							total_power_via_recombination = (read_adf11(acdfile, 'acd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
							total_nH2_ne_value = []
							for i4,nH2_ne_value in enumerate(nH2_ne_values):
								total_nH2_ne_value.append( coeff_2 *  nH2_ne_value)
								# total_nH2_ne_value = nH2_ne_value * coeff_2
							total_nH2_ne_value = np.array(total_nH2_ne_value)
							population_states_H2 = np.transpose(population_states_H2, (0,1,3,2,4,5,6))	# H, Hm, H2p, H2, ne, Te
							population_states_H2 += total_nH2_ne_value
							population_states_H2 = np.transpose(population_states_H2, (0,1,3,2,4,5,6))	# H, Hm, H2, H2p, ne, Te

							for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
								total_nH2p_ne_value = ( nH2p_ne_value * coeff_1 )
								coeff_4 = (((From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,total_wavelengths)).T *(ne_values.flatten()**2)).T).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
								population_states_H2p[:,:,:,i5] = total_nH2p_ne_value
								for i3,nHm_ne_value in enumerate(nHm_ne_values):
									nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value
									if nHp_ne_value<0:
										continue
									elif nHp_ne_value==0:
										nHp_ne_value=1e-8
										power_via_recombination[:,i3,:,i5] = 0
										power_rad_rec_bremm[:,i3,:,i5] = 0
									else:
										power_via_recombination[:,i3,:,i5] = total_power_via_recombination * nHp_ne_value
										power_rad_rec_bremm[:,i3,:,i5] = total_power_rad_rec_bremm * nHp_ne_value
									coeff_3 = (((From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_value*ne_values.flatten()]).T ,total_wavelengths)).T *(ne_values.flatten()**2)).T).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
									total_nHm_ne_value = nHm_ne_value*( coeff_3 + coeff_4 )
									temp1 = 0
									# for i1,nH_ne_value in enumerate(nH_ne_values):
									# 	for i4,nH2_ne_value in enumerate(nH2_ne_values):
									population_states_Hm[:,i3,:,i5] = total_nHm_ne_value
							population_states_molecules = population_states_Hm + population_states_H2 + population_states_H2p
							power_rad_mol = np.sum((population_states_molecules * multiplicative_factor_full_full),axis=-1)
							power_rad_Hm = np.sum((population_states_Hm * multiplicative_factor_full_full),axis=-1)
							power_rad_H2 = np.sum((population_states_H2 * multiplicative_factor_full_full),axis=-1)
							power_rad_H2p = np.sum((population_states_H2p * multiplicative_factor_full_full),axis=-1)

							return power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination,power_rad_Hm,power_rad_H2,power_rad_H2p

						def calc_power_balance_elements_simplified2(H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps,Te_values,ne_values,multiplicative_factor_full_full,record_nH_ne_values,record_nHm_ne_values,record_nH2_ne_values,record_nH2p_ne_values,record_nHp_ne_values,T_Hp_values,T_H2p_values,T_Hm_values,coeff_1_record,coeff_2_record,coeff_3_record,coeff_4_record):
							total_wavelengths = np.unique(excited_states_From_Hn_with_Hp)
							power_rad_H2p = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							coeff_1 = coeff_1_record.reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
							power_rad_H2p = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							nH_ne_excited_states_mol = power_rad_H2p + np.sum((coeff_1),axis=-1) * (ne_values)
							power_rad_H2p = power_rad_H2p + np.sum((coeff_1 * multiplicative_factor_full_full),axis=-1) * (ne_values**2)
							power_rad_H2p = np.float32(power_rad_H2p * (record_nH2p_ne_values.reshape(H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)))	# H, Hm, H2, H2p, ne, Te
							nH_ne_excited_states_mol = np.float32(nH_ne_excited_states_mol * (record_nH2p_ne_values.reshape(H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)))	# H, Hm, H2, H2p, ne, Te
							# coeff_1 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2p))))
							coeff_2 = coeff_2_record.reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
							power_rad_H2 = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							temp = power_rad_H2 + np.sum((coeff_2),axis=-1) * (ne_values)
							power_rad_H2 = power_rad_H2 + np.sum((coeff_2 * multiplicative_factor_full_full),axis=-1) * (ne_values**2)
							power_rad_H2 = np.float32(power_rad_H2 * np.transpose([(record_nH2_ne_values.reshape(H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*(H2p_steps), (1,0,2,3)))	# H, Hm, H2, H2p, ne, Te
							temp = np.float32(temp * np.transpose([(record_nH2_ne_values.reshape(H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*(H2p_steps), (1,0,2,3)))	# H, Hm, H2, H2p, ne, Te
							nH_ne_excited_states_mol += temp
							power_rad_excit = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							total_power_rad_excit = (read_adf11(pltfile, 'plt', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
							power_rad_excit = power_rad_excit + total_power_rad_excit
							power_rad_excit = np.float32(np.transpose(power_rad_excit, (1,2,3,0,4,5)) * record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)))	# Hm, H2, H2p, H, ne, Te
							power_rad_excit = np.transpose(power_rad_excit, (3,0,1,2,4,5))	# H, Hm, H2, H2p, ne, Te
							power_via_ionisation = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
							total_power_via_ionisation = (read_adf11(scdfile, 'scd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
							power_via_ionisation = power_via_ionisation + total_power_via_ionisation
							power_via_ionisation = np.float32(np.transpose(power_via_ionisation, (1,2,3,0,4,5)) * record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)))	# Hm, H2, H2p, H, ne, Te
							power_via_ionisation = np.transpose(power_via_ionisation, (3,0,1,2,4,5))	# H, Hm, H2, H2p, ne, Te
							total_power_rad_rec_bremm = (read_adf11(prbfile, 'prb', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
							power_rad_rec_bremm = np.float32([(total_power_rad_rec_bremm * record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))).tolist()]*(H_steps))
							total_power_via_recombination = (read_adf11(acdfile, 'acd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
							power_via_recombination = np.float32([(total_power_via_recombination * record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))).tolist()]*(H_steps))
							power_via_brem =  np.float32([(record_nHp_ne_values.reshape(Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps) * 5.35*1e-37 * (Te_values/1000)**0.5 * (ne_values**2)).tolist()]*H_steps)	# Wesson, Tokamaks
							power_rad_Hm = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne, Te
							power_rec_neutral = 3/2*(power_via_recombination/13.6*(T_Hp_values.reshape((TS_ne_steps,TS_Te_steps))*eV_to_K)).astype(np.float32)	# power removed from plasma column due to recombination by the kinetic energy of the neutral (assuming Te=TH+)

							for i4 in range(H2_steps):
								for i5 in range(H2p_steps):
									nH2p_ne_values = record_nH2p_ne_values[i4,i5]
									# coeff_4 = (From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_values*ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
									coeff_4 = coeff_4_record[i4*H2p_steps + i5].reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
									temp = np.sum((coeff_4),axis=-1)*(ne_values)
									coeff_4 = np.sum((coeff_4 * multiplicative_factor_full_full),axis=-1)*(ne_values**2)
									for i3 in range(Hm_steps):
										nHm_ne_values = record_nHm_ne_values[i4,i3]
										nHp_ne_values = 1 - nH2p_ne_values + nHm_ne_values
										nHp_ne_good = nHp_ne_values>=0
										# nHp_ne_mid = nHp_ne_values==0
										# nHp_ne_bad = nHp_ne_values<0
										# nHp_ne_values[nHp_ne_mid]=1e-10
										# nHp_ne_values[nHp_ne_bad]=1e-10
										# temp = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten()[nHp_ne_good],T_Hp_values[nHp_ne_good],T_Hm_values[nHp_ne_good],ne_values.flatten()[nHp_ne_good],nHp_ne_values[nHp_ne_good]*(ne_values.flatten()[nHp_ne_good])]).T ,total_wavelengths)
										# coeff_3 = np.zeros((TS_ne_steps*TS_Te_steps,len(total_wavelengths)))
										# coeff_3[nHp_ne_good] = temp
										# coeff_3 = coeff_3.reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										# coeff_3 = (From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_values*(ne_values.flatten())]).T ,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										coeff_3 = coeff_3_record[i4*Hm_steps*H2p_steps + i5*Hm_steps + i3].reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										temp += np.sum((coeff_3),axis=-1) *(ne_values)
										coeff_3 = np.sum((coeff_3 * multiplicative_factor_full_full),axis=-1) *(ne_values**2)
										# coeff_3[(np.logical_and(nHp_ne_mid,nHp_ne_bad)).reshape((TS_ne_steps,TS_Te_steps))]=0
										# nHp_ne_good = np.logical_or(nHp_ne_good,nHp_ne_mid).reshape((TS_ne_steps,TS_Te_steps))
										nHp_ne_good = nHp_ne_good.reshape((TS_ne_steps,TS_Te_steps))
										power_rad_Hm[:,i3,i4,i5,nHp_ne_good] = (nHm_ne_values.reshape((TS_ne_steps,TS_Te_steps))*( coeff_3 + coeff_4 )).astype(np.float32)[nHp_ne_good]
										nH_ne_excited_states_mol[:,i3,i4,i5] += (nHm_ne_values.reshape((TS_ne_steps,TS_Te_steps))*( temp ))
							power_rad_mol = (power_rad_Hm + power_rad_H2 + power_rad_H2p).astype(np.float32)
							power_heating_rec = (power_via_recombination - power_rad_rec_bremm + power_via_brem).astype(np.float32)
							# power_heating_rec[power_heating_rec<0]=0
							tot_rad_power = (power_rad_excit+power_rad_rec_bremm+power_rad_mol).astype(np.float32)
							total_removed_power_atomic = np.float32(power_via_ionisation + power_rad_excit + power_via_recombination + power_rec_neutral + power_via_brem)
							# total_removed_power = power_via_ionisation + power_rad_excit + power_via_recombination + power_rec_neutral + power_via_brem + power_rad_mol

							return power_rad_H2p,power_rad_H2,power_rad_excit,power_via_ionisation,power_rad_rec_bremm,power_via_recombination,power_via_brem,power_rec_neutral,power_rad_Hm,power_rad_mol,power_heating_rec,tot_rad_power,total_removed_power_atomic,nH_ne_excited_states_mol

						def calc_stuff(arg):
							try:
								domain_index = arg[0]
								sgna = 0;print('worker '+str(current_process())+' marker '+str(sgna)+' '+str(domain_index))
								my_time_pos = arg[1]
								my_r_pos = arg[2]
								pass_index = arg[3]
								guess = arg[4]
								ionization_length_H = arg[5]
								# ionization_length_Hm = arg[6]
								ionization_length_H2 = arg[6]
								# ionization_length_H2p = arg[8]
								to_print = arg[7]

								inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								inverted_profiles_crop_sigma_restrict = inverted_profiles_sigma_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop[my_time_pos, my_r_pos]
								merge_dne_prof_multipulse_interp_crop_limited_restrict = max(merge_dne_prof_multipulse_interp_crop[my_time_pos, my_r_pos],0.1)
								merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop[my_time_pos, my_r_pos]
								merge_dTe_prof_multipulse_interp_crop_limited_restrict = max(merge_dTe_prof_multipulse_interp_crop[my_time_pos, my_r_pos],0.1)
								recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
								excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()
								max_frac_acceptable_deviation = max_frac_acceptable_deviation_ext

								if pass_index<=1:
									if (merge_ne_prof_multipulse_interp_crop_limited_restrict < 5e-07 or merge_Te_prof_multipulse_interp_crop_limited_restrict < 0.1):
										print('worker '+str(current_process())+' marker 999 '+str(domain_index)+' my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped ne %.3g, Te %.3g' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict))
										results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output
								else:
									if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										print('worker '+str(current_process())+' marker 999 '+str(domain_index)+' my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped ne %.3g, Te %.3g' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict))
										results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output

								start_time = tm.time()
								print('worker '+str(current_process())+' actually running '+str(domain_index))
								# if np.sum(inverted_profiles_crop_restrict == 0)>2:
								# 	continue

								if False:
									T_Hp = 12000	# K
									T_Hm = 12000	# K
									T_H2p = 5000	# K
								else:
									T_Hp = merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K	# K
									T_Hm = np.exp(TH2_fit_from_simulations(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))/eV_to_K	# K
									T_H2p = np.exp(TH2_fit_from_simulations(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))/eV_to_K	# K
								ne = merge_ne_prof_multipulse_interp_crop_limited_restrict * 1e20
								multiplicative_factor = energy_difference[n_list_all - 4] * einstein_coeff[n_list_all - 4] / J_to_eV
								if merge_ne_prof_multipulse_interp_crop_limited_restrict>2:
									min_mol_fraction = min_mol_fraction_ext/10
								else:
									min_mol_fraction = min_mol_fraction_ext


								if False:	# pre 21/05/2020
									max_nH2_from_pressure_int = max_nH2_from_pressure_all[my_time_pos]
									if ionization_length_H<=0.5:
										max_nmolecules_ne_low_ionisation_length = 0.05
										max_nH2_from_pressure_int = ne/10
									else:
										max_nmolecules_ne_low_ionisation_length = 0.15
										max_nH2_from_pressure_int = max_nH2_from_pressure*1
								elif False:	# post 21/05/2020
									max_nH2_from_pressure_int = nH2_from_pressure*max((1-np.sum(dr/ionization_length_H[my_time_pos, my_r_pos:])*1e3),1e-6)	# H2 ionisation 3-4 order stronger than H
									max_nmolecules_ne_low_ionisation_length = nH2_from_pressure*ionization_length_H[my_time_pos, my_r_pos]*1e-3*min(np.sum(dr/ionization_length_H[my_time_pos, my_r_pos:])*1e3,1)	# H2 ionisation 3-4 order stronger than H
									# if ionization_length_H[my_time_pos, my_r_pos]<=0.5:
									# 	max_nmolecules_ne_low_ionisation_length = 10*nH2_from_pressure/ne*300/(max(merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K,300))
									# else:
									# 	max_nmolecules_ne_low_ionisation_length = nH2_from_pressure
								elif True:	# this is after analysis of Ray simulations with B2.5-Eunomia
									max_nH2_ne = np.max(nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict))*20
									min_nH2_ne = np.min(nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict))/5
									centre_nH2_ne = nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict)
									# limit_H_H2_up = interpolate.interp1d([0.1,0.2,4],[100,20,20],fill_value='extrapolate')
									# limit_H_H2_down = interpolate.interp1d([0.1,2,4],[10,0.03,0.03],fill_value='extrapolate')
									# limit_H_H2_up = np.exp(limit_H_H2_up(np.log(min(merge_Te_prof_multipulse_interp_crop_limited_restrict-merge_dTe_prof_multipulse_interp_crop_limited_restrict,0.1))))
									# limit_H_H2_down = np.exp(limit_H_H2_down(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict+merge_dTe_prof_multipulse_interp_crop_limited_restrict)))
									# max_nH_ne = min(limit_H_H2_up-min_nH2_ne,20)
									# min_nH_ne = max(limit_H_H2_down-max_nH2_ne,3e-2)
									max_nH_ne = np.exp(limit_H_up(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))
									min_nH_ne = np.exp(limit_H_down(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))
									centre_nH_ne = nH_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict)


								# if pass_index>1:
								# 	if ionization_length_H2<1e-6:
								# 		max_nH2_from_pressure_int = ne/100000

								# TS_steps = 11
								TS_Te_steps = 13	# 13, 15
								TS_ne_steps = 17	# 17, 19
								if collect_power_PDF:
									to_find_steps = 23	# 25/21
								else:
									to_find_steps = 23	# 25/21
								H_steps = 13	# this MUST be odd		# 23/13, 15
								H2_steps = 7	# this MUST be odd		# 11/7
								# probability = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps))
								# guessed_values = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps))
								# calculated_emission = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,len(n_list_all)))
								Te_values = np.linspace(max(np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])/2,merge_Te_prof_multipulse_interp_crop_limited_restrict-4*merge_dTe_prof_multipulse_interp_crop_limited_restrict),merge_Te_prof_multipulse_interp_crop_limited_restrict+4*merge_dTe_prof_multipulse_interp_crop_limited_restrict,TS_Te_steps)
								# if pass_index<=1:
								# 	Te_values[Te_values<0.1]=0.1
								# else:
								# Te_values[Te_values<np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])/2]=np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])/2
								Te_values_array = np.unique(Te_values)
								# gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
								# Te_probs = gauss(np.linspace(-1,+1,TS_steps),1/((2*np.pi)**0.5),1,0)
								# Te_probs = Te_probs/np.sum(Te_probs)
								# # Te_probs = np.ones((TS_steps,TS_steps))*Te_probs

								# ne_values = ne+np.linspace(-2,+6,TS_ne_steps)*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20
								ne_values = np.logspace(np.log10(max(ne-2*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20,1e20*np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])/10)),np.log10(ne+8*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20),num=TS_ne_steps)
								# if pass_index<=1:
								# 	ne_values[ne_values<5e13]=5e13
								# else:
								# ne_values[ne_values<1e20*np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])/4]=1e20*np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])/4
								ne_values_array = np.unique(ne_values)
								# ne_probs = gauss(np.linspace(-1,+1,TS_steps),1/((2*np.pi)**0.5),1,0)
								# ne_probs = ne_probs/np.sum(ne_probs)
								# # ne_probs = (np.ones((TS_steps,TS_steps))*ne_probs).T
								if False:
									# nHp_ne = np.logspace(np.log10(max_nHp_ne),np.log10(max(min_nHp_ne,0.01)),num=to_find_steps)	# this is 1 - nH2p_ne + nHm_ne
									nH_ne = np.logspace(np.log10(max_n_neutrals_ne),np.log10(max(min_nH_ne,0.1)),num=to_find_steps)
									# nHpolecule_ne = np.logspace(np.log10(max_nmolecules_ne_low_ionisation_length),np.log10(max_nmolecules_ne_low_ionisation_length/1000),num=to_find_steps)
									# nH2_ne = np.logspace(np.log10(max_nH2_from_pressure_int/ne),np.log10(max_nH2_from_pressure_int/10000/ne),num=to_find_steps)
									nHpolecule_ne = np.logspace(np.log10(10*max_nmolecules_ne_low_ionisation_length/ne),np.log10(max_nmolecules_ne_low_ionisation_length/1000/ne),num=to_find_steps)
									nH2_ne = np.logspace(np.log10(10*max_nH2_from_pressure_int/ne),np.log10(1e-3*max_nH2_from_pressure_int/ne),num=to_find_steps_H2)
								if True:	# this is after analysis of Ray simulations with B2.5-Eunomia
									# nH2_ne_values = np.array([min_nH2_ne,(centre_nH2_ne+2*min_nH2_ne)/3,(2*centre_nH2_ne+min_nH2_ne)/3,centre_nH2_ne,(2*centre_nH2_ne+max_nH2_ne)/3,(centre_nH2_ne+2*max_nH2_ne)/3,max_nH2_ne])
									# # nH2_ne_probs = gauss(np.linspace(-2,+2,5),1/((2*np.pi)**0.5),1,0)
									# # nH2_ne_probs = nH2_ne_probs/np.sum(nH2_ne_probs)
									# nH2_ne_log_probs = -0.5*(np.linspace(-2,+2,7)**2)
									H2_left_interval = np.logspace(np.log10(min_nH2_ne),np.log10(centre_nH2_ne),num=(H2_steps+1)/2)[:-1]
									H2_right_interval = np.logspace(np.log10(centre_nH2_ne),np.log10(max_nH2_ne),num=(H2_steps+1)/2)[1:]
									nH2_ne_values = np.array(H2_left_interval.tolist() + [centre_nH2_ne] + H2_right_interval.tolist())
									H2_left_interval_log_probs = -0.5*((np.log10(H2_left_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/min_nH2_ne)/2))**2)	# centre_nH2_ne-min_nH2_ne is 2 sigma
									H2_right_interval_log_probs = -0.5*((np.log10(H2_right_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/max_nH2_ne)/2))**2)	# centre_nH2_ne-max_nH2_ne is 2 sigma
									nH2_ne_log_probs = np.array(H2_left_interval_log_probs.tolist() + [0] + H2_right_interval_log_probs.tolist())
									nH2_ne_log_probs = nH2_ne_log_probs -np.log(np.sum(np.exp(nH2_ne_log_probs)))	# normalisation for logarithmic probabilities
									# nH_ne_probs = gauss(np.linspace(-2,+2,5),1/((2*np.pi)**0.5),1,0)
									# nH_ne_probs = nH_ne_probs/np.sum(nH_ne_probs)
									if True:	# known probability distribution for nH
										# nH_ne_values = np.array([min_nH_ne,(centre_nH_ne+3*min_nH_ne)/4,(2*centre_nH_ne+2*min_nH_ne)/4,(3*centre_nH_ne+min_nH_ne)/4,centre_nH_ne,(3*centre_nH_ne+max_nH_ne)/4,(2*centre_nH_ne+2*max_nH_ne)/4,(centre_nH_ne+3*max_nH_ne)/4,max_nH_ne])
										# nH_ne_log_probs = -0.5*(np.linspace(-2,+2,9)**2)
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=(H_steps-1))
										# H_left_interval = np.logspace(np.log10(min_nH_ne),np.log10(centre_nH_ne),num=(H_steps+1)/2)[:-1]
										# H_right_interval = np.logspace(np.log10(centre_nH_ne),np.log10(max_nH_ne),num=(H_steps+1)/2)[1:]
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										nH_ne_values = np.array(H_left_interval.tolist() + [centre_nH_ne] + H_right_interval.tolist())
										H_left_interval_log_probs = -(0.5*((np.log10(H_left_interval/centre_nH_ne)/(np.log10(centre_nH_ne/min_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-min_nH_ne is 3 sigma
										H_right_interval_log_probs = -(0.5*((np.log10(H_right_interval/centre_nH_ne)/(np.log10(centre_nH_ne/max_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-max_nH_ne is 3 sigma
										nH_ne_log_probs = np.array(H_left_interval_log_probs.tolist() + [0] + H_right_interval_log_probs.tolist())
									else:	# uniform probability for nH
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=H_steps)
										nH_ne_log_probs = np.ones((H_steps))
									nH_ne_log_probs = nH_ne_log_probs -np.log(np.sum(np.exp(nH_ne_log_probs)))	# normalisation for logarithmic probabilities
									nH2p_ne_values = np.logspace(np.log10(max(min_mol_fraction,min_nH2_ne*1e-5)),np.log10(min(centre_nH2_ne/10,10-1e-3)),num=to_find_steps)
									nHm_ne_values = np.logspace(np.log10(max(min_mol_fraction,min_nH2_ne*1e-5)),np.log10(min(centre_nH2_ne/10,10-1e-3)),num=to_find_steps)

								if True:	# 2020/07/13 at the moment these are not used /2020/07/15 let's try to
									def nH_ne_values_Te(Te,H_steps):
										H_steps = H_steps//2*2+1
										max_nH_ne = np.exp(limit_H_up(np.log(Te)))
										min_nH_ne = np.exp(limit_H_down(np.log(Te)))
										centre_nH_ne = nH_ne_fit_from_simulations(Te)
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=(H_steps-1))
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										nH_ne_values = np.array(H_left_interval.tolist() + [centre_nH_ne] + H_right_interval.tolist())
										return nH_ne_values
									def nH_ne_log_probs_Te(Te,nH_ne_values):
										max_nH_ne = np.exp(limit_H_up(np.log(Te)))
										min_nH_ne = np.exp(limit_H_down(np.log(Te)))
										centre_nH_ne = nH_ne_fit_from_simulations(Te)
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										nH_ne_values = np.array(H_left_interval.tolist() + [centre_nH_ne] + H_right_interval.tolist())
										H_left_interval_log_probs = -(0.5*((np.log10(H_left_interval/centre_nH_ne)/(np.log10(centre_nH_ne/min_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-min_nH_ne is 3 sigma
										H_right_interval_log_probs = -(0.5*((np.log10(H_right_interval/centre_nH_ne)/(np.log10(centre_nH_ne/max_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-max_nH_ne is 3 sigma
										nH_ne_log_probs = np.array(H_left_interval_log_probs.tolist() + [0] + H_right_interval_log_probs.tolist())
										return nH_ne_log_probs
									def nH2_ne_values_Te(Te,H2_steps):
										H2_steps = H2_steps//2*2+1
										max_nH2_ne = np.max(nH2_ne_fit_from_simulations(Te))*20
										min_nH2_ne = np.min(nH2_ne_fit_from_simulations(Te))/5
										centre_nH2_ne = nH2_ne_fit_from_simulations(Te)
										H2_left_interval = np.logspace(np.log10(min_nH2_ne),np.log10(centre_nH2_ne),num=(H2_steps+1)/2)[:-1]
										H2_right_interval = np.logspace(np.log10(centre_nH2_ne),np.log10(max_nH2_ne),num=(H2_steps+1)/2)[1:]
										nH2_ne_values = np.array(H2_left_interval.tolist() + [centre_nH2_ne] + H2_right_interval.tolist())
										return nH2_ne_values
									def nH2_ne_log_probs_Te(Te,nH2_ne_values):
										max_nH2_ne = np.max(nH2_ne_fit_from_simulations(Te))*20
										min_nH2_ne = np.min(nH2_ne_fit_from_simulations(Te))/5
										centre_nH2_ne = nH2_ne_fit_from_simulations(Te)
										H2_left_interval = np.logspace(np.log10(min_nH2_ne),np.log10(centre_nH2_ne),num=(H2_steps+1)/2)[:-1]
										H2_right_interval = np.logspace(np.log10(centre_nH2_ne),np.log10(max_nH2_ne),num=(H2_steps+1)/2)[1:]
										nH2_ne_values = np.array(H2_left_interval.tolist() + [centre_nH2_ne] + H2_right_interval.tolist())
										H2_left_interval_log_probs = -0.5*((np.log10(H2_left_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/min_nH2_ne)/2))**2)	# centre_nH2_ne-min_nH2_ne is 2 sigma
										H2_right_interval_log_probs = -0.5*((np.log10(H2_right_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/max_nH2_ne)/2))**2)	# centre_nH2_ne-max_nH2_ne is 2 sigma
										nH2_ne_log_probs = np.array(H2_left_interval_log_probs.tolist() + [0] + H2_right_interval_log_probs.tolist())
										nH2_ne_log_probs = nH2_ne_log_probs -np.log(np.sum(np.exp(nH2_ne_log_probs)))	# normalisation for logarithmic probabilities
										return nH2_ne_log_probs

								if False:	# I don't look anymore at a fixed H2+/H- ratio but use the Bayesian aproach instead, so this is not usefull anymore
									# section added to search the effect of a fixed fraction of nH-/nH2+ on power balance
									nHm_ne_additional_values = []
									for fraction in fixed_fractions_nHm_H2p:
										for value in nH2p_ne_values*fraction:
											if np.min(np.abs(nHm_ne_values - value)/value)>max_frac_acceptable_deviation*3:
												nHm_ne_additional_values.append(value)
									nHm_ne_additional_values = np.array(nHm_ne_additional_values)
									nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values<centre_nH2_ne/10]
									# nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values>min_mol_fraction]
									if len(nHm_ne_values)+len(nHm_ne_additional_values)>40:	# emergency measure to limit the memory usage
										max_frac_acceptable_deviation *= 1.2
										print('worker '+str(current_process())+' '+str(domain_index)+' max_frac_acceptable_deviation increased on 1 Hm '+str(len(nHm_ne_values)+len(nHm_ne_additional_values)))
										nHm_ne_additional_values = []
										for fraction in fixed_fractions_nHm_H2p:
											for value in nH2p_ne_values*fraction:
												if np.min(np.abs(nHm_ne_values - value)/value)>max_frac_acceptable_deviation*3:
													nHm_ne_additional_values.append(value)
										nHm_ne_additional_values = np.array(nHm_ne_additional_values)
										nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values<centre_nH2_ne/10]
										print('worker '+str(current_process())+' '+str(domain_index)+' 1 Hm reduced to '+str(len(nHm_ne_values)+len(nHm_ne_additional_values)))
										# nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values>min_mol_fraction]
									nHm_ne_values = np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))


								# calculated_emission = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,len(n_list_all)))
								# for i1,nH_ne_value in enumerate(nH_ne):
								# 	total_nH_ne_value = (((excitation_internal[n_list_all - 4] *  nH_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# 	nHp_ne_value = 1
								# 	# for i2,nHp_ne_value in enumerate(nHp_ne):
								# 	total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# 	for i3,nHm_ne_value in enumerate(nHpolecule_ne):
								# 		for i4,nH2_ne_value in enumerate(nHpolecule_ne):
								# 			total_nH2_ne_value = nH2_ne_value*From_H2_pop_coeff_full(np.array([Te_values.flatten(),ne_values.flatten()]).T,n_list_all)
								# 			for i5,nH2p_ne_value in enumerate(nHpolecule_ne):
								# 				total_nHm_ne_value = nHm_ne_value*( From_Hn_with_Hp_pop_coeff_full(np.array([Te_values.flatten(),T_Hp*np.ones_like(Te_values.flatten()),T_Hm*np.ones_like(Te_values.flatten()),ne_values.flatten()*1e20,nHp_ne_value*ne_values.flatten()*1e20]).T ,n_list_all) + From_Hn_with_H2p_pop_coeff_full(np.array([Te_values.flatten(),T_H2p*np.ones_like(Te_values.flatten()),T_Hm*np.ones_like(Te_values.flatten()),ne_values.flatten()*1e20,nH2p_ne_value*ne_values.flatten()*1e20]).T,n_list_all) )
								# 				total_nH2p_ne_value = nH2p_ne_value*From_H2p_pop_coeff_full(np.array([Te_values.flatten(),ne_values.flatten()*1e20]).T,n_list_all)
								# 				# for i6,nH3p_ne_value in enumerate(nHpolecule_ne):
								# 				# 	total_nH3p_ne_value = nH3p_ne_value*From_H3p_pop_coeff_full(np.array([Te_values.flatten(),ne_values.flatten()*1e20]).T,n_list_all)
								# 				total = total_nH_ne_value+total_nHp_ne_value+total_nH2_ne_value+total_nHm_ne_value+total_nH2p_ne_value# +total_nH3p_ne_value
								# 				total = (total.T*(Te_values.flatten() ** 2)).T*multiplicative_factor * 1e40
								# 				calculated_emission[:,:,i1,i3,i4,i5,:]=total.reshape((5,5,8))

								for loop_index in [0,1]:
									TS_Te_steps = len(Te_values_array)
									TS_ne_steps = len(ne_values_array)

									Te_log_probs = -(0.5*(((Te_values_array-merge_Te_prof_multipulse_interp_crop_limited_restrict)/(merge_dTe_prof_multipulse_interp_crop_limited_restrict/2))**2))**1	# super gaussian order 1
									Te_log_probs = Te_log_probs -np.log(np.sum(np.exp(Te_log_probs)))	# normalisation for logarithmic probabilities
									ne_log_probs = -(0.5*(((ne_values_array-ne)/(merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20/2))**2))**1	# super gaussian order 1
									ne_log_probs = ne_log_probs -np.log(np.sum(np.exp(ne_log_probs)))	# normalisation for logarithmic probabilities
									ne_values = (np.ones((TS_Te_steps,TS_ne_steps))*ne_values_array).T
									Te_values = np.ones((TS_ne_steps,TS_Te_steps))*Te_values_array

									excitation_internal = []
									for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
										temp = read_adf15(pecfile, isel, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										temp[np.isnan(temp)] = 0
										# temp = temp.reshape((np.shape(Te_values)))
										excitation_internal.append(temp)
									excitation_internal = np.array(excitation_internal)  # in # photons cm^-3 s^-1
									excitation_internal = (excitation_internal.T * (10 ** -6) * (energy_difference / J_to_eV))  # in W m^-3 / (# / m^3)**2
									excitation_internal = (excitation_internal[:,n_list_all - 4] /multiplicative_factor)  # in m^-3 / (# / m^3)**2

									recombination_internal = []
									for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
										temp = read_adf15(pecfile, isel, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										temp[np.isnan(temp)] = 0
										# temp = temp.reshape((np.shape(Te_values)))
										recombination_internal.append(temp)
									recombination_internal = np.array(recombination_internal)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
									recombination_internal = (recombination_internal.T * (10 ** -6) * (energy_difference / J_to_eV))  # in W m^-3 / (# / m^3)**2
									recombination_internal = (recombination_internal[:,n_list_all - 4] /multiplicative_factor)  # in m^-3 / (# / m^3)**2

									# calculated_emission = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,len(n_list_all)))
									calculated_emission_log_probs = -np.ones((len(nH_ne_values),len(nHm_ne_values),H2_steps,len(nH2p_ne_values),TS_ne_steps,TS_Te_steps),dtype=np.float32)*np.inf	# H, Hm, H2, H2p, ne, Te
									# calculated_emission_error = np.ones((to_find_steps,to_find_steps))	# Hm, H2p
									# nHp_ne_value = 1
									# total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
									# total_nHp_ne_value = recombination_internal * nHp_ne_value
									coeff_1 = From_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,n_list_all)
									coeff_2 = From_H2_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,n_list_all)
									T_Hm_values = np.exp(TH2_fit_from_simulations(np.log(Te_values.flatten())))/eV_to_K	# K
									T_H2p_values = np.exp(TH2_fit_from_simulations(np.log(Te_values.flatten())))/eV_to_K	# K
									T_Hp_values = Te_values.flatten()/eV_to_K	# K
									coeff_3_record = []
									coeff_4_record = []
									total_nH_ne_value = []
									for i1,nH_ne_value in enumerate(nH_ne_values):
										# total_nH_ne_value.append(excitation_internal *  nH_ne_value)
										total_nH_ne_value.append(np.ones((H2_steps,*np.shape(excitation_internal)))*excitation_internal *  nH_ne_value)
										# total_nH_ne_value = excitation_internal *  nH_ne_value
									total_nH_ne_value = np.array(total_nH_ne_value)
									total_nH_ne_value = np.transpose(total_nH_ne_value*multiplicative_factor, (0,1,3,2))	# H, H2, lines, ne*Te
									total_nH_ne_value = total_nH_ne_value * (ne_values.flatten() ** 2)
									total_nH_ne_value = np.float32(np.transpose(total_nH_ne_value, (0,1,3,2)))	# H, H2, ne*Te, lines
									total_nH2_ne_value = []
									for i4,nH2_ne_value in enumerate(nH2_ne_values):
										total_nH2_ne_value.append( coeff_2 *  nH2_ne_value )
										# total_nH2_ne_value = nH2_ne_value * coeff_2
									total_nH2_ne_value = np.array(total_nH2_ne_value)
									total_nH2_ne_value = np.transpose(total_nH2_ne_value*multiplicative_factor, (0,2,1))	# H2, lines, ne*Te
									total_nH2_ne_value = total_nH2_ne_value * (ne_values.flatten() ** 2)
									total_nH2_ne_value = np.float32(np.transpose(total_nH2_ne_value, (0,2,1)))	# H2, ne*Te, lines
									total_nH_nH2_ne_value = total_nH_ne_value + total_nH2_ne_value
									for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
										total_nH2p_ne_value = nH2p_ne_value * coeff_1
										total_nH2p_ne_value = (total_nH2p_ne_value*multiplicative_factor).T	# lines, ne*Te
										total_nH2p_ne_value = total_nH2p_ne_value * (ne_values.flatten() ** 2)
										total_nH2p_ne_value = np.float32(total_nH2p_ne_value.T)	# ne*Te, lines
										total_nH_nH2_nH2p_ne_value = total_nH_nH2_ne_value + total_nH2p_ne_value
										coeff_4 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,n_list_all)
										coeff_4_record.append(coeff_4)
										for i3,nHm_ne_value in enumerate(nHm_ne_values):
											nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value
											if nHp_ne_value<0:
												nHp_ne_value=1e-8
												coeff_3_record.append(0)
												continue
											elif nHp_ne_value==0:
												nHp_ne_value=1e-8
												total_nHp_ne_value = 0
											else:
												total_nHp_ne_value = recombination_internal * nHp_ne_value
											coeff_3 = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_value*ne_values.flatten()]).T ,n_list_all)
											coeff_3_record.append(coeff_3)
											total_nHm_ne_value = nHm_ne_value*( coeff_3 + coeff_4 )
											temp1 = 0
											# for i1,nH_ne_value in enumerate(nH_ne_values):
											# 	for i4,nH2_ne_value in enumerate(nH2_ne_values):
											# 		total = total_nH_ne_value[i1]+total_nH2_ne_value[i4]+total_nHp_ne_value+total_nHm_ne_value+total_nH2p_ne_value# +total_nH3p_ne_value
											# 		calculated_emission = (total.T*(ne_values.flatten() ** 2)).T*multiplicative_factor
											# 		temp = -0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1)
											# 		# temp1 += np.sum(temp * Te_probs.flatten() * ne_probs.flatten())*nH_ne_probs[i1]*nH2_ne_probs[i4]
											# 		calculated_emission_log_probs[i1,i3,i4,i5]= temp.reshape((TS_ne_steps,TS_Te_steps))
											total = total_nHp_ne_value+total_nHm_ne_value# +total_nH3p_ne_value	# H, H2, ne*Te, lines
											total = (total*multiplicative_factor).T	# lines, ne*Te
											total = np.float32(total * (ne_values.flatten() ** 2))
											calculated_emission = total_nH_nH2_nH2p_ne_value + total.T	# H, H2, ne*Te, lines
											temp = np.float32(-0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1))
											calculated_emission_log_probs[:,i3,:,i5]= temp.reshape((len(nH_ne_values),H2_steps,TS_ne_steps,TS_Te_steps))
									# calculated_emission_log_probs -= np.max(calculated_emission_log_probs)
									calculated_emission_log_probs = calculated_emission_log_probs-np.log(np.sum(np.exp(calculated_emission_log_probs)))	# normalisation for logarithmic probabilities

									# likelihood_log_probs = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
									# for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
									# 	for i3,nHm_ne_value in enumerate(nHm_ne_values):
									# 		for i1,nH_ne_value in enumerate(nH_ne_values):
									# 			temp_i1 = nH_ne_log_probs[i1]
									# 			for i4,nH2_ne_value in enumerate(nH2_ne_values):
									# 				temp_i4 = nH2_ne_log_probs[i4]
									# 				for i6 in range(TS_ne_steps):
									# 					temp_i6 = ne_log_probs[i6]
									# 					for i7 in range(TS_Te_steps):
									# 						likelihood_log_probs[i1,i3,i4,i5,i6,i7]= calculated_emission_log_probs[i1,i3,i4,i5,i6,i7]+Te_log_probs[i7]+temp_i6+temp_i4+temp_i1
									# likelihood_log_probs = ((calculated_emission_log_probs + Te_log_probs + (np.ones((TS_Te_steps,TS_ne_steps))*ne_log_probs).T + (np.ones((TS_Te_steps,TS_ne_steps,len(nH2p_ne_values),len(nH2_ne_values)))*nH2_ne_log_probs).T ).T + nH_ne_log_probs).T
									likelihood_log_probs = np.float32(((calculated_emission_log_probs + np.float32(Te_log_probs) + (np.ones((TS_Te_steps,TS_ne_steps),dtype=np.float32)*np.float32(ne_log_probs)).T + (np.ones((TS_Te_steps,TS_ne_steps,len(nH2p_ne_values),len(nH2_ne_values)),dtype=np.float32)*np.float32(nH2_ne_log_probs)).T ).T + np.float32(nH_ne_log_probs)).T)
									# likelihood_log_probs = likelihood_log_probs-np.max(likelihood_log_probs)
									likelihood_log_probs = likelihood_log_probs-np.log(np.sum(np.exp(likelihood_log_probs)))	# normalisation for logarithmic probabilities

									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' Initial loop nr '+str(loop_index)+' done '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)))

									if loop_index==0:
										if False:	# logarithmic interval scaling
											d_nH_ne_values = np.ones_like(nH_ne_values)
											d_nHm_ne_values = np.ones_like(nHm_ne_values)
											d_nH2_ne_values = np.array([*np.diff(np.log10(nH2_ne_values[[0,1]])),*(np.diff(np.log10(nH2_ne_values))[:-1]/2+np.diff(np.log10(nH2_ne_values))[1:]/2),*np.diff(np.log10(nH2_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2_ne_values[[0,-1]]))+np.diff(np.log10(nH2_ne_values[[0,1]]))/2+np.diff(np.log10(nH2_ne_values[[-2,-1]]))/2)
											d_nH2p_ne_values = np.ones_like(nH2p_ne_values)
										elif True:	# linear interval scaling
											d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])/(np.diff(nH_ne_values[[0,-1]])+np.diff(nH_ne_values[[0,1]])/2+np.diff(nH_ne_values[[-2,-1]])/2)
											d_nHm_ne_values = np.array([*np.diff(nHm_ne_values[[0,1]]),*(np.diff(nHm_ne_values)[:-1]/2+np.diff(nHm_ne_values)[1:]/2),*np.diff(nHm_ne_values[[-2,-1]])])/(np.diff(nHm_ne_values[[0,-1]])+np.diff(nHm_ne_values[[0,1]])/2+np.diff(nHm_ne_values[[-2,-1]])/2)
											d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])/(np.diff(nH2_ne_values[[0,-1]])+np.diff(nH2_ne_values[[0,1]])/2+np.diff(nH2_ne_values[[-2,-1]])/2)
											d_nH2p_ne_values = np.array([*np.diff(nH2p_ne_values[[0,1]]),*(np.diff(nH2p_ne_values)[:-1]/2+np.diff(nH2p_ne_values)[1:]/2),*np.diff(nH2p_ne_values[[-2,-1]])])/(np.diff(nH2p_ne_values[[0,-1]])+np.diff(nH2p_ne_values[[0,1]])/2+np.diff(nH2p_ne_values[[-2,-1]])/2)
										d_ne_values_array = np.ones_like(ne_values_array)
										d_Te_values_array = np.ones_like(Te_values_array)
										hypervolume_of_each_combination = (np.array([(np.array([(np.array([(np.array([(np.array([d_nH_ne_values]*len(d_nHm_ne_values)).T*d_nHm_ne_values).T]*len(d_nH2_ne_values)).T*d_nH2_ne_values).T]*len(d_nH2p_ne_values)).T*d_nH2p_ne_values).T]*len(d_ne_values_array)).T*d_ne_values_array).T]*len(d_Te_values_array)).T*d_Te_values_array)

										marginalised_log_prob_ne_Te = np.sum(np.exp(likelihood_log_probs)*hypervolume_of_each_combination,axis=(0,1,2,3))	# ne, Te
										# print(marginalised_log_prob_ne_Te)
										index_most_likely = marginalised_log_prob_ne_Te.argmax()
										# print(index_most_likely)
										most_likely_Te_index = index_most_likely%TS_Te_steps
										most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
										marginalised_log_prob_ne = marginalised_log_prob_ne_Te[:,most_likely_Te_index]
										marginalised_log_prob_Te = marginalised_log_prob_ne_Te[most_likely_ne_index]
										# print(marginalised_log_prob_ne)
										# print(marginalised_log_prob_Te)
										# marginalised_log_prob_ne = np.log(np.sum(np.exp(likelihood_log_probs)*hypervolume_of_each_combination,axis=(0,1,2,3,5)))	# ne, Te
										# marginalised_log_prob_Te = np.log(np.sum(np.exp(likelihood_log_probs)*hypervolume_of_each_combination,axis=(0,1,2,3,4)))	# ne, Te

										ne_values_limits = np.array([ne_values_array for _, ne_values_array in sorted(zip(marginalised_log_prob_ne, ne_values_array))])[-4:]
										ne_additional_values = np.linspace(np.min(ne_values_limits),np.max(ne_values_limits),12)
										ne_values_array = np.unique(np.concatenate((ne_values_array,ne_additional_values)))
										Te_values_limits = np.array([Te_values_array for _, Te_values_array in sorted(zip(marginalised_log_prob_Te, Te_values_array))])[-4:]
										Te_additional_values = np.linspace(np.min(Te_values_limits),np.max(Te_values_limits),7)
										Te_values_array = np.unique(np.concatenate((Te_values_array,Te_additional_values)))




								# total_nH2p_ne_value
								# nH2p_ne_value = np.array([[(np.ones((to_find_steps,to_find_steps,to_find_steps_H2,to_find_steps))*nHpolecule_ne).tolist()]*TS_steps*TS_steps]*len(n_list_all))
								# nHm_ne_value = np.array([[[(np.ones((to_find_steps,to_find_steps_H2,to_find_steps)).T*nHpolecule_ne).T.tolist()]*to_find_steps]*TS_steps*TS_steps]*len(n_list_all))
								# nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value

								# calculated_emission_error = np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1)
								# calculated_emission_error = np.sum(calculated_emission_error.T * Te_probs,axis=-1)
								# calculated_emission_error = np.sum(calculated_emission_error * ne_probs,axis=-1).T

								index_best_fit = calculated_emission_log_probs.argmax()
								del calculated_emission_log_probs
								best_fit_Te_index = index_best_fit%TS_Te_steps
								best_fit_ne_index = (index_best_fit-best_fit_Te_index)//TS_Te_steps%TS_ne_steps
								best_fit_nH2p_ne_index = ((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps%len(nH2p_ne_values)
								best_fit_nH2_ne_index = (((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
								best_fit_nHm_ne_index = ((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values) - best_fit_nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
								best_fit_nH_ne_index = (((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values) - best_fit_nH2_ne_index)//len(nH2_ne_values) - best_fit_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)

								best_fit_Te_value = Te_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_ne_value = ne_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_nH2p_ne_value = nH2p_ne_values[best_fit_nH2p_ne_index]
								best_fit_nH2_ne_value = nH2_ne_values[best_fit_nH2_ne_index]
								best_fit_nHm_ne_value = nHm_ne_values[best_fit_nHm_ne_index]
								best_fit_nH_ne_value = nH_ne_values[best_fit_nH_ne_index]


								index_most_likely = likelihood_log_probs.argmax()
								most_likely_Te_index = index_most_likely%TS_Te_steps
								most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
								most_likely_nH2p_ne_index = ((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps%len(nH2p_ne_values)
								most_likely_nH2_ne_index = (((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
								most_likely_nHm_ne_index = ((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values) - most_likely_nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
								most_likely_nH_ne_index = (((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values) - most_likely_nH2_ne_index)//len(nH2_ne_values) - most_likely_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)
								max_likelihood_log_prob = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]

								most_likely_Te_value = Te_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_ne_value = ne_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_nH2p_ne_value = nH2p_ne_values[most_likely_nH2p_ne_index]
								most_likely_nH2_ne_value = nH2_ne_values[most_likely_nH2_ne_index]
								most_likely_nHm_ne_value = nHm_ne_values[most_likely_nHm_ne_index]
								most_likely_nH_ne_value = nH_ne_values[most_likely_nH_ne_index]

								# now I marginalise H2, Te, ne in order to find the most likely Hm, H2p for the next step
								if False:	# logarithmic interval scaling
									d_nH_ne_values = np.ones_like(nH_ne_values)
									d_nHm_ne_values = np.ones_like(nHm_ne_values)
									d_nH2_ne_values = np.array([*np.diff(np.log10(nH2_ne_values[[0,1]])),*(np.diff(np.log10(nH2_ne_values))[:-1]/2+np.diff(np.log10(nH2_ne_values))[1:]/2),*np.diff(np.log10(nH2_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2_ne_values[[0,-1]]))+np.diff(np.log10(nH2_ne_values[[0,1]]))/2+np.diff(np.log10(nH2_ne_values[[-2,-1]]))/2)
									d_nH2p_ne_values = np.ones_like(nH2p_ne_values)
								elif True:	# linear interval scaling
									d_nH_ne_values = np.ones_like(nH_ne_values)
									d_nHm_ne_values = np.ones_like(nHm_ne_values)
									d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])/(np.diff(nH2_ne_values[[0,-1]])+np.diff(nH2_ne_values[[0,1]])/2+np.diff(nH2_ne_values[[-2,-1]])/2)
									d_nH2p_ne_values = np.ones_like(nH2p_ne_values)
								d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])/(np.diff(ne_values_array[[0,-1]])+np.diff(ne_values_array[[0,1]])/2+np.diff(ne_values_array[[-2,-1]])/2)
								d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])/(np.diff(Te_values_array[[0,-1]])+np.diff(Te_values_array[[0,1]])/2+np.diff(Te_values_array[[-2,-1]])/2)
								hypervolume_of_each_combination = (np.array([(np.array([(np.array([(np.array([(np.array([d_nH_ne_values]*len(d_nHm_ne_values)).T*d_nHm_ne_values).T]*len(d_nH2_ne_values)).T*d_nH2_ne_values).T]*len(d_nH2p_ne_values)).T*d_nH2p_ne_values).T]*len(d_ne_values_array)).T*d_ne_values_array).T]*len(d_Te_values_array)).T*d_Te_values_array)

								marginalised_likelihood_log_probs = np.log(np.sum(np.exp(likelihood_log_probs)*np.float32(hypervolume_of_each_combination),axis=(2,4,5)))	# H, Hm, H2, H2p, ne, Te
								marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.max(marginalised_likelihood_log_probs)
								marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.log(np.sum(np.exp(marginalised_likelihood_log_probs)))	# normalisation for logarithmic probabilities
								index_most_likely = marginalised_likelihood_log_probs.argmax()
								most_likely_marginalised_nH2p_ne_index = index_most_likely%len(nH2p_ne_values)
								most_likely_marginalised_nHm_ne_index = (index_most_likely-most_likely_marginalised_nH2p_ne_index)//len(nH2p_ne_values)%len(nHm_ne_values)
								most_likely_marginalised_nH_ne_index = ((index_most_likely-most_likely_marginalised_nH2p_ne_index)//len(nH2p_ne_values)-most_likely_marginalised_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)

								most_likely_marginalised_nH2p_ne_value = nH2p_ne_values[most_likely_marginalised_nH2p_ne_index]
								most_likely_marginalised_nHm_ne_value = nHm_ne_values[most_likely_marginalised_nHm_ne_index]
								most_likely_marginalised_nH_ne_value = nH_ne_values[most_likely_marginalised_nH_ne_index]

								first_most_likely_Te_value = cp.deepcopy(most_likely_Te_value)
								first_most_likely_ne_value = cp.deepcopy(most_likely_ne_value)
								first_most_likely_nH2p_ne_value = cp.deepcopy(most_likely_nH2p_ne_value)
								first_most_likely_nH2_ne_value = cp.deepcopy(most_likely_nH2_ne_value)
								first_most_likely_nHm_ne_value = cp.deepcopy(most_likely_nHm_ne_value)
								first_most_likely_nH_ne_value = cp.deepcopy(most_likely_nH_ne_value)
								first_most_likely_marginalised_nH2p_ne_value = cp.deepcopy(most_likely_marginalised_nH2p_ne_value)
								first_most_likely_marginalised_nHm_ne_value = cp.deepcopy(most_likely_marginalised_nHm_ne_value)
								first_most_likely_marginalised_nH_ne_value = cp.deepcopy(most_likely_marginalised_nH_ne_value)

								nH2p_ne_value_where_expand = nH2p_ne_values[likelihood_log_probs[0,0,0,:,most_likely_ne_index,most_likely_Te_index].argmax()]
								nHm_ne_value_where_expand = nHm_ne_values[likelihood_log_probs[0,:,0,0,most_likely_ne_index,most_likely_Te_index].argmax()]
								nH_ne_value_where_expand = nH_ne_values[likelihood_log_probs[:,0,0,0,most_likely_ne_index,most_likely_Te_index].argmax()]
								marginalised_nH2p_ne_value_where_expand = nH2p_ne_values[marginalised_likelihood_log_probs[0,0,:].argmax()]
								marginalised_nHm_ne_value_where_expand = nHm_ne_values[marginalised_likelihood_log_probs[0,:,0].argmax()]
								marginalised_nH_ne_value_where_expand = nH_ne_values[marginalised_likelihood_log_probs[:,0,0].argmax()]

								next_nH2p_ne_value_up = max(nH2p_ne_value_where_expand,marginalised_nH2p_ne_value_where_expand)*1.5
								next_nH2p_ne_value_down = min(nH2p_ne_value_where_expand,marginalised_nH2p_ne_value_where_expand)/25
								next_nHm_ne_value_up = max(nHm_ne_value_where_expand,marginalised_nHm_ne_value_where_expand)*1.5
								next_nHm_ne_value_down = min(nHm_ne_value_where_expand,marginalised_nHm_ne_value_where_expand)/25
								next_nH_ne_value_up = max(nH_ne_value_where_expand,marginalised_nH_ne_value_where_expand)*1.5
								next_nH_ne_value_down = min(nH_ne_value_where_expand,marginalised_nH_ne_value_where_expand)/25

								additional_steps = 15	# 15
								nHm_ne_additional_values = np.logspace(np.log10(max(min_mol_fraction/10,next_nHm_ne_value_down)),np.log10(max(min_mol_fraction*5,next_nHm_ne_value_up)),num=additional_steps)
								nH2p_ne_additional_values = np.logspace(np.log10(max(min_mol_fraction/10,next_nH2p_ne_value_down)),np.log10(max(min_mol_fraction*5,next_nH2p_ne_value_up)),num=additional_steps)
								nH_ne_additional_values = np.logspace(np.log10(next_nH_ne_value_down),np.log10(next_nH_ne_value_up),num=int(1*additional_steps))


								if (max(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)>next_nHm_ne_value_up or min(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)<next_nHm_ne_value_down):
									nHm_ne_additional_values_2 = np.logspace(np.log10(min(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)/2),np.log10(max(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)*2),num=additional_steps)
									nHm_ne_additional_values = np.unique(np.concatenate((nHm_ne_additional_values,nHm_ne_additional_values_2)))
								# else:
								# 	nHm_ne_additional_values = np.array([(most_likely_marginalised_nHm_ne_value+most_likely_nHm_ne_value)/2*0.99,1.01*(most_likely_marginalised_nHm_ne_value+most_likely_nHm_ne_value)/2])
								temp = []
								for value in nHm_ne_additional_values:
									if np.min(np.abs(nHm_ne_values - value)/value)>max_frac_acceptable_deviation:
									# if not(value in nHm_ne_values):
										temp.append(value)
								nHm_ne_additional_values = np.array(temp)
								nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values<centre_nH2_ne/6]
								# nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values>min_mol_fraction]

								if len(nHm_ne_values)+len(nHm_ne_additional_values)>45:	# emergency measure to limit the memory usage
									max_frac_acceptable_deviation *= 1.6
									print('worker '+str(current_process())+' '+str(domain_index)+' max_frac_acceptable_deviation increased on 2 Hm '+str(len(nHm_ne_values)+len(nHm_ne_additional_values)))
									temp = []
									for value in nHm_ne_additional_values:
										if np.min(np.abs(nHm_ne_values - value)/value)>max_frac_acceptable_deviation:
										# if not(value in nHm_ne_values):
											temp.append(value)
									nHm_ne_additional_values = np.array(temp)
									nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values<centre_nH2_ne/6]
									print('worker '+str(current_process())+' '+str(domain_index)+' 2 Hm reduced to '+str(len(nHm_ne_values)+len(nHm_ne_additional_values)))
									# nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values>min_mol_fraction]

								if (max(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)>next_nH_ne_value_up or min(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)<next_nH_ne_value_down):
									nH_ne_additional_values_2 = np.logspace(np.log10(min(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)/2),np.log10(max(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)*2),num=additional_steps)
									nH_ne_additional_values = np.unique(np.concatenate((nH_ne_additional_values,nH_ne_additional_values_2)))
								# else:
								# 	nH_ne_additional_values = np.array([(most_likely_marginalised_nH_ne_value+most_likely_nH_ne_value)/2*0.99,1.01*(most_likely_marginalised_nH_ne_value+most_likely_nH_ne_value)/2])
								temp = []
								for value in nH_ne_additional_values:
									if np.min(np.abs(nH_ne_values - value)/value)>max_frac_acceptable_deviation:
									# if not(value in nH_ne_values):
										temp.append(value)
								nH_ne_additional_values = np.array(temp)
								nH_ne_values = np.sort(np.concatenate((nH_ne_values,nH_ne_additional_values)))
								H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
								H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
								nH_ne_values = np.array(H_left_interval.tolist() + H_right_interval.tolist())
								H_left_interval_log_probs = -(0.5*((np.log10(H_left_interval/centre_nH_ne)/(np.log10(centre_nH_ne/min_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-min_nH_ne is 3 sigma
								H_right_interval_log_probs = -(0.5*((np.log10(H_right_interval/centre_nH_ne)/(np.log10(centre_nH_ne/max_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-max_nH_ne is 3 sigma
								nH_ne_log_probs = np.array(H_left_interval_log_probs.tolist() + H_right_interval_log_probs.tolist())

								if (max(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)>next_nH2p_ne_value_up or min(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)<next_nH2p_ne_value_down):
									nH2p_ne_additional_values_2 = np.logspace(np.log10(min(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)/2),np.log10(max(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)*2),num=additional_steps)
									nH2p_ne_additional_values = np.unique(np.concatenate((nH2p_ne_additional_values,nH2p_ne_additional_values_2)))
								# else:
								# 	nH2p_ne_additional_values = np.array([(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2*0.99,1.01*(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2])
								temp = []
								for value in nH2p_ne_additional_values:
									if np.min(np.abs(nH2p_ne_values - value)/value)>max_frac_acceptable_deviation:
									# if not(value in nH2p_ne_values):
										temp.append(value)
								nH2p_ne_additional_values = np.array(temp)
								nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values<centre_nH2_ne/6]
								# nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values>min_mol_fraction]

								# section added to search the effect of a fixed fraction of nH-/nH2+ on power balance
								temp_Hm = np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))
								temp_H2p = np.sort(np.concatenate((nH2p_ne_values,nH2p_ne_additional_values)))
								# temp = temp_Hm/temp_H2p
								# temp = np.meshgrid(temp_H2p, temp_Hm)[1]/np.meshgrid(temp_H2p, temp_Hm)[0]
								temp_nH2p_ne_add = []
								for fraction in fixed_fractions_nHm_H2p:
									for value in temp_Hm/fraction:
										if np.min(np.abs(np.concatenate((temp_H2p,temp_nH2p_ne_add)) - value)/value)>max_frac_acceptable_deviation*1.5:
											if np.max(likelihood_log_probs[:,np.abs(nHm_ne_values-value*fraction).argmin(),:,np.abs(nH2p_ne_values-value).argmin(),:,:])-np.max(likelihood_log_probs)>-3:
												temp_nH2p_ne_add.append(value)
								temp_nH2p_ne_add = np.array(temp_nH2p_ne_add)
								temp_nH2p_ne_add = temp_nH2p_ne_add[temp_nH2p_ne_add<centre_nH2_ne/10]
								# temp_nH2p_ne_add = temp_nH2p_ne_add[temp_nH2p_ne_add>min_mol_fraction]
								nH2p_ne_additional_values = np.concatenate((temp_nH2p_ne_add,nH2p_ne_additional_values))
								nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values<centre_nH2_ne/10]
								# nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values>min_mol_fraction]
								if len(nH2p_ne_values)+len(nH2p_ne_additional_values)+len(temp_nH2p_ne_add)>45:	# emergency measure to limit the memory usage
									max_frac_acceptable_deviation *= 1.6
									print('worker '+str(current_process())+' '+str(domain_index)+' max_frac_acceptable_deviation increased on H2p '+str(len(nH2p_ne_values)+len(nH2p_ne_additional_values)+len(temp_nH2p_ne_add)))

									nH2p_ne_additional_values = np.logspace(np.log10(max(min_mol_fraction/10,next_nH2p_ne_value_down)),np.log10(max(min_mol_fraction*5,next_nH2p_ne_value_up)),num=additional_steps)

									if (max(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)>next_nH2p_ne_value_up or min(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)<next_nH2p_ne_value_down):
										nH2p_ne_additional_values_2 = np.logspace(np.log10(min(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)/2),np.log10(max(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)*2),num=additional_steps)
										nH2p_ne_additional_values = np.unique(np.concatenate((nH2p_ne_additional_values,nH2p_ne_additional_values_2)))
									# else:
									# 	nH2p_ne_additional_values = np.array([(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2*0.99,1.01*(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2])
									temp = []
									for value in nH2p_ne_additional_values:
										if np.min(np.abs(nH2p_ne_values - value)/value)>max_frac_acceptable_deviation:
										# if not(value in nH2p_ne_values):
											temp.append(value)
									nH2p_ne_additional_values = np.array(temp)
									nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values<centre_nH2_ne/6]
									# nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values>min_mol_fraction]

									# section added to search the effect of a fixed fraction of nH-/nH2+ on power balance
									temp_Hm = np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))
									temp_H2p = np.sort(np.concatenate((nH2p_ne_values,nH2p_ne_additional_values)))

									temp_nH2p_ne_add = []
									for fraction in fixed_fractions_nHm_H2p:
										for value in temp_Hm/fraction:
											if np.min(np.abs(np.concatenate((temp_H2p,temp_nH2p_ne_add)) - value)/value)>max_frac_acceptable_deviation*1.5:
												if np.max(likelihood_log_probs[:,np.abs(nHm_ne_values-value*fraction).argmin(),:,np.abs(nH2p_ne_values-value).argmin(),:,:])-np.max(likelihood_log_probs)>-3:
													temp_nH2p_ne_add.append(value)
									temp_nH2p_ne_add = np.array(temp_nH2p_ne_add)
									temp_nH2p_ne_add = temp_nH2p_ne_add[temp_nH2p_ne_add<centre_nH2_ne/10]
									print('worker '+str(current_process())+' '+str(domain_index)+' H2p reduced to '+str(len(nH2p_ne_values)+len(nH2p_ne_additional_values)+len(temp_nH2p_ne_add)))
									# temp_nH2p_ne_add = temp_nH2p_ne_add[temp_nH2p_ne_add>min_mol_fraction]
									nH2p_ne_additional_values = np.concatenate((temp_nH2p_ne_add,nH2p_ne_additional_values))
									nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values<centre_nH2_ne/10]
									# nH2p_ne_additional_values = nH2p_ne_additional_values[nH2p_ne_additional_values>min_mol_fraction]


								calculated_emission_log_probs_expanded = -np.ones((len(nH_ne_values),len(nHm_ne_additional_values)+len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values)+len(nH2p_ne_additional_values),TS_ne_steps,TS_Te_steps),dtype=np.float32)*np.inf	# H, Hm, H2, H2p, ne, Te
								# calculated_emission_error = np.ones((to_find_steps,to_find_steps))	# Hm, H2p
								# nHp_ne_value = 1
								# total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# total_nHp_ne_value = recombination_internal * nHp_ne_value
								# coeff_3_record_2 = []
								# coeff_4_record_2 = []
								total_nH_ne_value = []
								for i1,nH_ne_value in enumerate(nH_ne_values):
									total_nH_ne_value.append(np.ones((len(nH2_ne_values),*np.shape(excitation_internal)))*excitation_internal *  nH_ne_value)
									# total_nH_ne_value.append(excitation_internal *  nH_ne_value)
									# total_nH_ne_value = excitation_internal *  nH_ne_value
								total_nH_ne_value = np.array(total_nH_ne_value)
								total_nH_ne_value = np.transpose(total_nH_ne_value*multiplicative_factor, (0,1,3,2))	# H, H2, lines, ne*Te
								total_nH_ne_value = total_nH_ne_value * (ne_values.flatten() ** 2)
								total_nH_ne_value = np.float32(np.transpose(total_nH_ne_value, (0,1,3,2)))	# H, H2, ne*Te, lines
								total_nH2_ne_value = []
								for i4,nH2_ne_value in enumerate(nH2_ne_values):
									total_nH2_ne_value.append( coeff_2 *  nH2_ne_value )
									# total_nH2_ne_value = nH2_ne_value * coeff_2
								total_nH2_ne_value = np.array(total_nH2_ne_value)
								total_nH2_ne_value = np.transpose(total_nH2_ne_value*multiplicative_factor, (0,2,1))	# H2, lines, ne*Te
								total_nH2_ne_value = total_nH2_ne_value * (ne_values.flatten() ** 2)
								total_nH2_ne_value = np.float32(np.transpose(total_nH2_ne_value, (0,2,1)))	# H2, ne*Te, lines
								total_nH_nH2_ne_value = total_nH_ne_value + total_nH2_ne_value
								for i5,nH2p_ne_value in enumerate(np.sort(np.concatenate((nH2p_ne_values,nH2p_ne_additional_values)))):
									total_nH2p_ne_value = nH2p_ne_value * coeff_1
									total_nH2p_ne_value = (total_nH2p_ne_value*multiplicative_factor).T	# lines, ne*Te
									total_nH2p_ne_value = total_nH2p_ne_value * (ne_values.flatten() ** 2)
									total_nH2p_ne_value = np.float32(total_nH2p_ne_value.T)	# ne*Te, lines
									total_nH_nH2_nH2p_ne_value = total_nH_nH2_ne_value + total_nH2p_ne_value
									if nH2p_ne_value in nH2p_ne_values:
										index_H2p = (np.abs(nH2p_ne_values-nH2p_ne_value)).argmin()
										coeff_4 = coeff_4_record[index_H2p]
									else:
										coeff_4 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,n_list_all)
									# coeff_4_record_2.append(coeff_4)
									for i3,nHm_ne_value in enumerate(np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))):
										nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value
										if nHp_ne_value<0:
											continue
										elif nHp_ne_value==0:
											nHp_ne_value=1e-8
											total_nHp_ne_value = 0
										else:
											total_nHp_ne_value = recombination_internal * nHp_ne_value
										if ((nH2p_ne_value in nH2p_ne_values) and (nHm_ne_value in nHm_ne_values)):
											index_Hm = (np.abs(nHm_ne_values-nHm_ne_value)).argmin()
											coeff_3 = coeff_3_record[int(index_H2p*len(nHm_ne_values)+index_Hm)]
										else:
											coeff_3 = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_value*ne_values.flatten()]).T ,n_list_all)
										# coeff_3_record_2.append(coeff_3)
										total_nHm_ne_value = nHm_ne_value*( coeff_3 + coeff_4 )
										temp1 = 0
										# for i1,nH_ne_value in enumerate(nH_ne_values):
										# 	for i4,nH2_ne_value in enumerate(nH2_ne_values):
										# 		total = total_nH_ne_value[i1]+total_nH2_ne_value[i4]+total_nHp_ne_value+total_nHm_ne_value+total_nH2p_ne_value# +total_nH3p_ne_value
										# 		calculated_emission = (total.T*(ne_values.flatten() ** 2)).T*multiplicative_factor
										# 		temp = -0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1)
										# 		# temp1 += np.sum(temp * Te_probs.flatten() * ne_probs.flatten())*nH_ne_probs[i1]*nH2_ne_probs[i4]
										# 		calculated_emission_log_probs_expanded[i1,i3,i4,i5]= temp.reshape((TS_ne_steps,TS_Te_steps))
										total = total_nHp_ne_value+total_nHm_ne_value# +total_nH3p_ne_value	# H, H2, ne*Te, lines
										total = (total*multiplicative_factor).T	# lines, ne*Te
										total = total * (ne_values.flatten() ** 2)
										calculated_emission = total_nH_nH2_nH2p_ne_value + total.T	# H, H2, ne*Te, lines
										temp = np.float32(-0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1))
										calculated_emission_log_probs_expanded[:,i3,:,i5]= temp.reshape((len(nH_ne_values),len(nH2_ne_values),TS_ne_steps,TS_Te_steps))
								# calculated_emission_log_probs_expanded = calculated_emission_log_probs_expanded - np.max(calculated_emission_log_probs_expanded)
								calculated_emission_log_probs_expanded = calculated_emission_log_probs_expanded-np.log(np.sum(np.exp(calculated_emission_log_probs_expanded)))	# normalisation for logarithmic probabilities
								nH2p_ne_values = np.sort(np.concatenate((nH2p_ne_values,nH2p_ne_additional_values)))
								nHm_ne_values = np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))

								# likelihood_log_probs = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
								# for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
								# 	for i3,nHm_ne_value in enumerate(nHm_ne_values):
								# 		for i1,nH_ne_value in enumerate(nH_ne_values):
								# 			temp_i1 = nH_ne_log_probs[i1]
								# 			for i4,nH2_ne_value in enumerate(nH2_ne_values):
								# 				temp_i4 = nH2_ne_log_probs[i4]
								# 				for i6 in range(TS_ne_steps):
								# 					temp_i6 = ne_log_probs[i6]
								# 					for i7 in range(TS_Te_steps):
								# 						likelihood_log_probs[i1,i3,i4,i5,i6,i7]= calculated_emission_log_probs_expanded[i1,i3,i4,i5,i6,i7]+Te_log_probs[i7]+temp_i6+temp_i4+temp_i1
								likelihood_log_probs = np.float32(((calculated_emission_log_probs_expanded + np.float32(Te_log_probs) + (np.ones((TS_Te_steps,TS_ne_steps),dtype=np.float32)*np.float32(ne_log_probs)).T + (np.ones((TS_Te_steps,TS_ne_steps,len(nH2p_ne_values),len(nH2_ne_values)),dtype=np.float32)*np.float32(nH2_ne_log_probs)).T ).T + np.float32(nH_ne_log_probs)).T)
								# likelihood_log_probs = likelihood_log_probs-np.max(likelihood_log_probs)
								likelihood_log_probs = likelihood_log_probs-np.log(np.sum(np.exp(likelihood_log_probs)))	# normalisation for logarithmic probabilities

								index_best_fit = calculated_emission_log_probs_expanded.argmax()
								best_fit_Te_index = index_best_fit%TS_Te_steps
								best_fit_ne_index = (index_best_fit-best_fit_Te_index)//TS_Te_steps%TS_ne_steps
								best_fit_nH2p_ne_index = ((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps%len(nH2p_ne_values)
								best_fit_nH2_ne_index = (((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
								best_fit_nHm_ne_index = ((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values) - best_fit_nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
								best_fit_nH_ne_index = (((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values) - best_fit_nH2_ne_index)//len(nH2_ne_values) - best_fit_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)

								best_fit_Te_value = Te_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_ne_value = ne_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_nH2p_ne_value = nH2p_ne_values[best_fit_nH2p_ne_index]
								best_fit_nH2_ne_value = nH2_ne_values[best_fit_nH2_ne_index]
								best_fit_nHm_ne_value = nHm_ne_values[best_fit_nHm_ne_index]
								best_fit_nH_ne_value = nH_ne_values[best_fit_nH_ne_index]


								index_most_likely = likelihood_log_probs.argmax()
								most_likely_Te_index = index_most_likely%TS_Te_steps
								most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
								most_likely_nH2p_ne_index = ((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps%len(nH2p_ne_values)
								most_likely_nH2_ne_index = (((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
								most_likely_nHm_ne_index = ((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values) - most_likely_nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
								most_likely_nH_ne_index = (((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values) - most_likely_nH2_ne_index)//len(nH2_ne_values) - most_likely_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)
								max_likelihood_log_prob = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]

								most_likely_Te_value = Te_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_ne_value = ne_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_nH2p_ne_value = nH2p_ne_values[most_likely_nH2p_ne_index]
								most_likely_nH2_ne_value = nH2_ne_values[most_likely_nH2_ne_index]
								most_likely_nHm_ne_value = nHm_ne_values[most_likely_nHm_ne_index]
								most_likely_nH_ne_value = nH_ne_values[most_likely_nH_ne_index]
								most_likely_T_Hm_value = np.exp(TH2_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K
								most_likely_T_H2p_value = np.exp(TH2_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K
								most_likely_T_Hp_value = most_likely_Te_value/eV_to_K	# K

								# now I marginalise H2, Te, ne in order to find the most likely Hm, H2p for the next step
								if False:	# logarithmic interval scaling
									d_nH_ne_values = np.ones_like(nH_ne_values)
									d_nHm_ne_values = np.ones_like(nHm_ne_values)
									d_nH2_ne_values = np.array([*np.diff(np.log10(nH2_ne_values[[0,1]])),*(np.diff(np.log10(nH2_ne_values))[:-1]/2+np.diff(np.log10(nH2_ne_values))[1:]/2),*np.diff(np.log10(nH2_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2_ne_values[[0,-1]]))+np.diff(np.log10(nH2_ne_values[[0,1]]))/2+np.diff(np.log10(nH2_ne_values[[-2,-1]]))/2)
									d_nH2p_ne_values = np.ones_like(nH2p_ne_values)
								elif True:	# linear interval scaling
									d_nH_ne_values = np.ones_like(nH_ne_values)
									d_nHm_ne_values = np.ones_like(nHm_ne_values)
									d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])/(np.diff(nH2_ne_values[[0,-1]])+np.diff(nH2_ne_values[[0,1]])/2+np.diff(nH2_ne_values[[-2,-1]])/2)
									d_nH2p_ne_values = np.ones_like(nH2p_ne_values)
								d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])/(np.diff(ne_values_array[[0,-1]])+np.diff(ne_values_array[[0,1]])/2+np.diff(ne_values_array[[-2,-1]])/2)
								d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])/(np.diff(Te_values_array[[0,-1]])+np.diff(Te_values_array[[0,1]])/2+np.diff(Te_values_array[[-2,-1]])/2)
								hypervolume_of_each_combination = (np.array([(np.array([(np.array([(np.array([(np.array([d_nH_ne_values]*len(d_nHm_ne_values)).T*d_nHm_ne_values).T]*len(d_nH2_ne_values)).T*d_nH2_ne_values).T]*len(d_nH2p_ne_values)).T*d_nH2p_ne_values).T]*len(d_ne_values_array)).T*d_ne_values_array).T]*len(d_Te_values_array)).T*d_Te_values_array)

								marginalised_likelihood_log_probs = np.log(np.sum(np.exp(likelihood_log_probs)*np.float32(hypervolume_of_each_combination),axis=(2,4,5)))	# H, Hm, H2, H2p, ne, Te
								marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.max(marginalised_likelihood_log_probs)
								marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.log(np.sum(np.exp(marginalised_likelihood_log_probs)))	# normalisation for logarithmic probabilities
								index_most_likely = marginalised_likelihood_log_probs.argmax()
								most_likely_marginalised_nH2p_ne_index = index_most_likely%len(nH2p_ne_values)
								most_likely_marginalised_nHm_ne_index = (index_most_likely-most_likely_marginalised_nH2p_ne_index)//len(nH2p_ne_values)%len(nHm_ne_values)
								most_likely_marginalised_nH_ne_index = ((index_most_likely-most_likely_marginalised_nH2p_ne_index)//len(nH2p_ne_values)-most_likely_marginalised_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)

								most_likely_marginalised_nH2p_ne_value = nH2p_ne_values[most_likely_marginalised_nH2p_ne_index]
								most_likely_marginalised_nHm_ne_value = nHm_ne_values[most_likely_marginalised_nHm_ne_index]
								most_likely_marginalised_nH_ne_value = nH_ne_values[most_likely_marginalised_nH_ne_index]

								# if (max(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)>next_nH2p_ne_value_up or min(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)<next_nH2p_ne_value_down):
								# 	nH2p_ne_additional_values = np.logspace(np.log10((most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2/3),np.log10(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value),num=additional_steps)
								# else:
								# 	nH2p_ne_additional_values = np.array([(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2*0.99,1.01*(most_likely_marginalised_nH2p_ne_value+most_likely_nH2p_ne_value)/2])
								#
								# if (max(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)>next_nHm_ne_value_up or min(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)<next_nHm_ne_value_down):
								# 	nHm_ne_additional_values = np.logspace(np.log10((most_likely_marginalised_nHm_ne_value+most_likely_nHm_ne_value)/2/3),np.log10(most_likely_marginalised_nHm_ne_value+most_likely_nHm_ne_value),num=additional_steps)
								# else:
								# 	nHm_ne_additional_values = np.array([(most_likely_marginalised_nHm_ne_value+most_likely_nHm_ne_value)/2*0.99,1.01*(most_likely_marginalised_nHm_ne_value+most_likely_nHm_ne_value)/2])
								#
								# if (max(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)>next_nH_ne_value_up or min(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)<next_nH_ne_value_down):
								# 	nH_ne_additional_values = np.logspace(np.log10((most_likely_marginalised_nH_ne_value+most_likely_nH_ne_value)/2/3),np.log10(most_likely_marginalised_nH_ne_value+most_likely_nH_ne_value),num=additional_steps)
								# else:
								# 	nH_ne_additional_values = np.array([(most_likely_marginalised_nH_ne_value+most_likely_nH_ne_value)/2*0.99,1.01*(most_likely_marginalised_nH_ne_value+most_likely_nH_ne_value)/2])
								# nH_ne_values = np.sort(np.concatenate((nH_ne_values,nH_ne_additional_values)))
								# H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
								# H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
								# nH_ne_values = np.array(H_left_interval.tolist() + H_right_interval.tolist())
								# H_left_interval_log_probs = -0.5*(((H_left_interval-centre_nH_ne)/(centre_nH_ne-min_nH_ne))**2)
								# H_right_interval_log_probs = -0.5*(((H_right_interval-centre_nH_ne)/(centre_nH_ne-max_nH_ne))**2)
								# nH_ne_log_probs = np.array(H_left_interval_log_probs.tolist() + H_right_interval_log_probs.tolist())
								#
								#
								# calculated_emission_log_probs_expanded_2 = np.zeros((len(nH_ne_values),len(nH2p_ne_values)+len(nH2p_ne_additional_values),len(nH2_ne_values),len(nHm_ne_values)+len(nHm_ne_additional_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
								# # calculated_emission_error = np.ones((to_find_steps,to_find_steps))	# Hm, H2p
								# # nHp_ne_value = 1
								# # total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# # total_nHp_ne_value = recombination_internal * nHp_ne_value
								# total_nH_ne_value = []
								# for i1,nH_ne_value in enumerate(nH_ne_values):
								# 	total_nH_ne_value.append(excitation_internal *  nH_ne_value)
								# 	# total_nH_ne_value = excitation_internal *  nH_ne_value
								# total_nH_ne_value = np.array(total_nH_ne_value)
								# total_nH2_ne_value = []
								# for i4,nH2_ne_value in enumerate(nH2_ne_values):
								# 	total_nH2_ne_value.append( coeff_2 *  nH2_ne_value )
								# 	# total_nH2_ne_value = nH2_ne_value * coeff_2
								# total_nH2_ne_value = np.array(total_nH2_ne_value)
								# for i5,nH2p_ne_value in enumerate(np.sort(np.concatenate((nH2p_ne_values,nH2p_ne_additional_values)))):
								# 	total_nH2p_ne_value = nH2p_ne_value * coeff_1
								# 	if nH2p_ne_value in nH2p_ne_values:
								# 		index_H2p = (np.abs(nH2p_ne_values-nH2p_ne_value)).argmin()
								# 		coeff_4 = coeff_4_record_2[index_H2p]
								# 	else:
								# 		coeff_4 = From_Hn_with_H2p_pop_coeff_full(np.array([Te_values.flatten(),T_H2p*np.ones_like(Te_values.flatten()),T_Hm*np.ones_like(Te_values.flatten()),ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,n_list_all)
								# 	for i3,nHm_ne_value in enumerate(np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))):
								#
								# 		nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value
								# 		total_nHp_ne_value = recombination_internal * nHp_ne_value
								# 		if ((nH2p_ne_value in nH2p_ne_values) and (nHm_ne_value in nHm_ne_values)):
								# 			index_Hm = (np.abs(nHm_ne_values-nHm_ne_value)).argmin()
								# 			coeff_3 = coeff_3_record_2[int(index_H2p*len(nHm_ne_values)+index_Hm)]
								# 		else:
								# 			coeff_3 = From_Hn_with_Hp_pop_coeff_full(np.array([Te_values.flatten(),T_Hp*np.ones_like(Te_values.flatten()),T_Hm*np.ones_like(Te_values.flatten()),ne_values.flatten(),nHp_ne_value*ne_values.flatten()]).T ,n_list_all)
								# 		total_nHm_ne_value = nHm_ne_value*( coeff_3 + coeff_4 )
								# 		temp1 = 0
								# 		for i1,nH_ne_value in enumerate(nH_ne_values):
								# 			for i4,nH2_ne_value in enumerate(nH2_ne_values):
								# 				total = total_nH_ne_value[i1]+total_nH2_ne_value[i4]+total_nHp_ne_value+total_nHm_ne_value+total_nH2p_ne_value# +total_nH3p_ne_value
								# 				calculated_emission = (total.T*(ne_values.flatten() ** 2)).T*multiplicative_factor
								# 				temp = -0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1)
								# 				# temp1 += np.sum(temp * Te_probs.flatten() * ne_probs.flatten())*nH_ne_probs[i1]*nH2_ne_probs[i4]
								# 				calculated_emission_log_probs_expanded_2[i1,i3,i4,i5]= temp.reshape((TS_ne_steps,TS_Te_steps))
								# calculated_emission_log_probs_expanded_2 = calculated_emission_log_probs_expanded_2-np.log(np.sum(np.exp(calculated_emission_log_probs_expanded_2)))	# normalisation for logarithmic probabilities
								# nH2p_ne_values = np.sort(np.concatenate((nH2p_ne_values,nH2p_ne_additional_values)))
								# nHm_ne_values = np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))
								#
								# likelihood_log_probs = np.zeros((len(nH_ne_values),len(nH2p_ne_values),len(nH2_ne_values),len(nHm_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
								# for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
								# 	for i3,nHm_ne_value in enumerate(nHm_ne_values):
								# 		for i1,nH_ne_value in enumerate(nH_ne_values):
								# 			temp_i1 = nH_ne_log_probs[i1]
								# 			for i4,nH2_ne_value in enumerate(nH2_ne_values):
								# 				temp_i4 = nH2_ne_log_probs[i4]
								# 				for i6 in range(TS_ne_steps):
								# 					temp_i6 = ne_log_probs[i6]
								# 					for i7 in range(TS_Te_steps):
								# 						likelihood_log_probs[i1,i3,i4,i5,i6,i7]= calculated_emission_log_probs_expanded_2[i1,i3,i4,i5,i6,i7]+Te_log_probs[i7]+temp_i6+temp_i4+temp_i1
								# likelihood_log_probs = likelihood_log_probs-np.max(likelihood_log_probs)-np.log(np.sum(np.exp(likelihood_log_probs-np.max(likelihood_log_probs))))	# normalisation for logarithmic probabilities
								#
								# index_best_fit = calculated_emission_log_probs_expanded_2.argmax()
								# best_fit_Te_index = index_best_fit%TS_Te_steps
								# best_fit_ne_index = (index_best_fit-best_fit_Te_index)//TS_Te_steps%TS_ne_steps
								# best_fit_nH2p_ne_index = ((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps%len(nH2p_ne_values)
								# best_fit_nH2_ne_index = (((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
								# best_fit_nHm_ne_index = ((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values) - best_fit_nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
								# best_fit_nH_ne_index = (((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_ne_index)//len(nH2p_ne_values) - best_fit_nH2_ne_index)//len(nH2_ne_values) - best_fit_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)
								#
								# best_fit_Te_value = Te_values[best_fit_ne_index,best_fit_Te_index]
								# best_fit_ne_value = ne_values[best_fit_ne_index,best_fit_Te_index]
								# best_fit_nH2p_ne_value = nH2p_ne_values[best_fit_nH2p_ne_index]
								# best_fit_nH2_ne_value = nH2_ne_values[best_fit_nH2_ne_index]
								# best_fit_nHm_ne_value = nHm_ne_values[best_fit_nHm_ne_index]
								# best_fit_nH_ne_value = nH_ne_values[best_fit_nH_ne_index]
								#
								#
								# index_most_likely = likelihood_log_probs.argmax()
								# most_likely_Te_index = index_most_likely%TS_Te_steps
								# most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
								# most_likely_nH2p_ne_index = ((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps%len(nH2p_ne_values)
								# most_likely_nH2_ne_index = (((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
								# most_likely_nHm_ne_index = ((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values) - most_likely_nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
								# most_likely_nH_ne_index = (((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_ne_index)//len(nH2p_ne_values) - most_likely_nH2_ne_index)//len(nH2_ne_values) - most_likely_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)
								# max_likelihood_log_prob = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
								#
								# most_likely_Te_value = Te_values[most_likely_ne_index,most_likely_Te_index]
								# most_likely_ne_value = ne_values[most_likely_ne_index,most_likely_Te_index]
								# most_likely_nH2p_ne_value = nH2p_ne_values[most_likely_nH2p_ne_index]
								# most_likely_nH2_ne_value = nH2_ne_values[most_likely_nH2_ne_index]
								# most_likely_nHm_ne_value = nHm_ne_values[most_likely_nHm_ne_index]
								# most_likely_nH_ne_value = nH_ne_values[most_likely_nH_ne_index]
								#
								# # now I marginalise H2, Te, ne in order to find the most likely Hm, H2p for the next step
								# marginalised_likelihood_log_probs = np.log(np.sum(np.exp(likelihood_log_probs),axis=(2,4,5)))	# H, Hm, H2, H2p, ne, Te
								# marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.max(marginalised_likelihood_log_probs)-np.log(np.sum(np.exp(marginalised_likelihood_log_probs-np.max(marginalised_likelihood_log_probs))))	# normalisation for logarithmic probabilities
								# index_most_likely = marginalised_likelihood_log_probs.argmax()
								# most_likely_marginalised_nH2p_ne_index = index_most_likely%len(nH2p_ne_values)
								# most_likely_marginalised_nHm_ne_index = (index_most_likely-most_likely_marginalised_nH2p_ne_index)//len(nH2p_ne_values)%len(nHm_ne_values)
								# most_likely_marginalised_nH_ne_index = ((index_most_likely-most_likely_marginalised_nH2p_ne_index)//len(nH2p_ne_values)-most_likely_marginalised_nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)
								#
								# most_likely_marginalised_nH2p_ne_value = nH2p_ne_values[most_likely_marginalised_nH2p_ne_index]
								# most_likely_marginalised_nHm_ne_value = nHm_ne_values[most_likely_marginalised_nHm_ne_index]
								# most_likely_marginalised_nH_ne_value = nH_ne_values[most_likely_marginalised_nH_ne_index]


								# scan_after_first = False	# I do enough scanning in the first phase, that's enough now
								# if scan_after_first:
								# 	next_nH2p_ne_value_up = max(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)*6
								# 	next_nH2p_ne_value_down = min(most_likely_marginalised_nH2p_ne_value,most_likely_nH2p_ne_value)/6
								# 	next_nHm_ne_value_up = max(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)*6
								# 	next_nHm_ne_value_down = min(most_likely_marginalised_nHm_ne_value,most_likely_nHm_ne_value)/6
								# 	next_nH_ne_value_up = max(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)*6
								# 	next_nH_ne_value_down = min(most_likely_marginalised_nH_ne_value,most_likely_nH_ne_value)/6

								# print('best_fit_nH_ne_index %.3g,best_fit_nHm_ne_value %.3g,best_fit_nH2_ne_value %.3g,best_fit_nH2p_ne_value %.3g' %(best_fit_nH_ne_index,best_fit_nHm_ne_value,best_fit_nH2_ne_value,best_fit_nH2p_ne_value))

								# I need as much memory as mpossible
								del calculated_emission_log_probs_expanded


								# Here I try to obtain the Probability Distribution Function (PDF) for the radiated power, ionisation and recombination rate
								if (collect_power_PDF or to_print):
									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' marker 1 '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) + str(np.shape(likelihood_log_probs)))
									# Approach suggested by Christopher Bowman. integral of the full probability distribution given intervals of given power
									if False:	# logarithmic interval scaling
										d_nH_ne_values = np.array([*np.diff(np.log10(nH_ne_values[[0,1]])),*(np.diff(np.log10(nH_ne_values))[:-1]/2+np.diff(np.log10(nH_ne_values))[1:]/2),*np.diff(np.log10(nH_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH_ne_values[[0,-1]]))+np.diff(np.log10(nH_ne_values[[0,1]]))/2+np.diff(np.log10(nH_ne_values[[-2,-1]]))/2)
										d_nHm_ne_values = np.array([*np.diff(np.log10(nHm_ne_values[[0,1]])),*(np.diff(np.log10(nHm_ne_values))[:-1]/2+np.diff(np.log10(nHm_ne_values))[1:]/2),*np.diff(np.log10(nHm_ne_values[[-2,-1]]))])/(np.diff(np.log10(nHm_ne_values[[0,-1]]))+np.diff(np.log10(nHm_ne_values[[0,1]]))/2+np.diff(np.log10(nHm_ne_values[[-2,-1]]))/2)
										d_nH2_ne_values = np.array([*np.diff(np.log10(nH2_ne_values[[0,1]])),*(np.diff(np.log10(nH2_ne_values))[:-1]/2+np.diff(np.log10(nH2_ne_values))[1:]/2),*np.diff(np.log10(nH2_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2_ne_values[[0,-1]]))+np.diff(np.log10(nH2_ne_values[[0,1]]))/2+np.diff(np.log10(nH2_ne_values[[-2,-1]]))/2)
										d_nH2p_ne_values = np.array([*np.diff(np.log10(nH2p_ne_values[[0,1]])),*(np.diff(np.log10(nH2p_ne_values))[:-1]/2+np.diff(np.log10(nH2p_ne_values))[1:]/2),*np.diff(np.log10(nH2p_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2p_ne_values[[0,-1]]))+np.diff(np.log10(nH2p_ne_values[[0,1]]))/2+np.diff(np.log10(nH2p_ne_values[[-2,-1]]))/2)
									elif True:	# linear interval scaling
										d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])/(np.diff(nH_ne_values[[0,-1]])+np.diff(nH_ne_values[[0,1]])/2+np.diff(nH_ne_values[[-2,-1]])/2)
										d_nHm_ne_values = np.array([*np.diff(nHm_ne_values[[0,1]]),*(np.diff(nHm_ne_values)[:-1]/2+np.diff(nHm_ne_values)[1:]/2),*np.diff(nHm_ne_values[[-2,-1]])])/(np.diff(nHm_ne_values[[0,-1]])+np.diff(nHm_ne_values[[0,1]])/2+np.diff(nHm_ne_values[[-2,-1]])/2)
										d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])/(np.diff(nH2_ne_values[[0,-1]])+np.diff(nH2_ne_values[[0,1]])/2+np.diff(nH2_ne_values[[-2,-1]])/2)
										d_nH2p_ne_values = np.array([*np.diff(nH2p_ne_values[[0,1]]),*(np.diff(nH2p_ne_values)[:-1]/2+np.diff(nH2p_ne_values)[1:]/2),*np.diff(nH2p_ne_values[[-2,-1]])])/(np.diff(nH2p_ne_values[[0,-1]])+np.diff(nH2p_ne_values[[0,1]])/2+np.diff(nH2p_ne_values[[-2,-1]])/2)

									d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])/(np.diff(ne_values_array[[0,-1]])+np.diff(ne_values_array[[0,1]])/2+np.diff(ne_values_array[[-2,-1]])/2)
									d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])/(np.diff(Te_values_array[[0,-1]])+np.diff(Te_values_array[[0,1]])/2+np.diff(Te_values_array[[-2,-1]])/2)
									hypervolume_of_each_combination = (np.array([(np.array([(np.array([(np.array([(np.array([d_nH_ne_values]*len(d_nHm_ne_values)).T*d_nHm_ne_values).T]*len(d_nH2_ne_values)).T*d_nH2_ne_values).T]*len(d_nH2p_ne_values)).T*d_nH2p_ne_values).T]*len(d_ne_values_array)).T*d_ne_values_array).T]*len(d_Te_values_array)).T*d_Te_values_array)

									likelihood_probs_times_volume = np.float32(np.exp(likelihood_log_probs)*hypervolume_of_each_combination)
									likelihood_probs_times_volume = likelihood_probs_times_volume/np.sum(likelihood_probs_times_volume)
									likelihood_probs_times_volume_short_lim = np.flip(np.sort(likelihood_probs_times_volume.flatten()),axis=0)[np.abs(np.cumsum(np.flip(np.sort(likelihood_probs_times_volume.flatten()),axis=0))-(1-1e-5)).argmin()]
									likelihood_probs_times_volume_short = (likelihood_probs_times_volume[likelihood_probs_times_volume>likelihood_probs_times_volume_short_lim].flatten()).astype(np.float32)
									likelihood_probs_times_volume_short = (likelihood_probs_times_volume_short/np.sum(likelihood_probs_times_volume_short)).astype(np.float32)

									if False:	# using the first iteration in calculating the power only of the best fits
										likelihood_probs = np.exp(likelihood_log_probs)
										min_fraction_of_prob_considered = max(1e-10,min(1e-4,(np.sort(likelihood_probs_times_volume.flatten())[-2000000:][0])/np.max(likelihood_probs_times_volume)))	# I select max some million samples
										# else:
										# 	min_fraction_of_prob_considered = max(1e-10,min(1e-1,(np.sort(likelihood_probs_times_volume.flatten())[-1000:][0])/np.max(likelihood_probs_times_volume)))	# I select max some million samples
										# min_fraction_of_prob_considered = 1e-10
										non_zero_prob_select = likelihood_probs_times_volume>np.max(likelihood_probs_times_volume)*min_fraction_of_prob_considered
										power_rad_excit = np.zeros_like(likelihood_probs)
										power_rad_rec_bremm = np.zeros_like(likelihood_probs)
										power_rad_mol = np.zeros_like(likelihood_probs)
										power_via_ionisation = np.zeros_like(likelihood_probs)
										power_via_recombination = np.zeros_like(likelihood_probs)
										power_rad_Hm = np.zeros_like(likelihood_probs)
										power_rad_H2 = np.zeros_like(likelihood_probs)
										power_rad_H2p = np.zeros_like(likelihood_probs)
										nH_ne_values_full,nHm_ne_values_full,nH2_ne_values_full,nH2p_ne_values_full,ne_values_full,Te_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2_ne_values,nH2p_ne_values,ne_values_array,Te_values_array,indexing='ij')	# H, Hm, H2, H2p, ne, Te
										# nH_ne_values_full = nH_ne_values_full[non_zero_prob_select]
										# nHm_ne_values_full = nHm_ne_values_full[non_zero_prob_select]
										# nH2_ne_values_full = nH2_ne_values_full[non_zero_prob_select]
										# nH2p_ne_values_full = nH2p_ne_values_full[non_zero_prob_select]
										# ne_values_full = ne_values_full[non_zero_prob_select]
										# Te_values_full = Te_values_full[non_zero_prob_select]
										T_Hm_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full)))/eV_to_K	# K
										T_H2p_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full)))/eV_to_K	# K
										T_Hp_values_full = Te_values_full/eV_to_K	# K


										power_rad_excit[non_zero_prob_select],power_rad_rec_bremm[non_zero_prob_select],power_rad_mol[non_zero_prob_select],power_via_ionisation[non_zero_prob_select],power_via_recombination[non_zero_prob_select],power_rad_Hm[non_zero_prob_select],power_rad_H2[non_zero_prob_select],power_rad_H2p[non_zero_prob_select] = calc_power_balance_elements(Te_values_full[non_zero_prob_select],ne_values_full[non_zero_prob_select],nH_ne_values_full[non_zero_prob_select],nHm_ne_values_full[non_zero_prob_select],nH2p_ne_values_full[non_zero_prob_select],nH2_ne_values_full[non_zero_prob_select],T_Hp_values_full[non_zero_prob_select],T_Hm_values_full[non_zero_prob_select],T_H2p_values_full[non_zero_prob_select])
									else:	# calculate the power of every combination, but much faster
										min_fraction_of_prob_considered = 0
										# power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination,power_rad_Hm,power_rad_H2,power_rad_H2p = calc_power_balance_elements_simplified(nH_ne_values,nHm_ne_values,nH2_ne_values,nH2p_ne_values,ne_values_array,Te_values_array,Te_values,ne_values,T_Hm_values,T_H2p_values,T_Hp_values)
										total_wavelengths = np.unique(excited_states_From_Hn_with_Hp)
										power_rad_H2p = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										coeff_1 = (From_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										power_rad_H2p = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										power_rad_H2p = power_rad_H2p + np.sum((coeff_1 * multiplicative_factor_full_full),axis=-1) * (ne_values**2)
										power_rad_H2p = np.transpose(power_rad_H2p, (0,1,2,4,5,3))	# H, Hm, H2, ne, Te, H2p
										power_rad_H2p = power_rad_H2p * nH2p_ne_values
										power_rad_H2p = np.transpose(power_rad_H2p, (0,1,2,5,3,4)).astype(np.float32)	# H, Hm, H2, H2p, ne, Te
										# coeff_1 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2p))))
										coeff_2 = (From_H2_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										power_rad_H2 = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										power_rad_H2 = power_rad_H2 + np.sum((coeff_2 * multiplicative_factor_full_full),axis=-1) * (ne_values**2)
										power_rad_H2 = np.transpose(power_rad_H2, (0,1,3,4,5,2))	# H, Hm, H2p, ne, Te, H2
										power_rad_H2 = power_rad_H2 * nH2_ne_values
										power_rad_H2 = np.transpose(power_rad_H2, (0,1,5,2,3,4)).astype(np.float32)	# H, Hm, H2, H2p, ne, Te
										# total_nH2_ne_value = []
										# for i4,nH2_ne_value in enumerate(nH2_ne_values):
										# 	total_nH2_ne_value.append( coeff_2 *  nH2_ne_value)
										# 	# total_nH2_ne_value = nH2_ne_value * coeff_2
										# total_nH2_ne_value = np.array(total_nH2_ne_value)
										# total_nH2_ne_value = np.sum(total_nH2_ne_value*multiplicative_factor_full_full, axis=-1)
										# power_rad_H2 = np.transpose(np.zeros_like(power_rad_excit), (0,1,3,2,4,5))	# H, Hm, H2p, H2, ne, Te
										# power_rad_H2 += total_nH2_ne_value
										# power_rad_H2 = np.transpose(power_rad_H2, (0,1,3,2,4,5))	# H, Hm, H2, H2p, ne, Te
										# coeff_2 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2))))
										power_rad_excit = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										total_power_rad_excit = (read_adf11(pltfile, 'plt', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
										power_rad_excit = power_rad_excit + total_power_rad_excit
										power_rad_excit = ((power_rad_excit.T * nH_ne_values).T).astype(np.float32)
										power_via_ionisation = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										total_power_via_ionisation = (read_adf11(scdfile, 'scd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
										power_via_ionisation = power_via_ionisation + total_power_via_ionisation
										power_via_ionisation = ((power_via_ionisation.T * nH_ne_values).T).astype(np.float32)
										total_power_rad_rec_bremm = (read_adf11(prbfile, 'prb', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
										total_power_via_recombination = (read_adf11(acdfile, 'acd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
										power_rad_Hm = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne, Te
										power_rad_rec_bremm = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne, Te
										power_via_recombination = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne, Te

										for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
											# total_nH2p_ne_value = ( nH2p_ne_value * coeff_1 )
											coeff_4 = (From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
											coeff_4 = np.sum((coeff_4 * multiplicative_factor_full_full),axis=-1)*(ne_values**2)
											# power_rad_H2p[:,:,:,i5] = np.sum((total_nH2p_ne_value * multiplicative_factor_full_full),axis=-1)
											for i3,nHm_ne_value in enumerate(nHm_ne_values):
												nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value
												if nHp_ne_value<0:
													continue
												elif nHp_ne_value==0:
													nHp_ne_value=1e-8
													power_via_recombination[:,i3,:,i5] = 0
													power_rad_rec_bremm[:,i3,:,i5] = 0
												else:
													power_via_recombination[:,i3,:,i5] = (total_power_via_recombination * nHp_ne_value).astype(np.float32)
													power_rad_rec_bremm[:,i3,:,i5] = (total_power_rad_rec_bremm * nHp_ne_value).astype(np.float32)
												coeff_3 = (From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_value*ne_values.flatten()]).T ,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
												coeff_3 = np.sum((coeff_3 * multiplicative_factor_full_full),axis=-1) *(ne_values**2)
												# total_nHm_ne_value = nHm_ne_value*( coeff_3 + coeff_4 )
												# for i1,nH_ne_value in enumerate(nH_ne_values):
												# 	for i4,nH2_ne_value in enumerate(nH2_ne_values):
												power_rad_Hm[:,i3,:,i5] = (nHm_ne_value*( coeff_3 + coeff_4 )).astype(np.float32)
										power_rad_mol = (power_rad_Hm + power_rad_H2 + power_rad_H2p).astype(np.float32)

									effective_ionisation_rates = power_via_ionisation/13.6*J_to_eV
									effective_recombination_rates = power_via_recombination/13.6*J_to_eV
									tot_rad_power = (power_rad_excit+power_rad_rec_bremm+power_rad_mol).astype(np.float32)

									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' marker 2 '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)))

									PDF_intervals = 20

									def build_log_PDF(power,PDF_intervals,non_zero_prob_select=3,use_all=True):
										# d_power = min(np.diff(np.log10(np.sort(power[power>0].flatten())[[0,-1]]))/PDF_intervals,0.5)
										if use_all:
											# num_samples = len(power.flatten())
											# power_values = np.sort(power.flatten())[(np.arange(PDF_intervals)*num_samples/PDF_intervals).astype(int)]
											power_short = (power[likelihood_probs_times_volume>likelihood_probs_times_volume_short_lim].flatten()).astype(np.float32)
											sorted_prob = (np.array([to_sort for _, to_sort in sorted(zip(power_short, likelihood_probs_times_volume_short))])).astype(np.float32)
											sorted_prob = (sorted_prob/np.sum(sorted_prob)).astype(np.float32)
											# print('1')
											power_values = (np.sort(power_short.flatten())).astype(np.float32)
											treshold = 1/500
											temp = (np.cumsum(sorted_prob)).astype(np.float32)
											# print('2')
											temp1=[]
											temp2 = []
											prev_loc=0
											for i in range(0,500):
												loc = np.abs(temp-(treshold*i+treshold/2)).argmin()
												temp1.append(power_values[loc])
												if i==0:
													temp2.append(temp[loc])
												else:
													temp2.append(temp[loc]-temp[prev_loc])
												prev_loc=loc
											# temp1.append(power_values[-1])
											# temp2.append(temp[-1]-np.sum(temp2))
											power_values = np.array(temp1)
											sorted_prob = np.array(temp2)
										else:
											num_samples = np.sum(non_zero_prob_select)
											power_values = np.sort(power[non_zero_prob_select])[(np.arange(PDF_intervals)*num_samples/PDF_intervals).astype(int)]
										# power_values = power_values[power_values>0]
										# print('3')
										done=0
										limit = len(power_values)*2
										while (done==0 and limit>0):
											limit-=1
											if limit==1:
												print('failed PDF building in t=%.3g, r=%.3g' %(my_time_pos,my_r_pos))
											for i in range(len(power_values)-1):
												if power_values[i]==0:
													continue
												# print(power_values)
												# if (power_values[i+1]/power_values[i]<1.1 and len(power_values)>3):
												if ((power_values[i+1]/power_values[i]<1.3 or sorted_prob[i]<1e-50) and len(power_values)>PDF_intervals):
													power_values = np.concatenate((power_values[:i+1],power_values[i+2:]))
													sorted_prob = np.concatenate((sorted_prob[:i],[np.sum(sorted_prob[i:i+2])],sorted_prob[i+2:]))
													break
												if i==len(power_values)-2:
													done=1
										# power_values = [*power_values[:-1][power_values[1:]/power_values[:-1]>1.05],power_values[-1]]
										power_values = np.array([0,np.min(power[power>0]),*power_values,np.max(power)])
										power_values = np.unique(power_values)
										# log_power = np.log10(power)
										# low_point = np.max(log_power)-d_power*PDF_intervals
										# log_power_values = np.array([-np.inf,*np.linspace(low_point,np.max(log_power),num=PDF_intervals)])
										prob_power = []
										actual_values_power = []
										for index in range(len(power_values)-1):
											if index==0:
												select = np.logical_and(power>=power_values[index],power<=power_values[index+1])
											else:
												select = np.logical_and(power>power_values[index],power<=power_values[index+1])
											if np.sum(select)==0:
												prob_power.append(0)
												actual_values_power.append(np.mean([power_values[index],power_values[index+1]]))
											else:
												prob_power.append(np.sum(likelihood_probs_times_volume[select]))
												temp = np.sum(likelihood_probs_times_volume[select]*power[select])/np.sum(likelihood_probs_times_volume[select])
												if np.isnan(temp):
													actual_values_power.append(np.nanmean(power[select]))
												else:
													actual_values_power.append(temp)
										prob_power = np.array(prob_power)/np.sum(prob_power)
										actual_values_power = np.array(actual_values_power)
										# print('4')
										return power_values,prob_power,actual_values_power

									intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit = build_log_PDF(power_rad_excit,PDF_intervals)
									intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm = build_log_PDF(power_rad_rec_bremm,PDF_intervals)
									intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol = build_log_PDF(power_rad_mol,PDF_intervals)
									intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation = build_log_PDF(power_via_ionisation,PDF_intervals)
									intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination = build_log_PDF(power_via_recombination,PDF_intervals)
									intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power = build_log_PDF(tot_rad_power,PDF_intervals)
									intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm = build_log_PDF(power_rad_Hm,PDF_intervals)
									intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2 = build_log_PDF(power_rad_H2,PDF_intervals)
									intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p = build_log_PDF(power_rad_H2p,PDF_intervals)
									power_balance_data = [intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit, intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm, intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol, intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation, intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination, intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power,intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm,intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2,intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p]
								else:
									intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit = [[0],[0],[0]]
									intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm = [[0],[0],[0]]
									intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol = [[0],[0],[0]]
									intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation = [[0],[0],[0]]
									intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination = [[0],[0],[0]]
									intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power = [[0],[0],[0]]
									intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm = [[0],[0],[0]]
									intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2 = [[0],[0],[0]]
									intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p = [[0],[0],[0]]
									power_balance_data = [intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit, intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm, intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol, intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation, intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination, intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power,intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm,intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2,intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p]


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# here I find the plame that contains the most of the high probability points
											nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(nH2p_ne_values,nHm_ne_values)
											temp = np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp[temp<1e-100]=1e-100
											# nH2p_ne_values_full=nH2p_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
											# nHm_ne_values_full=nHm_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
											# temp=temp[temp>np.exp(max_likelihood_log_prob)*0.8]
											fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]

											nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2p_ne_values,indexing='ij')
											temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp[temp<1e-100]=1e-100
											# nH_ne_values_full=nH_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
											# nH2p_ne_values_full=nH2p_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
											# nHm_ne_values_full=nHm_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
											# temp=temp[temp>np.exp(max_likelihood_log_prob)*0.8]
											def find_correlation(params):
												calc = line_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum(((nHm_ne_values_full-calc)*temp)**2)/np.sum(temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(temp**2))
												return diff
											x_scale = np.abs(np.array([1e-3,fit1[0],fit1[1]]))
											x_scale[x_scale==0]=1e-6
											sol_line = least_squares(find_correlation,[0,fit1[0],fit1[1]],max_nfev=10000,x_scale=x_scale)
											R2_sol_line = 1-find_correlation(sol_line.x)

											def find_correlation(params):
												calc = parabola_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum(((nHm_ne_values_full-calc)*temp)**2)/np.sum(temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(temp**2))
												return diff
											x_scale = np.abs(np.array([1e-3,sol_line.x[0],1e-3,sol_line.x[1],sol_line.x[2]]))
											x_scale[x_scale==0]=1e-6
											sol_parab = least_squares(find_correlation,[0,sol_line.x[0],0,sol_line.x[1],sol_line.x[2]],max_nfev=10000,x_scale=x_scale)
											R2_sol_parab = 1-find_correlation(sol_parab.x)

											nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(nH2p_ne_values,nHm_ne_values)
											temp = np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,:,:])
											temp[temp<1e-100]=1e-100
											fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]

											nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2p_ne_values,indexing='ij')
											temp = np.exp(marginalised_likelihood_log_probs[:,:,:])
											temp[temp<1e-100]=1e-100
											# nH_ne_values_full=nH_ne_values_full[temp>np.max(temp)/1.2]
											# nH2p_ne_values_full=nH2p_ne_values_full[temp>np.max(temp)/1.2]
											# nHm_ne_values_full=nHm_ne_values_full[temp>np.max(temp)/1.2]
											# temp=temp[temp>np.max(temp)/1.2]
											def find_correlation(params):
												calc = line_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum(((nHm_ne_values_full-calc)*temp)**2)/np.sum(temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(temp**2))
												return diff
											x_scale = np.abs(np.array([1e-3,fit1[0],fit1[1]]))
											x_scale[x_scale==0]=1e-6
											marginalised_sol_line = least_squares(find_correlation,[0,fit1[0],fit1[1]],max_nfev=10000,x_scale=x_scale)
											R2_marginalised_sol_line = 1-find_correlation(marginalised_sol_line.x)

											def find_correlation(params):
												calc = parabola_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum(((nHm_ne_values_full-calc)*temp)**2)/np.sum(temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(temp**2))
												return diff
											x_scale = np.abs(np.array([1e-3,sol_line.x[0],1e-3,sol_line.x[1],sol_line.x[2]]))
											x_scale[x_scale==0]=1e-6
											marginalised_sol_parab = least_squares(find_correlation,[0,marginalised_sol_line.x[0],0,marginalised_sol_line.x[1],marginalised_sol_line.x[2]],max_nfev=10000,x_scale=x_scale)
											R2_marginalised_sol_parab = 1-find_correlation(marginalised_sol_parab.x)


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											print('worker '+str(current_process())+' '+str(domain_index)+' first scan best_fit_nH_ne_index %.3g,best_fit_nHm_ne_value %.3g,best_fit_nH2_ne_value %.3g,best_fit_nH2p_ne_value %.3g' %(centre_nH_ne,best_fit_nHm_ne_value,centre_nH2_ne,best_fit_nH2p_ne_value))
											# tm.sleep(np.random.random()*10)
											if False:
												fig, ax = plt.subplots( 2,1,figsize=(10, 25), squeeze=True)
												fig.suptitle('best_fit_nH_ne_index %.3g,best_fit_nHm_ne_value %.3g,best_fit_nH2_ne_value %.3g,best_fit_nH2p_ne_value %.3g' %(centre_nH_ne*ne,best_fit_nHm_ne_value*ne,centre_nH2_ne*ne,best_fit_nH2p_ne_value*ne) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g eV, ' % merge_Te_prof_multipulse_interp_crop_limited_restrict + '%.3g #10^20/m^3]' % merge_ne_prof_multipulse_interp_crop_limited_restrict +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % centre_nH_ne + '%.3g, ' %(1 - best_fit_nH2p_ne_value + best_fit_nHm_ne_value)+ '%.3g, ' % best_fit_nHm_ne_value+ '%.3g, ' % centre_nH2_ne+ '%.3g, ' % best_fit_nH2p_ne_value+ '%.3g]' % 0 +'\nH ionization length %.3gm' % ionization_length_H +'\nH2 ionization length %.3gm' % ionization_length_H2)
												plot_index = 0
												# im = ax[plot_index].plot(nH_ne*ne, calculated_emission_error[:,best_fit_nHm_ne_index,best_fit_nH2_ne_index,best_fit_nH2p_ne_index]);
												# im = ax[plot_index].plot([best_fit_nH_ne_index*ne,best_fit_nH_ne_index*ne], np.sort(calculated_emission_error[:,best_fit_nHm_ne_index,best_fit_nH2_ne_index,best_fit_nH2p_ne_index])[[0,-1]],'k--');
												# ax[plot_index].set_title('nH')
												# ax[plot_index].set_ylabel('fitting error')
												# ax[plot_index].set_xlabel('density [#/m^3]')
												# ax[plot_index].set_xscale('log')
												# ax[plot_index].set_yscale('log')
												# plot_index += 1
												im = ax[plot_index].plot(nHm_ne_values*ne, calculated_emission_error[:,best_fit_nH2p_ne_index]);
												im = ax[plot_index].plot([best_fit_nHm_ne_value*ne,best_fit_nHm_ne_value*ne], np.sort(calculated_emission_error[:,best_fit_nH2p_ne_index])[[0,-1]],'k--');
												ax[plot_index].set_title('nH-')
												ax[plot_index].set_ylabel('fitting error')
												ax[plot_index].set_xlabel('density [#/m^3]')
												ax[plot_index].set_xscale('log')
												ax[plot_index].set_yscale('log')
												plot_index += 1
												# im = ax[plot_index].plot(nH2_ne*ne, calculated_emission_error[best_fit_nH_ne_index,best_fit_nHm_ne_index,:,best_fit_nH2p_ne_index]);
												# im = ax[plot_index].plot([best_fit_nH2_ne_value*ne,best_fit_nH2_ne_value*ne], np.sort(calculated_emission_error[best_fit_nH_ne_index,best_fit_nHm_ne_index,:,best_fit_nH2p_ne_index])[[0,-1]],'k--');
												# ax[plot_index].set_title('nH2')
												# ax[plot_index].set_ylabel('fitting error')
												# ax[plot_index].set_xlabel('density [#/m^3]')
												# ax[plot_index].set_xscale('log')
												# ax[plot_index].set_yscale('log')
												# plot_index += 1
												im = ax[plot_index].plot(nH2p_ne_values*ne, calculated_emission_error[best_fit_nHm_ne_index,:]);
												im = ax[plot_index].plot([best_fit_nH2p_ne_value*ne,best_fit_nH2p_ne_value*ne], np.sort(calculated_emission_error[best_fit_nHm_ne_index,:])[[0,-1]],'k--');
												ax[plot_index].set_title('nH2+')
												ax[plot_index].set_ylabel('fitting error')
												ax[plot_index].set_xlabel('density [#/m^3]')
												ax[plot_index].set_xscale('log')
												ax[plot_index].set_yscale('log')
												# plt.pause(0.01)
											elif True:
												print('First scan\nmost_likely_nH_ne_index %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g,most_likely_Te_value %.3g,most_likely_ne_value %.3g' %(most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value,most_likely_Te_value,most_likely_ne_value))
												fig, ax = plt.subplots( 4,2,figsize=(20, 45), squeeze=False)
												fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH2p_ne_value))
												plot_index = 0
												im = ax[plot_index,0].plot(range(TS_Te_steps)-most_likely_Te_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,:]),label='Te');
												im = ax[plot_index,0].plot(range(TS_ne_steps)-most_likely_ne_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,:,most_likely_Te_index]),label='ne');
												im = ax[plot_index,0].plot(range(len(nH2p_ne_values))-most_likely_nH2p_ne_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),label='nH2+/ne');
												im = ax[plot_index,0].plot(range(len(nH2_ne_values))-most_likely_nH2_ne_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,:,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]),label='nH2/ne');
												im = ax[plot_index,0].plot(range(len(nHm_ne_values))-most_likely_nHm_ne_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]),label='nH-/ne');
												im = ax[plot_index,0].plot(range(len(nH_ne_values))-most_likely_nH_ne_index,np.exp(likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]),label='nH/ne');
												ax[plot_index,0].set_title('Likelihood around the best')
												ax[plot_index,0].set_ylabel('normalised likelihood')
												ax[plot_index,0].set_xlabel('range used for search')
												ax[plot_index,0].legend(loc='best')
												# ax[plot_index].set_xscale('log')
												# ax[plot_index,0].set_yscale('log')
												# ax[plot_index,0].set_ylim(bottom=np.exp(max_likelihood_log_prob)*1e-2,top=np.exp(max_likelihood_log_prob)*1.1)

												im = ax[plot_index,1].plot(range(len(nH2p_ne_values))-most_likely_marginalised_nH2p_ne_index,np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_ne_index,:]),label='nH2+/ne');
												im = ax[plot_index,1].plot(range(len(nHm_ne_values))-most_likely_marginalised_nHm_ne_index,np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,:,most_likely_marginalised_nH2p_ne_index]),label='nH-/ne');
												im = ax[plot_index,1].plot(range(len(nH_ne_values))-most_likely_marginalised_nH_ne_index,np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_ne_index,most_likely_marginalised_nH2p_ne_index]),label='nH/ne');
												ax[plot_index,1].set_title('Marginalised likelihood around the best')
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('range used for search')
												ax[plot_index,1].legend(loc='best')
												# ax[plot_index].set_xscale('log')
												# ax[plot_index,1].set_yscale('log')
												# ax[plot_index,1].set_ylim(bottom=np.exp(np.max(marginalised_likelihood_log_probs))*1e-2,top=np.exp(np.max(marginalised_likelihood_log_probs))*1.1)

												plot_index += 1
												im = ax[plot_index,0].contourf(nH2p_ne_values,nHm_ne_values, np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,0])
												im = ax[plot_index,0].contour(nH2p_ne_values,nHm_ne_values, np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10);
												im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nHm_ne_value,color='k',marker='$M$',markersize=30);
												im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nHm_ne_value,color='k',marker='$X$',markersize=30);
												im = ax[plot_index,0].plot(first_most_likely_marginalised_nH2p_ne_value,first_most_likely_marginalised_nHm_ne_value,color='y',marker='$M$',markersize=15);
												im = ax[plot_index,0].plot(first_most_likely_nH2p_ne_value,first_most_likely_nHm_ne_value,color='y',marker='$X$',markersize=15);
												# if scan_after_first:
												# 	im = ax[plot_index,0].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
												im = ax[plot_index,0].plot(np.meshgrid(nH2p_ne_values, nHm_ne_values)[0],np.meshgrid(nH2p_ne_values, nHm_ne_values)[1],'k,')
												im = ax[plot_index,0].plot([np.min(nH2p_ne_values),np.min(nH2p_ne_values)],[np.min(nHm_ne_values),np.max(nHm_ne_values)],'k--');
												for fraction in fixed_fractions_nHm_H2p:
													im = ax[plot_index,0].plot([np.min(nH2p_ne_values),np.max(nH2p_ne_values)],[np.min(nH2p_ne_values)*fraction,np.max(nH2p_ne_values)*fraction],'k--');
												im = ax[plot_index,0].plot([np.min(nH2p_ne_values),np.max(nH2p_ne_values)],[np.min(nHm_ne_values),np.min(nHm_ne_values)],'k--');
												nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(nH2p_ne_values,nHm_ne_values)
												temp = np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
												temp[temp<1e-100]=1e-100
												# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												nH2p_ne_values_full = nH2p_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												nHm_ne_values_full = nHm_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												fit1 = np.polyfit(nH2p_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												fit_average = [(fit1[0]+1/fit2[0])/2,(fit1[1]-fit2[1]/fit2[0])/2]
												reverse_fit_average = [1/fit_average[0],-fit_average[1]/fit_average[0]]
												im = ax[plot_index,0].plot(nH2p_ne_values,np.polyval(fit_average,nH2p_ne_values),'k--')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H\nM=marginalised best, X=unmarginalised best, --=samples\nblue=fit H-/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
												ax[plot_index,0].set_ylabel('nH-/ne')
												ax[plot_index,0].set_xlabel('nH2+/ne')
												ax[plot_index,0].set_xscale('log')
												ax[plot_index,0].set_yscale('log')

												im = ax[plot_index,1].contourf(nH2p_ne_values,nHm_ne_values, np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,1])
												im = ax[plot_index,1].contour(nH2p_ne_values,nHm_ne_values, np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,:,:]),levels=10);
												im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nHm_ne_value,color='k',marker='$M$',markersize=30);
												im = ax[plot_index,1].plot(most_likely_nH2p_ne_value,most_likely_nHm_ne_value,color='k',marker='$X$',markersize=30);
												im = ax[plot_index,1].plot(first_most_likely_marginalised_nH2p_ne_value,first_most_likely_marginalised_nHm_ne_value,color='y',marker='$M$',markersize=15);
												im = ax[plot_index,1].plot(first_most_likely_nH2p_ne_value,first_most_likely_nHm_ne_value,color='y',marker='$X$',markersize=15);
												# if scan_after_first:
												# 	im = ax[plot_index,1].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
												im = ax[plot_index,1].plot(np.meshgrid(nH2p_ne_values, nHm_ne_values)[0],np.meshgrid(nH2p_ne_values, nHm_ne_values)[1],'k,')
												nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(nH2p_ne_values,nHm_ne_values)
												temp = np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index])
												temp[temp<1e-100]=1e-100
												# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												nH2p_ne_values_full = nH2p_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												nHm_ne_values_full = nHm_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												fit1 = np.polyfit(nH2p_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H\nblue=fit H-/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
												ax[plot_index,1].set_ylabel('nH-/ne')
												ax[plot_index,1].set_xlabel('nH2+/ne')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].set_yscale('log')

												plot_index += 1
												im = ax[plot_index,0].contourf(nH2p_ne_values,nH_ne_values, np.exp(likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,0])
												im = ax[plot_index,0].contour(nH2p_ne_values,nH_ne_values, np.exp(likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10);
												im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=30);
												im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=30);
												im = ax[plot_index,0].plot(first_most_likely_marginalised_nH2p_ne_value,first_most_likely_marginalised_nH_ne_value,color='y',marker='$M$',markersize=15);
												im = ax[plot_index,0].plot(first_most_likely_nH2p_ne_value,first_most_likely_nH_ne_value,color='y',marker='$X$',markersize=15);
												# if scan_after_first:
												# 	im = ax[plot_index,0].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nH_ne_value_down,next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down],'k--');
												im = ax[plot_index,0].plot(np.meshgrid(nH2p_ne_values, nH_ne_values)[0],np.meshgrid(nH2p_ne_values, nH_ne_values)[1],'k,')
												nH2p_ne_values_full,nH_ne_values_full = np.meshgrid(nH2p_ne_values,nH_ne_values)
												temp = np.exp(likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
												temp[temp<1e-100]=1e-100
												# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												# fit2 = curve_fit(line,nH_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												nH2p_ne_values_full = nH2p_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												nH_ne_values_full = nH_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												fit1 = np.polyfit(nH2p_ne_values_full,nH_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nH_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.polyval(fit2,np.sort(nH_ne_values_full)),np.sort(nH_ne_values_full),'b')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H-\nM=marginalised best, X=unmarginalised best\nblue=fit H/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
												ax[plot_index,0].set_ylabel('nH/ne')
												ax[plot_index,0].set_xlabel('nH2+/ne')
												ax[plot_index,0].set_xscale('log')
												ax[plot_index,0].set_yscale('log')

												im = ax[plot_index,1].contourf(nH2p_ne_values,nH_ne_values, np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_ne_index,:]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,1])
												im = ax[plot_index,1].contour(nH2p_ne_values,nH_ne_values, np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_ne_index,:]),levels=10);
												im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=30);
												im = ax[plot_index,1].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=30);
												im = ax[plot_index,1].plot(first_most_likely_marginalised_nH2p_ne_value,first_most_likely_marginalised_nH_ne_value,color='y',marker='$M$',markersize=15);
												im = ax[plot_index,1].plot(first_most_likely_nH2p_ne_value,first_most_likely_nH_ne_value,color='y',marker='$X$',markersize=15);
												# if scan_after_first:
												# 	im = ax[plot_index,1].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nH_ne_value_down,next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down],'k--');
												im = ax[plot_index,1].plot(np.meshgrid(nH2p_ne_values, nH_ne_values)[0],np.meshgrid(nH2p_ne_values, nH_ne_values)[1],'k,')
												nH2p_ne_values_full,nH_ne_values_full = np.meshgrid(nH2p_ne_values,nH_ne_values)
												temp = np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_ne_index,:])
												temp[temp<1e-100]=1e-100
												# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												# fit2 = curve_fit(line,nH_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												nH2p_ne_values_full = nH2p_ne_values_full[temp>np.max(temp)/1.2]
												nH_ne_values_full = nH_ne_values_full[temp>np.max(temp)/1.2]
												fit1 = np.polyfit(nH2p_ne_values_full,nH_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nH_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.polyval(fit2,np.sort(nH_ne_values_full)),np.sort(nH_ne_values_full),'b')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H-\nblue=fit H/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
												ax[plot_index,1].set_ylabel('nH/ne')
												ax[plot_index,1].set_xlabel('nH2+/ne')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].set_yscale('log')

												plot_index += 1
												im = ax[plot_index,0].contourf(nH_ne_values,nHm_ne_values, np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index].T),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,0])
												im = ax[plot_index,0].contour(nH_ne_values,nHm_ne_values, np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index].T),levels=10);
												im = ax[plot_index,0].plot(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,color='k',marker='$M$',markersize=30);
												im = ax[plot_index,0].plot(most_likely_nH_ne_value,most_likely_nHm_ne_value,color='k',marker='$X$',markersize=30);
												im = ax[plot_index,0].plot(first_most_likely_marginalised_nH_ne_value,first_most_likely_marginalised_nHm_ne_value,color='y',marker='$M$',markersize=15);
												im = ax[plot_index,0].plot(first_most_likely_nH_ne_value,first_most_likely_nHm_ne_value,color='y',marker='$X$',markersize=15);
												# if scan_after_first:
												# 	im = ax[plot_index,0].plot([next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down,next_nH_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
												im = ax[plot_index,0].plot(np.meshgrid(nH_ne_values, nHm_ne_values)[0],np.meshgrid(nH_ne_values, nHm_ne_values)[1],'k,')
												nH_ne_values_full,nHm_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values)
												temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index].T)
												temp[temp<1e-100]=1e-100
												# fit1 = curve_fit(line,nH_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												nH_ne_values_full = nH_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												nHm_ne_values_full = nHm_ne_values_full[temp>np.exp(max_likelihood_log_prob)*0.8]
												fit1 = np.polyfit(nH_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.sort(nH_ne_values_full),np.polyval(fit1,np.sort(nH_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H2+\nM=marginalised best, X=unmarginalised best\nblue=fit H-/H (%.3g,%.3g)R2 %.3g\nfit H/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
												ax[plot_index,0].set_ylabel('nH-/ne')
												ax[plot_index,0].set_xlabel('nH/ne')
												ax[plot_index,0].set_xscale('log')
												ax[plot_index,0].set_yscale('log')

												im = ax[plot_index,1].contourf(nH_ne_values,nHm_ne_values, np.exp(marginalised_likelihood_log_probs[:,:,most_likely_marginalised_nH2p_ne_index].T),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,1])
												im = ax[plot_index,1].contour(nH_ne_values,nHm_ne_values, np.exp(marginalised_likelihood_log_probs[:,:,most_likely_marginalised_nH2p_ne_index].T),levels=10);
												im = ax[plot_index,1].plot(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,color='k',marker='$M$',markersize=30);
												im = ax[plot_index,1].plot(most_likely_nH_ne_value,most_likely_nHm_ne_value,color='k',marker='$X$',markersize=30);
												im = ax[plot_index,1].plot(first_most_likely_marginalised_nH_ne_value,first_most_likely_marginalised_nHm_ne_value,color='y',marker='$M$',markersize=15);
												im = ax[plot_index,1].plot(first_most_likely_nH_ne_value,first_most_likely_nHm_ne_value,color='y',marker='$X$',markersize=15);
												# if scan_after_first:
												# 	im = ax[plot_index,1].plot([next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down,next_nH_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
												im = ax[plot_index,1].plot(np.meshgrid(nH_ne_values, nHm_ne_values)[0],np.meshgrid(nH_ne_values, nHm_ne_values)[1],'k,')
												nH_ne_values_full,nHm_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values)
												temp = np.exp(marginalised_likelihood_log_probs[:,:,most_likely_marginalised_nH2p_ne_index].T)
												temp[temp<1e-100]=1e-100
												# fit1 = curve_fit(line,nH_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
												# R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
												nH_ne_values_full = nH_ne_values_full[temp>np.max(temp)/1.2]
												nHm_ne_values_full = nHm_ne_values_full[temp>np.max(temp)/1.2]
												fit1 = np.polyfit(nH_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.sort(nH_ne_values_full),np.polyval(fit1,np.sort(nH_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H2+\nblue=fit H-/H (%.3g,%.3g)R2 %.3g\nfit H/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
												ax[plot_index,1].set_ylabel('nH-/ne')
												ax[plot_index,1].set_xlabel('nH/ne')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].set_yscale('log')
											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											fig, ax = plt.subplots( 7,2,figsize=(22, 60), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH2p_ne_value))
											plot_index = 0
											index = likelihood_log_probs[:,0,:,:,:,:].argmax()	# H, Hm, H2, H2p, ne, Te
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2p_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2p_ne_values)
											nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values)%len(nH2_ne_values)
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
											im = ax[plot_index,0].contourf(nH2p_ne_values,nH_ne_values, np.exp(likelihood_log_probs[:,0,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(nH2p_ne_values,nH_ne_values, np.exp(likelihood_log_probs[:,0,nH2_ne_index,:,ne_index,Te_index]),levels=10);
											im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,0].plot(nH2p_ne_values[nH2p_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,0].plot(np.meshgrid(nH2p_ne_values, nH_ne_values)[0],np.meshgrid(nH2p_ne_values, nH_ne_values)[1],'k,')
											ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, nH-=%.3g\nM=marginalised best, X=unmarginalised best' %(np.min(nHm_ne_values)))
											ax[plot_index,0].set_ylabel('nH/ne')
											ax[plot_index,0].set_xlabel('nH2+/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values)
											temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
											temp_likelihood = np.transpose(likelihood_log_probs, (0,2,3,1,4,5))	# H, H2, H2p, Hm, ne, Te
											temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
											temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>fixed_fractions_nHm_H2p[0]/(1+max_frac_acceptable_deviation*1.5),temp<fixed_fractions_nHm_H2p[0]*(1+max_frac_acceptable_deviation*1.5)).flatten(),:,:]
											nH2p_ne_values_full = nH2p_ne_values_full[np.logical_and(temp>fixed_fractions_nHm_H2p[0]/(1+max_frac_acceptable_deviation*1.5),temp<fixed_fractions_nHm_H2p[0]*(1+max_frac_acceptable_deviation*1.5))]
											index = temp_likelihood.argmax()
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2p_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2p_ne_values_full)
											nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full)%len(nH2_ne_values)
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
											im = ax[plot_index,1].contourf(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,1])
											im = ax[plot_index,1].contour(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10);
											im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,1].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,1].plot(nH2p_ne_values_full[nH2p_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,1].plot(np.meshgrid(nH2p_ne_values_full, nH_ne_values)[0],np.meshgrid(nH2p_ne_values_full, nH_ne_values)[1],'k,')
											ax[plot_index,1].set_title('PDF at most likely H2, Te, ne, nH-/nH2+=%.3g+/-%.3g' %(fixed_fractions_nHm_H2p[0],max_frac_acceptable_deviation*1.5*100)+'%')
											ax[plot_index,1].set_ylabel('nH/ne')
											ax[plot_index,1].set_xlabel('nH2+/ne')
											ax[plot_index,1].set_xscale('log')
											ax[plot_index,1].set_yscale('log')

											plot_index += 1
											nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values)
											temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
											temp_likelihood = np.transpose(likelihood_log_probs, (0,2,3,1,4,5))	# H, H2, H2p, Hm, ne, Te
											temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
											temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>fixed_fractions_nHm_H2p[1]/(1+max_frac_acceptable_deviation*1.5),temp<fixed_fractions_nHm_H2p[1]*(1+max_frac_acceptable_deviation*1.5)).flatten(),:,:]
											nH2p_ne_values_full = nH2p_ne_values_full[np.logical_and(temp>fixed_fractions_nHm_H2p[1]/(1+max_frac_acceptable_deviation*1.5),temp<fixed_fractions_nHm_H2p[1]*(1+max_frac_acceptable_deviation*1.5))]
											index = temp_likelihood.argmax()
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2p_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2p_ne_values_full)
											nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full)%len(nH2_ne_values)
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
											im = ax[plot_index,0].contourf(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10);
											im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,0].plot(nH2p_ne_values_full[nH2p_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,0].plot(np.meshgrid(nH2p_ne_values_full, nH_ne_values)[0],np.meshgrid(nH2p_ne_values_full, nH_ne_values)[1],'k,')
											ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, nH-/nH2+=%.3g+/-%.3g' %(fixed_fractions_nHm_H2p[1],max_frac_acceptable_deviation*1.5*100)+'%')
											ax[plot_index,0].set_ylabel('nH/ne')
											ax[plot_index,0].set_xlabel('nH2+/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values)
											temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
											temp_likelihood = np.transpose(likelihood_log_probs, (0,2,3,1,4,5))	# H, H2, H2p, Hm, ne, Te
											temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
											temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>fixed_fractions_nHm_H2p[2]/(1+max_frac_acceptable_deviation*1.5),temp<fixed_fractions_nHm_H2p[2]*(1+max_frac_acceptable_deviation*1.5)).flatten(),:,:]
											nH2p_ne_values_full = nH2p_ne_values_full[np.logical_and(temp>fixed_fractions_nHm_H2p[2]/(1+max_frac_acceptable_deviation*1.5),temp<fixed_fractions_nHm_H2p[2]*(1+max_frac_acceptable_deviation*1.5))]
											index = temp_likelihood.argmax()
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2p_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2p_ne_values_full)
											nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full)%len(nH2_ne_values)
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
											im = ax[plot_index,1].contourf(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,1])
											im = ax[plot_index,1].contour(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10);
											im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,1].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,1].plot(nH2p_ne_values_full[nH2p_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,1].plot(np.meshgrid(nH2p_ne_values_full, nH_ne_values)[0],np.meshgrid(nH2p_ne_values_full, nH_ne_values)[1],'k,')
											ax[plot_index,1].set_title('PDF at most likely H2, Te, ne, nH-/nH2+=%.3g+/-%.3g' %(fixed_fractions_nHm_H2p[2],max_frac_acceptable_deviation*1.5*100)+'%')
											ax[plot_index,1].set_ylabel('nH/ne')
											ax[plot_index,1].set_xlabel('nH2+/ne')
											ax[plot_index,1].set_xscale('log')
											ax[plot_index,1].set_yscale('log')

											plot_index += 1
											index = likelihood_log_probs[:,:,:,0,:,:].argmax()	# H, Hm, H2, H2p, ne, Te
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2_ne_values)
											nHm_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2_ne_index)//len(nH2_ne_values)%len(nHm_ne_values)
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2_ne_index)//len(nH2_ne_values) - nHm_ne_index)//len(nHm_ne_values)%len(nH_ne_values)
											im = ax[plot_index,0].contourf(nHm_ne_values,nH_ne_values, np.exp(likelihood_log_probs[:,:,nH2_ne_index,0,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(nHm_ne_values,nH_ne_values, np.exp(likelihood_log_probs[:,:,nH2_ne_index,0,ne_index,Te_index]),levels=10);
											im = ax[plot_index,0].plot(most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,0].plot(most_likely_nHm_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,0].plot(nHm_ne_values[nHm_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,0].plot(np.meshgrid(nHm_ne_values, nH_ne_values)[0],np.meshgrid(nHm_ne_values, nH_ne_values)[1],'k,')
											ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, nH2+=%.3g' %(np.min(nH2p_ne_values)))
											ax[plot_index,0].set_ylabel('nH/ne')
											ax[plot_index,0].set_xlabel('nH-/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											try:
												nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values)
												temp = np.polyval(fit_average,nH2p_ne_values_full)
												temp = temp/nHm_ne_values_full
												additional_max_frac_acceptable_deviation = 1
												if np.sum(np.logical_and(temp>1/(1+max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation)))<4:
													additional_max_frac_acceptable_deviation = 2
												# temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
												temp_likelihood = np.transpose(likelihood_log_probs, (0,2,3,1,4,5))	# H, H2, H2p, Hm, ne, Te
												temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
												temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation)).flatten(),:,:]
												nH2p_ne_values_full = nH2p_ne_values_full[np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation))]
												index = temp_likelihood.argmax()
												Te_index = index%TS_Te_steps
												ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
												nH2p_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2p_ne_values_full)
												nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full)%len(nH2_ne_values)
												nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
												im = ax[plot_index,1].contourf(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, H2, Hm+H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,1])
												im = ax[plot_index,1].contour(nH2p_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10);
												im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
												im = ax[plot_index,1].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
												im = ax[plot_index,1].plot(nH2p_ne_values_full[nH2p_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
												im = ax[plot_index,1].plot(np.meshgrid(nH2p_ne_values_full, nH_ne_values)[0],np.meshgrid(nH2p_ne_values_full, nH_ne_values)[1],'k,')
												ax[plot_index,1].set_title('PDF at most likely on H2, Te, ne, nH-=%.3gnH2+ +%.3g +/-%.3g' %(*fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%')
												ax[plot_index,1].set_ylabel('nH/ne')
												ax[plot_index,1].set_xlabel('nH2+/ne')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].set_yscale('log')
											except Exception as e:
												ax[plot_index,1].set_title('PDF at most likely on H2, Te, ne, nH-=%.3gnH2+ +%.3g +/-%.3g' %(*fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%'+'\nFAILED because: '+str(e))
												ax[plot_index,1].set_ylabel('nH/ne')
												ax[plot_index,1].set_xlabel('nH2+/ne')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].set_yscale('log')

											plot_index += 1
											try:
												nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(nH2p_ne_values,nHm_ne_values)
												temp = np.polyval(reverse_fit_average,nHm_ne_values_full)
												temp = temp/nH2p_ne_values_full
												additional_max_frac_acceptable_deviation = 1
												if np.sum(np.logical_and(temp>1/(1+max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation)))<4:
													additional_max_frac_acceptable_deviation = 2
												# temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
												temp_likelihood = np.transpose(likelihood_log_probs, (0,2,1,3,4,5))	# H, H2, Hm, H2p, ne, Te
												temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
												temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation)).flatten(),:,:]
												nHm_ne_values_full = nHm_ne_values_full[np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation))]
												index = temp_likelihood.argmax()
												Te_index = index%TS_Te_steps
												ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
												nHm_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nHm_ne_values_full)
												nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nHm_ne_index)//len(nHm_ne_values_full)%len(nH2_ne_values)
												nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nHm_ne_index)//len(nHm_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
												im = ax[plot_index,0].contourf(nHm_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, H2, Hm+H2p, ne, Te
												# im = ax[plot_index,0].scatter(np.meshgrid(nHm_ne_values_full,nH_ne_values)[0],np.meshgrid(nHm_ne_values_full,nH_ne_values)[1], c=np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]), cmap='rainbow');	# H, H2, Hm+H2p, ne, Te
												plt.colorbar(im, ax=ax[plot_index,0])
												im = ax[plot_index,0].contour(nHm_ne_values_full,nH_ne_values, np.exp(temp_likelihood[:,nH2_ne_index,:,ne_index,Te_index]),levels=10);
												im = ax[plot_index,0].plot(most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
												im = ax[plot_index,0].plot(most_likely_nHm_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
												im = ax[plot_index,0].plot(nHm_ne_values_full[nHm_ne_index],nH_ne_values[nH_ne_index],color='k',marker='$X$',markersize=30);
												im = ax[plot_index,0].plot(np.meshgrid(nHm_ne_values_full, nH_ne_values)[0],np.meshgrid(nHm_ne_values_full, nH_ne_values)[1],'k,')
												ax[plot_index,0].set_title('PDF at most likely on H2, Te, ne, nH2+=%.3gnH- +%.3g +/-%.3g' %(*reverse_fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%')
												ax[plot_index,0].set_ylabel('nH/ne')
												ax[plot_index,0].set_xlabel('nH-/ne')
												ax[plot_index,0].set_xscale('log')
												ax[plot_index,0].set_yscale('log')
											except Exception as e:
												ax[plot_index,0].set_title('PDF at most likely on H2, Te, ne, nH2+=%.3gnH- +%.3g +/-%.3g' %(*reverse_fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%'+'\nFAILED because: '+str(e))
												ax[plot_index,0].set_ylabel('nH/ne')
												ax[plot_index,0].set_xlabel('nH-/ne')
												ax[plot_index,0].set_xscale('log')
												ax[plot_index,0].set_yscale('log')

											# if True:	# here I tried to plot the probability distribution across the region of nH2p/nHm correlation, but it is not that helpfull.
											try:
												nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values)
												temp = np.polyval(fit_average,nH2p_ne_values_full)
												temp = temp/nHm_ne_values_full
												additional_max_frac_acceptable_deviation = 1
												if np.sum(np.logical_and(temp>1/(1+max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation)))<4:
													additional_max_frac_acceptable_deviation = 2
												# temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
												temp_likelihood = np.transpose(likelihood_log_probs, (0,2,3,1,4,5))	# H, H2, H2p, Hm, ne, Te
												temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
												temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation)).flatten(),:,:]
												nH2p_ne_values_full = nH2p_ne_values_full[np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation))]
												index = temp_likelihood.argmax()
												Te_index = index%TS_Te_steps
												ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
												nH2p_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nH2p_ne_values_full)
												nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full)%len(nH2_ne_values)
												nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_ne_index)//len(nH2p_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
												im = ax[plot_index,1].plot(nH2p_ne_values_full.flatten(),np.exp(temp_likelihood[nH_ne_index,nH2_ne_index,:,ne_index,Te_index]).flatten(),'+',label='nH2+ >> nH-');

												nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(nH2p_ne_values,nHm_ne_values)
												temp = np.polyval(reverse_fit_average,nHm_ne_values_full)
												temp = temp/nH2p_ne_values_full
												additional_max_frac_acceptable_deviation = 1
												if np.sum(np.logical_and(temp>1/(1+max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation)))<4:
													additional_max_frac_acceptable_deviation = 2
												# temp = nHm_ne_values_full/nH2p_ne_values_full	# H, Hm, H2, H2p, ne, Te
												temp_likelihood = np.transpose(likelihood_log_probs, (0,2,1,3,4,5))	# H, H2, Hm, H2p, ne, Te
												temp_likelihood = temp_likelihood.reshape((len(nH_ne_values),len(nH2_ne_values),len(nHm_ne_values)*len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))
												temp_likelihood = temp_likelihood[:,:,np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation)).flatten(),:,:]
												nHm_ne_values_full = nHm_ne_values_full[np.logical_and(temp>1/(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation),temp<1*(1+max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation))]
												index = temp_likelihood.argmax()
												Te_index = index%TS_Te_steps
												ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
												nHm_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%len(nHm_ne_values_full)
												nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nHm_ne_index)//len(nHm_ne_values_full)%len(nH2_ne_values)
												nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nHm_ne_index)//len(nHm_ne_values_full) - nH2_ne_index)//len(nH2_ne_values)%len(nH_ne_values)
												im = ax[plot_index,1].plot(1/nHm_ne_values_full.flatten(),np.exp(temp_likelihood[nH_ne_index,nH2_ne_index,:,ne_index,Te_index].T).flatten(),'+',label='nH- >> nH2+');
												ax[plot_index,1].set_title('PDF at most likely on H, H2, Te, ne\nnH-=%.3gnH2+ +%.3g +/-%.3g' %(*fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%'+'\nnH2+=%.3gnH-%.3g +/-%.3g' %(*reverse_fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%')
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('nH2+/ne, 1/(nH-/ne)')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].legend(loc='best')
											except Exception as e:
												ax[plot_index,1].set_title('PDF at most likely on H, H2, Te, ne\nnH-=%.3gnH2+ +%.3g +/-%.3g' %(*fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%'+'\nnH2+=%.3gnH-%.3g +/-%.3g' %(*reverse_fit_average,max_frac_acceptable_deviation*additional_max_frac_acceptable_deviation*100)+'%'+'\nFAILED because: '+str(e))
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('nH2+/ne, 1/(nH-/ne)')
												ax[plot_index,1].set_xscale('log')
												ax[plot_index,1].legend(loc='best')

											plot_index += 1
											ax[plot_index,0].remove()
											ax[plot_index,0]=fig.add_subplot(7,2,9,projection='3d')
											# nH_ne_sample = np.logspace(np.log10(np.min(nH_ne_values)),np.log10(np.max(nH_ne_values)),num=1000)
											# nH2p_ne_sample = np.logspace(np.log10(np.min(nH2p_ne_values)),np.log10(np.max(nH2p_ne_values)),num=10000)
											nH_ne_values_full,nH2p_ne_values_full = np.meshgrid(nH_ne_values,nH2p_ne_values,indexing='ij')
											nHm_ne_values_full = np.zeros_like(nH_ne_values_full)
											# specific_prob = np.zeros_like(nH_ne_values_full)
											temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp[temp<1e-100]=1e-100
											for iH,nH_ne in enumerate(nH_ne_values):
												for i2p,nH2p_ne in enumerate(nH2p_ne_values):
													calc = line_3D(nH_ne,nH2p_ne,*sol_line.x)
													im = np.abs(nHm_ne_values-calc).argmin()
													nHm_ne_values_full[iH,i2p] = nHm_ne_values[im]
											# 		nH_ne_values_full[iH,i2p] = nH_ne_values[np.abs(nH_ne_values-nH_ne).argmin()]
											# 		nH2p_ne_values_full[iH,i2p] = nH2p_ne_values[np.abs(nH2p_ne_values-nH2p_ne).argmin()]
											# 		specific_prob[iH,i2p]=temp[np.abs(nH_ne_values-nH_ne).argmin(),im,np.abs(nH2p_ne_values-nH2p_ne).argmin()]
											select = temp>=np.exp(max_likelihood_log_prob)*0.9
											# sample=np.array([nH_ne_values_full.flatten(),nHm_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),specific_prob.flatten()]).T
											# reduced_sample = sample[sample[:,3]>=np.exp(max_likelihood_log_prob)*0.9]
											# temp_reduced_sample=np.array([[0,0,0,0]])
											# for i in range(1,len(reduced_sample)-1):
											# 	if np.sum(np.logical_and(np.logical_and(temp_reduced_sample[:,0]==reduced_sample[i,0],temp_reduced_sample[:,1]==reduced_sample[i,1]),temp_reduced_sample[:,2]==reduced_sample[i,2]))==0:
											# 		temp_reduced_sample = np.concatenate((temp_reduced_sample,[reduced_sample[i]]))
											# reduced_sample = temp_reduced_sample[1:]
											# specific_prob = reduced_sample[3]
											# my_col = cm.rainbow(specific_prob/np.max(specific_prob)*255,alpha=0.5)
											# scatter = ax[plot_index,0].scatter(np.log10(reduced_sample[:,2]),np.log10(reduced_sample[:,1]),np.log10(reduced_sample[:,0]), c=reduced_sample[:,3], cmap='rainbow', zorder = 0.6)
											# surf = ax[plot_index,0].plot_surface(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full), facecolors=my_col,linewidth=1,rstride=1,cstride=1, antialiased=False,alpha=0.5, zorder = 0.1)
											ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											# ax[plot_index,0].plot(np.log10(reduced_sample[:,2]),np.log10(reduced_sample[:,1]),np.log10(reduced_sample[:,0]),'go', zorder = 0.6)
											nH_ne_values_full_temp,nHm_ne_values_full_temp,nH2p_ne_values_full_temp = np.meshgrid(nH_ne_values,nHm_ne_values,nH2p_ne_values,indexing='ij')
											scatter = ax[plot_index,0].scatter(np.log10(nH2p_ne_values_full_temp)[select],np.log10(nHm_ne_values_full_temp)[select],np.log10(nH_ne_values_full_temp)[select], c=temp[select], cmap='rainbow', zorder = 0.6)
											ax[plot_index,0].plot(np.log10(nH2p_ne_values_full_temp)[temp>=np.exp(max_likelihood_log_prob)*0.8],np.log10(nHm_ne_values_full_temp)[temp>=np.exp(max_likelihood_log_prob)*0.8],np.log10(nH_ne_values_full_temp)[temp>=np.exp(max_likelihood_log_prob)*0.8],'k+', zorder = 0.5)
											ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											ax[plot_index,0].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,0].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,0].view_init(elev=60,azim=45)
											ax[plot_index,0].set_title('Best 20 and 10'+'%'+' of likelihood at most likely H2, Te, ne\nnH=%.3gnH2+ +%.3gnH- +%.3g, R2=%.3g' %(sol_line.x[0],sol_line.x[1],sol_line.x[2],R2_sol_line))
											ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											ax[plot_index,0].set_zlabel('Log10 nH_ne')
											# ax[plot_index,1].remove()
											# ax[plot_index,1]=fig.add_subplot(7,2,10,projection='3d')
											# nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values,indexing='ij')
											# nH_ne_values_full = np.zeros_like(nHm_ne_values_full)
											# specific_prob = np.zeros_like(nHm_ne_values_full)
											# temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											# temp[temp<1e-100]=1e-100
											# for im,nHm_ne in enumerate(nHm_ne_values):
											# 	for i2p,nH2p_ne in enumerate(nH2p_ne_values):
											# 		calc = parabola_3D(nH2p_ne,nHm_ne,*sol_parab.x)
											# 		nH_ne_values_full[im,i2p] = max(calc,np.min(nH_ne_values))
											# 		iH = np.abs(nH_ne_values-calc).argmin()
											# 		specific_prob[im,i2p]=temp[iH,im,i2p]
											# my_col = cm.rainbow(specific_prob/np.max(specific_prob)*255,alpha=0.5)
											# # surf = ax[plot_index,1].plot_surface(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full), facecolors=my_col,linewidth=1,rstride=1,cstride=1, antialiased=False,alpha=0.5)
											# ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y')
											# ax[plot_index,1].plot(np.log10(nH2p_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],np.log10(nHm_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],np.log10(nH_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],'go', zorder = 0.6)
											# nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2p_ne_values,indexing='ij')
											# ax[plot_index,1].plot(np.log10(nH2p_ne_values_full)[temp>np.exp(max_likelihood_log_prob)*0.8],np.log10(nHm_ne_values_full)[temp>np.exp(max_likelihood_log_prob)*0.8],np.log10(nH_ne_values_full)[temp>np.exp(max_likelihood_log_prob)*0.8],'k+', zorder = 0.5)
											# ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											# ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,1].view_init(elev=60,azim=45)
											# ax[plot_index,1].set_title('Best 20'+'%'+' of likelihood at most likely H2, Te, ne\nnH=%.3gnH2+^2 +%.3gnH2+ +%.3gnH-^2 +%.3gnH- +%.3g, R2=%.3g' %(sol_parab.x[0],sol_parab.x[1],sol_parab.x[2],sol_parab.x[3],sol_parab.x[4],R2_sol_parab))
											# ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											# ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											# ax[plot_index,1].set_zlabel('Log10 nH_ne')

											# ax[plot_index,0].remove()
											# ax[plot_index,0]=fig.add_subplot(7,2,11,projection='3d')
											# nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values,indexing='ij')
											# nH_ne_values_full = np.zeros_like(nHm_ne_values_full)
											# specific_prob = np.zeros_like(nHm_ne_values_full)
											# temp = np.exp(marginalised_likelihood_log_probs)
											# temp[temp<1e-100]=1e-100
											# for im,nHm_ne in enumerate(nHm_ne_values):
											# 	for i2p,nH2p_ne in enumerate(nH2p_ne_values):
											# 		calc = line_3D(nH2p_ne,nHm_ne,*marginalised_sol_line.x)
											# 		nH_ne_values_full[im,i2p] = max(calc,np.min(nH_ne_values))
											# 		iH = np.abs(nH_ne_values-calc).argmin()
											# 		specific_prob[im,i2p]=temp[iH,im,i2p]
											# my_col = cm.rainbow(specific_prob/np.max(specific_prob)*255,alpha=0.5)
											# # surf = ax[plot_index,0].plot_surface(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full), facecolors=my_col,linewidth=1,rstride=1,cstride=1, antialiased=False,alpha=0.5)
											# ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y')
											# ax[plot_index,0].plot(np.log10(nH2p_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],np.log10(nHm_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],np.log10(nH_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],'go', zorder = 0.6)
											# nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2p_ne_values,indexing='ij')
											# ax[plot_index,0].plot(np.log10(nH2p_ne_values_full)[temp>np.max(temp)/1.2],np.log10(nHm_ne_values_full)[temp>np.max(temp)/1.2],np.log10(nH_ne_values_full)[temp>np.max(temp)/1.2],'k+', zorder = 0.5)
											# ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											# ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,0].view_init(elev=60)
											# ax[plot_index,0].set_title('Best 20'+'%'+' of marginalised likelihood\nnH=%.3gnH2+ +%.3gnH- +%.3g, R2=%.3g' %(marginalised_sol_line.x[0],marginalised_sol_line.x[1],marginalised_sol_line.x[2],R2_marginalised_sol_line))
											# ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											# ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											# ax[plot_index,0].set_zlabel('Log10 nH_ne')
											# ax[plot_index,1].remove()
											# ax[plot_index,1]=fig.add_subplot(7,2,12,projection='3d')
											# nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nHm_ne_values,nH2p_ne_values,indexing='ij')
											# nH_ne_values_full = np.zeros_like(nHm_ne_values_full)
											# specific_prob = np.zeros_like(nHm_ne_values_full)
											# temp = np.exp(marginalised_likelihood_log_probs)
											# temp[temp<1e-100]=1e-100
											# for im,nHm_ne in enumerate(nHm_ne_values):
											# 	for i2p,nH2p_ne in enumerate(nH2p_ne_values):
											# 		calc = parabola_3D(nH2p_ne,nHm_ne,*marginalised_sol_parab.x)
											# 		nH_ne_values_full[im,i2p] = max(calc,np.min(nH_ne_values))
											# 		iH = np.abs(nH_ne_values-calc).argmin()
											# 		specific_prob[im,i2p]=temp[iH,im,i2p]
											# my_col = cm.rainbow(specific_prob/np.max(specific_prob)*255,alpha=0.5)
											# # surf = ax[plot_index,1].plot_surface(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full), facecolors=my_col,linewidth=1,rstride=1,cstride=1, antialiased=False,alpha=0.5, zorder = 0.5)
											# ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y')
											# ax[plot_index,1].plot(np.log10(nH2p_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],np.log10(nHm_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],np.log10(nH_ne_values_full)[specific_prob>np.max(specific_prob)/1.2],'go', zorder = 0.6)
											# nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2p_ne_values,indexing='ij')
											# ax[plot_index,1].plot(np.log10(nH2p_ne_values_full)[temp>np.max(temp)/1.2],np.log10(nHm_ne_values_full)[temp>np.max(temp)/1.2],np.log10(nH_ne_values_full)[temp>np.max(temp)/1.2],'k+', zorder = 0.5)
											# ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											# ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,1].view_init(elev=60,azim=45)
											# ax[plot_index,1].set_title('Best 20'+'%'+' of marginalised likelihood\nnH=%.3gnH2+^2 +%.3gnH2+ +%.3gnH-^2 +%.3gnH- +%.3g, R2=%.3g' %(marginalised_sol_parab.x[0],marginalised_sol_parab.x[1],marginalised_sol_parab.x[2],marginalised_sol_parab.x[3],marginalised_sol_parab.x[4],R2_marginalised_sol_parab))
											# ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											# ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											# ax[plot_index,1].set_zlabel('Log10 nH_ne')

											# H, Hm, H2, H2p, ne, Te
											# power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination = calc_power_balance_elements(most_likely_Te_value,most_likely_ne_value,reduced_sample[:,0],reduced_sample[:,1],reduced_sample[:,2],most_likely_nH2_ne_value,most_likely_T_Hp_value,most_likely_T_Hm_value,most_likely_T_H2p_value)
											# power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination = calc_power_balance_elements(most_likely_Te_value,most_likely_ne_value,nH_ne_values_full_temp[temp>=np.exp(max_likelihood_log_prob)*0.9],nHm_ne_values_full_temp[temp>=np.exp(max_likelihood_log_prob)*0.9],nH2p_ne_values_full_temp[temp>=np.exp(max_likelihood_log_prob)*0.9],most_likely_nH2_ne_value,most_likely_T_Hp_value,most_likely_T_Hm_value,most_likely_T_H2p_value)
											ax[plot_index,1].remove()
											ax[plot_index,1]=fig.add_subplot(7,2,10,projection='3d')
											ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											# scatter = ax[plot_index,1].scatter(np.log10(reduced_sample[:,2]),np.log10(reduced_sample[:,1]),np.log10(reduced_sample[:,0]), c=power_rad_excit, cmap='rainbow', zorder = 0.4)
											scatter = ax[plot_index,1].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_rad_excit[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,1]).set_label('Power [W]')
											ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											ax[plot_index,1].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,1].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,1].view_init(elev=60,azim=45)
											ax[plot_index,1].set_title('Radiative power sink due to H excitation')
											ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											ax[plot_index,1].set_zlabel('Log10 nH_ne')

											plot_index += 1
											ax[plot_index,0].remove()
											ax[plot_index,0]=fig.add_subplot(7,2,11,projection='3d')
											ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,0].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_rad_rec_bremm[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,0]).set_label('Power [W]')
											ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											ax[plot_index,0].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,0].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,0].view_init(elev=60,azim=45)
											ax[plot_index,0].set_title('Radiative power sink due to recombination and Bremsstrahlung')
											ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											ax[plot_index,0].set_zlabel('Log10 nH_ne')

											ax[plot_index,1].remove()
											ax[plot_index,1]=fig.add_subplot(7,2,12,projection='3d')
											ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,1].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_rad_mol[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,1]).set_label('Power [W]')
											ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											ax[plot_index,1].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,1].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,1].view_init(elev=60,azim=45)
											ax[plot_index,1].set_title('Radiative power sink due molecule induced H de-excitation')
											ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											ax[plot_index,1].set_zlabel('Log10 nH_ne')

											plot_index += 1
											ax[plot_index,0].remove()
											ax[plot_index,0]=fig.add_subplot(7,2,13,projection='3d')
											ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,0].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_via_ionisation[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,0]).set_label('Power [W]')
											ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											ax[plot_index,0].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,0].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,0].view_init(elev=60,azim=45)
											ax[plot_index,0].set_title('Power sink due to atomic ionisation')
											ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											ax[plot_index,0].set_zlabel('Log10 nH_ne')

											ax[plot_index,1].remove()
											ax[plot_index,1]=fig.add_subplot(7,2,14,projection='3d')
											ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,1].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_via_recombination[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,1]).set_label('Power [W]')
											ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											ax[plot_index,1].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,1].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,1].view_init(elev=60,azim=45)
											ax[plot_index,1].set_title('Power sink due to atomic recombination')
											ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											ax[plot_index,1].set_zlabel('Log10 nH_ne')


											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											fig, ax = plt.subplots( 2,2,figsize=(30, 20), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH2p_ne_value))
											plot_index = 0
											nH_ne_values_full,nHm_ne_values_full,nH2_ne_values_full,nH2p_ne_values_full,ne_values_full,Te_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2_ne_values,nH2p_ne_values,ne_values_array,Te_values_array,indexing='ij')	# H, Hm, H2, H2p, ne, Te
											fraction_of_max_prob_selected = 50000
											select = likelihood_log_probs>max_likelihood_log_prob-np.log(fraction_of_max_prob_selected)
											while np.sum(select)/10>50000:
												fraction_of_max_prob_selected*=0.9
												select = likelihood_log_probs>max_likelihood_log_prob-np.log(fraction_of_max_prob_selected)
											select = np.logical_and(likelihood_log_probs>max_likelihood_log_prob-np.log(fraction_of_max_prob_selected),np.random.random(np.shape(select))<0.1)
											temp_prob = np.exp(likelihood_log_probs[select])
											max_temp_prob = np.max(temp_prob)
											nH_ne_values_full = nH_ne_values_full[select]
											nHm_ne_values_full = nHm_ne_values_full[select]
											nH2_ne_values_full = nH2_ne_values_full[select]
											nH2p_ne_values_full = nH2p_ne_values_full[select]
											Te_values_full = Te_values_full[select]
											ne_values_full = ne_values_full[select]
											T_Hm_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full.flatten())))/eV_to_K	# K
											T_H2p_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full.flatten())))/eV_to_K	# K
											T_Hp_values_full = Te_values_full.flatten()/eV_to_K	# K
											# power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination = calc_power_balance_elements(Te_values_full,ne_values_full,nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full,nH2_ne_values_full,T_Hp_values_full,T_Hm_values_full,T_H2p_values_full)
											most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_power_rad_Hm,most_likely_power_rad_H2,most_likely_power_rad_H2p = calc_power_balance_elements(most_likely_Te_value,most_likely_ne_value,most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2p_ne_value,most_likely_nH2_ne_value,most_likely_T_Hp_value,most_likely_T_Hm_value,most_likely_T_H2p_value)
											most_likely_tot_rad_power = most_likely_power_rad_excit+most_likely_power_rad_rec_bremm+most_likely_power_rad_mol
											color = ['b', 'r', 'm', 'y', 'g', 'c', 'k', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']
											im = ax[plot_index,0].plot(tot_rad_power[select],100*temp_prob/max_temp_prob,color[5]+'+',label='tot_rad_power');
											im = ax[plot_index,0].plot(most_likely_tot_rad_power,100,color[5]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_excit[select],100*temp_prob/max_temp_prob,color[0]+'+',label='power_rad_excit');
											im = ax[plot_index,0].plot(most_likely_power_rad_excit,100,color[0]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_rec_bremm[select],100*temp_prob/max_temp_prob,color[1]+'+',label='power_rad_rec_bremm');
											im = ax[plot_index,0].plot(most_likely_power_rad_rec_bremm,100,color[1]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_mol[select],100*temp_prob/max_temp_prob,color[2]+'+',label='power_rad_mol');
											im = ax[plot_index,0].plot(most_likely_power_rad_mol,100,color[2]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_via_ionisation[select],100*temp_prob/max_temp_prob,color[3]+'+',label='power_via_ionisation');
											im = ax[plot_index,0].plot(most_likely_power_via_ionisation,100,color[3]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_via_recombination[select],100*temp_prob/max_temp_prob,color[4]+'+',label='power_via_recombination');
											im = ax[plot_index,0].plot(most_likely_power_via_recombination,100,color[4]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_Hm[select],100*temp_prob/max_temp_prob,color[5]+'+',label='power_rad_Hm');
											im = ax[plot_index,0].plot(most_likely_power_rad_Hm,100,color[5]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_H2[select],100*temp_prob/max_temp_prob,color[6]+'+',label='power_rad_H2');
											im = ax[plot_index,0].plot(most_likely_power_rad_H2,100,color[6]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_H2p[select],100*temp_prob/max_temp_prob,'+',color=color[7],label='power_rad_H2p');
											im = ax[plot_index,0].plot(most_likely_power_rad_H2p,100,'o',color=color[7],markersize=30,fillstyle='none');
											ax[plot_index,0].set_title('Power balance for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('Power [W/m3]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											ax[plot_index,0].grid()

											im = ax[plot_index,1].plot(Te_values_full,100*temp_prob/max_temp_prob,'+');
											im = ax[plot_index,1].plot(most_likely_Te_value,100,'o',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_Te_prof_multipulse_interp_crop_limited_restrict,100,'x',markersize=30);
											ax[plot_index,1].set_title('Te for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('temperature [eV]')
											# ax[plot_index,0].set_xscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											plot_index += 1
											im = ax[plot_index,0].plot(nH_ne_values_full,100*temp_prob/max_temp_prob,color[0]+'+',label='nH_ne');
											im = ax[plot_index,0].plot(centre_nH_ne,100,color[0]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH_ne_value,100,color[0]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(nHm_ne_values_full,100*temp_prob/max_temp_prob,color[1]+'+',label='nHm_ne');
											im = ax[plot_index,0].plot(most_likely_nHm_ne_value,100,color[1]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(nH2_ne_values_full,100*temp_prob/max_temp_prob,color[2]+'+',label='nH2_ne');
											im = ax[plot_index,0].plot(centre_nH2_ne,100,color[2]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH2_ne_value,100,color[2]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(nH2p_ne_values_full,100*temp_prob/max_temp_prob,color[3]+'+',label='nH2p_ne');
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,100,color[3]+'o',markersize=30,fillstyle='none');
											ax[plot_index,0].set_title('Relative densities for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML, X=central')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('[au]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											ax[plot_index,0].grid()

											im = ax[plot_index,1].plot(ne_values_full,100*temp_prob/max_temp_prob,'+');
											im = ax[plot_index,1].plot(most_likely_ne_value,100,'o',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20,100,'x',markersize=30);
											ax[plot_index,1].set_title('ne for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('density [#/m3]')
											# ax[plot_index,0].set_yscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								# Here I find an approximate value for the measurement precision
								def find_sigma(x,sigma):
									return x/sigma

								# to calculate the integral of the probability I need their width
								if False:	# logarithmic interval scaling
									d_nH_ne_values = np.array([*np.diff(np.log10(nH_ne_values[[0,1]])),*(np.diff(np.log10(nH_ne_values))[:-1]/2+np.diff(np.log10(nH_ne_values))[1:]/2),*np.diff(np.log10(nH_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH_ne_values[[0,-1]]))+np.diff(np.log10(nH_ne_values[[0,1]]))/2+np.diff(np.log10(nH_ne_values[[-2,-1]]))/2)
									d_nHm_ne_values = np.array([*np.diff(np.log10(nHm_ne_values[[0,1]])),*(np.diff(np.log10(nHm_ne_values))[:-1]/2+np.diff(np.log10(nHm_ne_values))[1:]/2),*np.diff(np.log10(nHm_ne_values[[-2,-1]]))])/(np.diff(np.log10(nHm_ne_values[[0,-1]]))+np.diff(np.log10(nHm_ne_values[[0,1]]))/2+np.diff(np.log10(nHm_ne_values[[-2,-1]]))/2)
									d_nH2_ne_values = np.array([*np.diff(np.log10(nH2_ne_values[[0,1]])),*(np.diff(np.log10(nH2_ne_values))[:-1]/2+np.diff(np.log10(nH2_ne_values))[1:]/2),*np.diff(np.log10(nH2_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2_ne_values[[0,-1]]))+np.diff(np.log10(nH2_ne_values[[0,1]]))/2+np.diff(np.log10(nH2_ne_values[[-2,-1]]))/2)
									d_nH2p_ne_values = np.array([*np.diff(np.log10(nH2p_ne_values[[0,1]])),*(np.diff(np.log10(nH2p_ne_values))[:-1]/2+np.diff(np.log10(nH2p_ne_values))[1:]/2),*np.diff(np.log10(nH2p_ne_values[[-2,-1]]))])/(np.diff(np.log10(nH2p_ne_values[[0,-1]]))+np.diff(np.log10(nH2p_ne_values[[0,1]]))/2+np.diff(np.log10(nH2p_ne_values[[-2,-1]]))/2)
								elif True:	# linear interval scaling
									d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])/(np.diff(nH_ne_values[[0,-1]])+np.diff(nH_ne_values[[0,1]])/2+np.diff(nH_ne_values[[-2,-1]])/2)
									d_nHm_ne_values = np.array([*np.diff(nHm_ne_values[[0,1]]),*(np.diff(nHm_ne_values)[:-1]/2+np.diff(nHm_ne_values)[1:]/2),*np.diff(nHm_ne_values[[-2,-1]])])/(np.diff(nHm_ne_values[[0,-1]])+np.diff(nHm_ne_values[[0,1]])/2+np.diff(nHm_ne_values[[-2,-1]])/2)
									d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])/(np.diff(nH2_ne_values[[0,-1]])+np.diff(nH2_ne_values[[0,1]])/2+np.diff(nH2_ne_values[[-2,-1]])/2)
									d_nH2p_ne_values = np.array([*np.diff(nH2p_ne_values[[0,1]]),*(np.diff(nH2p_ne_values)[:-1]/2+np.diff(nH2p_ne_values)[1:]/2),*np.diff(nH2p_ne_values[[-2,-1]])])/(np.diff(nH2p_ne_values[[0,-1]])+np.diff(nH2p_ne_values[[0,1]])/2+np.diff(nH2p_ne_values[[-2,-1]])/2)
								d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])/(np.diff(ne_values_array[[0,-1]])+np.diff(ne_values_array[[0,1]])/2+np.diff(ne_values_array[[-2,-1]])/2)
								d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])/(np.diff(Te_values_array[[0,-1]])+np.diff(Te_values_array[[0,1]])/2+np.diff(Te_values_array[[-2,-1]])/2)

								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,:]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,:]
								temp_2 = np.exp(temp_2+np.log(d_Te_values_array)-np.log(np.sum(np.exp(temp_2)*d_Te_values_array)))
								try:
									# sigma_Te_right = curve_fit(find_sigma,np.abs(Te_values[0,most_likely_Te_index:]-most_likely_Te_value),temp[most_likely_Te_index:],p0=[1])[0][0]#,sigma=np.abs(Te_values[0,most_likely_Te_index:]-most_likely_Te_value)/most_likely_Te_value+0.1)[0]
									sigma_Te_right = temp_2[most_likely_Te_index:]
									if np.sum(sigma_Te_right)<0.34:
										sigma_Te_right=0
									else:
										sigma_Te_right = np.abs(np.array([sum(sigma_Te_right[:_+1]) for _ in range(len(sigma_Te_right)) ])-0.34)
										sigma_Te_right = sigma_Te_right[1:].argmin()
										sigma_Te_right = -Te_values_array[most_likely_Te_index]+Te_values_array[most_likely_Te_index+1+sigma_Te_right]
								except:
									sigma_Te_right=0
								try:
									# sigma_Te_left = curve_fit(find_sigma,np.abs(Te_values[0,:most_likely_Te_index+1]-most_likely_Te_value),temp[:most_likely_Te_index+1],p0=[1])[0][0]#,sigma=np.abs(Te_values[0,:most_likely_Te_index+1]-most_likely_Te_value)/most_likely_Te_value+0.1)[0]
									sigma_Te_left = np.flip(temp_2[:most_likely_Te_index+1],axis=0)
									if np.sum(sigma_Te_left)<0.34:
										sigma_Te_left=0
									else:
										sigma_Te_left = np.abs(np.array([sum(sigma_Te_left[:_+1]) for _ in range(len(sigma_Te_left)) ])-0.34)
										sigma_Te_left = sigma_Te_left[1:].argmin()
										sigma_Te_left = Te_values_array[most_likely_Te_index]-Te_values_array[most_likely_Te_index-1-sigma_Te_left]
								except:
									sigma_Te_left=0
								sigma_Te = max(sigma_Te_right,sigma_Te_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,:,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,:,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_ne_values_array)-np.log(np.sum(np.exp(temp_2)*d_ne_values_array)))
								try:
									# sigma_ne_right = curve_fit(find_sigma,np.abs(ne_values[most_likely_ne_index:,0]-most_likely_ne_value),temp[most_likely_ne_index:],p0=[1])[0][0]#,sigma=np.abs(ne_values[most_likely_ne_index:,0]-most_likely_ne_value)/most_likely_ne_value+0.1)[0]
									sigma_ne_right = temp_2[most_likely_ne_index:]
									if np.sum(sigma_ne_right)<0.34:
										sigma_ne_right=0
									else:
										sigma_ne_right = np.abs(np.array([sum(sigma_ne_right[:_+1]) for _ in range(len(sigma_ne_right)) ])-0.34)
										sigma_ne_right = sigma_ne_right[1:].argmin()
										sigma_ne_right = -ne_values_array[most_likely_ne_index]+ne_values_array[most_likely_ne_index+1+sigma_ne_right]
								except:
									sigma_ne_right=0
								try:
									# sigma_ne_left = curve_fit(find_sigma,np.abs(ne_values[:most_likely_ne_index+1,0]-most_likely_ne_value),temp[:most_likely_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(ne_values[:most_likely_ne_index+1,0]-most_likely_ne_value)/most_likely_ne_value+0.1)[0]
									sigma_ne_left = np.flip(temp_2[:most_likely_ne_index+1],axis=0)
									if np.sum(sigma_ne_left)<0.34:
										sigma_ne_left=0
									else:
										sigma_ne_left = np.abs(np.array([sum(sigma_ne_left[:_+1]) for _ in range(len(sigma_ne_left)) ])-0.34)
										sigma_ne_left = sigma_ne_left[1:].argmin()
										sigma_ne_left = ne_values_array[most_likely_ne_index]-ne_values_array[most_likely_ne_index-1-sigma_ne_left]
								except:
									sigma_ne_left=0
								sigma_ne = max(sigma_ne_right,sigma_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nH2p_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nH2p_ne_values)))
								try:
									# sigma_nH2p_ne_right = curve_fit(find_sigma,np.abs(nH2p_ne_values[most_likely_nH2p_ne_index:]-most_likely_nH2p_ne_value),temp[most_likely_nH2p_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nH2p_ne_values[most_likely_nH2p_ne_index:]-most_likely_nH2p_ne_value)/most_likely_nH2p_ne_value+0.1)[0]
									sigma_nH2p_ne_right = temp_2[most_likely_nH2p_ne_index:]
									if np.sum(sigma_nH2p_ne_right)<0.34:
										sigma_nH2p_ne_right=0
									else:
										sigma_nH2p_ne_right = np.abs(np.array([sum(sigma_nH2p_ne_right[:_+1]) for _ in range(len(sigma_nH2p_ne_right)) ])-0.34)
										sigma_nH2p_ne_right = sigma_nH2p_ne_right[1:].argmin()
										sigma_nH2p_ne_right = -nH2p_ne_values[most_likely_nH2p_ne_index]+nH2p_ne_values[most_likely_nH2p_ne_index+1+sigma_nH2p_ne_right]
								except:
									sigma_nH2p_ne_right=0
								try:
									# sigma_nH2p_ne_left = curve_fit(find_sigma,np.abs(nH2p_ne_values[:most_likely_nH2p_ne_index+1]-most_likely_nH2p_ne_value),temp[:most_likely_nH2p_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nH2p_ne_values[:most_likely_nH2p_ne_index+1]-most_likely_nH2p_ne_value)/most_likely_nH2p_ne_value+0.1)[0]
									sigma_nH2p_ne_left = np.flip(temp_2[:most_likely_nH2p_ne_index+1],axis=0)
									if np.sum(sigma_nH2p_ne_left)<0.34:
										sigma_nH2p_ne_left=0
									else:
										sigma_nH2p_ne_left = np.abs(np.array([sum(sigma_nH2p_ne_left[:_+1]) for _ in range(len(sigma_nH2p_ne_left)) ])-0.34)
										sigma_nH2p_ne_left = sigma_nH2p_ne_left[1:].argmin()
										sigma_nH2p_ne_left = nH2p_ne_values[most_likely_nH2p_ne_index]-nH2p_ne_values[most_likely_nH2p_ne_index-1-sigma_nH2p_ne_left]
								except:
									sigma_nH2p_ne_left=0
								sigma_nH2p_ne = max(sigma_nH2p_ne_right,sigma_nH2p_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,:,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,:,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nH2_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nH2_ne_values)))
								try:
									# sigma_nH2_ne_right = curve_fit(find_sigma,np.abs(nH2_ne_values[most_likely_nH2_ne_index:]-most_likely_nH2_ne_value),temp[most_likely_nH2_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nH2_ne_values[most_likely_nH2_ne_index:]-most_likely_nH2_ne_value)/most_likely_nH2_ne_value+0.1)[0]
									sigma_nH2_ne_right = temp_2[most_likely_nH2_ne_index:]
									if np.sum(sigma_nH2_ne_right)<0.34:
										sigma_nH2_ne_right=0
									else:
										sigma_nH2_ne_right = np.abs(np.array([sum(sigma_nH2_ne_right[:_+1]) for _ in range(len(sigma_nH2_ne_right)) ])-0.34)
										sigma_nH2_ne_right = sigma_nH2_ne_right[1:].argmin()
										sigma_nH2_ne_right = -nH2_ne_values[most_likely_nH2_ne_index]+nH2_ne_values[most_likely_nH2_ne_index+1+sigma_nH2_ne_right]
								except:
									sigma_nH2_ne_right=0
								try:
									# sigma_nH2_ne_left = curve_fit(find_sigma,np.abs(nH2_ne_values[:most_likely_nH2_ne_index+1]-most_likely_nH2_ne_value),temp[:most_likely_nH2_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nH2_ne_values[:most_likely_nH2_ne_index+1]-most_likely_nH2_ne_value)/most_likely_nH2_ne_value+0.1)[0]
									sigma_nH2_ne_left = np.flip(temp_2[:most_likely_nH2_ne_index+1],axis=0)
									if np.sum(sigma_nH2_ne_left)<0.34:
										sigma_nH2_ne_left=0
									else:
										sigma_nH2_ne_left = np.abs(np.array([sum(sigma_nH2_ne_left[:_+1]) for _ in range(len(sigma_nH2_ne_left)) ])-0.34)
										sigma_nH2_ne_left = sigma_nH2_ne_left[1:].argmin()
										sigma_nH2_ne_left = nH2_ne_values[most_likely_nH2_ne_index]-nH2_ne_values[most_likely_nH2_ne_index-1-sigma_nH2_ne_left]
								except:
									sigma_nH2_ne_left=0
								sigma_nH2_ne = max(sigma_nH2_ne_right,sigma_nH2_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nHm_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nHm_ne_values)))
								try:
									# sigma_nHm_ne_right = curve_fit(find_sigma,np.abs(nHm_ne_values[most_likely_nHm_ne_index:]-most_likely_nHm_ne_value),temp[most_likely_nHm_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nHm_ne_values[most_likely_nHm_ne_index:]-most_likely_nHm_ne_value)/most_likely_nHm_ne_value+0.1)[0]
									sigma_nHm_ne_right = temp_2[most_likely_nHm_ne_index:]
									if np.sum(sigma_nHm_ne_right)<0.34:
										sigma_nHm_ne_right=0
									else:
										sigma_nHm_ne_right = np.abs(np.array([sum(sigma_nHm_ne_right[:_+1]) for _ in range(len(sigma_nHm_ne_right)) ])-0.34)
										sigma_nHm_ne_right = sigma_nHm_ne_right[1:].argmin()
										sigma_nHm_ne_right = -nHm_ne_values[most_likely_nHm_ne_index]+nHm_ne_values[most_likely_nHm_ne_index+1+sigma_nHm_ne_right]
								except:
									sigma_nHm_ne_right=0
								try:
									# sigma_nHm_ne_left = curve_fit(find_sigma,np.abs(nHm_ne_values[:most_likely_nHm_ne_index+1]-most_likely_nHm_ne_value),temp[:most_likely_nHm_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nHm_ne_values[:most_likely_nHm_ne_index+1]-most_likely_nHm_ne_value)/most_likely_nHm_ne_value+0.1)[0]
									sigma_nHm_ne_left = np.flip(temp_2[:most_likely_nHm_ne_index+1],axis=0)
									if np.sum(sigma_nHm_ne_left)<0.34:
										sigma_nHm_ne_left=0
									else:
										sigma_nHm_ne_left = np.abs(np.array([sum(sigma_nHm_ne_left[:_+1]) for _ in range(len(sigma_nHm_ne_left)) ])-0.34)
										sigma_nHm_ne_left = sigma_nHm_ne_left[1:].argmin()
										sigma_nHm_ne_left = nHm_ne_values[most_likely_nHm_ne_index]-nHm_ne_values[most_likely_nHm_ne_index-1-sigma_nHm_ne_left]
								except:
									sigma_nHm_ne_left=0
								sigma_nHm_ne = max(sigma_nHm_ne_right,sigma_nHm_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nH_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nH_ne_values)))
								try:
									# sigma_nH_ne_right = curve_fit(find_sigma,np.abs(nH_ne_values[most_likely_nH_ne_index:]-most_likely_nH_ne_value),temp[most_likely_nH_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nH_ne_values[most_likely_nH_ne_index:]-most_likely_nH_ne_value)/most_likely_nH_ne_value+0.1)[0]
									sigma_nH_ne_right = temp_2[most_likely_nH_ne_index:]
									if np.sum(sigma_nH_ne_right)<0.34:
										sigma_nH_ne_right=0
									else:
										sigma_nH_ne_right = np.abs(np.array([sum(sigma_nH_ne_right[:_+1]) for _ in range(len(sigma_nH_ne_right)) ])-0.34)
										sigma_nH_ne_right = sigma_nH_ne_right[1:].argmin()
										sigma_nH_ne_right = -nH_ne_values[most_likely_nH_ne_index]+nH_ne_values[most_likely_nH_ne_index+1+sigma_nH_ne_right]
								except:
									sigma_nH_ne_right=0
								try:
									# sigma_nH_ne_left = curve_fit(find_sigma,np.abs(nH_ne_values[:most_likely_nH_ne_index+1]-most_likely_nH_ne_value),temp[:most_likely_nH_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nH_ne_values[:most_likely_nH_ne_index+1]-most_likely_nH_ne_value)/most_likely_nH_ne_value+0.1)[0][0]
									sigma_nH_ne_left = np.flip(temp_2[:most_likely_nH_ne_index+1],axis=0)
									if np.sum(sigma_nH_ne_left)<0.34:
										sigma_nH_ne_left=0
									else:
										sigma_nH_ne_left = np.abs(np.array([sum(sigma_nH_ne_left[:_+1]) for _ in range(len(sigma_nH_ne_left)) ])-0.34)
										sigma_nH_ne_left = sigma_nH_ne_left[1:].argmin()
										sigma_nH_ne_left = nH_ne_values[most_likely_nH_ne_index]-nH_ne_values[most_likely_nH_ne_index-1-sigma_nH_ne_left]
								except:
									sigma_nH_ne_left=0
								sigma_nH_ne = max(sigma_nH_ne_right,sigma_nH_ne_left)
								sigma_nHp_ne = (1+most_likely_nHm_ne_value-most_likely_nH2p_ne_value-0)*((sigma_nHm_ne)**2+(sigma_nH2p_ne)**2)**0.5
								sigma_nH3p_ne = 0

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											fig, ax = plt.subplots( 2,2,figsize=(30, 20), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH2p_ne_value))
											plot_index = 0
											color = ['b', 'r', 'm', 'y', 'g', 'c', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_excit.tolist()*2)[1:-1],100*np.array([prob_power_rad_excit.tolist()]*2).T.flatten(),color=color[0],label='power_rad_excit');
											im = ax[plot_index,0].plot(actual_values_power_rad_excit,100*prob_power_rad_excit,'+',color=color[0],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_excit,100,color[0]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_rec_bremm.tolist()*2)[1:-1],100*np.array([prob_power_rad_rec_bremm.tolist()]*2).T.flatten(),color=color[1],label='power_rad_rec_bremm');
											im = ax[plot_index,0].plot(actual_values_power_rad_rec_bremm,100*prob_power_rad_rec_bremm,'+',color=color[1],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_rec_bremm,100,color[1]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_mol.tolist()*2)[1:-1],100*np.array([prob_power_rad_mol.tolist()]*2).T.flatten(),color=color[2],label='power_rad_mol');
											im = ax[plot_index,0].plot(actual_values_power_rad_mol,100*prob_power_rad_mol,'+',color=color[2],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_mol,100,color[2]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_via_ionisation.tolist()*2)[1:-1],100*np.array([prob_power_via_ionisation.tolist()]*2).T.flatten(),color=color[3],label='power_via_ionisation');
											im = ax[plot_index,0].plot(actual_values_power_via_ionisation,100*prob_power_via_ionisation,'+',color=color[3],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_via_ionisation,100,color[3]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_via_recombination.tolist()*2)[1:-1],100*np.array([prob_power_via_recombination.tolist()]*2).T.flatten(),color=color[4],label='power_via_recombination');
											im = ax[plot_index,0].plot(actual_values_power_via_recombination,100*prob_power_via_recombination,'+',color=color[4],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_via_recombination,100,color[4]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_tot_rad_power.tolist()*2)[1:-1],100*np.array([prob_tot_rad_power.tolist()]*2).T.flatten(),color=color[5],label='tot_rad_power');
											im = ax[plot_index,0].plot(actual_values_tot_rad_power,100*prob_tot_rad_power,'+',color=color[5],markersize=5);
											im = ax[plot_index,0].plot(most_likely_tot_rad_power,100,color[5]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_Hm.tolist()*2)[1:-1],100*np.array([prob_power_rad_Hm.tolist()]*2).T.flatten(),color=color[6],label='power_rad_Hm');
											im = ax[plot_index,0].plot(actual_values_power_rad_Hm,100*prob_power_rad_Hm,'+',color=color[6],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_Hm,100,'o',color=color[6],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_H2.tolist()*2)[1:-1],100*np.array([prob_power_rad_H2.tolist()]*2).T.flatten(),color=color[7],label='power_rad_H2');
											im = ax[plot_index,0].plot(actual_values_power_rad_H2,100*prob_power_rad_H2,'+',color=color[7],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_H2,100,'o',color=color[7],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_H2p.tolist()*2)[1:-1],100*np.array([prob_power_rad_H2p.tolist()]*2).T.flatten(),color=color[8],label='power_rad_H2p');
											im = ax[plot_index,0].plot(actual_values_power_rad_H2p,100*prob_power_rad_H2p,'+',color=color[8],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_H2p,100,'o',color=color[8],markersize=10,fillstyle='none');
											ax[plot_index,0].set_title('Power balance PDF, prob times volume below %.3g of peak neglected, O=ML' %(min_fraction_of_prob_considered))
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('Power [W/m3]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											# ax[plot_index,0].set_xlim(left=1e-1*np.min([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power]))
											ax[plot_index,0].set_xlim(left=min(100,1e-1*np.min([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power])),right=1e2*np.max([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power]))
											ax[plot_index,0].grid()

											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,:]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,1].plot(Te_values_array,100*temp_2);
											im = ax[plot_index,1].plot(most_likely_Te_value,100,'ko',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_Te_prof_multipulse_interp_crop_limited_restrict,100,'kx',markersize=30);
											im = ax[plot_index,1].plot(Te_values_array,100*np.exp(Te_log_probs)/np.sum(np.exp(Te_log_probs)),':');
											im = ax[plot_index,1].plot([most_likely_Te_value-sigma_Te_left,most_likely_Te_value-sigma_Te_left],[0,100],'k--');
											im = ax[plot_index,1].plot([most_likely_Te_value+sigma_Te_right,most_likely_Te_value+sigma_Te_right],[0,100],'k--');
											im = ax[plot_index,1].plot([np.min(Te_values_limits),np.min(Te_values_limits)],[0,100],'y--');
											im = ax[plot_index,1].plot([np.max(Te_values_limits),np.max(Te_values_limits)],[0,100],'y--');
											ax[plot_index,1].set_title('Te at highest likelihood with precision\n :=prior, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('temperature [eV]')
											# ax[plot_index,0].set_xscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											plot_index += 1
											temp_2 = likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(nH_ne_values,100*temp_2,color[0],label='nH_ne');
											im = ax[plot_index,0].plot(centre_nH_ne,100,color[0]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH_ne_value,100,color[0]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nH_ne_value-sigma_nH_ne_left,most_likely_nH_ne_value-sigma_nH_ne_left],[0,100],color[0]+'--');
											im = ax[plot_index,0].plot([most_likely_nH_ne_value+sigma_nH_ne_right,most_likely_nH_ne_value+sigma_nH_ne_right],[0,100],color[0]+'--');
											im = ax[plot_index,0].plot(nH_ne_values,100*np.exp(nH_ne_log_probs)/np.sum(np.exp(nH_ne_log_probs)),color[0]+':');
											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(nHm_ne_values,100*temp_2,color[1],label='nHm_ne');
											im = ax[plot_index,0].plot(most_likely_nHm_ne_value,100,color[1]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nHm_ne_value-sigma_nHm_ne_left,most_likely_nHm_ne_value-sigma_nHm_ne_left],[0,100],color[1]+'--');
											im = ax[plot_index,0].plot([most_likely_nHm_ne_value+sigma_nHm_ne_right,most_likely_nHm_ne_value+sigma_nHm_ne_right],[0,100],color[1]+'--');
											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,:,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(nH2_ne_values,100*temp_2,color[2],label='nH2_ne');
											im = ax[plot_index,0].plot(centre_nH2_ne,100,color[2]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH2_ne_value,100,color[2]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nH2_ne_value-sigma_nH2_ne_left,most_likely_nH2_ne_value-sigma_nH2_ne_left],[0,100],color[2]+'--');
											im = ax[plot_index,0].plot([most_likely_nH2_ne_value+sigma_nH2_ne_right,most_likely_nH2_ne_value+sigma_nH2_ne_right],[0,100],color[2]+'--');
											im = ax[plot_index,0].plot(nH2_ne_values,100*np.exp(nH2_ne_log_probs)/np.sum(np.exp(nH2_ne_log_probs)),color[2]+':');
											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(nH2p_ne_values,100*temp_2,color[3],label='nH2p_ne');
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,100,color[3]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nH2p_ne_value-sigma_nH2p_ne_left,most_likely_nH2p_ne_value-sigma_nH2p_ne_left],[0,100],color[3]+'--');
											im = ax[plot_index,0].plot([most_likely_nH2p_ne_value+sigma_nH2p_ne_right,most_likely_nH2p_ne_value+sigma_nH2p_ne_right],[0,100],color[3]+'--');
											ax[plot_index,0].set_title('Relative densities at highest likelihood with precision\n :=prior, O=ML, X=central')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('[au]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											ax[plot_index,0].grid()

											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,:,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,1].plot(ne_values_array,100*temp_2);
											im = ax[plot_index,1].plot(most_likely_ne_value,100,'ko',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20,100,'kx',markersize=30);
											im = ax[plot_index,1].plot(ne_values_array,100*np.exp(ne_log_probs)/np.sum(np.exp(ne_log_probs)),':');
											im = ax[plot_index,1].plot([most_likely_ne_value-sigma_ne_left,most_likely_ne_value-sigma_ne_left],[0,100],'k--');
											im = ax[plot_index,1].plot([most_likely_ne_value+sigma_ne_right,most_likely_ne_value+sigma_ne_right],[0,100],'k--');ne_values_limits
											im = ax[plot_index,1].plot([np.min(ne_values_limits),np.min(ne_values_limits)],[0,100],'y--');
											im = ax[plot_index,1].plot([np.max(ne_values_limits),np.max(ne_values_limits)],[0,100],'y--');
											ax[plot_index,1].set_title('ne at highest likelihood with precision\n :=prior, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('density [#/m3]')
											# ax[plot_index,0].set_yscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')

								# I add this because I want to see how Halpha works
								n_list_all_full = np.array([3]+np.array(n_list_all).tolist())
								multiplicative_factor_full = energy_difference_full[n_list_all_full - 2] * einstein_coeff_full[n_list_all_full - 2] / J_to_eV


								excitation_full = []
								for isel in (np.array(n_list_all_full)-2):
									temp = read_adf15(pecfile, isel, most_likely_Te_value,most_likely_ne_value * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									excitation_full.append(temp)
								excitation_full = np.array(excitation_full).flatten()  # in # photons cm^-3 s^-1
								excitation_full = (excitation_full * (10 ** -6) * (energy_difference_full[n_list_all_full - 2] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

								recombination_full = []
								for isel in (np.array(n_list_all_full)+16):
									temp = read_adf15(pecfile, isel, most_likely_Te_value,most_likely_ne_value * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									recombination_full.append(temp)
								recombination_full = np.array(recombination_full).flatten()  # in # photons cm^-3 s^-1 / (# cm^-3)**2
								recombination_full = (recombination_full * (10 ** -6) * (energy_difference_full[n_list_all_full - 2] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2


								def fit_Yacora_pop_coeff(ne,Te,T_Hp,T_Hm,T_H2p,multiplicative_factor,excitation_restrict,recombination_restrict):
									def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
										# I add this because I want to see how Halpha works
										# nHp_ne=1+nHm_ne-nH2p_ne-nH3p_ne
										multiplicative_factor = energy_difference_full[n_list_all - 2] * einstein_coeff_full[n_list_all - 2] / J_to_eV
										total = np.array([(excitation_full[n_list_all - 3] *  nH_ne /multiplicative_factor).astype('float')])
										total += np.array([(recombination_full[n_list_all - 3] * nHp_ne /multiplicative_factor).astype('float')])
										# total = nH_ne*From_H_pop_coeff_full([[Te,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
										# total += nHp_ne*From_Hp_pop_coeff_full([[Te,ne]],n_list_all)
										total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[Te,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full_extra([[Te,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
										total += nH2_ne*From_H2_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total += nH2p_ne*From_H2p_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total += nH3p_ne*From_H3p_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total = total[0]*(ne ** 2)*multiplicative_factor
										# print(total)
										return np.log(total)
									return calculated_emission

								nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = most_likely_nH_ne_value,1+most_likely_nHm_ne_value-most_likely_nH2p_ne_value-0,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value,0
								# nH_ne_sigma, nHp_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = 1,1,1,1,1,1
								# residuals = np.sum(((np.log(inverted_profiles_crop_restrict) - fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, *fit[0]))) ** 2)
								residuals = np.sum(((inverted_profiles_crop_restrict - np.exp(fit_Yacora_pop_coeff(most_likely_ne_value,most_likely_Te_value,T_Hp,T_Hm,T_H2p,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne)))/inverted_profiles_crop_sigma_restrict) ** 2)

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											plt.figure(figsize=(20, 10))
											# nH_ne, nHp_ne, nH2p_ne = fit[0]
											# nHp_ne = 1 + nHm_ne - nH2p_ne
											plt.errorbar(n_list_all,inverted_profiles_crop_restrict,yerr=inverted_profiles_crop_sigma_restrict,label='OES')
											plt.plot(n_list_all_full,(excitation_full *  nH_ne).astype('float')*(most_likely_ne_value ** 2),label='direct excitation\nH(q) + e-  H(p>q) + e- (ADAS coeff)')
											plt.plot(n_list_all_full,(recombination_full * nHp_ne).astype('float')*(most_likely_ne_value ** 2),label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e- (ADAS coeff)')
											# plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[most_likely_Te_value,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
											# plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[most_likely_Te_value,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
											plt.plot(n_list_all_full,nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[most_likely_Te_value,T_Hp,T_Hm,most_likely_ne_value,nHp_ne*most_likely_ne_value]],n_list_all_full) )[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H+ mutual neutralisation\nH+ + H-  H(p) + H')
											plt.plot(n_list_all_full,nHm_ne*( From_Hn_with_H2p_pop_coeff_full_extra([[most_likely_Te_value,T_H2p,T_Hm,most_likely_ne_value,nH2p_ne*most_likely_ne_value]],n_list_all_full) )[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2+ mutual neutralisation\nH2+ + H-  H(p) + H2')
											plt.plot(n_list_all_full,nH2_ne*From_H2_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
											plt.plot(n_list_all_full,nH2p_ne*From_H2p_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
											plt.plot(n_list_all_full,nH3p_ne*From_H3p_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
											temp = np.exp(fit_Yacora_pop_coeff(most_likely_ne_value,most_likely_Te_value,T_Hp,T_Hm,T_H2p,multiplicative_factor_full,excitation_restrict,recombination_restrict)(n_list_all_full, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne))
											plt.plot(n_list_all_full,temp,'--',label='total fit')
											plt.plot(n_list_all_full,((excitation_full *  nH_ne).astype('float')*(most_likely_ne_value ** 2) + (recombination_full * nHp_ne).astype('float')*(most_likely_ne_value ** 2)),'+',label='excitation + recombination')
											plt.semilogy()
											plt.legend(loc='best', fontsize='x-small')
											plt.ylim(np.min(inverted_profiles_crop_restrict)/2,max(np.max(inverted_profiles_crop_restrict)*2,np.max(temp)))
											plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g+/-%.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value,sigma_Te) + '%.3g(ML %.3g+/-%.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20,sigma_ne*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g+/-%.3g, ' %(nH_ne,sigma_nH_ne) + '%.3g+/-%.3g, ' %(nHp_ne,sigma_nHp_ne)+ '%.3g+/-%.3g, ' %(nHm_ne,sigma_nHm_ne)+ '%.3g+/-%.3g, ' %(nH2_ne,sigma_nH2_ne)+ '%.3g+/-%.3g, ' %(nH2p_ne,sigma_nH2p_ne)+ '%.3g+/-%.3g]' %(nH3p_ne,sigma_nH3p_ne) +'\nH ionization length %.3gm' % ionization_length_H +'\nH2 ionization length %.3gm' % ionization_length_H2)
											plt.xlabel('Exctited state n')
											plt.ylabel('Line emissivity n->2 [W m^-3]')
											# plt.pause(0.01)
											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')

								end_time = tm.time()
								time_spent = end_time-start_time

								sgna =999 ;print('worker '+str(current_process())+' marker '+str(sgna)+' '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_spent/60),int(time_spent%60)))
								results = [nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne,residuals,most_likely_Te_value,most_likely_ne_value*1e-20,sigma_Te,sigma_ne,sigma_nH_ne,sigma_nHp_ne,sigma_nHm_ne,sigma_nH2_ne,sigma_nH2p_ne,sigma_nH3p_ne,False,power_balance_data]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
								try:
									del build_log_PDF,find_correlation,find_sigma,fit_Yacora_pop_coeff
								except:
									try:
										del build_log_PDF,find_sigma,fit_Yacora_pop_coeff
									except:
										del find_sigma,fit_Yacora_pop_coeff
							except Exception as e:
								results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
								print('child multiprocessor terminated with error '+str(e)+'worker '+str(current_process())+' '+str(domain_index)+' t=%.3g, r=%.3g' %(my_time_pos,my_r_pos))
							return output

						def calc_stuff_2(arg):
							try:
								domain_index = arg[0]
								sgna = 0;print('worker '+str(current_process())+' marker '+str(sgna)+' '+str(domain_index))
								my_time_pos = arg[1]
								my_r_pos = arg[2]
								pass_index = arg[3]
								guess = arg[4]
								ionization_length_H = arg[5]
								# ionization_length_Hm = arg[6]
								ionization_length_H2 = arg[6]
								# ionization_length_H2p = arg[8]
								to_print = arg[7]

								inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								inverted_profiles_crop_sigma_restrict = inverted_profiles_sigma_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop[my_time_pos, my_r_pos]
								merge_dne_prof_multipulse_interp_crop_limited_restrict = max(merge_dne_prof_multipulse_interp_crop[my_time_pos, my_r_pos],0.1)
								merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop[my_time_pos, my_r_pos]
								merge_dTe_prof_multipulse_interp_crop_limited_restrict = max(merge_dTe_prof_multipulse_interp_crop[my_time_pos, my_r_pos],0.1)
								recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
								excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()
								max_frac_acceptable_deviation = max_frac_acceptable_deviation_ext

								if pass_index<=1:
									if (merge_ne_prof_multipulse_interp_crop_limited_restrict < 5e-07 or merge_Te_prof_multipulse_interp_crop_limited_restrict < 0.1):
										print('worker '+str(current_process())+' marker 999 '+str(domain_index)+' my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped ne %.3g, Te %.3g' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict))
										results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output
								else:
									if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										print('worker '+str(current_process())+' marker 999 '+str(domain_index)+' my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped ne %.3g, Te %.3g' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict))
										results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output

								start_time = tm.time()
								print('worker '+str(current_process())+' actually running '+str(domain_index))
								# if np.sum(inverted_profiles_crop_restrict == 0)>2:
								# 	continue

								if False:
									T_Hp = 12000	# K
									T_Hm = 12000	# K
									T_H2p = 5000	# K
								else:
									T_Hp = merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K	# K
									T_Hm = np.exp(TH2_fit_from_simulations(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))/eV_to_K	# K
									T_H2p = np.exp(TH2_fit_from_simulations(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))/eV_to_K	# K
								ne = merge_ne_prof_multipulse_interp_crop_limited_restrict * 1e20
								multiplicative_factor = energy_difference[n_list_all - 4] * einstein_coeff[n_list_all - 4] / J_to_eV
								if merge_ne_prof_multipulse_interp_crop_limited_restrict>2:
									min_mol_fraction = min_mol_fraction_ext/10
								else:
									min_mol_fraction = min_mol_fraction_ext


								if False:	# pre 21/05/2020
									max_nH2_from_pressure_int = max_nH2_from_pressure_all[my_time_pos]
									if ionization_length_H<=0.5:
										max_nmolecules_ne_low_ionisation_length = 0.05
										max_nH2_from_pressure_int = ne/10
									else:
										max_nmolecules_ne_low_ionisation_length = 0.15
										max_nH2_from_pressure_int = max_nH2_from_pressure*1
								elif False:	# post 21/05/2020
									max_nH2_from_pressure_int = nH2_from_pressure*max((1-np.sum(dr/ionization_length_H[my_time_pos, my_r_pos:])*1e3),1e-6)	# H2 ionisation 3-4 order stronger than H
									max_nmolecules_ne_low_ionisation_length = nH2_from_pressure*ionization_length_H[my_time_pos, my_r_pos]*1e-3*min(np.sum(dr/ionization_length_H[my_time_pos, my_r_pos:])*1e3,1)	# H2 ionisation 3-4 order stronger than H
									# if ionization_length_H[my_time_pos, my_r_pos]<=0.5:
									# 	max_nmolecules_ne_low_ionisation_length = 10*nH2_from_pressure/ne*300/(max(merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K,300))
									# else:
									# 	max_nmolecules_ne_low_ionisation_length = nH2_from_pressure
								elif True:	# this is after analysis of Ray simulations with B2.5-Eunomia
									max_nH2_ne = np.max(nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict))*20
									min_nH2_ne = np.min(nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict))/5
									centre_nH2_ne = nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict)
									# limit_H_H2_up = interpolate.interp1d([0.1,0.2,4],[100,20,20],fill_value='extrapolate')
									# limit_H_H2_down = interpolate.interp1d([0.1,2,4],[10,0.03,0.03],fill_value='extrapolate')
									# limit_H_H2_up = np.exp(limit_H_H2_up(np.log(min(merge_Te_prof_multipulse_interp_crop_limited_restrict-merge_dTe_prof_multipulse_interp_crop_limited_restrict,0.1))))
									# limit_H_H2_down = np.exp(limit_H_H2_down(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict+merge_dTe_prof_multipulse_interp_crop_limited_restrict)))
									# max_nH_ne = min(limit_H_H2_up-min_nH2_ne,20)
									# min_nH_ne = max(limit_H_H2_down-max_nH2_ne,3e-2)
									max_nH_ne = np.exp(limit_H_up(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))
									min_nH_ne = np.exp(limit_H_down(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))
									centre_nH_ne = nH_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict)


								# if pass_index>1:
								# 	if ionization_length_H2<1e-6:
								# 		max_nH2_from_pressure_int = ne/100000

								# TS_steps = 11
								TS_Te_steps = 13	# 13, 15
								TS_Te_steps_increase = 5
								TS_ne_steps = 13	# 17, 19
								TS_ne_steps_increase = 6
								if collect_power_PDF:
									to_find_steps = 11	# 25/21
								else:
									to_find_steps = 11	# 25/21
								H_steps = 13	# this MUST be odd		# 23/13, 15
								H2_steps = 13	# this MUST be odd		# 11/7
								# probability = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps))
								# guessed_values = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps))
								# calculated_emission = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,len(n_list_all)))
								# Te_values = np.linspace(max(np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])/2,merge_Te_prof_multipulse_interp_crop_limited_restrict-4*merge_dTe_prof_multipulse_interp_crop_limited_restrict),merge_Te_prof_multipulse_interp_crop_limited_restrict+4*merge_dTe_prof_multipulse_interp_crop_limited_restrict,TS_Te_steps)
								Te_values = np.linspace(max(merge_Te_prof_multipulse_interp_crop_limited_restrict-4*merge_dTe_prof_multipulse_interp_crop_limited_restrict,min(0.1,merge_Te_prof_multipulse_interp_crop_limited_restrict/2)),merge_Te_prof_multipulse_interp_crop_limited_restrict+4*merge_dTe_prof_multipulse_interp_crop_limited_restrict,TS_Te_steps)
								# if pass_index<=1:
								# 	Te_values[Te_values<0.1]=0.1
								# else:
								# Te_values[Te_values<np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])/2]=np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])/2
								Te_values_array = np.unique(Te_values)
								Te_values_array_initial = np.array([0])
								# gauss = lambda x, A, sig, x0: A * np.exp(-(((x - x0) / sig) ** 2)/2)
								# Te_probs = gauss(np.linspace(-1,+1,TS_steps),1/((2*np.pi)**0.5),1,0)
								# Te_probs = Te_probs/np.sum(Te_probs)
								# # Te_probs = np.ones((TS_steps,TS_steps))*Te_probs

								# ne_values = ne+np.linspace(-2,+6,TS_ne_steps)*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20
								# ne_values = np.logspace(np.log10(max(ne-2*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20,1e20*np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])/10)),np.log10(ne+8*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20),num=TS_ne_steps)
								min_ne = max(ne-4*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20,min(0.3*1e20,ne/10))
								max_ne = ne+8*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20
								steps_left = np.ceil(1.5*(TS_ne_steps-1)*(ne-min_ne)/(max_ne-min_ne))
								steps_right = np.ceil(1/1.5*(TS_ne_steps-1)*(max_ne-ne)/(max_ne-min_ne))
								# ne_values = np.logspace(np.log10(max(ne-2*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20,min(0.05*1e20,ne/2))),np.log10(ne+8*merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20),num=TS_ne_steps)
								ne_values = [*np.logspace(np.log10(min_ne),np.log10(ne),num=steps_left+1),*np.logspace(np.log10(ne),np.log10(max_ne),num=steps_right+1)]
								ne_values = np.unique(ne_values)
								ne_values_array_initial = np.array([0])
								# if pass_index<=1:
								# 	ne_values[ne_values<5e13]=5e13
								# else:
								# ne_values[ne_values<1e20*np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])/4]=1e20*np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])/4
								ne_values_array = np.unique(ne_values)
								# ne_probs = gauss(np.linspace(-1,+1,TS_steps),1/((2*np.pi)**0.5),1,0)
								# ne_probs = ne_probs/np.sum(ne_probs)
								# # ne_probs = (np.ones((TS_steps,TS_steps))*ne_probs).T
								if False:
									# nHp_ne = np.logspace(np.log10(max_nHp_ne),np.log10(max(min_nHp_ne,0.01)),num=to_find_steps)	# this is 1 - nH2p_ne + nHm_ne
									nH_ne = np.logspace(np.log10(max_n_neutrals_ne),np.log10(max(min_nH_ne,0.1)),num=to_find_steps)
									# nHpolecule_ne = np.logspace(np.log10(max_nmolecules_ne_low_ionisation_length),np.log10(max_nmolecules_ne_low_ionisation_length/1000),num=to_find_steps)
									# nH2_ne = np.logspace(np.log10(max_nH2_from_pressure_int/ne),np.log10(max_nH2_from_pressure_int/10000/ne),num=to_find_steps)
									nHpolecule_ne = np.logspace(np.log10(10*max_nmolecules_ne_low_ionisation_length/ne),np.log10(max_nmolecules_ne_low_ionisation_length/1000/ne),num=to_find_steps)
									nH2_ne = np.logspace(np.log10(10*max_nH2_from_pressure_int/ne),np.log10(1e-3*max_nH2_from_pressure_int/ne),num=to_find_steps_H2)
								if True:	# this is after analysis of Ray simulations with B2.5-Eunomia
									# nH2_ne_values = np.array([min_nH2_ne,(centre_nH2_ne+2*min_nH2_ne)/3,(2*centre_nH2_ne+min_nH2_ne)/3,centre_nH2_ne,(2*centre_nH2_ne+max_nH2_ne)/3,(centre_nH2_ne+2*max_nH2_ne)/3,max_nH2_ne])
									# # nH2_ne_probs = gauss(np.linspace(-2,+2,5),1/((2*np.pi)**0.5),1,0)
									# # nH2_ne_probs = nH2_ne_probs/np.sum(nH2_ne_probs)
									# nH2_ne_log_probs = -0.5*(np.linspace(-2,+2,7)**2)
									H2_left_interval = np.logspace(np.log10(min_nH2_ne),np.log10(centre_nH2_ne),num=(H2_steps+1)/2)[:-1]
									H2_right_interval = np.logspace(np.log10(centre_nH2_ne),np.log10(max_nH2_ne),num=(H2_steps+1)/2)[1:]
									nH2_ne_values = np.array(H2_left_interval.tolist() + [centre_nH2_ne] + H2_right_interval.tolist())
									H2_left_interval_log_probs = -0.5*((np.log10(H2_left_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/min_nH2_ne)/2))**2)	# centre_nH2_ne-min_nH2_ne is 2 sigma
									H2_right_interval_log_probs = -0.5*((np.log10(H2_right_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/max_nH2_ne)/2))**2)	# centre_nH2_ne-max_nH2_ne is 2 sigma
									nH2_ne_log_probs = np.array(H2_left_interval_log_probs.tolist() + [0] + H2_right_interval_log_probs.tolist())
									nH2_ne_log_probs = nH2_ne_log_probs -np.log(np.sum(np.exp(nH2_ne_log_probs)))	# normalisation for logarithmic probabilities
									# nH_ne_probs = gauss(np.linspace(-2,+2,5),1/((2*np.pi)**0.5),1,0)
									# nH_ne_probs = nH_ne_probs/np.sum(nH_ne_probs)
									if False:	# known probability distribution for nH
										# nH_ne_values = np.array([min_nH_ne,(centre_nH_ne+3*min_nH_ne)/4,(2*centre_nH_ne+2*min_nH_ne)/4,(3*centre_nH_ne+min_nH_ne)/4,centre_nH_ne,(3*centre_nH_ne+max_nH_ne)/4,(2*centre_nH_ne+2*max_nH_ne)/4,(centre_nH_ne+3*max_nH_ne)/4,max_nH_ne])
										# nH_ne_log_probs = -0.5*(np.linspace(-2,+2,9)**2)
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=(H_steps-1))
										# H_left_interval = np.logspace(np.log10(min_nH_ne),np.log10(centre_nH_ne),num=(H_steps+1)/2)[:-1]
										# H_right_interval = np.logspace(np.log10(centre_nH_ne),np.log10(max_nH_ne),num=(H_steps+1)/2)[1:]
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										nH_ne_values = np.array(H_left_interval.tolist() + [centre_nH_ne] + H_right_interval.tolist())
										H_left_interval_log_probs = -(0.5*((np.log10(H_left_interval/centre_nH_ne)/(np.log10(centre_nH_ne/min_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-min_nH_ne is 3 sigma
										H_right_interval_log_probs = -(0.5*((np.log10(H_right_interval/centre_nH_ne)/(np.log10(centre_nH_ne/max_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-max_nH_ne is 3 sigma
										nH_ne_log_probs = np.array(H_left_interval_log_probs.tolist() + [0] + H_right_interval_log_probs.tolist())
									elif False:	# uniform probability for nH
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=H_steps)
										nH_ne_log_probs = np.ones((H_steps))
									elif False:	# 2020/07/16 I restructure the code to look at nH2+/nH2 rather than nH2+/ne, same for H-
										nH_ne_log_probs = nH_ne_log_probs -np.log(np.sum(np.exp(nH_ne_log_probs)))	# normalisation for logarithmic probabilities
										nH2p_ne_values = np.logspace(np.log10(max(min_mol_fraction,min_nH2_ne*1e-5)),np.log10(min(centre_nH2_ne/10,10-1e-3)),num=to_find_steps)
										nHm_ne_values = np.logspace(np.log10(max(min_mol_fraction,min_nH2_ne*1e-5)),np.log10(min(centre_nH2_ne/10,10-1e-3)),num=to_find_steps)


								if True:	# 2020/07/13 at the moment these are not used /2020/07/15 let's try to
									def nH_ne_values_Te(Te,H_steps):
										H_steps = H_steps//2*2+1
										max_nH_ne = np.exp(limit_H_up(np.log(Te)))
										min_nH_ne = np.exp(limit_H_down(np.log(Te)))
										centre_nH_ne = nH_ne_fit_from_simulations(Te)
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=(H_steps-1))
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										nH_ne_values = np.array(H_left_interval.tolist() + [centre_nH_ne] + H_right_interval.tolist())
										return nH_ne_values
									def nH_ne_values_Te_expanded(Te,H_steps,how_expand_nH_ne_indexes):
										H_steps = H_steps//2*2+1
										max_nH_ne = np.exp(limit_H_up(np.log(Te)))
										min_nH_ne = np.exp(limit_H_down(np.log(Te)))
										centre_nH_ne = nH_ne_fit_from_simulations(Te)
										nH_ne_values = np.logspace(np.log10(min_nH_ne),np.log10(max_nH_ne),num=(H_steps-1))
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										nH_ne_values = np.array(H_left_interval.tolist() + [centre_nH_ne] + H_right_interval.tolist())
										nH_ne_additional_values=[]
										for i in range(H_steps-1):
											if how_expand_nH_ne_indexes[i]!=0:
												nH_ne_additional_values.extend(np.logspace(np.log10(nH_ne_values[i]),np.log10(nH_ne_values[i+1]),num=how_expand_nH_ne_indexes[i]+2)[1:-1])
										return np.sort(np.concatenate((nH_ne_values,nH_ne_additional_values)))
									def nH_ne_log_probs_Te(Te,nH_ne_values):
										max_nH_ne = np.exp(limit_H_up(np.log(Te)))
										min_nH_ne = np.exp(limit_H_down(np.log(Te)))
										centre_nH_ne = nH_ne_fit_from_simulations(Te)
										H_left_interval = nH_ne_values[nH_ne_values-centre_nH_ne<=0]
										H_right_interval = nH_ne_values[nH_ne_values-centre_nH_ne>0]
										H_left_interval_log_probs = -(0.5*((np.log10(H_left_interval/centre_nH_ne)/(np.log10(centre_nH_ne/min_nH_ne)/2))**2))**1	# super gaussian order 1, centre_nH_ne-min_nH_ne is 2 sigma
										H_right_interval_log_probs = -(0.5*((np.log10(H_right_interval/centre_nH_ne)/(np.log10(centre_nH_ne/max_nH_ne)/3))**2))**2	# super gaussian order 2, centre_nH_ne-max_nH_ne is 3 sigma
										nH_ne_log_probs = np.array(H_left_interval_log_probs.tolist() + H_right_interval_log_probs.tolist())
										return nH_ne_log_probs
									def nH2_ne_values_Te(Te,H2_steps):
										H2_steps = H2_steps//2*2+1
										max_nH2_ne = nH2_ne_fit_from_simulations(Te)*20
										min_nH2_ne = nH2_ne_fit_from_simulations(Te)/5
										centre_nH2_ne = nH2_ne_fit_from_simulations(Te)
										H2_left_interval = np.logspace(np.log10(min_nH2_ne),np.log10(centre_nH2_ne),num=(H2_steps+1)/2)[:-1]
										H2_right_interval = np.logspace(np.log10(centre_nH2_ne),np.log10(max_nH2_ne),num=(H2_steps+1)/2)[1:]
										nH2_ne_values = np.array(H2_left_interval.tolist() + [centre_nH2_ne] + H2_right_interval.tolist())
										return nH2_ne_values
									def nH2_ne_log_probs_Te(Te,nH2_ne_values):
										max_nH2_ne = np.max(nH2_ne_fit_from_simulations(Te))*20
										min_nH2_ne = np.min(nH2_ne_fit_from_simulations(Te))/5
										centre_nH2_ne = nH2_ne_fit_from_simulations(Te)
										H2_left_interval = nH2_ne_values[nH2_ne_values-centre_nH2_ne<=0]
										H2_right_interval = nH2_ne_values[nH2_ne_values-centre_nH2_ne>0]
										H2_left_interval_log_probs = -0.5*((np.log10(H2_left_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/min_nH2_ne)/2))**2)	# centre_nH2_ne-min_nH2_ne is 2 sigma
										H2_right_interval_log_probs = -0.5*((np.log10(H2_right_interval/centre_nH2_ne)/(np.log10(centre_nH2_ne/max_nH2_ne)/2))**2)	# centre_nH2_ne-max_nH2_ne is 2 sigma
										nH2_ne_log_probs = np.array(H2_left_interval_log_probs.tolist() + H2_right_interval_log_probs.tolist())
										# nH2_ne_log_probs = nH2_ne_log_probs -np.log(np.sum(np.exp(nH2_ne_log_probs)))	# normalisation for logarithmic probabilities
										return nH2_ne_log_probs
									def nH2p_nH2_values_Te_ne(Te,ne,to_find_steps):
										if np.shape(Te)==():
											nH2p_nH2_values = np.logspace(np.log10(max(1e-9,1e-2*min(H2p_H2_v_ratio_AMJUEL(ne,Te),H2p_H2_v0_ratio_AMJUEL(ne,Te)))),np.log10(max(1,1e4*max(H2p_H2_v_ratio_AMJUEL(ne,Te),H2p_H2_v0_ratio_AMJUEL(ne,Te)))),num=to_find_steps)
										else:
											temp=[]
											for i in range(len(Te)):
												temp.append(np.logspace(np.log10(max(1e-9,1e-2*min(H2p_H2_v_ratio_AMJUEL(ne[i],Te[i]),H2p_H2_v0_ratio_AMJUEL(ne[i],Te[i])))),np.log10(max(1,1e4*max(H2p_H2_v_ratio_AMJUEL(ne[i],Te[i]),H2p_H2_v0_ratio_AMJUEL(ne[i],Te[i])))),num=to_find_steps))
											nH2p_nH2_values = np.array(temp).T
										return nH2p_nH2_values
									def nH2p_nH2_values_Te_ne_expanded(Te,ne,to_find_steps,how_expand_nH2p_nH2_indexes):
										if np.shape(Te)==():
											nH2p_nH2_values = np.logspace(np.log10(max(1e-9,1e-2*min(H2p_H2_v_ratio_AMJUEL(ne,Te),H2p_H2_v0_ratio_AMJUEL(ne,Te)))),np.log10(max(1,1e4*max(H2p_H2_v_ratio_AMJUEL(ne,Te),H2p_H2_v0_ratio_AMJUEL(ne,Te)))),num=to_find_steps)
											nH2p_nH2_additional_values=[]
											for i in range(to_find_steps-1):
												if how_expand_nH2p_nH2_indexes[i]!=0:
													nH2p_nH2_additional_values.extend(np.logspace(np.log10(nH2p_nH2_values[i]),np.log10(nH2p_nH2_values[i+1]),num=how_expand_nH2p_nH2_indexes[i]+2)[1:-1])
											nH2p_nH2_values = np.sort(np.concatenate((nH2p_nH2_values,nH2p_nH2_additional_values)))
										else:
											temp=[]
											for i in range(len(Te)):
												nH2p_nH2_values = np.logspace(np.log10(max(1e-9,1e-2*min(H2p_H2_v_ratio_AMJUEL(ne[i],Te[i]),H2p_H2_v0_ratio_AMJUEL(ne[i],Te[i])))),np.log10(max(1,1e4*max(H2p_H2_v_ratio_AMJUEL(ne[i],Te[i]),H2p_H2_v0_ratio_AMJUEL(ne[i],Te[i])))),num=to_find_steps)
												nH2p_nH2_additional_values=[]
												for i in range(to_find_steps-1):
													if how_expand_nH2p_nH2_indexes[i]!=0:
														nH2p_nH2_additional_values.extend(np.logspace(np.log10(nH2p_nH2_values[i]),np.log10(nH2p_nH2_values[i+1]),num=how_expand_nH2p_nH2_indexes[i]+2)[1:-1])
												temp.append(np.sort(np.concatenate((nH2p_nH2_values,nH2p_nH2_additional_values))))
											nH2p_nH2_values = np.array(temp).T
										return nH2p_nH2_values
									def nHm_nH2_values_Te(Te,to_find_steps):
										if np.shape(Te)==():
											nHm_nH2_values = np.logspace(np.log10(max(1e-10,1e-2*min(Hm_H2_v_ratio_AMJUEL(Te),Hm_H2_v0_ratio_AMJUEL(Te)))),np.log10(1),num=to_find_steps)
										else:
											temp=[]
											for i in range(len(Te)):
												temp.append(np.logspace(np.log10(max(1e-10,1e-2*min(Hm_H2_v_ratio_AMJUEL(Te[i]),Hm_H2_v0_ratio_AMJUEL(Te[i])))),np.log10(1),num=to_find_steps))
											nHm_nH2_values = np.array(temp).T
										return nHm_nH2_values
									def nHm_nH2_values_Te_expanded(Te,to_find_steps,how_expand_nHm_nH2_indexes):
										if np.shape(Te)==():
											nHm_nH2_values = np.logspace(np.log10(max(1e-10,1e-2*min(Hm_H2_v_ratio_AMJUEL(Te),Hm_H2_v0_ratio_AMJUEL(Te)))),np.log10(1),num=to_find_steps)
											nHm_nH2_additional_values = []
											for i in range(to_find_steps-1):
												if how_expand_nHm_nH2_indexes[i]!=0:
													nHm_nH2_additional_values.extend(np.logspace(np.log10(nHm_nH2_values[i]),np.log10(nHm_nH2_values[i+1]),num=how_expand_nHm_nH2_indexes[i]+2)[1:-1])
											nHm_nH2_values = np.sort(np.concatenate((nHm_nH2_values,nHm_nH2_additional_values)))
										else:
											temp=[]
											for i in range(len(Te)):
												nHm_nH2_values = np.logspace(np.log10(max(1e-10,1e-2*min(Hm_H2_v_ratio_AMJUEL(Te[i]),Hm_H2_v0_ratio_AMJUEL(Te[i])))),np.log10(1),num=to_find_steps)
												nHm_nH2_additional_values=[]
												for i in range(to_find_steps-1):
													if how_expand_nHm_nH2_indexes[i]!=0:
														nHm_nH2_additional_values.extend(np.logspace(np.log10(nHm_nH2_values[i]),np.log10(nHm_nH2_values[i+1]),num=how_expand_nHm_nH2_indexes[i]+2)[1:-1])
												temp.append(np.sort(np.concatenate((nHm_nH2_values,nHm_nH2_additional_values))))
											nHm_nH2_values = np.array(temp).T
										return nHm_nH2_values


								if False:	# I don't look anymore at a fixed H2+/H- ratio but use the Bayesian aproach instead, so this is not usefull anymore
									# section added to search the effect of a fixed fraction of nH-/nH2+ on power balance
									nHm_ne_additional_values = []
									for fraction in fixed_fractions_nHm_H2p:
										for value in nH2p_ne_values*fraction:
											if np.min(np.abs(nHm_ne_values - value)/value)>max_frac_acceptable_deviation*3:
												nHm_ne_additional_values.append(value)
									nHm_ne_additional_values = np.array(nHm_ne_additional_values)
									nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values<centre_nH2_ne/10]
									# nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values>min_mol_fraction]
									if len(nHm_ne_values)+len(nHm_ne_additional_values)>40:	# emergency measure to limit the memory usage
										max_frac_acceptable_deviation *= 1.2
										print('worker '+str(current_process())+' '+str(domain_index)+' max_frac_acceptable_deviation increased on 1 Hm '+str(len(nHm_ne_values)+len(nHm_ne_additional_values)))
										nHm_ne_additional_values = []
										for fraction in fixed_fractions_nHm_H2p:
											for value in nH2p_ne_values*fraction:
												if np.min(np.abs(nHm_ne_values - value)/value)>max_frac_acceptable_deviation*3:
													nHm_ne_additional_values.append(value)
										nHm_ne_additional_values = np.array(nHm_ne_additional_values)
										nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values<centre_nH2_ne/10]
										print('worker '+str(current_process())+' '+str(domain_index)+' 1 Hm reduced to '+str(len(nHm_ne_values)+len(nHm_ne_additional_values)))
										# nHm_ne_additional_values = nHm_ne_additional_values[nHm_ne_additional_values>min_mol_fraction]
									nHm_ne_values = np.sort(np.concatenate((nHm_ne_values,nHm_ne_additional_values)))


								# calculated_emission = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,len(n_list_all)))
								# for i1,nH_ne_value in enumerate(nH_ne):
								# 	total_nH_ne_value = (((excitation_internal[n_list_all - 4] *  nH_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# 	nHp_ne_value = 1
								# 	# for i2,nHp_ne_value in enumerate(nHp_ne):
								# 	total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# 	for i3,nHm_ne_value in enumerate(nHpolecule_ne):
								# 		for i4,nH2_ne_value in enumerate(nHpolecule_ne):
								# 			total_nH2_ne_value = nH2_ne_value*From_H2_pop_coeff_full(np.array([Te_values.flatten(),ne_values.flatten()]).T,n_list_all)
								# 			for i5,nH2p_ne_value in enumerate(nHpolecule_ne):
								# 				total_nHm_ne_value = nHm_ne_value*( From_Hn_with_Hp_pop_coeff_full(np.array([Te_values.flatten(),T_Hp*np.ones_like(Te_values.flatten()),T_Hm*np.ones_like(Te_values.flatten()),ne_values.flatten()*1e20,nHp_ne_value*ne_values.flatten()*1e20]).T ,n_list_all) + From_Hn_with_H2p_pop_coeff_full(np.array([Te_values.flatten(),T_H2p*np.ones_like(Te_values.flatten()),T_Hm*np.ones_like(Te_values.flatten()),ne_values.flatten()*1e20,nH2p_ne_value*ne_values.flatten()*1e20]).T,n_list_all) )
								# 				total_nH2p_ne_value = nH2p_ne_value*From_H2p_pop_coeff_full(np.array([Te_values.flatten(),ne_values.flatten()*1e20]).T,n_list_all)
								# 				# for i6,nH3p_ne_value in enumerate(nHpolecule_ne):
								# 				# 	total_nH3p_ne_value = nH3p_ne_value*From_H3p_pop_coeff_full(np.array([Te_values.flatten(),ne_values.flatten()*1e20]).T,n_list_all)
								# 				total = total_nH_ne_value+total_nHp_ne_value+total_nH2_ne_value+total_nHm_ne_value+total_nH2p_ne_value# +total_nH3p_ne_value
								# 				total = (total.T*(Te_values.flatten() ** 2)).T*multiplicative_factor * 1e40
								# 				calculated_emission[:,:,i1,i3,i4,i5,:]=total.reshape((5,5,8))

								for loop_index in [0,1]:
									TS_Te_steps = len(Te_values_array)
									TS_ne_steps = len(ne_values_array)

									Te_log_probs = -(0.5*(((Te_values_array-merge_Te_prof_multipulse_interp_crop_limited_restrict)/(merge_dTe_prof_multipulse_interp_crop_limited_restrict/2))**2))**1	# super gaussian order 1
									Te_log_probs = Te_log_probs -np.log(np.sum(np.exp(Te_log_probs)))	# normalisation for logarithmic probabilities
									ne_log_probs = -(0.5*(((ne_values_array-ne)/(merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20/2))**2))**1	# super gaussian order 1
									ne_log_probs = ne_log_probs -np.log(np.sum(np.exp(ne_log_probs)))	# normalisation for logarithmic probabilities
									ne_values = (np.ones((TS_Te_steps,TS_ne_steps))*ne_values_array).T
									Te_values = np.ones((TS_ne_steps,TS_Te_steps))*Te_values_array

									# excitation_internal = []
									# for isel in [2, 3, 4, 5, 6, 7, 8, 9, 10]:
									# 	temp = read_adf15(pecfile, isel, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									# 	temp[np.isnan(temp)] = 0
									# 	# temp = temp.reshape((np.shape(Te_values)))
									# 	excitation_internal.append(temp)
									# excitation_internal = np.array(excitation_internal)  # in # photons cm^-3 s^-1
									# excitation_internal = (excitation_internal.T * (10 ** -6) * (energy_difference / J_to_eV))  # in W m^-3 / (# / m^3)**2
									# excitation_internal = (excitation_internal[:,n_list_all - 4] /multiplicative_factor)  # in m^-3 / (# / m^3)**2

									multiplicative_factor_full = energy_difference_full * einstein_coeff_full / J_to_eV
									excitation_full = []
									for isel in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]:
										if isel==0:
											temp = read_adf15(pecfile_2, 1, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										else:
											temp = read_adf15(pecfile, isel, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										temp[np.isnan(temp)] = 0
										temp[np.isinf(temp)] = 0
										# temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
										excitation_full.append(temp)
									del temp
									excitation_full = np.array(excitation_full)  # in # photons cm^-3 s^-1
									excitation_full = (excitation_full.T * (10 ** -6) * (energy_difference_full / J_to_eV))  # in W m^-3 / (# / m^3)**2
									excitation_full = (excitation_full /multiplicative_factor_full)  # in m^-3 / (# / m^3)**2
									excitation_internal = excitation_full[:,n_list_all - 2]

									# recombination_internal = []
									# for isel in [20, 21, 22, 23, 24, 25, 26, 27, 28]:
									# 	temp = read_adf15(pecfile, isel, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									# 	temp[np.isnan(temp)] = 0
									# 	# temp = temp.reshape((np.shape(Te_values)))
									# 	recombination_internal.append(temp)
									# recombination_internal = np.array(recombination_internal)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
									# recombination_internal = (recombination_internal.T * (10 ** -6) * (energy_difference / J_to_eV))  # in W m^-3 / (# / m^3)**2
									# recombination_internal = (recombination_internal[:,n_list_all - 4] /multiplicative_factor)  # in m^-3 / (# / m^3)**2

									recombination_full = []
									for isel in [0, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]:
										if isel==0:
											temp = read_adf15(pecfile_2, 67, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										else:
											temp = read_adf15(pecfile, isel, Te_values.flatten(),(ne_values * 10 ** (- 6)).flatten())[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										temp[np.isnan(temp)] = 0
										# temp = temp.reshape((np.shape(merge_Te_prof_multipulse_interp_crop_limited)))
										recombination_full.append(temp)
									del temp
									recombination_full = np.array(recombination_full)  # in # photons cm^-3 s^-1 / (# cm^-3)**2
									recombination_full = (recombination_full.T * (10 ** -6) * (energy_difference_full / J_to_eV))  # in W m^-3 / (# / m^3)**2
									recombination_full = (recombination_full /multiplicative_factor_full)  # in m^-3 / (# / m^3)**2
									recombination_internal = recombination_full[:,n_list_all - 2]

									total_wavelengths = np.unique(excited_states_From_Hn_with_Hp)
									# calculated_emission = np.ones((TS_steps,TS_steps,to_find_steps,to_find_steps,to_find_steps,to_find_steps,len(n_list_all)))
									calculated_emission_log_probs = -np.ones((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps),dtype=np.float32)*np.inf	# H, Hm, H2, H2p, ne, Te
									# calculated_emission_error = np.ones((to_find_steps,to_find_steps))	# Hm, H2p
									# nHp_ne_value = 1
									# total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
									# total_nHp_ne_value = recombination_internal * nHp_ne_value
									coeff_1_record = From_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)
									coeff_1 = coeff_1_record[:,n_list_all-2]
									coeff_2_record = From_H2_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)
									coeff_2 = coeff_2_record[:,n_list_all-2]
									T_Hm_values = np.exp(TH2_fit_from_simulations(np.log(Te_values.flatten())))/eV_to_K	# K
									T_Hm_values[T_Hm_values<300]=300
									T_H2p_values = np.exp(TH2_fit_from_simulations(np.log(Te_values.flatten())))/eV_to_K	# K
									T_H2p_values[T_H2p_values<300]=300
									T_Hp_values = Te_values.flatten()/eV_to_K	# K
									T_Hp_values[T_Hp_values<300]=300
									T_H2_values = np.exp(TH2_fit_from_simulations(np.log(Te_values.flatten())))/eV_to_K	# K
									T_H2_values[T_H2_values<300]=300
									T_H_values = np.exp(TH_fit_from_simulations(np.log(Te_values.flatten())))/eV_to_K	# K
									T_H_values[T_H_values<300]=300
									coeff_3_record = []
									coeff_4_record = []
									record_nH_ne_values = []
									record_nH_ne_log_prob = []
									for i_Te_for_nH_ne,Te_for_nH_ne in enumerate(Te_values_array):
										nH_ne_values = nH_ne_values_Te(Te_for_nH_ne,H_steps)
										record_nH_ne_values.append(nH_ne_values)
										nH_ne_log_probs = nH_ne_log_probs_Te(Te_for_nH_ne,nH_ne_values)
										record_nH_ne_log_prob.append(nH_ne_log_probs)
									total_nH_ne_value = multiplicative_factor*np.array([[record_nH_ne_values]*TS_ne_steps]*len(n_list_all)).T	# H, Te, ne, lines
									total_nH_ne_value = np.transpose(total_nH_ne_value, (0,1,3,2))*(ne_values_array ** 2)	# H, Te, lines, ne
									total_nH_ne_value = excitation_internal*(np.transpose(total_nH_ne_value, (0,3,1,2))).reshape((H_steps,TS_ne_steps*TS_Te_steps,len(n_list_all)))	# H, ne*Te, lines
									total_nH_ne_value = np.float32(np.transpose(np.array([total_nH_ne_value.tolist()]*H2_steps),(1,0,2,3)))	# H, H2, ne*Te, lines
									record_nH_ne_values = (np.array([record_nH_ne_values]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H_steps))).T
									record_nH_ne_log_prob = (np.array([record_nH_ne_log_prob]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H_steps))).T
									nH_ne_excited_states_atomic = [[[np.float32(record_nH_ne_values*np.sum(excitation_full,axis=-1)*ne_values.flatten()).tolist()]*to_find_steps]*H2_steps]*to_find_steps
									nH_ne_excited_states_atomic = np.transpose(nH_ne_excited_states_atomic, (3,0,1,2,4))
									# total_nH_ne_value = []
									# for i1,nH_ne_value in enumerate(nH_ne_values):
									# 	# total_nH_ne_value.append(excitation_internal *  nH_ne_value)
									# 	total_nH_ne_value.append(np.ones((H2_steps,*np.shape(excitation_internal)))*excitation_internal *  nH_ne_value)
									# 	# total_nH_ne_value = excitation_internal *  nH_ne_value
									# total_nH_ne_value = np.array(total_nH_ne_value)
									# total_nH_ne_value = np.transpose(total_nH_ne_value*multiplicative_factor, (0,1,3,2))	# H, H2, lines, ne*Te
									# total_nH_ne_value = total_nH_ne_value * (ne_values.flatten() ** 2)
									# total_nH_ne_value = np.float32(np.transpose(total_nH_ne_value, (0,1,3,2)))	# H, H2, ne*Te, lines
									total_nH2_ne_value = []
									record_nH2_ne_values = []
									record_nH2_ne_log_prob = []
									for i_Te_for_nH2_ne,Te_for_nH2_ne in enumerate(Te_values_array):
										nH2_ne_values = nH2_ne_values_Te(Te_for_nH2_ne,H2_steps)
										record_nH2_ne_values.append(nH2_ne_values)
										nH2_ne_log_probs = nH2_ne_log_probs_Te(Te_for_nH2_ne,nH2_ne_values)
										record_nH2_ne_log_prob.append(nH2_ne_log_probs)
									total_nH2_ne_value = multiplicative_factor*np.array([[record_nH2_ne_values]*TS_ne_steps]*len(n_list_all)).T	# H2, Te, ne, lines
									total_nH2_ne_value = np.transpose(total_nH2_ne_value, (0,1,3,2))*(ne_values_array ** 2)	# H2, Te, lines, ne
									total_nH2_ne_value = np.float32(coeff_2*(np.transpose(total_nH2_ne_value, (0,3,1,2))).reshape((H2_steps,TS_ne_steps*TS_Te_steps,len(n_list_all))))	# H2, ne*Te, lines
									record_nH2_ne_values = (np.array([record_nH2_ne_values]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H2_steps))).T
									record_nH2_ne_log_prob = (np.array([record_nH2_ne_log_prob]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H2_steps))).T
									# total_nH2_ne_value = []
									# for i4,nH2_ne_value in enumerate(nH2_ne_values):
									# 	total_nH2_ne_value.append( coeff_2 *  nH2_ne_value )
									# 	# total_nH2_ne_value = nH2_ne_value * coeff_2
									# total_nH2_ne_value = np.array(total_nH2_ne_value)
									# total_nH2_ne_value = np.transpose(total_nH2_ne_value*multiplicative_factor, (0,2,1))	# H2, lines, ne*Te
									# total_nH2_ne_value = total_nH2_ne_value * (ne_values.flatten() ** 2)
									# total_nH2_ne_value = np.float32(np.transpose(total_nH2_ne_value, (0,2,1)))	# H2, ne*Te, lines
									total_nH_nH2_ne_values = total_nH_ne_value + total_nH2_ne_value
									record_nH2p_nH2_values = nH2p_nH2_values_Te_ne(Te_values.flatten(),ne_values.flatten(),to_find_steps)
									record_nH2p_ne_values = np.transpose([record_nH2_ne_values.tolist()]*(to_find_steps) ,(1,0,2)) * record_nH2p_nH2_values
									record_nHm_nH2_values = nHm_nH2_values_Te(Te_values.flatten(),to_find_steps)
									record_nHm_ne_values = np.transpose([record_nH2_ne_values.tolist()]*(to_find_steps) ,(1,0,2)) * record_nHm_nH2_values
									record_nHp_ne_values = 1 - record_nH2p_ne_values + np.transpose([record_nHm_ne_values.tolist()]*(to_find_steps), (2,1,0,3))	# Hm, H2, H2p, ne*Te
									record_nHp_ne_values[record_nHp_ne_values<=0] = 1e-15
									recombination_full_sum = np.sum(recombination_full,axis=-1)
									for i4 in range(H2_steps):
										for i5 in range(to_find_steps):
											nH2p_nH2_values = record_nH2p_nH2_values[i5]
											nH2p_ne_values = record_nH2_ne_values[i4]*nH2p_nH2_values
											total_nH2p_ne_values = np.float32(nH2p_ne_values *(ne_values.flatten() ** 2) * (coeff_1*multiplicative_factor).T).T
											coeff_4 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_values*ne_values.flatten()]).T,total_wavelengths)
											coeff_4_record.append(coeff_4)
											coeff_4 = coeff_4[:,n_list_all-2]
											total_nH_nH2_nH2p_ne_values = total_nH_nH2_ne_values[:,i4] + total_nH2p_ne_values
										# total_nH2p_ne_value = nH2p_ne_value * coeff_1
										# total_nH2p_ne_value = (total_nH2p_ne_value*multiplicative_factor).T	# lines, ne*Te
										# total_nH2p_ne_value = total_nH2p_ne_value * (ne_values.flatten() ** 2)
										# total_nH2p_ne_value = np.float32(total_nH2p_ne_value.T)	# ne*Te, lines
										# total_nH_nH2_nH2p_ne_value = total_nH_nH2_ne_value + total_nH2p_ne_value
										# coeff_4 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,n_list_all)
										# coeff_4_record.append(coeff_4)
											for i3 in range(to_find_steps):
												nHm_nH2_values = record_nHm_nH2_values[i3]
												nHm_ne_values = record_nH2_ne_values[i4]*nHm_nH2_values
												nHp_ne_values = 1 - nH2p_ne_values + nHm_ne_values
												nHp_ne_good = nHp_ne_values>0
												# nHp_ne_mid = nHp_ne_values==0
												nHp_ne_bad = nHp_ne_values<0
												# nHp_ne_values[nHp_ne_mid]=1e-10
												nHp_ne_values[nHp_ne_bad]=0
												total_nHp_ne_values = (recombination_internal.T * nHp_ne_values).T
												nH_ne_excited_states_atomic[:,i3,i4,i5] += np.float32(recombination_full_sum * nHp_ne_values * ne_values.flatten())
												# total_nHp_ne_values[nHp_ne_mid]=0
												coeff_3 = np.zeros((len(nHp_ne_values),len(total_wavelengths)))
												coeff_3[nHp_ne_good] = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten()[nHp_ne_good],T_Hp_values[nHp_ne_good],T_Hm_values[nHp_ne_good],ne_values.flatten()[nHp_ne_good],(nHp_ne_values*ne_values.flatten())[nHp_ne_good]]).T ,total_wavelengths)
												# coeff_3[np.logical_and(nHp_ne_mid,nHp_ne_bad)]=0
												coeff_3_record.append(coeff_3)
												coeff_3 = coeff_3[:,n_list_all-2]
												total_nHm_ne_values = (nHm_ne_values*( coeff_3 + coeff_4 ).T).T
												total = total_nHp_ne_values+total_nHm_ne_values# +total_nH3p_ne_value	# H, H2, ne*Te, lines
												total = (total*multiplicative_factor).T	# lines, ne*Te
												total = np.float32(total * (ne_values.flatten() ** 2))
												calculated_emission = total_nH_nH2_nH2p_ne_values + total.T	# H, H2, ne*Te, lines
												temp = np.float32(-0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1))
												nHp_ne_good = np.logical_not(nHp_ne_bad.reshape((TS_ne_steps,TS_Te_steps)))
												calculated_emission_log_probs[:,i3,i4,i5,nHp_ne_good]= temp.reshape((H_steps,TS_ne_steps,TS_Te_steps))[:,nHp_ne_good]
												del temp,calculated_emission
											# if nHp_ne_value<0:
											# 	nHp_ne_value=1e-8
											# 	coeff_3_record.append(0)
											# 	continue
											# elif nHp_ne_value==0:
											# 	nHp_ne_value=1e-8
											# 	total_nHp_ne_value = 0
											# else:
											# coeff_3 = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_value*ne_values.flatten()]).T ,n_list_all)
											# coeff_3_record.append(coeff_3)
											# total_nHm_ne_value = nHm_ne_value*( coeff_3 + coeff_4 )
											# total = total_nHp_ne_value+total_nHm_ne_value# +total_nH3p_ne_value	# H, H2, ne*Te, lines
											# total = (total*multiplicative_factor).T	# lines, ne*Te
											# total = np.float32(total * (ne_values.flatten() ** 2))
											# calculated_emission = total_nH_nH2_nH2p_ne_value + total.T	# H, H2, ne*Te, lines
											# temp = np.float32(-0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1))
											# calculated_emission_log_probs[:,i3,:,i5]= temp.reshape((len(nH_ne_values),H2_steps,TS_ne_steps,TS_Te_steps))
									calculated_emission_log_probs = calculated_emission_log_probs-np.max(calculated_emission_log_probs)
									calculated_emission_log_probs = calculated_emission_log_probs-np.log(np.sum(np.exp(calculated_emission_log_probs)))	# normalisation for logarithmic probabilities

									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' Initial loop nr '+str(loop_index)+'-3 done '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) +' - good=%.3g, nan=%.3g, -inf=%.3g' %( np.sum(np.isfinite(calculated_emission_log_probs)),np.sum(np.isnan(calculated_emission_log_probs)),np.sum(np.isinf(calculated_emission_log_probs)) ) )

									power_rad_H2p,power_rad_H2,power_rad_excit,power_via_ionisation,power_rad_rec_bremm,power_via_recombination,power_via_brem,power_rec_neutral,power_rad_Hm,power_rad_mol,power_heating_rec,tot_rad_power,total_removed_power_atomic,nH_ne_excited_states_mol = calc_power_balance_elements_simplified2(H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps,Te_values,ne_values,multiplicative_factor_full_full,record_nH_ne_values,record_nHm_ne_values,record_nH2_ne_values,record_nH2p_ne_values,record_nHp_ne_values,T_Hp_values,T_H2p_values,T_Hm_values,coeff_1_record,coeff_2_record,coeff_3_record,coeff_4_record)
									total_removed_power = total_removed_power_atomic + power_rad_mol

									area = 2*np.pi*(r_crop[my_r_pos] + np.median(np.diff(r_crop))/2) * np.median(np.diff(r_crop))
									length = 0.351+target_OES_distance/1000	# mm distance skimmer to OES/TS + OES/TS to target
									total_removed_power_times_volume = total_removed_power * area*length
									# power_penalty = np.zeros_like((total_removed_power_times_volume),dtype=np.float32)
									if False:	# here I do not use any info on the shape of the plasma upstream
										select = total_removed_power_times_volume>interpolated_power_pulse_shape(time_crop[my_time_pos])/source_power_spread
										power_penalty[select] = np.float32(-0.5*((total_removed_power_times_volume[select] - interpolated_power_pulse_shape(time_crop[my_time_pos])/source_power_spread)/(interpolated_power_pulse_shape_std(time_crop[my_time_pos])))**2)
									else:	# here I do
										max_local_flow_vel = max(1,homogeneous_mach_number[my_time_pos])*upstream_adiabatic_collisional_velocity[my_time_pos,my_r_pos]
										total_removable_power_times_volume_SS = area*(0.5*hydrogen_mass*(max_local_flow_vel**2) + (5*Te_all_upstream[my_time_pos,my_r_pos] + ionisation_potential + dissociation_potential)/eV_to_K*boltzmann_constant_J)*max_local_flow_vel*ne_all_upstream[my_time_pos,my_r_pos]*1e20
										total_removable_power_times_volume_dynamic = area*length/dt*1000*(0.5*hydrogen_mass*(max_local_flow_vel**2) + (5*Te_values + ionisation_potential + dissociation_potential)/eV_to_K*boltzmann_constant_J)*ne_values
										total_removable_power_times_volume = total_removable_power_times_volume_SS + total_removable_power_times_volume_dynamic
										total_removable_power_times_volume = np.array([[[[total_removable_power_times_volume.tolist()]*to_find_steps]*H2_steps]*to_find_steps]*H_steps,dtype=np.float32)
										if False:
											select = total_removed_power_times_volume>total_removable_power_times_volume
											power_penalty[select] = np.float32(-0.5*((total_removed_power_times_volume[select] - total_removable_power_times_volume[select])/total_removable_power_times_volume[select])**2)
										elif True:	# real formula for the probability of an inequality
											# total_removed_power_times_volume_sigma = (0.2*total_removed_power_atomic + 0.5*power_rad_mol) * area*length
											total_removed_power_times_volume_sigma = (( (power_atomic_precision**2)*(power_via_ionisation**2 + power_rad_excit**2 + power_via_recombination**2 + power_rec_neutral**2 + power_via_brem**2) + (power_molecular_precision**2)*(power_rad_Hm**2 + power_rad_H2**2 + power_rad_H2p**2))**0.5) * area*length	#this properly adds in quadrature all the uncertanties
											total_removable_power_times_volume_sigma = (total_removable_power_times_volume*power_budget_precision)
											# power_penalty = np.log( 1 + np.erf( (total_removable_power_times_volume-total_removed_power_times_volume)/(2**0.5 * (total_removed_power_times_volume_sigma**2 + (total_removable_power_times_volume*0.5)**2)**0.5)) )
											power_penalty = np.float32(np.erf( total_removed_power_times_volume/( 2**0.5 * total_removed_power_times_volume_sigma ) ))
											power_penalty += np.float32(np.erf( (total_removable_power_times_volume-total_removed_power_times_volume)/(2**0.5 * (total_removed_power_times_volume_sigma**2 + total_removable_power_times_volume_sigma**2)**0.5)))
											power_penalty = power_penalty/np.float32(0.5 + np.erf( total_removed_power_times_volume/( 2**0.5 * total_removed_power_times_volume_sigma ) ))
											power_penalty = power_penalty/np.float32(0.5 + np.erf( total_removable_power_times_volume/( 2**0.5 * total_removable_power_times_volume_sigma ) ))
											time_lapsed = tm.time()-start_time
											print('worker '+str(current_process())+' Initial loop nr '+str(loop_index)+'-2 done '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) +' - good=%.3g, nan=%.3g, -inf=%.3g, -<0 =%.3g, min=%.3g' %( np.sum(np.isfinite(power_penalty)),np.sum(np.isnan(power_penalty)),np.sum(np.isinf(power_penalty)),np.sum(power_penalty<0) ,np.nanmin(power_penalty)) )
											power_penalty[power_penalty<0]=0
											power_penalty = np.log(power_penalty)
											# power_penalty += -np.log( 1+ np.erf( total_removed_power_times_volume/( 2**0.5 * total_removed_power_times_volume_sigma ) ) ) - np.log( 1+ np.erf( total_removable_power_times_volume/( 2**0.5 * total_removable_power_times_volume*0.5 ) ) )
											power_penalty -= power_penalty.max()
											# del total_removed_power_times_volume_sigma

									nH_ne_excited_states = nH_ne_excited_states_atomic + nH_ne_excited_states_mol.reshape((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps*TS_Te_steps))
									temp = np.transpose(np.transpose(nH_ne_excited_states, (1,2,3,0,4)) > record_nH_ne_values, (3,0,1,2,4))
									nH_ne_penalty = np.zeros_like(nH_ne_excited_states,dtype=np.float16)
									nH_ne_penalty[temp==True] = -np.inf
									del temp
									nH_ne_penalty = nH_ne_penalty.reshape((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps))
									del nH_ne_excited_states_atomic,nH_ne_excited_states_mol

									# likelihood_log_probs = np.zeros((len(nH_ne_values),len(nHm_ne_values),len(nH2_ne_values),len(nH2p_ne_values),TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
									# for i5,nH2p_ne_value in enumerate(nH2p_ne_values):
									# 	for i3,nHm_ne_value in enumerate(nHm_ne_values):
									# 		for i1,nH_ne_value in enumerate(nH_ne_values):
									# 			temp_i1 = nH_ne_log_probs[i1]
									# 			for i4,nH2_ne_value in enumerate(nH2_ne_values):
									# 				temp_i4 = nH2_ne_log_probs[i4]
									# 				for i6 in range(TS_ne_steps):
									# 					temp_i6 = ne_log_probs[i6]
									# 					for i7 in range(TS_Te_steps):
									# 						likelihood_log_probs[i1,i3,i4,i5,i6,i7]= calculated_emission_log_probs[i1,i3,i4,i5,i6,i7]+Te_log_probs[i7]+temp_i6+temp_i4+temp_i1
									# likelihood_log_probs = ((calculated_emission_log_probs + Te_log_probs + (np.ones((TS_Te_steps,TS_ne_steps))*ne_log_probs).T + (np.ones((TS_Te_steps,TS_ne_steps,len(nH2p_ne_values),len(nH2_ne_values)))*nH2_ne_log_probs).T ).T + nH_ne_log_probs).T
									likelihood_log_probs = calculated_emission_log_probs + np.float32(Te_log_probs) + (np.ones((TS_Te_steps,TS_ne_steps),dtype=np.float32)*np.float32(ne_log_probs)).T + np.float32(np.transpose([np.float32(record_nH2_ne_log_prob).reshape((H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*to_find_steps,(1,0,2,3)))
									likelihood_log_probs = np.transpose(np.transpose(likelihood_log_probs,(1,2,3,0,4,5)) + np.float32(record_nH_ne_log_prob.reshape((H_steps,TS_ne_steps,TS_Te_steps))) ,(3,0,1,2,4,5)) + power_penalty + nH_ne_penalty
									likelihood_log_probs -= np.max(likelihood_log_probs)
									likelihood_log_probs -= np.log(np.sum(np.exp(likelihood_log_probs)))	# normalisation for logarithmic probabilities

									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' Initial loop nr '+str(loop_index)+'-1 done '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) +' - good=%.3g, nan=%.3g, -inf=%.3g' %( np.sum(np.isfinite(likelihood_log_probs)),np.sum(np.isnan(likelihood_log_probs)),np.sum(np.isinf(likelihood_log_probs)) ) )

									# H, Hm, H2, H2p, ne, Te
									all_nHm_ne_values = np.array([np.transpose(np.array([record_nHm_ne_values.reshape((H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps)).tolist()]*to_find_steps), (2,1,0,3,4)).tolist()]*H_steps,dtype=np.float32)
									all_nH2p_ne_values = np.array([[record_nH2p_ne_values.reshape((H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps)).tolist()]*to_find_steps]*H_steps,dtype=np.float32)
									all_nHm_nH2_values = np.transpose(np.array([[[record_nHm_nH2_values.reshape((to_find_steps,TS_ne_steps,TS_Te_steps)).tolist()]*to_find_steps]*H2_steps]*H_steps,dtype=np.float32), (0,3,1,2,4,5))
									all_nH2p_nH2_values = np.array([[[record_nH2p_nH2_values.reshape((to_find_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2_steps]*to_find_steps]*H_steps,dtype=np.float32)
									all_nH2_ne_values = np.array([[np.transpose([record_nH2_ne_values.reshape((H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*to_find_steps, (1,0,2,3)).tolist()]*to_find_steps]*H_steps, dtype=np.float32)
									all_nH_ne_values = np.array(np.transpose([[[record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)).tolist()]*to_find_steps]*H2_steps]*to_find_steps, (3,0,1,2,4,5)), dtype=np.float32)
									all_ne_values = np.array([[[[ne_values.tolist()]*to_find_steps]*H2_steps]*to_find_steps]*H_steps,dtype=np.float32)
									all_Te_values = np.array([[[[Te_values.tolist()]*to_find_steps]*H2_steps]*to_find_steps]*H_steps,dtype=np.float32)
									all_nHp_ne_values = np.array([record_nHp_ne_values.reshape((to_find_steps,H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H_steps,dtype=np.float32)

									if include_particles_limitation:
										particles_penalty = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_Hp_destruction = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_e_destruction = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_Hm_destruction = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_H2p_destruction = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_Hp_destruction_sigma = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_e_destruction_sigma = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_Hm_destruction_sigma = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										all_net_H2p_destruction_sigma = np.zeros_like((likelihood_log_probs),dtype=np.float32)
										if False:
											x_full =np.array([all_nH_ne_values[np.isfinite(likelihood_log_probs)],all_nHm_nH2_values[np.isfinite(likelihood_log_probs)],all_nH2_ne_values[np.isfinite(likelihood_log_probs)],all_nH2p_nH2_values[np.isfinite(likelihood_log_probs)],1e-20*all_ne_values[np.isfinite(likelihood_log_probs)],all_Te_values[np.isfinite(likelihood_log_probs)]]).T
											all_net_Hp_destruction[np.isfinite(likelihood_log_probs)] = area*length*dt/1000*(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_Hp_destruction,np.log(x_full), bounds_error=False,fill_value=None))
											all_net_e_destruction[np.isfinite(likelihood_log_probs)] = area*length*dt/1000*(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_e_destruction,np.log(x_full), bounds_error=False,fill_value=None))
											all_net_Hm_destruction[np.isfinite(likelihood_log_probs)] = area*length*dt/1000*(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_Hm_destruction,np.log(x_full), bounds_error=False,fill_value=None))
											all_net_H2p_destruction[np.isfinite(likelihood_log_probs)] = area*length*dt/1000*(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_H2p_destruction,np.log(x_full), bounds_error=False,fill_value=None))
											del x_full
										elif True:	# I optimised the real functions enough that it's about the same speed as the interpolated method
											temp_coord = np.ones_like(nH_ne_excited_states[:,:,:,:,0])
											for i6 in range(TS_Te_steps):
												fractional_population_states_H2 = calc_H2_fractional_population_states(T_H2p_values[i6])
												for i5 in range(TS_ne_steps):
													if ((Te_values_array[i6] in Te_values_array_initial) and (ne_values_array[i5] in ne_values_array_initial)) and loop_index>0:
														i5_old = np.abs(ne_values_array_initial-ne_values_array[i5]).argmin()
														i6_old = np.abs(Te_values_array_initial-Te_values_array[i6]).argmin()
														all_net_Hp_destruction[:,:,:,:,i5,i6] = record_all_net_Hp_destruction[:,:,:,:,i5_old,i6_old]
														all_net_e_destruction[:,:,:,:,i5,i6] = record_all_net_e_destruction[:,:,:,:,i5_old,i6_old]
														all_net_Hm_destruction[:,:,:,:,i5,i6] = record_all_net_Hm_destruction[:,:,:,:,i5_old,i6_old]
														all_net_H2p_destruction[:,:,:,:,i5,i6] = record_all_net_H2p_destruction[:,:,:,:,i5_old,i6_old]
													else:
														temp_nH_excited_states = nH_ne_excited_states[:,:,:,:,i5*TS_Te_steps+i6]*ne_values_array[i5]*1e-20
														arguments = (temp_coord*Te_values_array[i6],temp_coord*T_Hp_values[i6],temp_coord*T_H_values[i6],temp_coord*T_H2_values[i6],temp_coord*T_Hm_values[i6],temp_coord*T_H2p_values[i6],temp_coord*ne_values_array[i5]*1e-20,all_nHp_ne_values[:,:,:,:,i5,i6],all_nH_ne_values[:,:,:,:,i5,i6],all_nH2_ne_values[:,:,:,:,i5,i6],all_nHm_ne_values[:,:,:,:,i5,i6],all_nH2p_ne_values[:,:,:,:,i5,i6],fractional_population_states_H2,temp_nH_excited_states)
														temp,temp_sigma = np.float32(RR_rate_destruction_Hp(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														temp1,temp1_sigma =	np.float32(RR_rate_creation_Hp(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														all_net_Hp_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
														all_net_Hp_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
														temp,temp_sigma = np.float32(RR_rate_destruction_e(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														temp1,temp1_sigma =	np.float32(RR_rate_creation_e(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														all_net_e_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
														all_net_e_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
														temp,temp_sigma = np.float32(RR_rate_destruction_Hm(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														temp1,temp1_sigma =	np.float32(RR_rate_creation_Hm(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														all_net_Hm_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
														all_net_Hm_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
														temp,temp_sigma = np.float32(RR_rate_destruction_H2p(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														temp1,temp1_sigma =	np.float32(RR_rate_creation_H2p(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
														all_net_H2p_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
														all_net_H2p_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
											del temp_coord,temp,temp_sigma,temp1,temp1_sigma
											all_net_Hp_destruction *= area*length*dt/1000
											all_net_e_destruction *= area*length*dt/1000
											all_net_Hm_destruction *= area*length*dt/1000
											all_net_H2p_destruction *= area*length*dt/1000
											all_net_Hp_destruction_sigma *= area*length*dt/1000
											all_net_e_destruction_sigma *= area*length*dt/1000
											all_net_Hm_destruction_sigma *= area*length*dt/1000
											all_net_H2p_destruction_sigma *= area*length*dt/1000
										total_removable_Hp = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*max_local_flow_vel + area*length*all_ne_values*all_nHp_ne_values*1e-20)	# I assume no molecules upstream >> nH+/ne~1
										total_removable_e = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*max_local_flow_vel + area*length*all_ne_values*1e-20)
										if False:
											select = all_net_Hp_destruction>total_removable_Hp
											particles_penalty[select] += np.float32(-0.5*((all_net_Hp_destruction[select] - total_removable_Hp[select])/total_removable_Hp[select])**2)	# 100% uncertanty
											select = all_net_e_destruction>total_removable_e
											particles_penalty[select] += np.float32(-0.5*((all_net_e_destruction[select] - total_removable_e[select])/total_removable_e[select])**2)	# 100% uncertanty
										elif True:
											particles_penalty += np.log( 1 + np.erf( (total_removable_Hp-all_net_Hp_destruction)/(2**0.5 * (all_net_Hp_destruction_sigma**2 + (total_removable_Hp*particle_atomic_budget_precision)**2)**0.5)) )
											particles_penalty += np.log( 1 + np.erf( (total_removable_e-all_net_e_destruction)/(2**0.5 * (all_net_e_destruction_sigma**2 + (total_removable_e*particle_atomic_budget_precision)**2)**0.5)) )

										total_removable_Hm = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*all_nHm_ne_values*max_local_flow_vel + area*length*all_ne_values*all_nHm_ne_values*1e-20)	# I assume molecules upstream ~ downstream
										total_removable_H2p = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*all_nH2p_ne_values*max_local_flow_vel + area*length*all_ne_values*all_nH2p_ne_values*1e-20)	# I assume molecules upstream ~ downstream
										if False:
											select = all_net_Hm_destruction>total_removable_Hm
											particles_penalty[select] += np.float32(-0.5*((all_net_Hm_destruction[select] - total_removable_Hm[select])/(total_removable_Hm[select]*2))**2)	# 200% uncertanty
											select = all_net_H2p_destruction>total_removable_H2p
											particles_penalty[select] += np.float32(-0.5*((all_net_H2p_destruction[select] - total_removable_H2p[select])/(total_removable_H2p[select]*2))**2)	# 200% uncertanty
										elif True:
											particles_penalty += np.log( 1 + np.erf( (total_removable_Hm-all_net_Hm_destruction)/(2**0.5 * (all_net_Hm_destruction_sigma**2 + (total_removable_Hm*particle_molecular_budget_precision)**2)**0.5)) )
											particles_penalty += np.log( 1 + np.erf( (total_removable_H2p-all_net_H2p_destruction)/(2**0.5 * (all_net_H2p_destruction_sigma**2 + (total_removable_H2p*particle_molecular_budget_precision)**2)**0.5)) )
										particles_penalty -= np.nanmax(particles_penalty)
										# particles_penalty[np.isnan(particles_penalty)]=-np.inf


										likelihood_log_probs += particles_penalty
										likelihood_log_probs -= np.max(likelihood_log_probs)
										likelihood_log_probs -= np.log(np.sum(np.exp(likelihood_log_probs)))	# normalisation for logarithmic probabilities

										if loop_index==0:
											record_all_net_Hp_destruction = all_net_Hp_destruction/(area*length*dt/1000)
											record_all_net_e_destruction = all_net_e_destruction/(area*length*dt/1000)
											record_all_net_Hm_destruction = all_net_Hm_destruction/(area*length*dt/1000)
											record_all_net_H2p_destruction = all_net_H2p_destruction/(area*length*dt/1000)
											record_all_net_Hp_destruction_sigma = all_net_Hp_destruction_sigma/(area*length*dt/1000)
											record_all_net_e_destruction_sigma = all_net_e_destruction_sigma/(area*length*dt/1000)
											record_all_net_Hm_destruction_sigma = all_net_Hm_destruction_sigma/(area*length*dt/1000)
											record_all_net_H2p_destruction_sigma = all_net_H2p_destruction_sigma/(area*length*dt/1000)
										else:
											del record_all_net_Hp_destruction,record_all_net_e_destruction,record_all_net_Hm_destruction,record_all_net_H2p_destruction,record_all_net_Hp_destruction_sigma,record_all_net_e_destruction_sigma,record_all_net_Hm_destruction_sigma,record_all_net_H2p_destruction_sigma
										del all_nHm_nH2_values,all_nH2p_nH2_values,all_nH2_ne_values,all_nH_ne_values,all_ne_values,all_Te_values,all_nHp_ne_values,all_net_Hp_destruction,all_net_Hp_destruction_sigma,total_removable_Hp,all_net_e_destruction,all_net_e_destruction_sigma,total_removable_e,all_net_Hm_destruction,all_net_Hm_destruction_sigma,all_net_H2p_destruction,all_net_H2p_destruction_sigma,total_removable_Hm,total_removable_H2p,all_nHm_ne_values,all_nH2p_ne_values
										del particles_penalty,nH_ne_excited_states,nH_ne_penalty,power_penalty

									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' Initial loop nr '+str(loop_index)+' done '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) +' - good=%.3g, nan=%.3g, -inf=%.3g' %( np.sum(np.isfinite(likelihood_log_probs)),np.sum(np.isnan(likelihood_log_probs)),np.sum(np.isinf(likelihood_log_probs)) ) )

									if loop_index==0:
										hypervolume_of_each_combination = np.ones((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps*TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne*Te
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,3,4,2))	# H, Hm, H2p, ne*Te, H2
										for i6 in range(TS_ne_steps*TS_Te_steps):
											nH2_ne_values = record_nH2_ne_values[:,i6]
											d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])
											hypervolume_of_each_combination[:,:,:,i6] *= d_nH2_ne_values/np.sum(d_nH2_ne_values)
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,2,3,1))	# H, H2, H2p, ne*Te, Hm
										for i6 in range(TS_ne_steps*TS_Te_steps):
											nHm_nH2_values = record_nHm_nH2_values[:,i6]
											d_nHm_nH2_values = np.array([*np.diff(nHm_nH2_values[[0,1]]),*(np.diff(nHm_nH2_values)[:-1]/2+np.diff(nHm_nH2_values)[1:]/2),*np.diff(nHm_nH2_values[[-2,-1]])])
											hypervolume_of_each_combination[:,:,:,i6] *= d_nHm_nH2_values/np.sum(d_nHm_nH2_values)
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,1,3,2))	# H, Hm, H2, ne*Te, H2p
										for i6 in range(TS_ne_steps*TS_Te_steps):
											nH2p_nH2_values = record_nH2p_nH2_values[:,i6]
											d_nH2p_nH2_values = np.array([*np.diff(nH2p_nH2_values[[0,1]]),*(np.diff(nH2p_nH2_values)[:-1]/2+np.diff(nH2p_nH2_values)[1:]/2),*np.diff(nH2p_nH2_values[[-2,-1]])])
											hypervolume_of_each_combination[:,:,:,i6] *= d_nH2p_nH2_values/np.sum(d_nH2p_nH2_values)
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (1,2,4,3,0))	# Hm, H2, H2p, ne*Te, H
										for i6 in range(TS_ne_steps*TS_Te_steps):
											nH_ne_values = record_nH_ne_values[:,i6]
											d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])
											hypervolume_of_each_combination[:,:,:,i6] *= d_nH_ne_values/np.sum(d_nH_ne_values)
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (4,0,1,2,3))	# H, Hm, H2, H2p, ne*Te
										hypervolume_of_each_combination = hypervolume_of_each_combination.reshape((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										d_Te_values_array = np.ones_like(Te_values_array)
										hypervolume_of_each_combination *= d_Te_values_array/np.sum(d_Te_values_array)
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, Te, ne
										d_ne_values_array = np.ones_like(ne_values_array)
										hypervolume_of_each_combination *= d_ne_values_array/np.sum(d_ne_values_array)
										hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, ne, Te

										marginalised_log_prob_ne_Te = np.sum(np.exp(likelihood_log_probs)*hypervolume_of_each_combination,axis=(0,1,2,3))	# ne, Te
										del hypervolume_of_each_combination
										# print(marginalised_log_prob_ne_Te)
										index_most_likely = marginalised_log_prob_ne_Te.argmax()
										# print(index_most_likely)
										most_likely_Te_index = index_most_likely%TS_Te_steps
										most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
										marginalised_log_prob_ne = marginalised_log_prob_ne_Te[:,most_likely_Te_index]
										marginalised_log_prob_Te = marginalised_log_prob_ne_Te[most_likely_ne_index]
										# print(marginalised_log_prob_ne)
										# print(marginalised_log_prob_Te)
										# marginalised_log_prob_ne = np.log(np.sum(np.exp(likelihood_log_probs)*hypervolume_of_each_combination,axis=(0,1,2,3,5)))	# ne, Te
										# marginalised_log_prob_Te = np.log(np.sum(np.exp(likelihood_log_probs)*hypervolume_of_each_combination,axis=(0,1,2,3,4)))	# ne, Te

										ne_values_limits = np.array([ne_values_array for _, ne_values_array in sorted(zip(marginalised_log_prob_ne, ne_values_array))])[-4:]
										# ne_additional_values = np.linspace(np.min(ne_values_limits),np.max(ne_values_limits),12)
										ne_additional_values = np.logspace(np.log10(np.min(ne_values_limits)),np.log10(np.max(ne_values_limits)),num=TS_ne_steps_increase)
										ne_values_array_initial = cp.deepcopy(ne_values_array)
										ne_values_array = np.unique(np.concatenate((ne_values_array,ne_additional_values)))
										Te_values_limits = np.array([Te_values_array for _, Te_values_array in sorted(zip(marginalised_log_prob_Te, Te_values_array))])[-4:]
										Te_additional_values = np.linspace(np.min(Te_values_limits),np.max(Te_values_limits),TS_Te_steps_increase)
										Te_values_array_initial = cp.deepcopy(Te_values_array)
										Te_values_array = np.unique(np.concatenate((Te_values_array,Te_additional_values)))




								# total_nH2p_ne_value
								# nH2p_ne_value = np.array([[(np.ones((to_find_steps,to_find_steps,to_find_steps_H2,to_find_steps))*nHpolecule_ne).tolist()]*TS_steps*TS_steps]*len(n_list_all))
								# nHm_ne_value = np.array([[[(np.ones((to_find_steps,to_find_steps_H2,to_find_steps)).T*nHpolecule_ne).T.tolist()]*to_find_steps]*TS_steps*TS_steps]*len(n_list_all))
								# nHp_ne_value = 1 - nH2p_ne_value + nHm_ne_value

								# calculated_emission_error = np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1)
								# calculated_emission_error = np.sum(calculated_emission_error.T * Te_probs,axis=-1)
								# calculated_emission_error = np.sum(calculated_emission_error * ne_probs,axis=-1).T

								index_best_fit = calculated_emission_log_probs.argmax()
								del calculated_emission_log_probs
								best_fit_Te_index = index_best_fit%TS_Te_steps
								best_fit_ne_index = (index_best_fit-best_fit_Te_index)//TS_Te_steps%TS_ne_steps
								best_fit_nH2p_nH2_index = ((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps%to_find_steps
								best_fit_nH2_ne_index = (((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_nH2_index)//to_find_steps%H2_steps
								best_fit_nHm_nH2_index = ((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_nH2_index)//to_find_steps - best_fit_nH2_ne_index)//H2_steps%to_find_steps
								best_fit_nH_ne_index = (((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_nH2_index)//to_find_steps - best_fit_nH2_ne_index)//H2_steps - best_fit_nHm_nH2_index)//to_find_steps%H_steps

								best_fit_Te_value = Te_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_ne_value = ne_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_nH2p_ne_value = record_nH2p_nH2_values[best_fit_nH2p_nH2_index,best_fit_ne_index*best_fit_Te_index]*record_nH2_ne_values[best_fit_nH2_ne_index,best_fit_ne_index*best_fit_Te_index]
								best_fit_nH2_ne_value = record_nH2_ne_values[best_fit_nH2_ne_index,best_fit_ne_index*best_fit_Te_index]
								best_fit_nHm_ne_value = record_nHm_nH2_values[best_fit_nHm_nH2_index,best_fit_ne_index*best_fit_Te_index]*record_nH2_ne_values[best_fit_nH2_ne_index,best_fit_ne_index*best_fit_Te_index]
								best_fit_nH_ne_value = record_nH_ne_values[best_fit_nH_ne_index,best_fit_ne_index*best_fit_Te_index]


								index_most_likely = likelihood_log_probs.argmax()
								most_likely_Te_index = index_most_likely%TS_Te_steps
								most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
								most_likely_nH2p_nH2_index = ((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps%to_find_steps
								most_likely_nH2_ne_index = (((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_nH2_index)//to_find_steps%H2_steps
								most_likely_nHm_nH2_index = ((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_nH2_index)//to_find_steps - most_likely_nH2_ne_index)//H2_steps%to_find_steps
								most_likely_nH_ne_index = (((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_nH2_index)//to_find_steps - most_likely_nH2_ne_index)//H2_steps - most_likely_nHm_nH2_index)//to_find_steps%H_steps
								max_likelihood_log_prob = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]

								most_likely_Te_value = Te_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_ne_value = ne_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_nH2p_ne_value = record_nH2p_nH2_values[most_likely_nH2p_nH2_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index] * record_nH2_ne_values[most_likely_nH2_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_nH2_ne_value = record_nH2_ne_values[most_likely_nH2_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_nHm_ne_value = record_nHm_nH2_values[most_likely_nHm_nH2_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index] * record_nH2_ne_values[most_likely_nH2_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_nH_ne_value = record_nH_ne_values[most_likely_nH_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]

								# now I marginalise H2, Te, ne in order to find the most likely Hm, H2p for the next step
								hypervolume_of_each_combination = np.ones((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps*TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne*Te
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,3,4,2))	# H, Hm, H2p, ne*Te, H2
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nH2_ne_values = record_nH2_ne_values[:,i6]
									d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])
									hypervolume_of_each_combination[:,:,:,i6] *= d_nH2_ne_values/np.sum(d_nH2_ne_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,2,3,1))	# H, H2, H2p, ne*Te, Hm
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nHm_nH2_values = record_nHm_nH2_values[:,i6]
									# d_nHm_nH2_values = np.array([*np.diff(nHm_nH2_values[[0,1]]),*(np.diff(nHm_nH2_values)[:-1]/2+np.diff(nHm_nH2_values)[1:]/2),*np.diff(nHm_nH2_values[[-2,-1]])])/(np.diff(nHm_nH2_values[[0,-1]])+np.diff(nHm_nH2_values[[0,1]])/2+np.diff(nHm_nH2_values[[-2,-1]])/2)
									d_nHm_nH2_values = np.ones_like(nHm_nH2_values)
									hypervolume_of_each_combination[:,:,:,i6] *= d_nHm_nH2_values/np.sum(d_nHm_nH2_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,1,3,2))	# H, Hm, H2, ne*Te, H2p
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nH2p_nH2_values = record_nH2p_nH2_values[:,i6]
									# d_nH2p_nH2_values = np.array([*np.diff(nH2p_nH2_values[[0,1]]),*(np.diff(nH2p_nH2_values)[:-1]/2+np.diff(nH2p_nH2_values)[1:]/2),*np.diff(nH2p_nH2_values[[-2,-1]])])/(np.diff(nH2p_nH2_values[[0,-1]])+np.diff(nH2p_nH2_values[[0,1]])/2+np.diff(nH2p_nH2_values[[-2,-1]])/2)
									d_nH2p_nH2_values = np.ones_like(nH2p_nH2_values)
									hypervolume_of_each_combination[:,:,:,i6] *= d_nH2p_nH2_values/np.sum(d_nH2p_nH2_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (1,2,4,3,0))	# Hm, H2, H2p, ne*Te, H
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nH_ne_values = record_nH_ne_values[:,i6]
									# d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])/(np.diff(nH_ne_values[[0,-1]])+np.diff(nH_ne_values[[0,1]])/2+np.diff(nH_ne_values[[-2,-1]])/2)
									d_nH_ne_values = np.ones_like(nH_ne_values)
									hypervolume_of_each_combination[:,:,:,i6] *= d_nH_ne_values/np.sum(d_nH_ne_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (4,0,1,2,3))	# H, Hm, H2, H2p, ne*Te
								hypervolume_of_each_combination = hypervolume_of_each_combination.reshape((H_steps,to_find_steps,H2_steps,to_find_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
								d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])
								hypervolume_of_each_combination *= d_Te_values_array/np.sum(d_Te_values_array)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, Te, ne
								d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])
								hypervolume_of_each_combination *= d_ne_values_array/np.sum(d_ne_values_array)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, ne, Te

								marginalised_likelihood_log_probs = np.log(np.sum(np.exp(np.float64(likelihood_log_probs))*hypervolume_of_each_combination,axis=(2,4,5)))	# H, Hm, H2, H2p, ne, Te
								del hypervolume_of_each_combination
								marginalised_likelihood_log_probs -= np.max(marginalised_likelihood_log_probs)
								marginalised_likelihood_log_probs -= np.log(np.sum(np.exp(marginalised_likelihood_log_probs)))	# normalisation for logarithmic probabilities
								index_most_likely = marginalised_likelihood_log_probs.argmax()
								most_likely_marginalised_nH2p_nH2_index = index_most_likely%to_find_steps
								most_likely_marginalised_nHm_nH2_index = (index_most_likely-most_likely_marginalised_nH2p_nH2_index)//to_find_steps%to_find_steps
								most_likely_marginalised_nH_ne_index = ((index_most_likely-most_likely_marginalised_nH2p_nH2_index)//to_find_steps-most_likely_marginalised_nHm_nH2_index)//to_find_steps%H_steps

								# now I cannot do this, because I don't have fixed density intervals
								# most_likely_marginalised_nH2p_ne_value = nH2p_ne_values[most_likely_marginalised_nH2p_nH2_index]
								# most_likely_marginalised_nHm_ne_value = nHm_ne_values[most_likely_marginalised_nHm_nH2_index]
								# most_likely_marginalised_nH_ne_value = nH_ne_values[most_likely_marginalised_nH_ne_index]

								first_most_likely_Te_value = cp.deepcopy(most_likely_Te_value)
								first_most_likely_ne_value = cp.deepcopy(most_likely_ne_value)
								first_most_likely_nH2p_ne_value = cp.deepcopy(most_likely_nH2p_ne_value)
								first_most_likely_nH2_ne_value = cp.deepcopy(most_likely_nH2_ne_value)
								first_most_likely_nHm_ne_value = cp.deepcopy(most_likely_nHm_ne_value)
								first_most_likely_nH_ne_value = cp.deepcopy(most_likely_nH_ne_value)
								first_most_likely_Te_index = cp.deepcopy(most_likely_Te_index)
								first_most_likely_ne_index = cp.deepcopy(most_likely_ne_index)
								first_most_likely_nH2p_nH2_index = cp.deepcopy(most_likely_nH2p_nH2_index)
								first_most_likely_nH2_ne_index = cp.deepcopy(most_likely_nH2_ne_index)
								first_most_likely_nHm_nH2_index = cp.deepcopy(most_likely_nHm_nH2_index)
								first_most_likely_nH_ne_index = cp.deepcopy(most_likely_nH_ne_index)

								first_most_likely_marginalised_nH2p_nH2_index = cp.deepcopy(most_likely_marginalised_nH2p_nH2_index)
								first_most_likely_marginalised_nHm_nH2_index = cp.deepcopy(most_likely_marginalised_nHm_nH2_index)
								first_most_likely_marginalised_nH_ne_index = cp.deepcopy(most_likely_marginalised_nH_ne_index)

								if np.sum(np.isfinite(likelihood_log_probs[0,0,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]))==0:
									nH2p_nH2_index_where_expand = np.nan
								else:
									nH2p_nH2_index_where_expand = likelihood_log_probs[0,0,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index].argmax()

								if np.sum(np.isfinite(likelihood_log_probs[0,:,most_likely_nH2_ne_index,0,most_likely_ne_index,most_likely_Te_index]))==0:
									nHm_nH2_index_where_expand = np.nan
								else:
									nHm_nH2_index_where_expand = likelihood_log_probs[0,:,most_likely_nH2_ne_index,0,most_likely_ne_index,most_likely_Te_index].argmax()

								if np.sum(np.isfinite(likelihood_log_probs[:,0,most_likely_nH2_ne_index,0,most_likely_ne_index,most_likely_Te_index]))==0:
									nH_ne_index_where_expand = np.nan
								else:
									nH_ne_index_where_expand = likelihood_log_probs[:,0,most_likely_nH2_ne_index,0,most_likely_ne_index,most_likely_Te_index].argmax()

								if np.sum(np.isfinite(marginalised_likelihood_log_probs[0,0,:]))==0:
									marginalised_nH2p_nH2_index_where_expand = np.nan
								else:
									marginalised_nH2p_nH2_index_where_expand = marginalised_likelihood_log_probs[0,0,:].argmax()

								if np.sum(np.isfinite(marginalised_likelihood_log_probs[0,:,0]))==0:
									marginalised_nHm_nH2_index_where_expand = np.nan
								else:
									marginalised_nHm_nH2_index_where_expand = marginalised_likelihood_log_probs[0,:,0].argmax()

								if np.sum(np.isfinite(marginalised_likelihood_log_probs[:,0,0]))==0:
									marginalised_nH_ne_index_where_expand = np.nan
								else:
									marginalised_nH_ne_index_where_expand = marginalised_likelihood_log_probs[:,0,0].argmax()

								del likelihood_log_probs,marginalised_likelihood_log_probs
								additional_steps = 5

								if np.sum(np.isnan([nH2p_nH2_index_where_expand,marginalised_nH2p_nH2_index_where_expand]))==2:
									next_nH2p_nH2_index_up = to_find_steps-1
								else:
									next_nH2p_nH2_index_up = min(int(np.nanmax([nH2p_nH2_index_where_expand,marginalised_nH2p_nH2_index_where_expand])+2),to_find_steps-1)
								if np.sum(np.isnan([nH2p_nH2_index_where_expand,marginalised_nH2p_nH2_index_where_expand]))==2:
									next_nH2p_nH2_index_down = 0
								else:
									next_nH2p_nH2_index_down = max(int(np.nanmin([nH2p_nH2_index_where_expand,marginalised_nH2p_nH2_index_where_expand])-2),0)
								next_nH2p_nH2_index_expansions_within_interval = int(additional_steps/(next_nH2p_nH2_index_up-next_nH2p_nH2_index_down))

								if np.sum(np.isnan([nHm_nH2_index_where_expand,marginalised_nHm_nH2_index_where_expand]))==2:
									next_nHm_nH2_index_up = to_find_steps-1
								else:
									next_nHm_nH2_index_up = min(int(np.nanmax([nHm_nH2_index_where_expand,marginalised_nHm_nH2_index_where_expand])+2),to_find_steps-1)
								if np.sum(np.isnan([nHm_nH2_index_where_expand,marginalised_nHm_nH2_index_where_expand]))==2:
									next_nHm_nH2_index_down = 0
								else:
									next_nHm_nH2_index_down = max(int(np.nanmin([nHm_nH2_index_where_expand,marginalised_nHm_nH2_index_where_expand])-2),0)
								next_nHm_nH2_index_expansions_within_interval = int(additional_steps/(next_nHm_nH2_index_up-next_nHm_nH2_index_down))

								if np.sum(np.isnan([nH_ne_index_where_expand,marginalised_nH_ne_index_where_expand]))==2:
									next_nH_ne_index_up = H_steps-1
								else:
									next_nH_ne_index_up = min(int(np.nanmax([nH_ne_index_where_expand,marginalised_nH_ne_index_where_expand])+2),H_steps-1)
								if np.sum(np.isnan([nH_ne_index_where_expand,marginalised_nH_ne_index_where_expand]))==2:
									next_nH_ne_index_down = 0
								else:
									next_nH_ne_index_down = max(int(np.nanmin([nH_ne_index_where_expand,marginalised_nH_ne_index_where_expand])-2),0)
								next_nH_ne_index_expansions_within_interval = int(additional_steps/(next_nH_ne_index_up-next_nH_ne_index_down))


								next_nHm_nH2_index_up_2 = min(most_likely_marginalised_nHm_nH2_index+2,to_find_steps-1)
								next_nHm_nH2_index_down_2 = max(most_likely_marginalised_nHm_nH2_index-2,0)

								next_nHm_nH2_index_up_3 = min(most_likely_nHm_nH2_index+2,to_find_steps-1)
								next_nHm_nH2_index_down_3 = max(most_likely_nHm_nH2_index-2,0)

								temp_1 = np.arange(next_nHm_nH2_index_down,next_nHm_nH2_index_up)
								temp_2 = np.arange(next_nHm_nH2_index_down_2,next_nHm_nH2_index_up_2)
								temp_3 = np.arange(next_nHm_nH2_index_down_3,next_nHm_nH2_index_up_3)
								next_nHm_nH2_index_expansions_within_interval_2 = int(2*additional_steps/len([*temp_2,*temp_3]))
								output = []
								for i in range(to_find_steps-1):
									temp_5 = 0
									if i in temp_1:
										temp_5 += next_nHm_nH2_index_expansions_within_interval
									if i in temp_2:
										temp_5 += next_nHm_nH2_index_expansions_within_interval_2
									if i in temp_3:
										temp_5 += next_nHm_nH2_index_expansions_within_interval_2
									output.append(temp_5)
								how_expand_nHm_nH2_indexes = np.array(output)
								how_much_expand_nHm_nH2_indexes = np.sum(how_expand_nHm_nH2_indexes)
								additional_nHm_nH2_point = []
								for i in range(to_find_steps-1):
									additional_nHm_nH2_point.append(False)
									if how_expand_nHm_nH2_indexes[i]!=0:
										temp=how_expand_nHm_nH2_indexes[i]
										while temp>0:
											additional_nHm_nH2_point.append(True)
											temp-=1
								additional_nHm_nH2_point.append(False)


								next_nH_ne_index_up_2 = min(most_likely_marginalised_nH_ne_index+2,H_steps-1)
								next_nH_ne_index_down_2 = max(most_likely_marginalised_nH_ne_index-2,0)

								next_nH_ne_index_up_3 = min(most_likely_nH_ne_index+2,H_steps-1)
								next_nH_ne_index_down_3 = max(most_likely_nH_ne_index-2,0)

								temp_1 = np.arange(next_nH_ne_index_down,next_nH_ne_index_up)
								temp_2 = np.arange(next_nH_ne_index_down_2,next_nH_ne_index_up_2)
								temp_3 = np.arange(next_nH_ne_index_down_3,next_nH_ne_index_up_3)
								next_nH_ne_index_expansions_within_interval_2 = int(2*additional_steps/len([*temp_2,*temp_3]))
								output = []
								for i in range(H_steps-1):
									temp_5 = 0
									if i in temp_1:
										temp_5 += next_nH_ne_index_expansions_within_interval
									if i in temp_2:
										temp_5 += next_nH_ne_index_expansions_within_interval_2
									if i in temp_3:
										temp_5 += next_nH_ne_index_expansions_within_interval_2
									output.append(temp_5)
								how_expand_nH_ne_indexes = np.array(output)
								how_much_expand_nH_ne_indexes = np.sum(how_expand_nH_ne_indexes)
								additional_nH_ne_point = []
								for i in range(H_steps-1):
									additional_nH_ne_point.append(False)
									if how_expand_nH_ne_indexes[i]!=0:
										temp=how_expand_nH_ne_indexes[i]
										while temp>0:
											additional_nH_ne_point.append(True)
											temp-=1
								additional_nH_ne_point.append(False)
								existing_nH_ne_point = np.logical_not(additional_nH_ne_point)

								next_nH2p_nH2_index_up_2 = min(most_likely_marginalised_nH2p_nH2_index+2,to_find_steps-1)
								next_nH2p_nH2_index_down_2 = max(most_likely_marginalised_nH2p_nH2_index-2,0)

								next_nH2p_nH2_index_up_3 = min(most_likely_nH2p_nH2_index+2,to_find_steps-1)
								next_nH2p_nH2_index_down_3 = max(most_likely_nH2p_nH2_index-2,0)

								temp_1 = np.arange(next_nH2p_nH2_index_down,next_nH2p_nH2_index_up)
								temp_2 = np.arange(next_nH2p_nH2_index_down_2,next_nH2p_nH2_index_up_2)
								temp_3 = np.arange(next_nH2p_nH2_index_down_3,next_nH2p_nH2_index_up_3)
								next_nH2p_nH2_index_expansions_within_interval_2 = int(2*additional_steps/len([*temp_2,*temp_3]))
								output = []
								for i in range(to_find_steps-1):
									temp_5 = 0
									if i in temp_1:
										temp_5 += next_nH2p_nH2_index_expansions_within_interval
									if i in temp_2:
										temp_5 += next_nH2p_nH2_index_expansions_within_interval_2
									if i in temp_3:
										temp_5 += next_nH2p_nH2_index_expansions_within_interval_2
									output.append(temp_5)
								how_expand_nH2p_nH2_indexes = np.array(output)
								how_much_expand_nH2p_nH2_indexes = np.sum(how_expand_nH2p_nH2_indexes)
								additional_nH2p_nH2_point = []
								for i in range(to_find_steps-1):
									additional_nH2p_nH2_point.append(False)
									if how_expand_nH2p_nH2_indexes[i]!=0:
										temp=how_expand_nH2p_nH2_indexes[i]
										while temp>0:
											additional_nH2p_nH2_point.append(True)
											temp-=1
								additional_nH2p_nH2_point.append(False)

								first_most_likely_nH2p_nH2_index = first_most_likely_nH2p_nH2_index + np.sum(how_expand_nH2p_nH2_indexes[:first_most_likely_nH2p_nH2_index])
								first_most_likely_nHm_nH2_index = first_most_likely_nHm_nH2_index + np.sum(how_expand_nHm_nH2_indexes[:first_most_likely_nHm_nH2_index])
								first_most_likely_nH_ne_index = first_most_likely_nH_ne_index + np.sum(how_expand_nH_ne_indexes[:first_most_likely_nH_ne_index])

								first_most_likely_marginalised_nH2p_nH2_index = first_most_likely_marginalised_nH2p_nH2_index + np.sum(how_expand_nH2p_nH2_indexes[:first_most_likely_marginalised_nH2p_nH2_index])
								first_most_likely_marginalised_nHm_nH2_index = first_most_likely_marginalised_nHm_nH2_index + np.sum(how_expand_nHm_nH2_indexes[:first_most_likely_marginalised_nHm_nH2_index])
								first_most_likely_marginalised_nH_ne_index = first_most_likely_marginalised_nH_ne_index + np.sum(how_expand_nH_ne_indexes[:first_most_likely_marginalised_nH_ne_index])


								calculated_emission_log_probs_expanded = -np.ones((H_steps+how_much_expand_nH_ne_indexes,to_find_steps+how_much_expand_nHm_nH2_indexes,H2_steps,to_find_steps+how_much_expand_nH2p_nH2_indexes,TS_ne_steps,TS_Te_steps),dtype=np.float32)*np.inf	# H, Hm, H2, H2p, ne, Te
								# calculated_emission_error = np.ones((to_find_steps,to_find_steps))	# Hm, H2p
								# nHp_ne_value = 1
								# total_nHp_ne_value = (((recombination_internal[n_list_all - 4] * nHp_ne_value*np.ones((TS_steps,TS_steps)) ).T/multiplicative_factor).T).astype('float').T.reshape((TS_steps*TS_steps,len(n_list_all)))
								# total_nHp_ne_value = recombination_internal * nHp_ne_value
								coeff_3_record_2 = []
								coeff_4_record_2 = []
								record_nH_ne_values = []
								record_nH_ne_log_prob = []
								for i_Te_for_nH_ne,Te_for_nH_ne in enumerate(Te_values_array):
									nH_ne_values = nH_ne_values_Te_expanded(Te_for_nH_ne,H_steps,how_expand_nH_ne_indexes)
									record_nH_ne_values.append(nH_ne_values)
									nH_ne_log_probs = nH_ne_log_probs_Te(Te_for_nH_ne,nH_ne_values)
									record_nH_ne_log_prob.append(nH_ne_log_probs)
								total_nH_ne_value = multiplicative_factor*np.array([[record_nH_ne_values]*TS_ne_steps]*len(n_list_all)).T	# H, Te, ne, lines
								total_nH_ne_value = np.transpose(total_nH_ne_value, (0,1,3,2))*(ne_values_array ** 2)	# H, Te, lines, ne
								total_nH_ne_value = excitation_internal*(np.transpose(total_nH_ne_value, (0,3,1,2))).reshape((H_steps+how_much_expand_nH_ne_indexes,TS_ne_steps*TS_Te_steps,len(n_list_all)))	# H, ne*Te, lines
								total_nH_ne_value = np.float32(np.transpose(np.array([total_nH_ne_value.tolist()]*H2_steps),(1,0,2,3)))	# H, H2, ne*Te, lines
								record_nH_ne_values = (np.array([record_nH_ne_values]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H_steps+how_much_expand_nH_ne_indexes))).T
								record_nH_ne_log_prob = (np.array([record_nH_ne_log_prob]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H_steps+how_much_expand_nH_ne_indexes))).T
								nH_ne_excited_states_atomic = [[[np.float32(record_nH_ne_values*np.sum(excitation_full,axis=-1)*ne_values.flatten()).tolist()]*(to_find_steps+how_much_expand_nH2p_nH2_indexes)]*H2_steps]*(to_find_steps+how_much_expand_nHm_nH2_indexes)
								nH_ne_excited_states_atomic = np.transpose(nH_ne_excited_states_atomic, (3,0,1,2,4))
								# total_nH_ne_value = []
								# for i1,nH_ne_value in enumerate(nH_ne_values):
								# 	total_nH_ne_value.append(np.ones((len(nH2_ne_values),*np.shape(excitation_internal)))*excitation_internal *  nH_ne_value)
								# 	# total_nH_ne_value.append(excitation_internal *  nH_ne_value)
								# 	# total_nH_ne_value = excitation_internal *  nH_ne_value
								# total_nH_ne_value = np.array(total_nH_ne_value)
								# total_nH_ne_value = np.transpose(total_nH_ne_value*multiplicative_factor, (0,1,3,2))	# H, H2, lines, ne*Te
								# total_nH_ne_value = total_nH_ne_value * (ne_values.flatten() ** 2)
								# total_nH_ne_value = np.float32(np.transpose(total_nH_ne_value, (0,1,3,2)))	# H, H2, ne*Te, lines
								total_nH2_ne_value = []
								record_nH2_ne_values = []
								record_nH2_ne_log_prob = []
								for i_Te_for_nH2_ne,Te_for_nH2_ne in enumerate(Te_values_array):
									nH2_ne_values = nH2_ne_values_Te(Te_for_nH2_ne,H2_steps)
									record_nH2_ne_values.append(nH2_ne_values)
									nH2_ne_log_probs = nH2_ne_log_probs_Te(Te_for_nH2_ne,nH2_ne_values)
									record_nH2_ne_log_prob.append(nH2_ne_log_probs)
								total_nH2_ne_value = multiplicative_factor*np.array([[record_nH2_ne_values]*TS_ne_steps]*len(n_list_all)).T	# H2, Te, ne, lines
								total_nH2_ne_value = np.transpose(total_nH2_ne_value, (0,1,3,2))*(ne_values_array ** 2)	# H2, Te, lines, ne
								total_nH2_ne_value = np.float32(coeff_2*(np.transpose(total_nH2_ne_value, (0,3,1,2))).reshape((H2_steps,TS_ne_steps*TS_Te_steps,len(n_list_all))))	# H2, ne*Te, lines
								record_nH2_ne_values = (np.array([record_nH2_ne_values]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H2_steps))).T
								record_nH2_ne_log_prob = (np.array([record_nH2_ne_log_prob]*TS_ne_steps).reshape((TS_ne_steps*TS_Te_steps,H2_steps))).T
								# total_nH2_ne_value = []
								# for i4,nH2_ne_value in enumerate(nH2_ne_values):
								# 	total_nH2_ne_value.append( coeff_2 *  nH2_ne_value )
								# 	# total_nH2_ne_value = nH2_ne_value * coeff_2
								# total_nH2_ne_value = np.array(total_nH2_ne_value)
								# total_nH2_ne_value = np.transpose(total_nH2_ne_value*multiplicative_factor, (0,2,1))	# H2, lines, ne*Te
								# total_nH2_ne_value = total_nH2_ne_value * (ne_values.flatten() ** 2)
								# total_nH2_ne_value = np.float32(np.transpose(total_nH2_ne_value, (0,2,1)))	# H2, ne*Te, lines
								total_nH_nH2_ne_values = total_nH_ne_value + total_nH2_ne_value
								record_nH2p_nH2_values = nH2p_nH2_values_Te_ne_expanded(Te_values.flatten(),ne_values.flatten(),to_find_steps,how_expand_nH2p_nH2_indexes)
								record_nH2p_nH2_values_initial = nH2p_nH2_values_Te_ne(Te_values.flatten(),ne_values.flatten(),to_find_steps)
								record_nH2p_ne_values = np.transpose([record_nH2_ne_values.tolist()]*(to_find_steps+how_much_expand_nH2p_nH2_indexes) ,(1,0,2)) * record_nH2p_nH2_values
								record_nHm_nH2_values = nHm_nH2_values_Te_expanded(Te_values.flatten(),to_find_steps,how_expand_nHm_nH2_indexes)
								record_nHm_nH2_values_initial = nHm_nH2_values_Te(Te_values.flatten(),to_find_steps)
								record_nHm_ne_values = np.transpose([record_nH2_ne_values.tolist()]*(to_find_steps+how_much_expand_nHm_nH2_indexes) ,(1,0,2)) * record_nHm_nH2_values

								record_nHp_ne_values = 1 - record_nH2p_ne_values + np.transpose([record_nHm_ne_values.tolist()]*(to_find_steps+how_much_expand_nH2p_nH2_indexes), (2,1,0,3))	# H, Hm, H2, H2p, ne, Te
								record_nHp_ne_values[record_nHp_ne_values<=0] = 1e-15

								# total_nH2p_ne_values = np.array([record_nH2_ne_values.T.tolist()]*(to_find_steps+how_much_expand_nH2p_nH2_indexes)).T * record_nH2p_nH2_values.T
								# total_nH2p_ne_values = np.transpose(total_nH2p_ne_values, (0,2,1)) * (ne_values.flatten() ** 2)
								# total_nH2p_ne_values = np.float32(np.array([total_nH2p_ne_values.T]*len(n_list_all)).T * (coeff_1*multiplicative_factor))
								# total_nH_nH2_ne_values = np.transpose(np.float32([total_nH_nH2_ne_values.tolist()]*(to_find_steps+how_much_expand_nH2p_nH2_indexes)), (1,2,0,3,4))
								# total_nH_nH2_nH2p_ne_values = total_nH_nH2_ne_values + total_nH2p_ne_values
								recombination_full_sum = np.sum(recombination_full,axis=-1)
								for i4 in range(H2_steps):
									# if include_particles_limitation and False:
									# 	selected_part_balance[:,:,np.arange(H2_steps)!=i4]=False
									for i5 in range(to_find_steps+how_much_expand_nH2p_nH2_indexes):
										nH2p_ne_values = record_nH2p_ne_values[i4,i5]
										total_nH2p_ne_values = np.float32(nH2p_ne_values *(ne_values.flatten() ** 2) * (coeff_1*multiplicative_factor).T).T
										if additional_nH2p_nH2_point[i5]:
											coeff_4 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_values*ne_values.flatten()]).T,total_wavelengths)
										else:
											i5_old = i5-np.sum(additional_nH2p_nH2_point[:i5+1])
											coeff_4 = coeff_4_record[i4*to_find_steps + i5_old]
										coeff_4_record_2.append(coeff_4)
										coeff_4 = coeff_4[:,n_list_all-2]
										total_nH_nH2_nH2p_ne_values = total_nH_nH2_ne_values[:,i4] + total_nH2p_ne_values
									# total_nH2p_ne_value = nH2p_ne_value * coeff_1
									# total_nH2p_ne_value = (total_nH2p_ne_value*multiplicative_factor).T	# lines, ne*Te
									# total_nH2p_ne_value = total_nH2p_ne_value * (ne_values.flatten() ** 2)
									# total_nH2p_ne_value = np.float32(total_nH2p_ne_value.T)	# ne*Te, lines
									# total_nH_nH2_nH2p_ne_value = total_nH_nH2_ne_value + total_nH2p_ne_value
									# coeff_4 = From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_value*ne_values.flatten()]).T,n_list_all)
										for i3 in range(to_find_steps+how_much_expand_nHm_nH2_indexes):
											# if include_particles_limitation and False:
											# 	selected_part_balance[:,np.arange(to_find_steps+how_much_expand_nHm_nH2_indexes)!=i3]=False
											nHm_ne_values = record_nHm_ne_values[i4,i3]
											nHp_ne_values = 1 - nH2p_ne_values + nHm_ne_values
											nHp_ne_good = nHp_ne_values>0
											nHp_ne_bad = nHp_ne_values<0
											nHp_ne_values[nHp_ne_bad]=0
											total_nHp_ne_values = (recombination_internal.T * nHp_ne_values).T
											nH_ne_excited_states_atomic[:,i3,i4,i5] += np.float32(recombination_full_sum * nHp_ne_values * ne_values.flatten())
											if additional_nH2p_nH2_point[i5] or additional_nHm_nH2_point[i3]:
												coeff_3 = np.zeros((len(nHp_ne_values),len(total_wavelengths)))
												coeff_3[nHp_ne_good] = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten()[nHp_ne_good],T_Hp_values[nHp_ne_good],T_Hm_values[nHp_ne_good],ne_values.flatten()[nHp_ne_good],(nHp_ne_values*ne_values.flatten())[nHp_ne_good]]).T ,total_wavelengths)
											else:
												i3_old = i3-np.sum(additional_nHm_nH2_point[:i3+1])
												coeff_3 = coeff_3_record[i4*to_find_steps*to_find_steps + i5_old*to_find_steps + i3_old]
												# all_net_e_destruction[:,i3,i4,i5]=record_all_net_e_destruction[]
											coeff_3_record_2.append(coeff_3)
											coeff_3 = coeff_3[:,n_list_all-2]
											# coeff_3[np.logical_and(nHp_ne_mid,nHp_ne_bad)]=0
											total_nHm_ne_values = (nHm_ne_values*( coeff_3 + coeff_4 ).T).T
											total = total_nHp_ne_values+total_nHm_ne_values# +total_nH3p_ne_value	# H, H2, ne*Te, lines
											total = (total*multiplicative_factor).T	# lines, ne*Te
											total = np.float32(total * (ne_values.flatten() ** 2))
											calculated_emission = total_nH_nH2_nH2p_ne_values + total.T	# H, H2, ne*Te, lines
											temp = np.float32(-0.5*np.sum(((calculated_emission - inverted_profiles_crop_restrict)/inverted_profiles_crop_sigma_restrict)**2,axis=-1))
											nHp_ne_good = np.logical_not(nHp_ne_bad).reshape((TS_ne_steps,TS_Te_steps))
											# nHp_ne_good = nHp_ne_good.reshape((TS_ne_steps,TS_Te_steps))
											calculated_emission_log_probs_expanded[:,i3,i4,i5,nHp_ne_good]= temp.reshape((H_steps+how_much_expand_nH_ne_indexes,TS_ne_steps,TS_Te_steps))[:,nHp_ne_good]
											del temp,calculated_emission
											# if include_particles_limitation and False:
											# 	if additional_nH2p_nH2_point[i5] or additional_nHm_nH2_point[i3]:
											# 		x_partial =np.array([record_nH_ne_values[:,nHp_ne_good.flatten()].flatten(),np.array([record_nHm_nH2_values[i3,nHp_ne_good.flatten()].tolist()]*(H_steps+how_much_expand_nH_ne_indexes)).flatten(),np.array([record_nH2_ne_values[i4,nHp_ne_good.flatten()].tolist()]*(H_steps+how_much_expand_nH_ne_indexes)).flatten(),np.array([record_nH2p_nH2_values[i5,nHp_ne_good.flatten()].tolist()]*(H_steps+how_much_expand_nH_ne_indexes)).flatten(),np.array([1e-20*ne_values.flatten()[nHp_ne_good.flatten()]]*(H_steps+how_much_expand_nH_ne_indexes)).flatten(),np.array([Te_values.flatten()[nHp_ne_good.flatten()]]*(H_steps+how_much_expand_nH_ne_indexes)).flatten()]).T
											# 		all_net_e_destruction[:,i3,i4,i5,nHp_ne_good]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_e_destruction,np.log(x_partial), bounds_error=False,fill_value=None)).reshape((H_steps+how_much_expand_nH_ne_indexes,np.sum(nHp_ne_good)))
											# 		all_net_Hp_destruction[:,i3,i4,i5,nHp_ne_good]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_Hp_destruction,np.log(x_partial), bounds_error=False,fill_value=None)).reshape((H_steps+how_much_expand_nH_ne_indexes,np.sum(nHp_ne_good)))
											# 		all_net_Hm_destruction[:,i3,i4,i5,nHp_ne_good]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_Hm_destruction,np.log(x_partial), bounds_error=False,fill_value=None)).reshape((H_steps+how_much_expand_nH_ne_indexes,np.sum(nHp_ne_good)))
											# 		all_net_H2p_destruction[:,i3,i4,i5,nHp_ne_good]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_H2p_destruction,np.log(x_partial), bounds_error=False,fill_value=None)).reshape((H_steps+how_much_expand_nH_ne_indexes,np.sum(nHp_ne_good)))
											# 	else:
											# 		x_partial =np.array([record_nH_ne_values[additional_nH_ne_point][:,nHp_ne_good.flatten()].flatten(),np.array([record_nHm_nH2_values[i3,nHp_ne_good.flatten()].tolist()]*(how_much_expand_nH_ne_indexes)).flatten(),np.array([record_nH2_ne_values[i4,nHp_ne_good.flatten()].tolist()]*(how_much_expand_nH_ne_indexes)).flatten(),np.array([record_nH2p_nH2_values[i5,nHp_ne_good.flatten()].tolist()]*(how_much_expand_nH_ne_indexes)).flatten(),np.array([1e-20*ne_values.flatten()[nHp_ne_good.flatten()]]*(how_much_expand_nH_ne_indexes)).flatten(),np.array([Te_values.flatten()[nHp_ne_good.flatten()]]*(how_much_expand_nH_ne_indexes)).flatten()]).T
											# 		selected_part_balance[existing_nH_ne_point]=False
											# 		selected_part_balance[:,:,:,np.arange(to_find_steps+how_much_expand_nH2p_nH2_indexes)!=i5]=False
											# 		selected_part_balance[additional_nH_ne_point,i3,i4,i5]=nHp_ne_good
											# 		all_net_e_destruction[selected_part_balance]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_e_destruction,np.log(x_partial), bounds_error=False,fill_value=None))
											# 		all_net_Hp_destruction[selected_part_balance]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_Hp_destruction,np.log(x_partial), bounds_error=False,fill_value=None))
											# 		all_net_Hm_destruction[selected_part_balance]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_Hm_destruction,np.log(x_partial), bounds_error=False,fill_value=None))
											# 		all_net_H2p_destruction[selected_part_balance]=(interpolate.interpn((np.log(samples_nH_ne_array),np.log(samples_nHm_nH2_array),np.log(samples_nH2_ne_array),np.log(samples_nH2p_nH2_array),np.log(samples_ne_array),np.log(samples_Te_array)),net_rate_H2p_destruction,np.log(x_partial), bounds_error=False,fill_value=None))
											# 		selected_part_balance[additional_nH_ne_point]=False
											# 		selected_part_balance[existing_nH_ne_point,i3,i4,i5]=nHp_ne_good
											# 		all_net_e_destruction[selected_part_balance]=record_all_net_e_destruction[:,i3_old,i4,i5_old,nHp_ne_good].flatten()
											# 		all_net_Hp_destruction[selected_part_balance]=record_all_net_Hp_destruction[:,i3_old,i4,i5_old,nHp_ne_good].flatten()
											# 		all_net_Hm_destruction[selected_part_balance]=record_all_net_Hm_destruction[:,i3_old,i4,i5_old,nHp_ne_good].flatten()
											# 		all_net_H2p_destruction[selected_part_balance]=record_all_net_H2p_destruction[:,i3_old,i4,i5_old,nHp_ne_good].flatten()

								del coeff_3_record,coeff_4_record
								# if include_particles_limitation and False:
								# 	del record_all_net_e_destruction,record_all_net_Hp_destruction,record_all_net_Hm_destruction,record_all_net_H2p_destruction,selected_part_balance
								# 	all_net_e_destruction = all_net_e_destruction*area*length*dt/1000
								# 	all_net_Hp_destruction = all_net_Hp_destruction*area*length*dt/1000
								# 	all_net_Hm_destruction = all_net_Hm_destruction*area*length*dt/1000
								# 	all_net_H2p_destruction = all_net_H2p_destruction*area*length*dt/1000

								calculated_emission_log_probs_expanded -= np.max(calculated_emission_log_probs_expanded)
								calculated_emission_log_probs_expanded -= np.log(np.sum(np.exp(calculated_emission_log_probs_expanded)))	# normalisation for logarithmic probabilities

								H_steps = H_steps+how_much_expand_nH_ne_indexes
								Hm_steps = to_find_steps+how_much_expand_nHm_nH2_indexes
								H2p_steps = to_find_steps+how_much_expand_nH2p_nH2_indexes

								power_rad_H2p,power_rad_H2,power_rad_excit,power_via_ionisation,power_rad_rec_bremm,power_via_recombination,power_via_brem,power_rec_neutral,power_rad_Hm,power_rad_mol,power_heating_rec,tot_rad_power,total_removed_power_atomic,nH_ne_excited_states_mol = calc_power_balance_elements_simplified2(H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps,Te_values,ne_values,multiplicative_factor_full_full,record_nH_ne_values,record_nHm_ne_values,record_nH2_ne_values,record_nH2p_ne_values,record_nHp_ne_values,T_Hp_values,T_H2p_values,T_Hm_values,coeff_1_record,coeff_2_record,coeff_3_record_2,coeff_4_record_2)
								total_removed_power = total_removed_power_atomic + power_rad_mol
								del coeff_1_record,coeff_2_record,coeff_3_record_2,coeff_4_record_2

								# thermal_velocity_H = ( (T_H_values*boltzmann_constant_J)/ hydrogen_mass)**0.5
								# temp = read_adf11(scdfile, 'scd', 1, 1, 1, Te_values.flatten(),(ne_values * 10 ** (0 - 6)).flatten())
								# temp[np.isnan(temp)] = 0
								# temp = temp.reshape((np.shape(Te_values))) * (10 ** -6)  # in ionisations m^-3 s-1 / (# / m^3)**2
								# ionization_length_H_CX = thermal_velocity_H.reshape((np.shape(Te_values)))/(temp * ne_values * 1e20 )
								# ionization_length_H_CX = np.where(np.isnan(ionization_length_H_CX), np.inf, ionization_length_H_CX)
								# # ionization_length_H_CX = np.where(np.isinf(ionization_length_H_CX), np.nan, ionization_length_H_CX)
								# # ionization_length_H_CX = np.where(np.isnan(ionization_length_H_CX), np.nanmax(ionization_length_H_CX[np.isfinite(ionization_length_H_CX)]), ionization_length_H_CX)

								temp = read_adf11(ccdfile, 'ccd', 1, 1, 1, Te_values.flatten(),(ne_values * 10 ** (0 - 6)).flatten())
								temp[np.isnan(temp)] = 0
								eff_CX_RR = temp.reshape((np.shape(Te_values))) * (10 ** -6)  # in CX m^-3 s-1 / (# / m^3)**2
								del temp
								eff_CX_RR_int = (eff_CX_RR * (ne_values**2) ).astype('float') * (record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)))
								eff_CX_RR_int = np.transpose([[[eff_CX_RR_int]*H2p_steps]*H2_steps]*Hm_steps, (3,0,1,2,4,5))
								eff_CX_RR_int = eff_CX_RR_int * np.array([(record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)))]*H_steps)

								# I separate the complete RR to the RR/nH I need for the CX length
								eff_CX_RR = (eff_CX_RR * (ne_values) ).astype('float32') * (np.ones_like(record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps))))
								eff_CX_RR = np.transpose([[[eff_CX_RR]*H2p_steps]*H2_steps]*Hm_steps, (3,0,1,2,4,5))
								eff_CX_RR = eff_CX_RR * np.array([(record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)))]*H_steps)	# H, Hm, H2, H2p, ne, Te

								# geometric_factor = (ionization_length_H_CX.T / np.abs(2*averaged_profile_sigma[my_time_pos]-r_crop[my_r_pos])).T	# I take diameter = 2 * FWHM
								# geometric_factor[geometric_factor>1] = 1
								delta_t = (T_Hp_values - T_H_values)
								delta_t[delta_t<0] = 0
								local_CX = np.float32(3/2* (delta_t.reshape((TS_ne_steps,TS_Te_steps)) * eV_to_K) * eff_CX_RR_int / J_to_eV)	# W / m^3
								del eff_CX_RR_int,delta_t

								# local_CX = P_RR_Hp_H1s__H1s_Hp(T_Hp_values,T_H_values,ne_values.flatten()*1e-20).reshape(np.shape(ne_values)) * (record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)))
								# local_CX = np.transpose([[[local_CX]*H2p_steps]*H2_steps]*Hm_steps , (3,0,1,2,4,5))	# H, Hm, H2, H2p, ne, Te

								area = 2*np.pi*(r_crop[my_r_pos] + np.median(np.diff(r_crop))/2) * np.median(np.diff(r_crop))
								length = 0.351+target_OES_distance/1000	# mm distance skimmer to OES/TS + OES/TS to target
								total_removed_power_times_volume = total_removed_power * area*length
								# power_penalty = np.zeros_like((total_removed_power_times_volume),dtype=np.float32)
								if False:	# here I do not use any info on the shape of the plasma upstream
									select = total_removed_power_times_volume>interpolated_power_pulse_shape(time_crop[my_time_pos])/source_power_spread
									power_penalty[select] = np.float32(-0.5*((total_removed_power_times_volume[select] - interpolated_power_pulse_shape(time_crop[my_time_pos])/source_power_spread)/(interpolated_power_pulse_shape_std(time_crop[my_time_pos])))**2)
								else:	# H, Hm, H2, H2p, ne, Te
									max_local_flow_vel = max(1,homogeneous_mach_number[my_time_pos])*upstream_adiabatic_collisional_velocity[my_time_pos,my_r_pos]
									total_removable_power_times_volume_SS = area*(0.5*hydrogen_mass*(max_local_flow_vel**2) + (5*Te_all_upstream[my_time_pos,my_r_pos] + ionisation_potential + dissociation_potential)/eV_to_K*boltzmann_constant_J)*max_local_flow_vel*ne_all_upstream[my_time_pos,my_r_pos]*1e20
									total_removable_power_times_volume_dynamic = area*length/dt*1000*(0.5*hydrogen_mass*(max_local_flow_vel**2) + (5*Te_values + ionisation_potential + dissociation_potential)/eV_to_K*boltzmann_constant_J)*ne_values
									total_removable_power_times_volume = total_removable_power_times_volume_SS + total_removable_power_times_volume_dynamic
									total_removable_power_times_volume = np.array([[[[total_removable_power_times_volume.tolist()]*H2p_steps]*H2_steps]*Hm_steps]*H_steps,dtype=np.float32)
									if False:
										select = total_removed_power_times_volume>total_removable_power_times_volume
										power_penalty[select] = np.float32(-0.5*((total_removed_power_times_volume[select] - total_removable_power_times_volume[select])/total_removable_power_times_volume[select])**2)
									elif True:	# real formula for the probability of an inequality
										# total_removed_power_times_volume_sigma = (0.2*total_removed_power_atomic + 0.5*power_rad_mol) * area*length
										total_removed_power_times_volume_sigma = (( (power_atomic_precision**2)*(power_via_ionisation**2 + power_rad_excit**2 + power_via_recombination**2 + power_rec_neutral**2 + power_via_brem**2) + (power_molecular_precision**2)*(power_rad_Hm**2 + power_rad_H2**2 + power_rad_H2p**2))**0.5) * area*length	#this properly adds in quadrature all the uncertanties
										total_removable_power_times_volume_sigma = (total_removable_power_times_volume*power_budget_precision)
										# power_penalty = np.log( 1 + np.erf( (total_removable_power_times_volume-total_removed_power_times_volume)/(2**0.5 * (total_removed_power_times_volume_sigma**2 + (total_removable_power_times_volume*0.5)**2)**0.5)) )
										power_penalty = np.float32(np.erf( total_removed_power_times_volume/( 2**0.5 * total_removed_power_times_volume_sigma ) ))
										power_penalty += np.float32(np.erf( (total_removable_power_times_volume-total_removed_power_times_volume)/(2**0.5 * (total_removed_power_times_volume_sigma**2 + total_removable_power_times_volume_sigma**2)**0.5)))
										power_penalty = power_penalty/np.float32(0.5 + np.erf( total_removed_power_times_volume/( 2**0.5 * total_removed_power_times_volume_sigma ) ))
										power_penalty = power_penalty/np.float32(0.5 + np.erf( total_removable_power_times_volume/( 2**0.5 * total_removable_power_times_volume_sigma ) ))
										time_lapsed = tm.time()-start_time
										print('worker '+str(current_process())+' marker 1-1 '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) +' - good=%.3g, nan=%.3g, -inf=%.3g, -<0 =%.3g, min=%.3g' %( np.sum(np.isfinite(power_penalty)),np.sum(np.isnan(power_penalty)),np.sum(np.isinf(power_penalty)),np.sum(power_penalty<0) ,np.nanmin(power_penalty)) )
										power_penalty[power_penalty<0]=0
										power_penalty = np.log(power_penalty)
										# power_penalty += -np.log( 1+ np.erf( total_removed_power_times_volume/( 2**0.5 * total_removed_power_times_volume_sigma ) ) ) - np.log( 1+ np.erf( total_removable_power_times_volume/( 2**0.5 * total_removable_power_times_volume*0.5 ) ) )
										del total_removed_power_times_volume_sigma
									power_penalty -= power_penalty.max()

								nH_ne_excited_states = nH_ne_excited_states_atomic + nH_ne_excited_states_mol.reshape((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps*TS_Te_steps))
								temp = np.transpose(np.transpose(nH_ne_excited_states, (1,2,3,0,4)) > record_nH_ne_values, (3,0,1,2,4))
								nH_ne_penalty = np.zeros_like(nH_ne_excited_states,dtype=np.float16)
								nH_ne_penalty[temp==True] = -np.inf
								del temp
								nH_ne_penalty = nH_ne_penalty.reshape((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))
								nH_ne_excited_states = nH_ne_excited_states.reshape((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))
								del nH_ne_excited_states_atomic,nH_ne_excited_states_mol

								likelihood_log_probs = calculated_emission_log_probs_expanded + np.float32(Te_log_probs) + (np.ones((TS_Te_steps,TS_ne_steps),dtype=np.float32)*np.float32(ne_log_probs)).T + np.float32(np.transpose([np.float32(record_nH2_ne_log_prob).reshape((H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*(H2p_steps),(1,0,2,3)))
								likelihood_log_probs = np.transpose(np.transpose(likelihood_log_probs,(1,2,3,0,4,5)) + np.float32(record_nH_ne_log_prob.reshape((H_steps,TS_ne_steps,TS_Te_steps))) ,(3,0,1,2,4,5)) + power_penalty + nH_ne_penalty
								likelihood_log_probs -= np.max(likelihood_log_probs)
								likelihood_log_probs -= np.log(np.sum(np.exp(likelihood_log_probs)))	# normalisation for logarithmic probabilities

								del power_penalty,nH_ne_penalty

								all_nHm_ne_values = np.array([np.transpose(np.array([record_nHm_ne_values.reshape((H2_steps,Hm_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2p_steps), (2,1,0,3,4)).tolist()]*H_steps,dtype=np.float32)
								all_nH2p_ne_values = np.array([[record_nH2p_ne_values.reshape((H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)).tolist()]*Hm_steps]*H_steps,dtype=np.float32)
								# all_nHm_nH2_values = np.transpose(np.array([[[record_nHm_nH2_values.reshape((Hm_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2p_steps]*H2_steps]*H_steps,dtype=np.float32), (0,3,1,2,4,5))
								# all_nH2p_nH2_values = np.array([[[record_nH2p_nH2_values.reshape((H2p_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2_steps]*Hm_steps]*H_steps,dtype=np.float32)
								all_nH2_ne_values = np.array([[np.transpose([record_nH2_ne_values.reshape((H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2p_steps, (1,0,2,3)).tolist()]*Hm_steps]*H_steps, dtype=np.float32)
								all_nH_ne_values = np.array(np.transpose([[[record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2p_steps]*H2_steps]*Hm_steps, (3,0,1,2,4,5)), dtype=np.float32)
								all_ne_values = np.array([[[[ne_values.tolist()]*H2p_steps]*H2_steps]*Hm_steps]*H_steps,dtype=np.float32)
								all_Te_values = np.array([[[[Te_values.tolist()]*H2p_steps]*H2_steps]*Hm_steps]*H_steps,dtype=np.float32)
								all_nHp_ne_values = np.array([record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H_steps,dtype=np.float32)

								if True:
									all_H_destruction_RR = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
									all_H_creation_RR = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
									all_H2_destruction_RR = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
									if include_particles_limitation:
										all_net_Hp_destruction = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_e_destruction = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_Hm_destruction = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_H2p_destruction = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_Hp_destruction_sigma = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_e_destruction_sigma = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_Hm_destruction_sigma = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										all_net_H2p_destruction_sigma = np.zeros_like((calculated_emission_log_probs_expanded),dtype=np.float32)
										# selected_part_balance = np.zeros_like(calculated_emission_log_probs_expanded,dtype=bool)
									temp_coord = np.ones_like(nH_ne_excited_states[:,:,:,:,0,0])
									for i6 in range(TS_Te_steps):
										fractional_population_states_H2 = calc_H2_fractional_population_states(T_H2p_values[i6])
										for i5 in range(TS_ne_steps):
											temp_nH_excited_states = nH_ne_excited_states[:,:,:,:,i5,i6]*ne_values_array[i5]*1e-20
											arguments = (temp_coord*Te_values_array[i6],temp_coord*T_Hp_values[i6],temp_coord*T_H_values[i6],temp_coord*T_H2_values[i6],temp_coord*T_Hm_values[i6],temp_coord*T_H2p_values[i6],temp_coord*ne_values_array[i5]*1e-20,all_nHp_ne_values[:,:,:,:,i5,i6],all_nH_ne_values[:,:,:,:,i5,i6],all_nH2_ne_values[:,:,:,:,i5,i6],all_nHm_ne_values[:,:,:,:,i5,i6],all_nH2p_ne_values[:,:,:,:,i5,i6],fractional_population_states_H2,temp_nH_excited_states)
											temp,temp_sigma = np.float32(RR_rate_destruction_H(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
											temp1,temp1_sigma =	np.float32(RR_rate_creation_H(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
											all_H_destruction_RR[:,:,:,:,i5,i6] = np.float32(temp)/(all_nH_ne_values[:,:,:,:,i5,i6]*ne_values_array[i5]*1e-20)
											all_H_creation_RR[:,:,:,:,i5,i6] = np.float32(temp1)	# attention, this will need to be multiplied for 1e20
											# all_net_H2p_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
											temp,temp_sigma = np.float32(RR_rate_destruction_H2(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
											# temp1,temp1_sigma =	np.float32(RR_rate_creation_H(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
											all_H2_destruction_RR[:,:,:,:,i5,i6] = np.float32(temp)/(all_nH2_ne_values[:,:,:,:,i5,i6]*ne_values_array[i5]*1e-20)
											# all_net_H2p_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
											if include_particles_limitation:
												temp,temp_sigma = np.float32(RR_rate_destruction_Hp(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												temp1,temp1_sigma =	np.float32(RR_rate_creation_Hp(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												all_net_Hp_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
												all_net_Hp_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
												temp,temp_sigma = np.float32(RR_rate_destruction_e(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												temp1,temp1_sigma =	np.float32(RR_rate_creation_e(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												all_net_e_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
												all_net_e_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
												temp,temp_sigma = np.float32(RR_rate_destruction_Hm(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												temp1,temp1_sigma =	np.float32(RR_rate_creation_Hm(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												all_net_Hm_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
												all_net_Hm_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
												temp,temp_sigma = np.float32(RR_rate_destruction_H2p(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												temp1,temp1_sigma =	np.float32(RR_rate_creation_H2p(*arguments,temp_nH_excited_states,particle_molecular_precision,particle_atomic_precision))
												all_net_H2p_destruction[:,:,:,:,i5,i6] = np.float32(temp - temp1)
												all_net_H2p_destruction_sigma[:,:,:,:,i5,i6] = 0.5*(temp_sigma**2 + temp1_sigma**2)**0.5
									del temp_coord,temp,temp_sigma,temp1,temp1_sigma
								if include_particles_limitation:
									particles_penalty = np.zeros_like((likelihood_log_probs),dtype=np.float32)
									all_net_Hp_destruction *= area*length*dt/1000
									all_net_e_destruction *= area*length*dt/1000
									all_net_Hm_destruction *= area*length*dt/1000
									all_net_H2p_destruction *= area*length*dt/1000
									all_net_Hp_destruction_sigma *= area*length*dt/1000
									all_net_e_destruction_sigma *= area*length*dt/1000
									all_net_Hm_destruction_sigma *= area*length*dt/1000
									all_net_H2p_destruction_sigma *= area*length*dt/1000
									total_removable_Hp = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*max_local_flow_vel + area*length*all_ne_values*all_nHp_ne_values*1e-20)	# I assume no molecules upstream >> nH+/ne~1
									total_removable_e = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*max_local_flow_vel + area*length*all_ne_values*1e-20)
									if False:
										select = all_net_Hp_destruction>total_removable_Hp
										particles_penalty[select] += np.float32(-0.5*((all_net_Hp_destruction[select] - total_removable_Hp[select])/total_removable_Hp[select])**2)	# 100% uncertanty
										# particles_penalty[np.isnan(particles_penalty)]=-np.inf
										select = all_net_e_destruction>total_removable_e
										particles_penalty[select] += np.float32(-0.5*((all_net_e_destruction[select] - total_removable_e[select])/total_removable_e[select])**2)	# 100% uncertanty
										# particles_penalty[np.isnan(particles_penalty)]=-np.inf
									elif True:
										particles_penalty += np.log( 1 + np.erf( (total_removable_Hp-all_net_Hp_destruction)/(2**0.5 * (all_net_Hp_destruction_sigma**2 + (total_removable_Hp*particle_atomic_budget_precision)**2)**0.5)) )
										particles_penalty += np.log( 1 + np.erf( (total_removable_e-all_net_e_destruction)/(2**0.5 * (all_net_e_destruction_sigma**2 + (total_removable_e*particle_atomic_budget_precision)**2)**0.5)) )
										del all_net_Hp_destruction_sigma,all_net_e_destruction_sigma

									total_removable_Hm = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*all_nHm_ne_values*max_local_flow_vel + area*length*all_nHm_ne_values*all_ne_values*1e-20)	# I assume molecules upstream ~ downstream
									total_removable_H2p = np.float32(area*dt/1000*ne_all_upstream[my_time_pos,my_r_pos]*all_nH2p_ne_values*max_local_flow_vel + area*length*all_nH2p_ne_values*all_ne_values*1e-20)	# I assume molecules upstream ~ downstream
									if False:
										select = all_net_Hm_destruction>total_removable_Hm
										particles_penalty[select] += np.float32(-0.5*((all_net_Hm_destruction[select] - total_removable_Hm[select])/(total_removable_Hm[select]*2))**2)	# 200% uncertanty
										# particles_penalty[np.isnan(particles_penalty)]=-np.inf
										select = all_net_H2p_destruction>total_removable_H2p
										particles_penalty[select] += np.float32(-0.5*((all_net_H2p_destruction[select] - total_removable_H2p[select])/(total_removable_H2p[select]*2))**2)	# 200% uncertanty
										particles_penalty[np.isnan(particles_penalty)]=-np.inf
									elif True:
										particles_penalty += np.log( 1 + np.erf( (total_removable_Hm-all_net_Hm_destruction)/(2**0.5 * (all_net_Hm_destruction_sigma**2 + (total_removable_Hm*particle_molecular_budget_precision)**2)**0.5)) )
										particles_penalty += np.log( 1 + np.erf( (total_removable_H2p-all_net_H2p_destruction)/(2**0.5 * (all_net_H2p_destruction_sigma**2 + (total_removable_H2p*particle_molecular_budget_precision)**2)**0.5)) )
										del all_net_Hm_destruction_sigma,all_net_H2p_destruction_sigma
									particles_penalty -= np.nanmax(particles_penalty)
									# particles_penalty[np.isnan(particles_penalty)] = -np.inf

									likelihood_log_probs += particles_penalty
									likelihood_log_probs -= np.max(likelihood_log_probs)
									likelihood_log_probs -= np.log(np.sum(np.exp(likelihood_log_probs)))	# normalisation for logarithmic probabilities

									del all_nHp_ne_values
									del particles_penalty

								# new addition to calculate CX properly accounting for entering cold neutrals and exiting hot ones
								thermal_velocity_H = ( (T_H_values*boltzmann_constant_J)/ hydrogen_mass)**0.5
								CX_term_1_1 = np.float32(dr*(eff_CX_RR + all_H_destruction_RR)/(thermal_velocity_H.reshape(np.shape(Te_values))))
								CX_term_1_2 = np.float32(dr*(eff_CX_RR + all_H_destruction_RR))
								delta_t = (T_Hp_values - T_H_values)
								delta_t[delta_t<0] = 0
								CX_term_1_3 = np.float32(3/2* ((delta_t.reshape(np.shape(Te_values))) * boltzmann_constant_J)*(eff_CX_RR)/(thermal_velocity_H.reshape(np.shape(Te_values))))
								CX_term_1_4 = np.float32(np.ones_like(eff_CX_RR)/(thermal_velocity_H.reshape(np.shape(Te_values))))
								thermal_velocity_H2 = ( (T_H2_values*boltzmann_constant_J)/ (2*hydrogen_mass))**0.5
								CX_term_1_5 = np.float32(dr*(all_H2_destruction_RR)/(thermal_velocity_H2.reshape(np.shape(Te_values))))
								CX_term_1_6 = np.float32(np.ones_like(eff_CX_RR)/(thermal_velocity_H2.reshape(np.shape(Te_values))))
								CX_term_1_7 = np.float32(3/2* ((T_Hp_values.reshape(np.shape(Te_values))) * boltzmann_constant_J *1e20)*(all_H_creation_RR))
								del thermal_velocity_H,thermal_velocity_H2

								index_best_fit = calculated_emission_log_probs_expanded.argmax()
								del calculated_emission_log_probs_expanded	# I need as much memory as mpossible
								best_fit_Te_index = index_best_fit%TS_Te_steps
								best_fit_ne_index = (index_best_fit-best_fit_Te_index)//TS_Te_steps%TS_ne_steps
								best_fit_nH2p_nH2_index = ((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps%(H2p_steps)
								best_fit_nH2_ne_index = (((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_nH2_index)//(H2p_steps)%H2_steps
								best_fit_nHm_nH2_index = ((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_nH2_index)//(H2p_steps) - best_fit_nH2_ne_index)//H2_steps%(Hm_steps)
								best_fit_nH_ne_index = (((((index_best_fit-best_fit_Te_index)//TS_Te_steps-best_fit_ne_index)//TS_ne_steps-best_fit_nH2p_nH2_index)//(H2p_steps) - best_fit_nH2_ne_index)//H2_steps - best_fit_nHm_nH2_index)//(Hm_steps)%(H_steps)

								best_fit_Te_value = Te_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_ne_value = ne_values[best_fit_ne_index,best_fit_Te_index]
								best_fit_nH2p_ne_value = record_nH2p_nH2_values[best_fit_nH2p_nH2_index,best_fit_ne_index*best_fit_Te_index]*record_nH2_ne_values[best_fit_nH2_ne_index,best_fit_ne_index*best_fit_Te_index]
								best_fit_nH2_ne_value = record_nH2_ne_values[best_fit_nH2_ne_index,best_fit_ne_index*best_fit_Te_index]
								best_fit_nHm_ne_value = record_nHm_nH2_values[best_fit_nHm_nH2_index,best_fit_ne_index*best_fit_Te_index]*record_nH2_ne_values[best_fit_nH2_ne_index,best_fit_ne_index*best_fit_Te_index]
								best_fit_nH_ne_value = record_nH_ne_values[best_fit_nH_ne_index,best_fit_ne_index*best_fit_Te_index]


								index_most_likely = likelihood_log_probs.argmax()
								most_likely_Te_index = index_most_likely%TS_Te_steps
								most_likely_ne_index = (index_most_likely-most_likely_Te_index)//TS_Te_steps%TS_ne_steps
								most_likely_nH2p_nH2_index = ((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps%(H2p_steps)
								most_likely_nH2_ne_index = (((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_nH2_index)//(H2p_steps)%H2_steps
								most_likely_nHm_nH2_index = ((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_nH2_index)//(H2p_steps) - most_likely_nH2_ne_index)//H2_steps%(Hm_steps)
								most_likely_nH_ne_index = (((((index_most_likely-most_likely_Te_index)//TS_Te_steps-most_likely_ne_index)//TS_ne_steps-most_likely_nH2p_nH2_index)//(H2p_steps) - most_likely_nH2_ne_index)//H2_steps - most_likely_nHm_nH2_index)//(Hm_steps)%(H_steps)
								max_likelihood_log_prob = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]

								most_likely_Te_value = Te_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_ne_value = ne_values[most_likely_ne_index,most_likely_Te_index]
								most_likely_nH2p_ne_value = record_nH2p_nH2_values[most_likely_nH2p_nH2_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index] * record_nH2_ne_values[most_likely_nH2_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_nH2_ne_value = record_nH2_ne_values[most_likely_nH2_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_nHm_ne_value = record_nHm_nH2_values[most_likely_nHm_nH2_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index] * record_nH2_ne_values[most_likely_nH2_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_nH_ne_value = record_nH_ne_values[most_likely_nH_ne_index,most_likely_ne_index*TS_Te_steps+most_likely_Te_index]
								most_likely_T_Hm_value = np.exp(TH2_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K
								most_likely_T_H2p_value = np.exp(TH2_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K
								most_likely_T_Hp_value = most_likely_Te_value/eV_to_K	# K
								most_likely_T_H_value = np.exp(TH_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K

								most_likely_total_removable_power_times_volume = total_removable_power_times_volume[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]/area/length
								max_total_removable_power_times_volume = total_removable_power_times_volume.max()/area/length
								min_total_removable_power_times_volume = total_removable_power_times_volume.min()/area/length
								most_likely_local_CX = local_CX[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
								if include_particles_limitation:
									most_likely_net_Hp_destruction = all_net_Hp_destruction[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_total_removable_Hp = total_removable_Hp[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_net_e_destruction = all_net_e_destruction[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_total_removable_e = total_removable_e[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_net_Hm_destruction = all_net_Hm_destruction[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_total_removable_Hm = total_removable_Hm[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_net_H2p_destruction = all_net_H2p_destruction[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
									most_likely_total_removable_H2p = total_removable_H2p[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]

								# now I marginalise H2, Te, ne in order to find the most likely Hm, H2p for the next step
								hypervolume_of_each_combination = np.ones((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps*TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne*Te
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,3,4,2))	# H, Hm, H2p, ne*Te, H2
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nH2_ne_values = record_nH2_ne_values[:,i6]
									d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])
									hypervolume_of_each_combination[:,:,:,i6] *= d_nH2_ne_values/np.sum(d_nH2_ne_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,2,3,1))	# H, H2, H2p, ne*Te, Hm
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nHm_nH2_values = record_nHm_nH2_values[:,i6]
									# d_nHm_nH2_values = np.array([*np.diff(nHm_nH2_values[[0,1]]),*(np.diff(nHm_nH2_values)[:-1]/2+np.diff(nHm_nH2_values)[1:]/2),*np.diff(nHm_nH2_values[[-2,-1]])])/(np.diff(nHm_nH2_values[[0,-1]])+np.diff(nHm_nH2_values[[0,1]])/2+np.diff(nHm_nH2_values[[-2,-1]])/2)
									d_nHm_nH2_values = np.ones_like(nHm_nH2_values)
									hypervolume_of_each_combination[:,:,:,i6] *= d_nHm_nH2_values/np.sum(d_nHm_nH2_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,1,3,2))	# H, Hm, H2, ne*Te, H2p
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nH2p_nH2_values = record_nH2p_nH2_values[:,i6]
									# d_nH2p_nH2_values = np.array([*np.diff(nH2p_nH2_values[[0,1]]),*(np.diff(nH2p_nH2_values)[:-1]/2+np.diff(nH2p_nH2_values)[1:]/2),*np.diff(nH2p_nH2_values[[-2,-1]])])/(np.diff(nH2p_nH2_values[[0,-1]])+np.diff(nH2p_nH2_values[[0,1]])/2+np.diff(nH2p_nH2_values[[-2,-1]])/2)
									d_nH2p_nH2_values = np.ones_like(nH2p_nH2_values)
									hypervolume_of_each_combination[:,:,:,i6] *= d_nH2p_nH2_values/np.sum(d_nH2p_nH2_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (1,2,4,3,0))	# Hm, H2, H2p, ne*Te, H
								for i6 in range(TS_ne_steps*TS_Te_steps):
									nH_ne_values = record_nH_ne_values[:,i6]
									# d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])/(np.diff(nH_ne_values[[0,-1]])+np.diff(nH_ne_values[[0,1]])/2+np.diff(nH_ne_values[[-2,-1]])/2)
									d_nH_ne_values = np.ones_like(nH_ne_values)
									hypervolume_of_each_combination[:,:,:,i6] *= d_nH_ne_values/np.sum(d_nH_ne_values)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (4,0,1,2,3))	# H, Hm, H2, H2p, ne*Te
								hypervolume_of_each_combination = hypervolume_of_each_combination.reshape((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
								d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])
								hypervolume_of_each_combination *= d_Te_values_array/np.sum(d_Te_values_array)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, Te, ne
								d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])
								hypervolume_of_each_combination *= d_ne_values_array/np.sum(d_ne_values_array)
								hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, ne, Te

								marginalised_likelihood_log_probs = np.log(np.sum(np.exp(likelihood_log_probs)*np.float32(hypervolume_of_each_combination),axis=(2,4,5)))	# H, Hm, H2, H2p, ne, Te
								marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.max(marginalised_likelihood_log_probs)
								marginalised_likelihood_log_probs = marginalised_likelihood_log_probs-np.log(np.sum(np.exp(marginalised_likelihood_log_probs)))	# normalisation for logarithmic probabilities
								index_most_likely = marginalised_likelihood_log_probs.argmax()
								most_likely_marginalised_nH2p_nH2_index = index_most_likely%(H2p_steps)
								most_likely_marginalised_nHm_nH2_index = (index_most_likely-most_likely_marginalised_nH2p_nH2_index)//(H2p_steps)%(Hm_steps)
								most_likely_marginalised_nH_ne_index = ((index_most_likely-most_likely_marginalised_nH2p_nH2_index)//(H2p_steps)-most_likely_marginalised_nHm_nH2_index)//(Hm_steps)%(H_steps)

								# now I cannot do this, because I don't have fixed density intervals
								# most_likely_marginalised_nH2p_ne_value = nH2p_ne_values[most_likely_marginalised_nH2p_ne_index]
								# most_likely_marginalised_nHm_ne_value = nHm_ne_values[most_likely_marginalised_nHm_ne_index]
								# most_likely_marginalised_nH_ne_value = nH_ne_values[most_likely_marginalised_nH_ne_index]


								# print('best_fit_nH_ne_index %.3g,best_fit_nHm_ne_value %.3g,best_fit_nH2_ne_value %.3g,best_fit_nH2p_ne_value %.3g' %(best_fit_nH_ne_index,best_fit_nHm_ne_value,best_fit_nH2_ne_value,best_fit_nH2p_ne_value))
								time_lapsed = tm.time()-start_time
								print('worker '+str(current_process())+' marker 1 '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)) + str(np.shape(likelihood_log_probs)) +' - good=%.3g, nan=%.3g, -inf=%.3g' %(np.sum(np.isfinite(likelihood_log_probs)),np.sum(np.isnan(likelihood_log_probs)),np.sum(np.isinf(likelihood_log_probs))) )

								# Here I try to obtain the Probability Distribution Function (PDF) for the radiated power, ionisation and recombination rate
								if (collect_power_PDF or to_print):
									# Approach suggested by Christopher Bowman. integral of the full probability distribution given intervals of given power
									hypervolume_of_each_combination = np.ones((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps*TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne*Te
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,3,4,2))	# H, Hm, H2p, ne*Te, H2
									for i6 in range(TS_ne_steps*TS_Te_steps):
										nH2_ne_values = record_nH2_ne_values[:,i6]
										d_nH2_ne_values = np.array([*np.diff(nH2_ne_values[[0,1]]),*(np.diff(nH2_ne_values)[:-1]/2+np.diff(nH2_ne_values)[1:]/2),*np.diff(nH2_ne_values[[-2,-1]])])
										hypervolume_of_each_combination[:,:,:,i6] *= d_nH2_ne_values/np.sum(d_nH2_ne_values)
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,2,3,1))	# H, H2, H2p, ne*Te, Hm
									for i6 in range(TS_ne_steps*TS_Te_steps):
										nHm_nH2_values = record_nHm_nH2_values[:,i6]
										d_nHm_nH2_values = np.array([*np.diff(nHm_nH2_values[[0,1]]),*(np.diff(nHm_nH2_values)[:-1]/2+np.diff(nHm_nH2_values)[1:]/2),*np.diff(nHm_nH2_values[[-2,-1]])])
										# d_nHm_nH2_values = np.ones_like(nHm_nH2_values)
										hypervolume_of_each_combination[:,:,:,i6] *= d_nHm_nH2_values/np.sum(d_nHm_nH2_values)
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,4,1,3,2))	# H, Hm, H2, ne*Te, H2p
									for i6 in range(TS_ne_steps*TS_Te_steps):
										nH2p_nH2_values = record_nH2p_nH2_values[:,i6]
										d_nH2p_nH2_values = np.array([*np.diff(nH2p_nH2_values[[0,1]]),*(np.diff(nH2p_nH2_values)[:-1]/2+np.diff(nH2p_nH2_values)[1:]/2),*np.diff(nH2p_nH2_values[[-2,-1]])])
										# d_nH2p_nH2_values = np.ones_like(nH2p_nH2_values)
										hypervolume_of_each_combination[:,:,:,i6] *= d_nH2p_nH2_values/np.sum(d_nH2p_nH2_values)
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (1,2,4,3,0))	# Hm, H2, H2p, ne*Te, H
									for i6 in range(TS_ne_steps*TS_Te_steps):
										nH_ne_values = record_nH_ne_values[:,i6]
										d_nH_ne_values = np.array([*np.diff(nH_ne_values[[0,1]]),*(np.diff(nH_ne_values)[:-1]/2+np.diff(nH_ne_values)[1:]/2),*np.diff(nH_ne_values[[-2,-1]])])
										# d_nH_ne_values = np.ones_like(nH_ne_values)
										hypervolume_of_each_combination[:,:,:,i6] *= d_nH_ne_values/np.sum(d_nH_ne_values)
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (4,0,1,2,3))	# H, Hm, H2, H2p, ne*Te
									hypervolume_of_each_combination = hypervolume_of_each_combination.reshape((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
									d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])
									hypervolume_of_each_combination *= d_Te_values_array/np.sum(d_Te_values_array)
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, Te, ne
									d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])
									hypervolume_of_each_combination *= d_ne_values_array/np.sum(d_ne_values_array)
									hypervolume_of_each_combination = np.transpose(hypervolume_of_each_combination, (0,1,2,3,5,4))	# H, Hm, H2, H2p, ne, Te

									likelihood_probs_times_volume = np.float32(np.exp(likelihood_log_probs)*hypervolume_of_each_combination)
									likelihood_probs_times_volume = likelihood_probs_times_volume/np.sum(likelihood_probs_times_volume)
									temp = np.flip(np.sort(likelihood_probs_times_volume.flatten()),axis=0)
									likelihood_probs_times_volume_short_lim = temp[np.abs(np.cumsum(temp)-(1-1e-6)).argmin()]
									del temp
									likelihood_probs_times_volume_short_lim_select = likelihood_probs_times_volume>likelihood_probs_times_volume_short_lim
									likelihood_probs_times_volume_short = (likelihood_probs_times_volume[likelihood_probs_times_volume_short_lim_select].flatten()).astype(np.float32)
									likelihood_probs_times_volume_short = (likelihood_probs_times_volume_short/np.sum(likelihood_probs_times_volume_short)).astype(np.float32)

									if False:	# using the first iteration in calculating the power only of the best fits
										likelihood_probs = np.exp(likelihood_log_probs)
										min_fraction_of_prob_considered = max(1e-10,min(1e-4,(np.sort(likelihood_probs_times_volume.flatten())[-2000000:][0])/np.max(likelihood_probs_times_volume)))	# I select max some million samples
										# else:
										# 	min_fraction_of_prob_considered = max(1e-10,min(1e-1,(np.sort(likelihood_probs_times_volume.flatten())[-1000:][0])/np.max(likelihood_probs_times_volume)))	# I select max some million samples
										# min_fraction_of_prob_considered = 1e-10
										non_zero_prob_select = likelihood_probs_times_volume>np.max(likelihood_probs_times_volume)*min_fraction_of_prob_considered
										power_rad_excit = np.zeros_like(likelihood_probs)
										power_rad_rec_bremm = np.zeros_like(likelihood_probs)
										power_rad_mol = np.zeros_like(likelihood_probs)
										power_via_ionisation = np.zeros_like(likelihood_probs)
										power_via_recombination = np.zeros_like(likelihood_probs)
										power_rad_Hm = np.zeros_like(likelihood_probs)
										power_rad_H2 = np.zeros_like(likelihood_probs)
										power_rad_H2p = np.zeros_like(likelihood_probs)
										nH_ne_values_full,nHm_ne_values_full,nH2_ne_values_full,nH2p_ne_values_full,ne_values_full,Te_values_full = np.meshgrid(nH_ne_values,nHm_ne_values,nH2_ne_values,nH2p_ne_values,ne_values_array,Te_values_array,indexing='ij')	# H, Hm, H2, H2p, ne, Te
										# nH_ne_values_full = nH_ne_values_full[non_zero_prob_select]
										# nHm_ne_values_full = nHm_ne_values_full[non_zero_prob_select]
										# nH2_ne_values_full = nH2_ne_values_full[non_zero_prob_select]
										# nH2p_ne_values_full = nH2p_ne_values_full[non_zero_prob_select]
										# ne_values_full = ne_values_full[non_zero_prob_select]
										# Te_values_full = Te_values_full[non_zero_prob_select]
										T_Hm_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full)))/eV_to_K	# K
										T_H2p_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full)))/eV_to_K	# K
										T_Hp_values_full = Te_values_full/eV_to_K	# K


										power_rad_excit[non_zero_prob_select],power_rad_rec_bremm[non_zero_prob_select],power_rad_mol[non_zero_prob_select],power_via_ionisation[non_zero_prob_select],power_via_recombination[non_zero_prob_select],power_rad_Hm[non_zero_prob_select],power_rad_H2[non_zero_prob_select],power_rad_H2p[non_zero_prob_select] = calc_power_balance_elements(Te_values_full[non_zero_prob_select],ne_values_full[non_zero_prob_select],nH_ne_values_full[non_zero_prob_select],nHm_ne_values_full[non_zero_prob_select],nH2p_ne_values_full[non_zero_prob_select],nH2_ne_values_full[non_zero_prob_select],T_Hp_values_full[non_zero_prob_select],T_Hm_values_full[non_zero_prob_select],T_H2p_values_full[non_zero_prob_select])
									else:	# calculate the power of every combination, but much faster
										min_fraction_of_prob_considered = 0
										non_zero_prob_select = likelihood_probs_times_volume>1*min_fraction_of_prob_considered
										likelihood_probs_times_volume_usefull = likelihood_probs_times_volume[non_zero_prob_select]
										# power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination,power_rad_Hm,power_rad_H2,power_rad_H2p = calc_power_balance_elements_simplified(nH_ne_values,nHm_ne_values,nH2_ne_values,nH2p_ne_values,ne_values_array,Te_values_array,Te_values,ne_values,T_Hm_values,T_H2p_values,T_Hp_values)

										# this now gets calculate right after the emission andconsidered in the likelyhood
										# total_wavelengths = np.unique(excited_states_From_Hn_with_Hp)
										# power_rad_H2p = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										# coeff_1 = (From_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										# power_rad_H2p = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										# power_rad_H2p = power_rad_H2p + np.sum((coeff_1 * multiplicative_factor_full_full),axis=-1) * (ne_values**2)
										# power_rad_H2p = np.float32(power_rad_H2p * (record_nH2p_ne_values.reshape(H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)))	# H, Hm, H2, H2p, ne, Te
										# # coeff_1 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2p))))
										# coeff_2 = (From_H2_pop_coeff_full_extra(np.array([Te_values.flatten(),ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										# power_rad_H2 = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										# power_rad_H2 = power_rad_H2 + np.sum((coeff_2 * multiplicative_factor_full_full),axis=-1) * (ne_values**2)
										# power_rad_H2 = np.float32(power_rad_H2 * np.transpose([(record_nH2_ne_values.reshape(H2_steps,TS_ne_steps,TS_Te_steps)).tolist()]*(H2p_steps), (1,0,2,3)))	# H, Hm, H2, H2p, ne, Te
										# # total_nH2_ne_value = []
										# # for i4,nH2_ne_value in enumerate(nH2_ne_values):
										# # 	total_nH2_ne_value.append( coeff_2 *  nH2_ne_value)
										# # 	# total_nH2_ne_value = nH2_ne_value * coeff_2
										# # total_nH2_ne_value = np.array(total_nH2_ne_value)
										# # total_nH2_ne_value = np.sum(total_nH2_ne_value*multiplicative_factor_full_full, axis=-1)
										# # power_rad_H2 = np.transpose(np.zeros_like(power_rad_excit), (0,1,3,2,4,5))	# H, Hm, H2p, H2, ne, Te
										# # power_rad_H2 += total_nH2_ne_value
										# # power_rad_H2 = np.transpose(power_rad_H2, (0,1,3,2,4,5))	# H, Hm, H2, H2p, ne, Te
										# # coeff_2 = coeff_1.reshape((*np.shape(Te_values),len(np.unique(excited_states_From_H2))))
										# power_rad_excit = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										# total_power_rad_excit = (read_adf11(pltfile, 'plt', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
										# power_rad_excit = power_rad_excit + total_power_rad_excit
										# power_rad_excit = np.float32(np.transpose(power_rad_excit, (1,2,3,0,4,5)) * record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)))	# Hm, H2, H2p, H, ne, Te
										# power_rad_excit = np.transpose(power_rad_excit, (3,0,1,2,4,5))	# H, Hm, H2, H2p, ne, Te
										# power_via_ionisation = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))	# H, Hm, H2, H2p, ne, Te
										# total_power_via_ionisation = (read_adf11(scdfile, 'scd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
										# power_via_ionisation = power_via_ionisation + total_power_via_ionisation
										# power_via_ionisation = np.float32(np.transpose(power_via_ionisation, (1,2,3,0,4,5)) * record_nH_ne_values.reshape((H_steps,TS_ne_steps,TS_Te_steps)))	# Hm, H2, H2p, H, ne, Te
										# power_via_ionisation = np.transpose(power_via_ionisation, (3,0,1,2,4,5))	# H, Hm, H2, H2p, ne, Te
										# total_power_rad_rec_bremm = (read_adf11(prbfile, 'prb', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2)).reshape((TS_ne_steps,TS_Te_steps))
										# power_rad_rec_bremm = np.float32([(total_power_rad_rec_bremm * record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))).tolist()]*(H_steps))
										# total_power_via_recombination = (read_adf11(acdfile, 'acd', 1, 1, 1, Te_values.flatten(),ne_values.flatten() * 10 ** (0 - 6)) * (10 ** -6) * (ne_values.flatten()**2) *13.6/J_to_eV).reshape((TS_ne_steps,TS_Te_steps))
										# power_via_recombination = np.float32([(total_power_via_recombination * record_nHp_ne_values.reshape((Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps))).tolist()]*(H_steps))
										# power_via_brem =  np.float32([(record_nHp_ne_values.reshape(Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps) * 5.35*1e-37 * (Te_values/1000)**0.5 * (ne_values**2)).tolist()]*H_steps)
										# power_rad_Hm = np.zeros((H_steps,Hm_steps,H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps),dtype=np.float32)	# H, Hm, H2, H2p, ne, Te
										# power_rec_neutral = (power_via_recombination/13.6*Te_values).astype(np.float32)	# power removed from plasma column due to recombination by the kinetic energy of the neutral (assuming Te=TH+)
										#
										#
										# for i4 in range(H2_steps):
										# 	for i5 in range(H2p_steps):
										# 		nH2p_ne_values = record_nH2p_ne_values[i4,i5]
										# 		coeff_4 = (From_Hn_with_H2p_pop_coeff_full_extra(np.array([Te_values.flatten(),T_H2p_values,T_Hm_values,ne_values.flatten(),nH2p_ne_values*ne_values.flatten()]).T,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										# 		coeff_4 = np.sum((coeff_4 * multiplicative_factor_full_full),axis=-1)*(ne_values**2)
										# 		for i3 in range(Hm_steps):
										# 			nHm_ne_values = record_nHm_ne_values[i4,i3]
										# 			nHp_ne_values = 1 - nH2p_ne_values + nHm_ne_values
										# 			nHp_ne_good = nHp_ne_values>0
										# 			nHp_ne_mid = nHp_ne_values==0
										# 			nHp_ne_bad = nHp_ne_values<0
										# 			nHp_ne_values[nHp_ne_mid]=1e-10
										# 			nHp_ne_values[nHp_ne_bad]=1e-10
										# 			# temp = From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten()[nHp_ne_good],T_Hp_values[nHp_ne_good],T_Hm_values[nHp_ne_good],ne_values.flatten()[nHp_ne_good],nHp_ne_values[nHp_ne_good]*(ne_values.flatten()[nHp_ne_good])]).T ,total_wavelengths)
										# 			# coeff_3 = np.zeros((TS_ne_steps*TS_Te_steps,len(total_wavelengths)))
										# 			# coeff_3[nHp_ne_good] = temp
										# 			# coeff_3 = coeff_3.reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										# 			coeff_3 = (From_Hn_with_Hp_pop_coeff_full_extra(np.array([Te_values.flatten(),T_Hp_values,T_Hm_values,ne_values.flatten(),nHp_ne_values*(ne_values.flatten())]).T ,total_wavelengths)).reshape((TS_ne_steps,TS_Te_steps,len(total_wavelengths)))
										# 			coeff_3 = np.sum((coeff_3 * multiplicative_factor_full_full),axis=-1) *(ne_values**2)
										# 			coeff_3[(np.logical_and(nHp_ne_mid,nHp_ne_bad)).reshape((TS_ne_steps,TS_Te_steps))]=0
										# 			nHp_ne_good = np.logical_or(nHp_ne_good,nHp_ne_mid).reshape((TS_ne_steps,TS_Te_steps))
										# 			power_rad_Hm[:,i3,i4,i5,nHp_ne_good] = (nHm_ne_values.reshape((TS_ne_steps,TS_Te_steps))*( coeff_3 + coeff_4 )).astype(np.float32)[nHp_ne_good]
										# power_rad_mol = (power_rad_Hm + power_rad_H2 + power_rad_H2p).astype(np.float32)
										# power_heating_rec = (power_via_recombination - power_rad_rec_bremm + power_via_brem).astype(np.float32)
										# # power_heating_rec[power_heating_rec<0]=0
										#
										# effective_ionisation_rates = power_via_ionisation/13.6*J_to_eV
										# effective_recombination_rates = power_via_recombination/13.6*J_to_eV
										# tot_rad_power = (power_rad_excit+power_rad_rec_bremm+power_rad_mol).astype(np.float32)

									time_lapsed = tm.time()-start_time
									print('worker '+str(current_process())+' marker 2 '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_lapsed/60),int(time_lapsed%60)))

									PDF_intervals = 20

									def build_log_PDF(power,PDF_intervals,use_all=True,treshold_ratio=1.3):
										# d_power = min(np.diff(np.log10(np.sort(power[power>0].flatten())[[0,-1]]))/PDF_intervals,0.5)
										if use_all:
											# num_samples = len(power.flatten())
											# power_values = np.sort(power.flatten())[(np.arange(PDF_intervals)*num_samples/PDF_intervals).astype(int)]
											power_short = (power[likelihood_probs_times_volume_short_lim_select].flatten()).astype(np.float32)
											sorted_prob = (np.array([to_sort for _, to_sort in sorted(zip(power_short, likelihood_probs_times_volume_short))])).astype(np.float32)
											sorted_prob = (sorted_prob/np.sum(sorted_prob)).astype(np.float32)
											# print('1')
											power_values = (np.sort(power_short.flatten())).astype(np.float32)
											treshold = 1/10000
											temp = (np.cumsum(sorted_prob)).astype(np.float32)
											# print('2')
											temp1=[]
											temp2 = []
											prev_loc=0
											for i in range(0,10000):
												loc = np.abs(temp-(treshold*i+treshold/2)).argmin()
												temp1.append(power_values[loc])
												if i==0:
													temp2.append(temp[loc])
												else:
													temp2.append(temp[loc]-temp[prev_loc])
												prev_loc=loc
											# temp1.append(power_values[-1])
											# temp2.append(temp[-1]-np.sum(temp2))
											power_values = np.array(temp1)
											sorted_prob = np.array(temp2)
										else:
											num_samples = np.sum(non_zero_prob_select)
											power_values = np.sort(power[non_zero_prob_select])[(np.arange(PDF_intervals)*num_samples/PDF_intervals).astype(int)]
										# power_values = power_values[power_values>0]
										# print('3')
										done=0
										limit = len(power_values)*2
										while (done==0 and limit>0):
											limit-=1
											if limit==1:
												print('failed PDF building in t=%.3g, r=%.3g' %(my_time_pos,my_r_pos))
											for i in range(len(power_values)-1):
												# print(power_values)
												# if (power_values[i+1]/power_values[i]<1.1 and len(power_values)>3):
												if power_values[i]>=0 and power_values[i+1]>=0:
													if power_values[i]!=0 and power_values[i+1]!=0:
														if ((power_values[i+1]/power_values[i]<treshold_ratio or sorted_prob[i]<1e-30) and len(power_values)>PDF_intervals):
															power_values = np.concatenate((power_values[:i+1],power_values[i+2:]))
															sorted_prob = np.concatenate((sorted_prob[:i],[np.sum(sorted_prob[i:i+2])],sorted_prob[i+2:]))
															break
												elif power_values[i]<0 and power_values[i+1]<0:
													if power_values[i]!=0 and power_values[i+1]!=0:
														if ((power_values[i]/power_values[i+1]<treshold_ratio or sorted_prob[i]<1e-30) and len(power_values)>PDF_intervals):
															power_values = np.concatenate((power_values[:i+1],power_values[i+2:]))
															sorted_prob = np.concatenate((sorted_prob[:i],[np.sum(sorted_prob[i:i+2])],sorted_prob[i+2:]))
															break
												if i==len(power_values)-2:
													done=1
										# power_values = [*power_values[:-1][power_values[1:]/power_values[:-1]>1.05],power_values[-1]]
										# log_power = np.log10(power)
										# low_point = np.max(log_power)-d_power*PDF_intervals
										# log_power_values = np.array([-np.inf,*np.linspace(low_point,np.max(log_power),num=PDF_intervals)])
										power_usefull = power[non_zero_prob_select]
										temp = power_usefull[power_usefull>0]
										if len(temp)==0:
											power_values = np.array([0,np.min(power_usefull),*power_values,np.max(power_usefull)])
										else:
											power_values = np.array([0,np.min(power_usefull),np.min(power_usefull[power_usefull>0]),*power_values,np.max(power_usefull)])
										power_values = np.unique(power_values)
										prob_power = []
										actual_values_power = []
										for index in range(len(power_values)-1):
											if index==0:
												select = np.logical_and(power_usefull>=power_values[index],power_usefull<=power_values[index+1])
											else:
												select = np.logical_and(power_usefull>power_values[index],power_usefull<=power_values[index+1])
											temp1 = power_usefull[select]
											temp2 = likelihood_probs_times_volume_usefull[select]
											if np.sum(select)==0:
												prob_power.append(0)
												actual_values_power.append(np.mean([power_values[index],power_values[index+1]]))
											else:
												prob_power.append(np.sum(temp2))
												temp = np.sum(temp2*temp1)/np.sum(prob_power[-1])
												if np.isnan(temp):
													actual_values_power.append(np.nanmean(temp1))
												else:
													actual_values_power.append(temp)
										prob_power = np.array(prob_power)/np.sum(prob_power)
										actual_values_power = np.array(actual_values_power)
										# print('4')
										return power_values,prob_power,actual_values_power

									intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit = build_log_PDF(power_rad_excit,PDF_intervals)
									intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm = build_log_PDF(power_rad_rec_bremm,PDF_intervals)
									intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol = build_log_PDF(power_rad_mol,PDF_intervals)
									intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation = build_log_PDF(power_via_ionisation,PDF_intervals)
									intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination = build_log_PDF(power_via_recombination,PDF_intervals)
									intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power = build_log_PDF(tot_rad_power,PDF_intervals)
									intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm = build_log_PDF(power_rad_Hm,PDF_intervals)
									intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2 = build_log_PDF(power_rad_H2,PDF_intervals)
									intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p = build_log_PDF(power_rad_H2p,PDF_intervals)
									intervals_power_heating_rec,prob_power_heating_rec,actual_values_power_heating_rec = build_log_PDF(power_heating_rec,PDF_intervals)
									intervals_power_rec_neutral,prob_power_rec_neutral,actual_values_power_rec_neutral = build_log_PDF(power_rec_neutral,PDF_intervals)
									intervals_power_via_brem,prob_power_via_brem,actual_values_power_via_brem = build_log_PDF(power_via_brem,PDF_intervals)
									intervals_total_removed_power,prob_total_removed_power,actual_values_total_removed_power = build_log_PDF(total_removed_power,PDF_intervals)
									intervals_nH_ne_excited_states,prob_nH_ne_excited_states,actual_values_nH_ne_excited_states = build_log_PDF(nH_ne_excited_states,PDF_intervals)
									intervals_ne_values,prob_ne_values,actual_values_ne_values = build_log_PDF(all_ne_values,PDF_intervals,treshold_ratio=1.05)
									intervals_Te_values,prob_Te_values,actual_values_Te_values = build_log_PDF(all_Te_values,PDF_intervals,treshold_ratio=1.05)
									all_nHm_ne_values = np.array([np.transpose(np.array([record_nHm_ne_values.reshape((H2_steps,Hm_steps,TS_ne_steps,TS_Te_steps)).tolist()]*H2p_steps), (2,1,0,3,4)).tolist()]*H_steps,dtype=np.float32)
									intervals_nHm_ne_values,prob_nHm_ne_values,actual_values_nHm_ne_values = build_log_PDF(all_nHm_ne_values,PDF_intervals)
									del all_nHm_ne_values
									all_nH2p_ne_values = np.array([[record_nH2p_ne_values.reshape((H2_steps,H2p_steps,TS_ne_steps,TS_Te_steps)).tolist()]*Hm_steps]*H_steps,dtype=np.float32)
									intervals_nH2p_ne_values,prob_nH2p_ne_values,actual_values_nH2p_ne_values = build_log_PDF(all_nH2p_ne_values,PDF_intervals)
									del all_nH2p_ne_values
									intervals_nH2_ne_values,prob_nH2_ne_values,actual_values_nH2_ne_values = build_log_PDF(all_nH2_ne_values,PDF_intervals)
									intervals_nH_ne_values,prob_nH_ne_values,actual_values_nH_ne_values = build_log_PDF(all_nH_ne_values,PDF_intervals)
									if include_particles_limitation:
										intervals_net_e_destruction,prob_net_e_destruction,actual_values_net_e_destruction = build_log_PDF(all_net_e_destruction,PDF_intervals)
										intervals_net_Hp_destruction,prob_net_Hp_destruction,actual_values_net_Hp_destruction = build_log_PDF(all_net_Hp_destruction,PDF_intervals)
										intervals_net_Hm_destruction,prob_net_Hm_destruction,actual_values_net_Hm_destruction = build_log_PDF(all_net_Hm_destruction,PDF_intervals)
										intervals_net_H2p_destruction,prob_net_H2p_destruction,actual_values_net_H2p_destruction = build_log_PDF(all_net_H2p_destruction,PDF_intervals)
									else:
										intervals_net_e_destruction,prob_net_e_destruction,actual_values_net_e_destruction = [[0],[0],[0]]
										intervals_net_Hp_destruction,prob_net_Hp_destruction,actual_values_net_Hp_destruction = [[0],[0],[0]]
										intervals_net_Hm_destruction,prob_net_Hm_destruction,actual_values_net_Hm_destruction = [[0],[0],[0]]
										intervals_net_H2p_destruction,prob_net_H2p_destruction,actual_values_net_H2p_destruction = [[0],[0],[0]]
									intervals_H_destruction_RR,prob_H_destruction_RR,actual_values_H_destruction_RR = build_log_PDF(all_H_destruction_RR,PDF_intervals)
									del all_H_destruction_RR
									intervals_H2_destruction_RR,prob_H2_destruction_RR,actual_values_H2_destruction_RR = build_log_PDF(all_H2_destruction_RR,PDF_intervals)
									del all_H2_destruction_RR
									intervals_local_CX,prob_local_CX,actual_values_local_CX = build_log_PDF(local_CX,PDF_intervals)
									intervals_eff_CX_RR,prob_eff_CX_RR,actual_values_eff_CX_RR = build_log_PDF(eff_CX_RR,PDF_intervals)
									del eff_CX_RR
									intervals_CX_term_1_1,prob_CX_term_1_1,actual_values_CX_term_1_1 = build_log_PDF(CX_term_1_1,PDF_intervals)
									del CX_term_1_1
									intervals_CX_term_1_2,prob_CX_term_1_2,actual_values_CX_term_1_2 = build_log_PDF(CX_term_1_2,PDF_intervals)
									del CX_term_1_2
									intervals_CX_term_1_3,prob_CX_term_1_3,actual_values_CX_term_1_3 = build_log_PDF(CX_term_1_3,PDF_intervals)
									del CX_term_1_3
									intervals_CX_term_1_4,prob_CX_term_1_4,actual_values_CX_term_1_4 = build_log_PDF(CX_term_1_4,PDF_intervals)
									del CX_term_1_4
									intervals_CX_term_1_5,prob_CX_term_1_5,actual_values_CX_term_1_5 = build_log_PDF(CX_term_1_5,PDF_intervals)
									del CX_term_1_5
									intervals_CX_term_1_6,prob_CX_term_1_6,actual_values_CX_term_1_6 = build_log_PDF(CX_term_1_6,PDF_intervals)
									del CX_term_1_6
									intervals_CX_term_1_7,prob_CX_term_1_7,actual_values_CX_term_1_7 = build_log_PDF(CX_term_1_7,PDF_intervals)
									del CX_term_1_7
									intervals_H_creation_RR,prob_H_creation_RR,actual_values_H_creation_RR = build_log_PDF(np.float64(all_H_creation_RR)*1e20,PDF_intervals)
									del all_H_creation_RR
									# power_balance_data = [intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit, intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm, intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol, intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation, intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination, intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power,intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm,intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2,intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p,intervals_power_heating_rec,prob_power_heating_rec,actual_values_power_heating_rec,intervals_power_rec_neutral,prob_power_rec_neutral,actual_values_power_rec_neutral,intervals_power_via_brem,prob_power_via_brem,actual_values_power_via_brem,intervals_total_removed_power,prob_total_removed_power,actual_values_total_removed_power]
									# real_prob_ne = np.sum(likelihood_probs_times_volume,axis=(0,1,2,3,5))	# H, Hm, H2, H2p, ne, Te
									# real_prob_Te = np.sum(likelihood_probs_times_volume,axis=(0,1,2,3,4))	# H, Hm, H2, H2p, ne, Te
									# real_prob_nH_ne = np.sum(likelihood_probs_times_volume,axis=(1,2,3,4,5))	# H, Hm, H2, H2p, ne, Te
									# real_prob_nH2_ne = np.sum(likelihood_probs_times_volume,axis=(0,1,3,4,5))	# H, Hm, H2, H2p, ne, Te
								else:
									intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit = [[0],[0],[0]]
									intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm = [[0],[0],[0]]
									intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol = [[0],[0],[0]]
									intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation = [[0],[0],[0]]
									intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination = [[0],[0],[0]]
									intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power = [[0],[0],[0]]
									intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm = [[0],[0],[0]]
									intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2 = [[0],[0],[0]]
									intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p = [[0],[0],[0]]
									intervals_power_heating_rec,prob_power_heating_rec,actual_values_power_heating_rec = [[0],[0],[0]]
									intervals_power_rec_neutral,prob_power_rec_neutral,actual_values_power_rec_neutral = [[0],[0],[0]]
									intervals_power_via_brem,prob_power_via_brem,actual_values_power_via_brem = [[0],[0],[0]]
									intervals_total_removed_power,prob_total_removed_power,actual_values_total_removed_power = [[0],[0],[0]]
									intervals_nH_ne_excited_states,prob_nH_ne_excited_states,actual_values_nH_ne_excited_states = [[0],[0],[0]]
									intervals_ne_values,prob_ne_values,actual_values_ne_values = [[0],[0],[0]]
									intervals_Te_values,prob_Te_values,actual_values_Te_values = [[0],[0],[0]]
									intervals_nHm_ne_values,prob_nHm_ne_values,actual_values_nHm_ne_values = [[0],[0],[0]]
									intervals_nH2p_ne_values,prob_nH2p_ne_values,actual_values_nH2p_ne_values = [[0],[0],[0]]
									intervals_nH2_ne_values,prob_nH2_ne_values,actual_values_nH2_ne_values = [[0],[0],[0]]
									intervals_nH_ne_values,prob_nH_ne_values,actual_values_nH_ne_values = [[0],[0],[0]]
									intervals_net_e_destruction,prob_net_e_destruction,actual_values_net_e_destruction = [[0],[0],[0]]
									intervals_net_Hp_destruction,prob_net_Hp_destruction,actual_values_net_Hp_destruction = [[0],[0],[0]]
									intervals_net_Hm_destruction,prob_net_Hm_destruction,actual_values_net_Hm_destruction = [[0],[0],[0]]
									intervals_net_H2p_destruction,prob_net_H2p_destruction,actual_values_net_H2p_destruction = [[0],[0],[0]]
									intervals_H_destruction_RR,prob_H_destruction_RR,actual_values_H_destruction_RR = [[0],[0],[0]]
									intervals_H2_destruction_RR,prob_H2_destruction_RR,actual_values_H2_destruction_RR = [[0],[0],[0]]
									intervals_local_CX,prob_local_CX,actual_values_local_CX = [[0],[0],[0]]
									intervals_eff_CX_RR,prob_eff_CX_RR,actual_values_eff_CX_RR = [[0],[0],[0]]
									intervals_CX_term_1_1,prob_CX_term_1_1,actual_values_CX_term_1_1 = [[0],[0],[0]]
									intervals_CX_term_1_2,prob_CX_term_1_2,actual_values_CX_term_1_2 = [[0],[0],[0]]
									intervals_CX_term_1_3,prob_CX_term_1_3,actual_values_CX_term_1_3 = [[0],[0],[0]]
									intervals_CX_term_1_4,prob_CX_term_1_4,actual_values_CX_term_1_4 = [[0],[0],[0]]
									intervals_CX_term_1_5,prob_CX_term_1_5,actual_values_CX_term_1_5 = [[0],[0],[0]]
									intervals_CX_term_1_6,prob_CX_term_1_6,actual_values_CX_term_1_6 = [[0],[0],[0]]
									intervals_CX_term_1_7,prob_CX_term_1_7,actual_values_CX_term_1_7 = [[0],[0],[0]]
									intervals_H_creation_RR,prob_H_creation_RR,actual_values_H_creation_RR = [[0],[0],[0]]
								power_balance_data = [intervals_power_rad_excit,prob_power_rad_excit,actual_values_power_rad_excit, intervals_power_rad_rec_bremm,prob_power_rad_rec_bremm,actual_values_power_rad_rec_bremm, intervals_power_rad_mol,prob_power_rad_mol,actual_values_power_rad_mol, intervals_power_via_ionisation,prob_power_via_ionisation,actual_values_power_via_ionisation, intervals_power_via_recombination,prob_power_via_recombination,actual_values_power_via_recombination, intervals_tot_rad_power,prob_tot_rad_power,actual_values_tot_rad_power,intervals_power_rad_Hm,prob_power_rad_Hm,actual_values_power_rad_Hm,intervals_power_rad_H2,prob_power_rad_H2,actual_values_power_rad_H2,intervals_power_rad_H2p,prob_power_rad_H2p,actual_values_power_rad_H2p,intervals_power_heating_rec,prob_power_heating_rec,actual_values_power_heating_rec,intervals_power_rec_neutral,prob_power_rec_neutral,actual_values_power_rec_neutral,intervals_power_via_brem,prob_power_via_brem,actual_values_power_via_brem,intervals_total_removed_power,prob_total_removed_power,actual_values_total_removed_power,intervals_nH_ne_excited_states,prob_nH_ne_excited_states,actual_values_nH_ne_excited_states,intervals_ne_values,prob_ne_values,actual_values_ne_values,intervals_Te_values,prob_Te_values,actual_values_Te_values,intervals_nHm_ne_values,prob_nHm_ne_values,actual_values_nHm_ne_values,intervals_nH2p_ne_values,prob_nH2p_ne_values,actual_values_nH2p_ne_values,intervals_nH2_ne_values,prob_nH2_ne_values,actual_values_nH2_ne_values,intervals_nH_ne_values,prob_nH_ne_values,actual_values_nH_ne_values,intervals_net_e_destruction,prob_net_e_destruction,actual_values_net_e_destruction,intervals_net_Hp_destruction,prob_net_Hp_destruction,actual_values_net_Hp_destruction,intervals_net_Hm_destruction,prob_net_Hm_destruction,actual_values_net_Hm_destruction,intervals_net_H2p_destruction,prob_net_H2p_destruction,actual_values_net_H2p_destruction,intervals_local_CX,prob_local_CX,actual_values_local_CX,intervals_H_destruction_RR,prob_H_destruction_RR,actual_values_H_destruction_RR,intervals_eff_CX_RR,prob_eff_CX_RR,actual_values_eff_CX_RR,intervals_H2_destruction_RR,prob_H2_destruction_RR,actual_values_H2_destruction_RR,intervals_CX_term_1_1,prob_CX_term_1_1,actual_values_CX_term_1_1,intervals_CX_term_1_2,prob_CX_term_1_2,actual_values_CX_term_1_2,intervals_CX_term_1_3,prob_CX_term_1_3,actual_values_CX_term_1_3,intervals_CX_term_1_4,prob_CX_term_1_4,actual_values_CX_term_1_4,intervals_CX_term_1_5,prob_CX_term_1_5,actual_values_CX_term_1_5,intervals_CX_term_1_6,prob_CX_term_1_6,actual_values_CX_term_1_6,intervals_CX_term_1_7,prob_CX_term_1_7,actual_values_CX_term_1_7,intervals_H_creation_RR,prob_H_creation_RR,actual_values_H_creation_RR]

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# here I find the plame that contains the most of the high probability points
											nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])
											temp = np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp=temp.flatten()
											fit1 = curve_fit(line,nH2p_ne_values_full.flatten()[temp>0],nHm_ne_values_full.flatten()[temp>0],p0=[1,1],sigma=(1/(temp[temp>0])).flatten())[0]

											nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],indexing='ij')
											temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp=temp.flatten()
											def find_correlation(params):
												calc = line_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum((((nHm_ne_values_full-calc).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))/(np.sum((((nHm_ne_values_full-np.mean(nHm_ne_values_full)).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))
												return diff
											x_scale = np.abs(np.array([1e-3,fit1[0],fit1[1]]))
											x_scale[x_scale==0]=1e-6
											sol_line = least_squares(find_correlation,[0,fit1[0],fit1[1]],max_nfev=10000,x_scale=x_scale)
											R2_sol_line = 1-find_correlation(sol_line.x)

											def find_correlation(params):
												calc = parabola_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum((((nHm_ne_values_full-calc).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))/(np.sum((((nHm_ne_values_full-np.mean(nHm_ne_values_full)).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))
												return diff
											x_scale = np.abs(np.array([1e-3,sol_line.x[0],1e-3,sol_line.x[1],sol_line.x[2]]))
											x_scale[x_scale==0]=1e-6
											sol_parab = least_squares(find_correlation,[0,sol_line.x[0],0,sol_line.x[1],sol_line.x[2]],max_nfev=10000,x_scale=x_scale)
											R2_sol_parab = 1-find_correlation(sol_parab.x)

											nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(np.arange(H2p_steps),np.arange(Hm_steps))
											temp = np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,:,:])
											temp=temp.flatten()
											fit1 = curve_fit(line,nH2p_ne_values_full.flatten()[temp>0],nHm_ne_values_full.flatten()[temp>0],p0=[1,1],sigma=(1/(temp[temp>0])).flatten())[0]

											nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full = np.meshgrid(np.arange(H_steps),np.arange(Hm_steps),np.arange(H2p_steps),indexing='ij')
											temp = np.exp(marginalised_likelihood_log_probs[:,:,:])
											temp=temp.flatten()
											def find_correlation(params):
												calc = line_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum((((nHm_ne_values_full-calc).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))/(np.sum((((nHm_ne_values_full-np.mean(nHm_ne_values_full)).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))
												return diff
											x_scale = np.abs(np.array([1e-3,fit1[0],fit1[1]]))
											x_scale[x_scale==0]=1e-6
											marginalised_sol_line = least_squares(find_correlation,[0,fit1[0],fit1[1]],max_nfev=10000,x_scale=x_scale)
											R2_marginalised_sol_line = 1-find_correlation(marginalised_sol_line.x)

											def find_correlation(params):
												calc = parabola_3D(nH_ne_values_full,nH2p_ne_values_full,*params)
												diff = (np.sum((((nHm_ne_values_full-calc).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))/(np.sum((((nHm_ne_values_full-np.mean(nHm_ne_values_full)).flatten()*temp)**2)[temp>0])/np.sum(temp[temp>0]**2))
												return diff
											x_scale = np.abs(np.array([1e-3,sol_line.x[0],1e-3,sol_line.x[1],sol_line.x[2]]))
											x_scale[x_scale==0]=1e-6
											marginalised_sol_parab = least_squares(find_correlation,[0,marginalised_sol_line.x[0],0,marginalised_sol_line.x[1],marginalised_sol_line.x[2]],max_nfev=10000,x_scale=x_scale)
											R2_marginalised_sol_parab = 1-find_correlation(marginalised_sol_parab.x)


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											print('worker '+str(current_process())+' '+str(domain_index)+' first scan best_fit_nH_ne_value %.3g,best_fit_nHm_ne_value %.3g,best_fit_nH2_ne_value %.3g,best_fit_nH2p_ne_value %.3g' %(best_fit_nH_ne_value,best_fit_nHm_ne_value,best_fit_nH2_ne_value,best_fit_nH2p_ne_value))
											# tm.sleep(np.random.random()*10)
											print('First scan\nmost_likely_nH_ne_index %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g,most_likely_Te_value %.3g,most_likely_ne_value %.3g' %(most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value,most_likely_Te_value,most_likely_ne_value))
											fig, ax = plt.subplots( 4,2,figsize=(20, 45), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best index: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_nH2_index,most_likely_marginalised_nH2p_nH2_index))
											plot_index = 0
											im = ax[plot_index,0].plot(range(TS_Te_steps)-most_likely_Te_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,:]),label='Te');
											im = ax[plot_index,0].plot(range(TS_ne_steps)-most_likely_ne_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,:,most_likely_Te_index]),label='ne');
											im = ax[plot_index,0].plot(range(H2p_steps)-most_likely_nH2p_nH2_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),label='nH2+/ne');
											im = ax[plot_index,0].plot(range(H2_steps)-most_likely_nH2_ne_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,:,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]),label='nH2/ne');
											im = ax[plot_index,0].plot(range(Hm_steps)-most_likely_nHm_nH2_index,np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]),label='nH-/ne');
											im = ax[plot_index,0].plot(range(H_steps)-most_likely_nH_ne_index,np.exp(likelihood_log_probs[:,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]),label='nH/ne');
											ax[plot_index,0].set_title('Likelihood around the best')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('range used for search')
											ax[plot_index,0].legend(loc='best')
											# ax[plot_index].set_xscale('log')
											# ax[plot_index,0].set_yscale('log')
											# ax[plot_index,0].set_ylim(bottom=np.exp(max_likelihood_log_prob)*1e-2,top=np.exp(max_likelihood_log_prob)*1.1)

											im = ax[plot_index,1].plot(range(H2p_steps)-most_likely_marginalised_nH2p_nH2_index,np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_nH2_index,:]),label='nH2+/ne');
											im = ax[plot_index,1].plot(range(Hm_steps)-most_likely_marginalised_nHm_nH2_index,np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,:,most_likely_marginalised_nH2p_nH2_index]),label='nH-/ne');
											im = ax[plot_index,1].plot(range(H_steps)-most_likely_marginalised_nH_ne_index,np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_nH2_index,most_likely_marginalised_nH2p_nH2_index]),label='nH/ne');
											ax[plot_index,1].set_title('Marginalised likelihood around the best')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('range used for search')
											ax[plot_index,1].legend(loc='best')
											# ax[plot_index].set_xscale('log')
											# ax[plot_index,1].set_yscale('log')
											# ax[plot_index,1].set_ylim(bottom=np.exp(np.max(marginalised_likelihood_log_probs))*1e-2,top=np.exp(np.max(marginalised_likelihood_log_probs))*1.1)

											plot_index += 1
											im = ax[plot_index,0].contourf(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10);
											# im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nHm_ne_value,color='k',marker='$M$',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nHm_ne_value,color='k',marker='$X$',markersize=30);
											# im = ax[plot_index,0].plot(first_most_likely_marginalised_nH2p_ne_value,first_most_likely_marginalised_nHm_ne_value,color='y',marker='$M$',markersize=15);
											im = ax[plot_index,0].plot(first_most_likely_nH2p_ne_value,first_most_likely_nHm_ne_value,color='y',marker='$X$',markersize=15);
											# if scan_after_first:
											# 	im = ax[plot_index,0].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
											im = ax[plot_index,0].plot(np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[0],np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1],'k,')
											nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])
											temp = np.exp(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp[temp<1e-100]=1e-100
											# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											start = 0.8
											while (np.sum(temp>np.max(temp)*start)<5 and start>0):
												start/=1.1
											nH2p_ne_values_full = nH2p_ne_values_full[temp>np.max(temp)*start]
											nHm_ne_values_full = nHm_ne_values_full[temp>np.max(temp)*start]
											try:
												fit1 = np.polyfit(nH2p_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												fit_average = [(fit1[0]+1/fit2[0])/2,(fit1[1]-fit2[1]/fit2[0])/2]
												reverse_fit_average = [1/fit_average[0],-fit_average[1]/fit_average[0]]
												im = ax[plot_index,0].plot(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],np.polyval(fit_average,record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]),'k--')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H\nM=marginalised best, X=unmarginalised best, --=samples\nblue=fit H-/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
											except:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps'+'fits failed')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H\nM=marginalised best, X=unmarginalised best, --=samples')
											ax[plot_index,0].set_ylabel('nH-/ne')
											ax[plot_index,0].set_xlabel('nH2+/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											im = ax[plot_index,1].contourf(range(H2p_steps),range(Hm_steps), np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,1])
											im = ax[plot_index,1].contour(range(H2p_steps),range(Hm_steps), np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index,:,:]),levels=10);
											im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_nH2_index,most_likely_marginalised_nHm_nH2_index,color='k',marker='$M$',markersize=30);
											im = ax[plot_index,1].plot(most_likely_nH2p_nH2_index,most_likely_nHm_nH2_index,color='k',marker='$X$',markersize=30);
											im = ax[plot_index,1].plot(first_most_likely_marginalised_nH2p_nH2_index,first_most_likely_marginalised_nHm_nH2_index,color='y',marker='$M$',markersize=15);
											im = ax[plot_index,1].plot(first_most_likely_nH2p_nH2_index,first_most_likely_nHm_nH2_index,color='y',marker='$X$',markersize=15);
											# if scan_after_first:
											# 	im = ax[plot_index,1].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
											im = ax[plot_index,1].plot(np.meshgrid(range(H2p_steps), range(Hm_steps))[0],np.meshgrid(range(H2p_steps), range(Hm_steps))[1],'k,')
											nH2p_ne_values_full,nHm_ne_values_full = np.meshgrid(range(H2p_steps),range(Hm_steps))
											temp = np.exp(marginalised_likelihood_log_probs[most_likely_marginalised_nH_ne_index])
											temp[temp<1e-100]=1e-100
											# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											start = 0.8
											while (np.sum(temp>np.max(temp)*start)<5 and start>0):
												start/=1.1
											nH2p_ne_values_full = nH2p_ne_values_full[temp>np.max(temp)*start]
											nHm_ne_values_full = nHm_ne_values_full[temp>np.max(temp)*start]
											try:
												fit1 = np.polyfit(nH2p_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H\nblue=fit H-/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
											except:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps'+'fits failed')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H')
											ax[plot_index,1].set_ylabel('nH-/nH2 index')
											ax[plot_index,1].set_xlabel('nH2+/nH2 index')
											# ax[plot_index,1].set_xscale('log')
											# ax[plot_index,1].set_yscale('log')

											plot_index += 1
											im = ax[plot_index,0].contourf(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], np.exp(likelihood_log_probs[:,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], np.exp(likelihood_log_probs[:,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]),levels=10);
											# im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=30);
											# im = ax[plot_index,0].plot(first_most_likely_marginalised_nH2p_ne_value,first_most_likely_marginalised_nH_ne_value,color='y',marker='$M$',markersize=15);
											im = ax[plot_index,0].plot(first_most_likely_nH2p_ne_value,first_most_likely_nH_ne_value,color='y',marker='$X$',markersize=15);
											# if scan_after_first:
											# 	im = ax[plot_index,0].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nH_ne_value_down,next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down],'k--');
											im = ax[plot_index,0].plot(np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[0],np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1],'k,')
											nH2p_ne_values_full,nH_ne_values_full = np.meshgrid(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])
											temp = np.exp(likelihood_log_probs[:,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp[temp<1e-100]=1e-100
											# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											# fit2 = curve_fit(line,nH_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											start = 0.8
											while (np.sum(temp>np.max(temp)*start)<5 and start>0):
												start/=1.1
											nH2p_ne_values_full = nH2p_ne_values_full[temp>np.max(temp)*start]
											nH_ne_values_full = nH_ne_values_full[temp>np.max(temp)*start]
											try:
												fit1 = np.polyfit(nH2p_ne_values_full,nH_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nH_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.polyval(fit2,np.sort(nH_ne_values_full)),np.sort(nH_ne_values_full),'b')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H-\nM=marginalised best, X=unmarginalised best\nblue=fit H/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
											except:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps'+'fits failed')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H-\nM=marginalised best, X=unmarginalised best')
											ax[plot_index,0].set_ylabel('nH/ne')
											ax[plot_index,0].set_xlabel('nH2+/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											im = ax[plot_index,1].contourf(range(H2p_steps),range(H_steps), np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_nH2_index,:]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,1])
											im = ax[plot_index,1].contour(range(H2p_steps),range(H_steps), np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_nH2_index,:]),levels=10);
											im = ax[plot_index,1].plot(most_likely_marginalised_nH2p_nH2_index,most_likely_marginalised_nH_ne_index,color='k',marker='$M$',markersize=30);
											im = ax[plot_index,1].plot(most_likely_nH2p_nH2_index,most_likely_nH_ne_index,color='k',marker='$X$',markersize=30);
											im = ax[plot_index,1].plot(first_most_likely_marginalised_nH2p_nH2_index,first_most_likely_marginalised_nH_ne_index,color='y',marker='$M$',markersize=15);
											im = ax[plot_index,1].plot(first_most_likely_nH2p_nH2_index,first_most_likely_nH_ne_index,color='y',marker='$X$',markersize=15);
											# if scan_after_first:
											# 	im = ax[plot_index,1].plot([next_nH2p_ne_value_up,next_nH2p_ne_value_up,next_nH2p_ne_value_down,next_nH2p_ne_value_down,next_nH2p_ne_value_up],[next_nH_ne_value_down,next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down],'k--');
											im = ax[plot_index,1].plot(np.meshgrid(range(H2p_steps), range(H_steps))[0],np.meshgrid(range(H2p_steps), range(H_steps))[1],'k,')
											nH2p_ne_values_full,nH_ne_values_full = np.meshgrid(range(H2p_steps),range(H_steps))
											temp = np.exp(marginalised_likelihood_log_probs[:,most_likely_marginalised_nHm_nH2_index,:])
											temp[temp<1e-100]=1e-100
											# fit1 = curve_fit(line,nH2p_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											# fit2 = curve_fit(line,nH_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											start = 0.8
											while (np.sum(temp>np.max(temp)*start)<5 and start>0):
												start/=1.1
											nH2p_ne_values_full = nH2p_ne_values_full[temp>np.max(temp)*start]
											nH_ne_values_full = nH_ne_values_full[temp>np.max(temp)*start]
											try:
												fit1 = np.polyfit(nH2p_ne_values_full,nH_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit1,nH2p_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.sort(nH2p_ne_values_full),np.polyval(fit1,np.sort(nH2p_ne_values_full)),'b')
												fit2 = np.polyfit(nH_ne_values_full,nH2p_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH2p_ne_values_full-np.polyval(fit2,nH_ne_values_full)))**2))/(np.sum(((nH2p_ne_values_full-np.mean(nH2p_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.polyval(fit2,np.sort(nH_ne_values_full)),np.sort(nH_ne_values_full),'b')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H-\nblue=fit H/H2+ (%.3g,%.3g)R2 %.3g\nfit H2+/H (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
											except:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps'+'fits failed')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H-')
											ax[plot_index,1].set_ylabel('nH/ne index')
											ax[plot_index,1].set_xlabel('nH2+/nH2 index')
											# ax[plot_index,1].set_xscale('log')
											# ax[plot_index,1].set_yscale('log')

											plot_index += 1
											im = ax[plot_index,0].contourf(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index].T),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index].T),levels=10);
											# im = ax[plot_index,0].plot(most_likely_marginalised_nH_ne_value,most_likely_marginalised_nHm_ne_value,color='k',marker='$M$',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH_ne_value,most_likely_nHm_ne_value,color='k',marker='$X$',markersize=30);
											# im = ax[plot_index,0].plot(first_most_likely_marginalised_nH_ne_value,first_most_likely_marginalised_nHm_ne_value,color='y',marker='$M$',markersize=15);
											im = ax[plot_index,0].plot(first_most_likely_nH_ne_value,first_most_likely_nHm_ne_value,color='y',marker='$X$',markersize=15);
											# if scan_after_first:
											# 	im = ax[plot_index,0].plot([next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down,next_nH_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
											im = ax[plot_index,0].plot(np.meshgrid(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[0],np.meshgrid(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index], record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1],'k,')
											nH_ne_values_full,nHm_ne_values_full = np.meshgrid(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])
											temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index].T)
											temp[temp<1e-100]=1e-100
											# fit1 = curve_fit(line,nH_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											start = 0.8
											while (np.sum(temp>np.max(temp)*start)<5 and start>0):
												start/=1.1
											nH_ne_values_full = nH_ne_values_full[temp>np.max(temp)*start]
											nHm_ne_values_full = nHm_ne_values_full[temp>np.max(temp)*start]
											try:
												fit1 = np.polyfit(nH_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.sort(nH_ne_values_full),np.polyval(fit1,np.sort(nH_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,0].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H2+\nM=marginalised best, X=unmarginalised best\nblue=fit H-/H (%.3g,%.3g)R2 %.3g\nfit H/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
											except:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps'+'fits failed')
												ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, H2+\nM=marginalised best, X=unmarginalised best')
											ax[plot_index,0].set_ylabel('nH-/ne')
											ax[plot_index,0].set_xlabel('nH/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											im = ax[plot_index,1].contourf(range(H_steps),range(Hm_steps), np.exp(marginalised_likelihood_log_probs[:,:,most_likely_marginalised_nH2p_nH2_index].T),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,1])
											im = ax[plot_index,1].contour(range(H_steps),range(Hm_steps), np.exp(marginalised_likelihood_log_probs[:,:,most_likely_marginalised_nH2p_nH2_index].T),levels=10);
											im = ax[plot_index,1].plot(most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_nH2_index,color='k',marker='$M$',markersize=30);
											im = ax[plot_index,1].plot(most_likely_nH_ne_index,most_likely_nHm_nH2_index,color='k',marker='$X$',markersize=30);
											im = ax[plot_index,1].plot(first_most_likely_marginalised_nH_ne_index,first_most_likely_marginalised_nHm_nH2_index,color='y',marker='$M$',markersize=15);
											im = ax[plot_index,1].plot(first_most_likely_nH_ne_index,first_most_likely_nHm_nH2_index,color='y',marker='$X$',markersize=15);
											# if scan_after_first:
											# 	im = ax[plot_index,1].plot([next_nH_ne_value_up,next_nH_ne_value_up,next_nH_ne_value_down,next_nH_ne_value_down,next_nH_ne_value_up],[next_nHm_ne_value_down,next_nHm_ne_value_up,next_nHm_ne_value_up,next_nHm_ne_value_down,next_nHm_ne_value_down],'k--');
											im = ax[plot_index,1].plot(np.meshgrid(range(H_steps), range(Hm_steps))[0],np.meshgrid(range(H_steps), range(Hm_steps))[1],'k,')
											nH_ne_values_full,nHm_ne_values_full = np.meshgrid(range(H_steps),range(Hm_steps))
											temp = np.exp(marginalised_likelihood_log_probs[:,:,most_likely_marginalised_nH2p_nH2_index].T)
											temp[temp<1e-100]=1e-100
											# fit1 = curve_fit(line,nH_ne_values_full.flatten(),nHm_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											# fit2 = curve_fit(line,nHm_ne_values_full.flatten(),nH_ne_values_full.flatten(),p0=[1,1],sigma=(1/temp).flatten())[0]
											# R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full))*temp)**2)/np.sum(1*temp**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full))*temp)**2)/np.sum(1*temp**2))
											start = 0.8
											while (np.sum(temp>np.max(temp)*start)<5 and start>0):
												start/=1.1
											nH_ne_values_full = nH_ne_values_full[temp>np.max(temp)*start]
											nHm_ne_values_full = nHm_ne_values_full[temp>np.max(temp)*start]
											try:
												fit1 = np.polyfit(nH_ne_values_full,nHm_ne_values_full,1)
												R2_fit1 = 1-(np.sum(((nHm_ne_values_full-np.polyval(fit1,nH_ne_values_full)))**2))/(np.sum(((nHm_ne_values_full-np.mean(nHm_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.sort(nH_ne_values_full),np.polyval(fit1,np.sort(nH_ne_values_full)),'b')
												fit2 = np.polyfit(nHm_ne_values_full,nH_ne_values_full,1)
												R2_fit2 = 1-(np.sum(((nH_ne_values_full-np.polyval(fit2,nHm_ne_values_full)))**2))/(np.sum(((nH_ne_values_full-np.mean(nH_ne_values_full)))**2))
												im = ax[plot_index,1].plot(np.polyval(fit2,np.sort(nHm_ne_values_full)),np.sort(nHm_ne_values_full),'b')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H2+\nblue=fit H-/H (%.3g,%.3g)R2 %.3g\nfit H/H- (%.3g,%.3g)R2 %.3g' %(*fit1,R2_fit1,*fit2,R2_fit2))
											except:
												print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps'+'fits failed')
												ax[plot_index,1].set_title('PDF marginalised on H2, Te, ne, most likely H2+')
											ax[plot_index,1].set_ylabel('nH-/nH2 index')
											ax[plot_index,1].set_xlabel('nH/ne index')
											# ax[plot_index,1].set_xscale('log')
											# ax[plot_index,1].set_yscale('log')
											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											fig, ax = plt.subplots( 4,2,figsize=(22, 30), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best index: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_nH2_index,most_likely_marginalised_nH2p_nH2_index))
											plot_index = 0
											index = likelihood_log_probs[:,0,:,:,:,:].argmax()	# H, Hm, H2, H2p, ne, Te
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2p_nH2_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%H2p_steps
											nH2_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_nH2_index)//H2p_steps%H2_steps
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2p_nH2_index)//H2p_steps - nH2_ne_index)//H2_steps%H_steps
											im = ax[plot_index,0].contourf(record_nH2p_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index],record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index], np.exp(likelihood_log_probs[:,0,nH2_ne_index,:,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,0])
											im = ax[plot_index,0].contour(record_nH2p_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index],record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index], np.exp(likelihood_log_probs[:,0,nH2_ne_index,:,ne_index,Te_index]),levels=10);
											# im = ax[plot_index,0].plot(most_likely_marginalised_nH2p_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,0].plot(record_nH2p_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index][nH2p_nH2_index],record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index][nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,0].plot(np.meshgrid(record_nH2p_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index], record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index])[0],np.meshgrid(record_nH2p_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index], record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index])[1],'k,')
											ax[plot_index,0].set_title('PDF at most likely H2, Te, ne, nH-=%.3g\nM=marginalised best, X=unmarginalised best' %(np.min(record_nHm_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index])))
											ax[plot_index,0].set_ylabel('nH/ne')
											ax[plot_index,0].set_xlabel('nH2+/ne')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_yscale('log')

											index = likelihood_log_probs[:,:,:,0,:,:].argmax()	# H, Hm, H2, H2p, ne, Te
											Te_index = index%TS_Te_steps
											ne_index = (index-Te_index)//TS_Te_steps%TS_ne_steps
											nH2_ne_index = ((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps%H2_steps
											nHm_ne_index = (((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2_ne_index)//H2_steps%Hm_steps
											nH_ne_index = ((((index-Te_index)//TS_Te_steps-ne_index)//TS_ne_steps-nH2_ne_index)//H2_steps - nHm_ne_index)//Hm_steps%H_steps
											im = ax[plot_index,1].contourf(record_nHm_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index],record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index], np.exp(likelihood_log_probs[:,:,nH2_ne_index,0,ne_index,Te_index]),levels=10, cmap='rainbow');	# H, Hm, H2, H2p, ne, Te
											plt.colorbar(im, ax=ax[plot_index,1])
											im = ax[plot_index,1].contour(record_nHm_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index],record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index], np.exp(likelihood_log_probs[:,:,nH2_ne_index,0,ne_index,Te_index]),levels=10);
											# im = ax[plot_index,1].plot(most_likely_marginalised_nHm_ne_value,most_likely_marginalised_nH_ne_value,color='k',marker='$M$',markersize=10);
											im = ax[plot_index,1].plot(most_likely_nHm_ne_value,most_likely_nH_ne_value,color='k',marker='$X$',markersize=10);
											im = ax[plot_index,1].plot(record_nHm_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index][nHm_ne_index],record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index][nH_ne_index],color='k',marker='$X$',markersize=30);
											im = ax[plot_index,1].plot(np.meshgrid(record_nHm_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index], record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index])[0],np.meshgrid(record_nHm_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index], record_nH_ne_values[:,ne_index*TS_Te_steps + Te_index])[1],'k,')
											ax[plot_index,1].set_title('PDF at most likely H2, Te, ne, nH2+=%.3g' %(np.min(record_nH2p_ne_values[nH2_ne_index,:,ne_index*TS_Te_steps + Te_index])))
											ax[plot_index,1].set_ylabel('nH/ne')
											ax[plot_index,1].set_xlabel('nH-/ne')
											ax[plot_index,1].set_xscale('log')
											ax[plot_index,1].set_yscale('log')

											plot_index += 1
											ax[plot_index,0].remove()
											ax[plot_index,0]=fig.add_subplot(4,2,3,projection='3d')
											# nH_ne_sample = np.logspace(np.log10(np.min(nH_ne_values)),np.log10(np.max(nH_ne_values)),num=1000)
											# nH2p_ne_sample = np.logspace(np.log10(np.min(nH2p_ne_values)),np.log10(np.max(nH2p_ne_values)),num=10000)
											nH_ne_values_full,nH2p_ne_values_full = np.meshgrid(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],indexing='ij')
											nHm_ne_values_full = np.zeros_like(nH_ne_values_full)
											# specific_prob = np.zeros_like(nH_ne_values_full)
											temp = np.exp(likelihood_log_probs[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index])
											temp[temp<1e-100]=1e-100
											for iH,nH_ne in enumerate(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]):
												for i2p,nH2p_ne in enumerate(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]):
													calc = line_3D(nH_ne,nH2p_ne,*sol_line.x)
													im = np.abs(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]-calc).argmin()
													nHm_ne_values_full[iH,i2p] = record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][im]
											# 		nH_ne_values_full[iH,i2p] = nH_ne_values[np.abs(nH_ne_values-nH_ne).argmin()]
											# 		nH2p_ne_values_full[iH,i2p] = nH2p_ne_values[np.abs(nH2p_ne_values-nH2p_ne).argmin()]
											# 		specific_prob[iH,i2p]=temp[np.abs(nH_ne_values-nH_ne).argmin(),im,np.abs(nH2p_ne_values-nH2p_ne).argmin()]
											select = temp>=np.exp(max_likelihood_log_prob)*0.9
											# sample=np.array([nH_ne_values_full.flatten(),nHm_ne_values_full.flatten(),nH2p_ne_values_full.flatten(),specific_prob.flatten()]).T
											# reduced_sample = sample[sample[:,3]>=np.exp(max_likelihood_log_prob)*0.9]
											# temp_reduced_sample=np.array([[0,0,0,0]])
											# for i in range(1,len(reduced_sample)-1):
											# 	if np.sum(np.logical_and(np.logical_and(temp_reduced_sample[:,0]==reduced_sample[i,0],temp_reduced_sample[:,1]==reduced_sample[i,1]),temp_reduced_sample[:,2]==reduced_sample[i,2]))==0:
											# 		temp_reduced_sample = np.concatenate((temp_reduced_sample,[reduced_sample[i]]))
											# reduced_sample = temp_reduced_sample[1:]
											# specific_prob = reduced_sample[3]
											# my_col = cm.rainbow(specific_prob/np.max(specific_prob)*255,alpha=0.5)
											# scatter = ax[plot_index,0].scatter(np.log10(reduced_sample[:,2]),np.log10(reduced_sample[:,1]),np.log10(reduced_sample[:,0]), c=reduced_sample[:,3], cmap='rainbow', zorder = 0.6)
											# surf = ax[plot_index,0].plot_surface(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full), facecolors=my_col,linewidth=1,rstride=1,cstride=1, antialiased=False,alpha=0.5, zorder = 0.1)
											ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											# ax[plot_index,0].plot(np.log10(reduced_sample[:,2]),np.log10(reduced_sample[:,1]),np.log10(reduced_sample[:,0]),'go', zorder = 0.6)
											nH_ne_values_full_temp,nHm_ne_values_full_temp,nH2p_ne_values_full_temp = np.meshgrid(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],indexing='ij')
											scatter = ax[plot_index,0].scatter(np.log10(nH2p_ne_values_full_temp)[select],np.log10(nHm_ne_values_full_temp)[select],np.log10(nH_ne_values_full_temp)[select], c=temp[select], cmap='rainbow', zorder = 0.6)
											ax[plot_index,0].plot(np.log10(nH2p_ne_values_full_temp)[temp>=np.exp(max_likelihood_log_prob)*0.8],np.log10(nHm_ne_values_full_temp)[temp>=np.exp(max_likelihood_log_prob)*0.8],np.log10(nH_ne_values_full_temp)[temp>=np.exp(max_likelihood_log_prob)*0.8],'k+', zorder = 0.5)
											# ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,0].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,0].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,0].view_init(elev=60,azim=45)
											ax[plot_index,0].set_title('Best 20 and 10'+'%'+' of likelihood at most likely H2, Te, ne\nnH=%.3gnH2+ +%.3gnH- +%.3g, R2=%.3g' %(sol_line.x[0],sol_line.x[1],sol_line.x[2],R2_sol_line))
											ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											ax[plot_index,0].set_zlabel('Log10 nH_ne')

											ax[plot_index,1].remove()
											ax[plot_index,1]=fig.add_subplot(4,2,4,projection='3d')
											ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											# scatter = ax[plot_index,1].scatter(np.log10(reduced_sample[:,2]),np.log10(reduced_sample[:,1]),np.log10(reduced_sample[:,0]), c=power_rad_excit, cmap='rainbow', zorder = 0.4)
											scatter = ax[plot_index,1].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_rad_excit[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,1]).set_label('Power [W]')
											# ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,1].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,1].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,1].view_init(elev=60,azim=45)
											ax[plot_index,1].set_title('Radiative power sink due to H excitation')
											ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											ax[plot_index,1].set_zlabel('Log10 nH_ne')

											plot_index += 1
											ax[plot_index,0].remove()
											ax[plot_index,0]=fig.add_subplot(4,2,5,projection='3d')
											ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,0].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_rad_rec_bremm[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,0]).set_label('Power [W]')
											# ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,0].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,0].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,0].view_init(elev=60,azim=45)
											ax[plot_index,0].set_title('Radiative power sink due to recombination and Bremsstrahlung')
											ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											ax[plot_index,0].set_zlabel('Log10 nH_ne')

											ax[plot_index,1].remove()
											ax[plot_index,1]=fig.add_subplot(4,2,6,projection='3d')
											ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,1].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_rad_mol[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,1]).set_label('Power [W]')
											# ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,1].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,1].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,1].view_init(elev=60,azim=45)
											ax[plot_index,1].set_title('Radiative power sink due molecule induced H de-excitation')
											ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											ax[plot_index,1].set_zlabel('Log10 nH_ne')

											plot_index += 1
											ax[plot_index,0].remove()
											ax[plot_index,0]=fig.add_subplot(4,2,7,projection='3d')
											ax[plot_index,0].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,0].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_via_ionisation[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,0]).set_label('Power [W]')
											# ax[plot_index,0].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,0].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,0].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,0].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,0].view_init(elev=60,azim=45)
											ax[plot_index,0].set_title('Power sink due to atomic ionisation')
											ax[plot_index,0].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,0].set_ylabel('Log10 nH-_ne')
											ax[plot_index,0].set_zlabel('Log10 nH_ne')

											ax[plot_index,1].remove()
											ax[plot_index,1]=fig.add_subplot(4,2,8,projection='3d')
											ax[plot_index,1].plot_wireframe(np.log10(nH2p_ne_values_full),np.log10(nHm_ne_values_full),np.log10(nH_ne_values_full),linewidth=0.5,rcount=15,ccount=15,color='y', zorder = 0.2)
											scatter = ax[plot_index,1].scatter(np.log10(nH2p_ne_values_full_temp[select]),np.log10(nHm_ne_values_full_temp[select]),np.log10(nH_ne_values_full_temp[select]), c=power_via_recombination[:,:,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index][select], cmap='rainbow', zorder = 0.4)
											plt.colorbar(scatter, ax=ax[plot_index,1]).set_label('Power [W]')
											# ax[plot_index,1].plot([np.log10(most_likely_marginalised_nH2p_ne_value)],[np.log10(most_likely_marginalised_nHm_ne_value)],[np.log10(most_likely_marginalised_nH_ne_value)],color='r',marker='$M$',markersize=30, zorder = 0.7)
											ax[plot_index,1].plot([np.log10(most_likely_nH2p_ne_value)],[np.log10(most_likely_nHm_ne_value)],[np.log10(most_likely_nH_ne_value)],color='r',marker='$X$',markersize=30, zorder = 0.8)
											# ax[plot_index,1].plot([np.log10(first_most_likely_marginalised_nH2p_ne_value)],[np.log10(first_most_likely_marginalised_nHm_ne_value)],[np.log10(first_most_likely_marginalised_nH_ne_value)],color='y',marker='$M$',markersize=15,zorder = 0.7)
											ax[plot_index,1].plot([np.log10(first_most_likely_nH2p_ne_value)],[np.log10(first_most_likely_nHm_ne_value)],[np.log10(first_most_likely_nH_ne_value)],color='y',marker='$X$',markersize=15, zorder = 0.8)
											ax[plot_index,1].view_init(elev=60,azim=45)
											ax[plot_index,1].set_title('Power sink due to atomic recombination')
											ax[plot_index,1].set_xlabel('Log10 nH2+_ne')
											ax[plot_index,1].set_ylabel('Log10 nH-_ne')
											ax[plot_index,1].set_zlabel('Log10 nH_ne')


											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_adaptable_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_second.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											fig, ax = plt.subplots( 4,2,figsize=(25, 40), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best index: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_nH2_index,most_likely_marginalised_nH2p_nH2_index))
											plot_index = 0
											nH_ne_values_full,nHm_ne_values_full,nH2_ne_values_full,nH2p_ne_values_full,ne_values_full,Te_values_full = np.meshgrid(np.arange(H_steps),np.arange(Hm_steps),np.arange(H2_steps),np.arange(H2p_steps),ne_values_array,Te_values_array,indexing='ij')	# H, Hm, H2, H2p, ne, Te
											fraction_of_max_prob_selected = 50000
											select = likelihood_probs_times_volume>likelihood_probs_times_volume.max()/fraction_of_max_prob_selected
											while np.sum(select)/10>50000:
												fraction_of_max_prob_selected*=0.9
												select = likelihood_probs_times_volume>likelihood_probs_times_volume.max()/fraction_of_max_prob_selected
											select = np.logical_and(likelihood_probs_times_volume>likelihood_probs_times_volume.max()/fraction_of_max_prob_selected,np.random.random(np.shape(select))<0.1)
											temp_prob = likelihood_probs_times_volume[select]
											max_temp_prob = np.max(temp_prob)
											nH_ne_values_full = nH_ne_values_full[select]
											nHm_ne_values_full = nHm_ne_values_full[select]
											nH2_ne_values_full = nH2_ne_values_full[select]
											nH2p_ne_values_full = nH2p_ne_values_full[select]
											Te_values_full = Te_values_full[select]
											ne_values_full = ne_values_full[select]
											if include_particles_limitation:
												all_net_Hp_destruction_full = all_net_Hp_destruction[select]
												all_net_e_destruction_full = all_net_e_destruction[select]
												all_net_Hm_destruction_full = all_net_Hm_destruction[select]
												all_net_H2p_destruction_full = all_net_H2p_destruction[select]
											T_Hm_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full.flatten())))/eV_to_K	# K
											T_H2p_values_full = np.exp(TH2_fit_from_simulations(np.log(Te_values_full.flatten())))/eV_to_K	# K
											T_Hp_values_full = Te_values_full.flatten()/eV_to_K	# K
											# power_rad_excit,power_rad_rec_bremm,power_rad_mol,power_via_ionisation,power_via_recombination = calc_power_balance_elements(Te_values_full,ne_values_full,nH_ne_values_full,nHm_ne_values_full,nH2p_ne_values_full,nH2_ne_values_full,T_Hp_values_full,T_Hm_values_full,T_H2p_values_full)
											most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_power_rad_Hm,most_likely_power_rad_H2,most_likely_power_rad_H2p = calc_power_balance_elements(most_likely_Te_value,most_likely_ne_value,most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2p_ne_value,most_likely_nH2_ne_value,most_likely_T_Hp_value,most_likely_T_Hm_value,most_likely_T_H2p_value)
											most_likely_tot_rad_power = most_likely_power_rad_excit+most_likely_power_rad_rec_bremm+most_likely_power_rad_mol
											most_likely_power_via_brem =  5.35*1e-37 * ( most_likely_ne_value**2 ) * (1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value) * (most_likely_Te_value/1000)**0.5
											most_likely_power_heating_rec = most_likely_power_via_recombination-most_likely_power_rad_rec_bremm + most_likely_power_via_brem
											most_likely_power_rec_neutral = most_likely_power_rad_rec_bremm + 3/2*most_likely_power_via_recombination/13.6*most_likely_Te_value
											most_likely_total_removed_power = most_likely_power_via_ionisation + most_likely_power_rad_mol + most_likely_power_rad_excit + most_likely_power_via_recombination + most_likely_power_via_brem + most_likely_power_rec_neutral
											color = ['b', 'r', 'm', 'y', 'g', 'c', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']
											im = ax[plot_index,0].plot(power_rad_excit[select],100*temp_prob/max_temp_prob,color[0]+'+',label='power_rad_excit');
											im = ax[plot_index,0].plot(most_likely_power_rad_excit,100,color[0]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_rec_bremm[select],100*temp_prob/max_temp_prob,color[1]+'+',label='power_rad_rec_bremm');
											im = ax[plot_index,0].plot(most_likely_power_rad_rec_bremm,100,color[1]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_mol[select],100*temp_prob/max_temp_prob,color[2]+'+',label='power_rad_mol');
											im = ax[plot_index,0].plot(most_likely_power_rad_mol,100,color[2]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_via_ionisation[select],100*temp_prob/max_temp_prob,color[3]+'+',label='power_via_ionisation');
											im = ax[plot_index,0].plot(most_likely_power_via_ionisation,100,color[3]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_via_recombination[select],100*temp_prob/max_temp_prob,color[4]+'+',label='power_via_recombination');
											im = ax[plot_index,0].plot(most_likely_power_via_recombination,100,color[4]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(tot_rad_power[select],100*temp_prob/max_temp_prob,color[5]+'+',label='tot_rad_power');
											im = ax[plot_index,0].plot(most_likely_tot_rad_power,100,color[5]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_Hm[select],100*temp_prob/max_temp_prob,'+',color=color[6],label='power_rad_Hm');
											im = ax[plot_index,0].plot(most_likely_power_rad_Hm,100,'o',color=color[6],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_H2[select],100*temp_prob/max_temp_prob,'+',color=color[7],label='power_rad_H2');
											im = ax[plot_index,0].plot(most_likely_power_rad_H2,100,'o',color=color[7],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rad_H2p[select],100*temp_prob/max_temp_prob,'+',color=color[8],label='power_rad_H2p');
											im = ax[plot_index,0].plot(most_likely_power_rad_H2p,100,'o',color=color[8],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_heating_rec[select],100*temp_prob/max_temp_prob,'+',color=color[9],label='power_heating_rec');
											im = ax[plot_index,0].plot(most_likely_power_heating_rec,100,'o',color=color[9],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_rec_neutral[select],100*temp_prob/max_temp_prob,'+',color=color[10],label='power_rec_neutral');
											im = ax[plot_index,0].plot(most_likely_power_rec_neutral,100,'o',color=color[10],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(power_via_brem[select],100*temp_prob/max_temp_prob,'+',color=color[11],label='power_via_brem');
											im = ax[plot_index,0].plot(most_likely_power_via_brem,100,'o',color=color[11],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(total_removed_power[select],100*temp_prob/max_temp_prob,'+',color=color[12],label='total_removed_power');
											im = ax[plot_index,0].plot(most_likely_total_removed_power,100,'o',color=color[12],markersize=30,fillstyle='none');
											# im = ax[plot_index,0].plot([interpolated_power_pulse_shape(time_crop[my_time_pos])/source_power_spread/area/length]*2,[0,100],'k--');
											im = ax[plot_index,0].plot(local_CX[select],100*temp_prob/max_temp_prob,'+',color=color[13],label='local_CX');
											im = ax[plot_index,0].plot(most_likely_local_CX,100,'o',color=color[13],markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_total_removable_power_times_volume]*2,[0,100],'k--');
											im = ax[plot_index,0].plot([max_total_removable_power_times_volume]*2,[0,100],'--',color='gray');
											im = ax[plot_index,0].plot([min_total_removable_power_times_volume]*2,[0,100],'--',color='gray');
											ax[plot_index,0].set_title('Power balance for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML' + '\nsigma: molecular %.3g%%, atomic %.3g%%, budget %.3g%%' %(power_molecular_precision*100,power_atomic_precision*100,power_budget_precision*100))
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('Power [W/m3]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].set_xlim(left=max(1,1e-1*np.min([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power,most_likely_power_heating_rec,most_likely_power_via_brem,most_likely_total_removed_power,most_likely_power_rec_neutral])))
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											ax[plot_index,0].grid()

											im = ax[plot_index,1].plot(Te_values_full,100*temp_prob/max_temp_prob,'+');
											im = ax[plot_index,1].plot(most_likely_Te_value,100,'o',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_Te_prof_multipulse_interp_crop_limited_restrict,100,'x',markersize=30);
											ax[plot_index,1].set_title('Te for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('temperature [eV]')
											# ax[plot_index,0].set_xscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											plot_index += 1
											im = ax[plot_index,0].plot(nH_ne_values_full,100*temp_prob/max_temp_prob,color[0]+'+',label='nH_ne');
											im = ax[plot_index,0].plot(record_nH_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index].argmax(),100,color[0]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH_ne_index,100,color[0]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(nHm_ne_values_full,100*temp_prob/max_temp_prob,color[1]+'+',label='nHm_nH2');
											im = ax[plot_index,0].plot(most_likely_nHm_nH2_index,100,color[1]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(nH2_ne_values_full,100*temp_prob/max_temp_prob,color[2]+'+',label='nH2_ne');
											im = ax[plot_index,0].plot(record_nH_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index].argmax(),100,color[2]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH2_ne_index,100,color[2]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot(nH2p_ne_values_full,100*temp_prob/max_temp_prob,color[3]+'+',label='nH2p_nH2');
											im = ax[plot_index,0].plot(most_likely_nH2p_nH2_index,100,color[3]+'o',markersize=30,fillstyle='none');
											ax[plot_index,0].set_title('Relative densities for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML, X=central')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('index')
											# ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											ax[plot_index,0].grid()

											im = ax[plot_index,1].plot(ne_values_full,100*temp_prob/max_temp_prob,'+');
											im = ax[plot_index,1].plot(most_likely_ne_value,100,'o',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20,100,'x',markersize=30);
											ax[plot_index,1].set_title('ne for likelyhood above %.3g' %(100/fraction_of_max_prob_selected) +'%'+' of of the PDF peak, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('density [#/m3]')
											# ax[plot_index,0].set_yscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											if include_particles_limitation:
												plot_index += 1
												im = ax[plot_index,0].plot(all_net_e_destruction_full,100*temp_prob/max_temp_prob,color[0]+'+');
												im = ax[plot_index,0].plot(most_likely_net_e_destruction,100,color[0]+'o',markersize=30,fillstyle='none');
												im = ax[plot_index,0].plot([most_likely_total_removable_e]*2,[0,100],'k--');
												im = ax[plot_index,0].plot([total_removable_e[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,0].plot([total_removable_e[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,0].set_title('electrons consumed within time and volume step')
												ax[plot_index,0].set_ylabel('normalised likelihood')
												ax[plot_index,0].set_xlabel('particles [#*10^20]')
												# ax[plot_index,0].set_xscale('log')
												ax[plot_index,0].legend(loc='best', fontsize='x-small')
												ax[plot_index,0].grid()

												im = ax[plot_index,1].plot(all_net_Hp_destruction_full,100*temp_prob/max_temp_prob,color[0]+'+');
												im = ax[plot_index,1].plot(most_likely_net_Hp_destruction,100,color[0]+'o',markersize=30,fillstyle='none');
												im = ax[plot_index,1].plot([most_likely_total_removable_Hp]*2,[0,100],'k--');
												im = ax[plot_index,1].plot([total_removable_Hp[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,1].plot([total_removable_Hp[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,1].set_title('H+ consumed within time and volume step')
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('particles [#*10^20]')

												plot_index += 1
												im = ax[plot_index,0].plot(all_net_Hm_destruction_full,100*temp_prob/max_temp_prob,color[0]+'+');
												im = ax[plot_index,0].plot(most_likely_net_Hm_destruction,100,color[0]+'o',markersize=30,fillstyle='none');
												im = ax[plot_index,0].plot([most_likely_total_removable_Hm]*2,[0,100],'k--');
												im = ax[plot_index,0].plot([total_removable_Hm[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,0].plot([total_removable_Hm[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,0].set_title('H- consumed within time and volume step')
												ax[plot_index,0].set_ylabel('normalised likelihood')
												ax[plot_index,0].set_xlabel('particles [#*10^20]')

												im = ax[plot_index,1].plot(all_net_H2p_destruction_full,100*temp_prob/max_temp_prob,color[0]+'+');
												im = ax[plot_index,1].plot(most_likely_net_H2p_destruction,100,color[0]+'o',markersize=30,fillstyle='none');
												im = ax[plot_index,1].plot([most_likely_total_removable_H2p]*2,[0,100],'k--');
												im = ax[plot_index,1].plot([total_removable_H2p[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,1].plot([total_removable_H2p[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,1].set_title('H2+ consumed within time and volume step')
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('particles [#*10^20]')

											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_third.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								# Here I find an approximate value for the measurement precision
								def find_sigma(x,sigma):
									return x/sigma

								# to calculate the integral of the probability I need their width
								if False:	# logarithmic interval scaling
									d_nH_ne_values = np.array([*np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])),*(np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[:-1]/2+np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[1:]/2),*np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))])/(np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]]))+np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]))/2+np.diff(np.log10(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))/2)
									d_nHm_ne_values = np.array([*np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])),*(np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[:-1]/2+np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[1:]/2),*np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))])/(np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]]))+np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]))/2+np.diff(np.log10(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))/2)
									d_nH2_ne_values = np.array([*np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])),*(np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[:-1]/2+np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[1:]/2),*np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))])/(np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]]))+np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]))/2+np.diff(np.log10(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))/2)
									d_nH2p_ne_values = np.array([*np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])),*(np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[:-1]/2+np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index]))[1:]/2),*np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))])/(np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]]))+np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]))/2+np.diff(np.log10(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]]))/2)
								elif True:	# linear interval scaling
									d_nH_ne_values = np.array([*np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]),*(np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[:-1]/2+np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1:]/2),*np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])])/(np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]])+np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])/2+np.diff(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])/2)
									d_nHm_ne_values = np.array([*np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]),*(np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[:-1]/2+np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1:]/2),*np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])])/(np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]])+np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])/2+np.diff(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])/2)
									d_nH2_ne_values = np.array([*np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]),*(np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[:-1]/2+np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1:]/2),*np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])])/(np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]])+np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])/2+np.diff(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])/2)
									d_nH2p_ne_values = np.array([*np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]]),*(np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[:-1]/2+np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])[1:]/2),*np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])])/(np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,-1]])+np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[0,1]])/2+np.diff(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][[-2,-1]])/2)
								d_ne_values_array = np.array([*np.diff(ne_values_array[[0,1]]),*(np.diff(ne_values_array)[:-1]/2+np.diff(ne_values_array)[1:]/2),*np.diff(ne_values_array[[-2,-1]])])/(np.diff(ne_values_array[[0,-1]])+np.diff(ne_values_array[[0,1]])/2+np.diff(ne_values_array[[-2,-1]])/2)
								d_Te_values_array = np.array([*np.diff(Te_values_array[[0,1]]),*(np.diff(Te_values_array)[:-1]/2+np.diff(Te_values_array)[1:]/2),*np.diff(Te_values_array[[-2,-1]])])/(np.diff(Te_values_array[[0,-1]])+np.diff(Te_values_array[[0,1]])/2+np.diff(Te_values_array[[-2,-1]])/2)

								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,:]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,:]
								temp_2 = np.exp(temp_2+np.log(d_Te_values_array)-np.log(np.sum(np.exp(temp_2)*d_Te_values_array)))
								try:
									# sigma_Te_right = curve_fit(find_sigma,np.abs(Te_values[0,most_likely_Te_index:]-most_likely_Te_value),temp[most_likely_Te_index:],p0=[1])[0][0]#,sigma=np.abs(Te_values[0,most_likely_Te_index:]-most_likely_Te_value)/most_likely_Te_value+0.1)[0]
									sigma_Te_right = temp_2[most_likely_Te_index:]
									if np.sum(sigma_Te_right)<0.34:
										sigma_Te_right=0
									else:
										sigma_Te_right = np.abs(np.array([sum(sigma_Te_right[:_+1]) for _ in range(len(sigma_Te_right)) ])-0.34)
										sigma_Te_right = sigma_Te_right[1:].argmin()
										sigma_Te_right = -Te_values_array[most_likely_Te_index]+Te_values_array[most_likely_Te_index+1+sigma_Te_right]
								except:
									sigma_Te_right=0
								try:
									# sigma_Te_left = curve_fit(find_sigma,np.abs(Te_values[0,:most_likely_Te_index+1]-most_likely_Te_value),temp[:most_likely_Te_index+1],p0=[1])[0][0]#,sigma=np.abs(Te_values[0,:most_likely_Te_index+1]-most_likely_Te_value)/most_likely_Te_value+0.1)[0]
									sigma_Te_left = np.flip(temp_2[:most_likely_Te_index+1],axis=0)
									if np.sum(sigma_Te_left)<0.34:
										sigma_Te_left=0
									else:
										sigma_Te_left = np.abs(np.array([sum(sigma_Te_left[:_+1]) for _ in range(len(sigma_Te_left)) ])-0.34)
										sigma_Te_left = sigma_Te_left[1:].argmin()
										sigma_Te_left = Te_values_array[most_likely_Te_index]-Te_values_array[most_likely_Te_index-1-sigma_Te_left]
								except:
									sigma_Te_left=0
								sigma_Te = max(sigma_Te_right,sigma_Te_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,:,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,:,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_ne_values_array)-np.log(np.sum(np.exp(temp_2)*d_ne_values_array)))
								try:
									# sigma_ne_right = curve_fit(find_sigma,np.abs(ne_values[most_likely_ne_index:,0]-most_likely_ne_value),temp[most_likely_ne_index:],p0=[1])[0][0]#,sigma=np.abs(ne_values[most_likely_ne_index:,0]-most_likely_ne_value)/most_likely_ne_value+0.1)[0]
									sigma_ne_right = temp_2[most_likely_ne_index:]
									if np.sum(sigma_ne_right)<0.34:
										sigma_ne_right=0
									else:
										sigma_ne_right = np.abs(np.array([sum(sigma_ne_right[:_+1]) for _ in range(len(sigma_ne_right)) ])-0.34)
										sigma_ne_right = sigma_ne_right[1:].argmin()
										sigma_ne_right = -ne_values_array[most_likely_ne_index]+ne_values_array[most_likely_ne_index+1+sigma_ne_right]
								except:
									sigma_ne_right=0
								try:
									# sigma_ne_left = curve_fit(find_sigma,np.abs(ne_values[:most_likely_ne_index+1,0]-most_likely_ne_value),temp[:most_likely_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(ne_values[:most_likely_ne_index+1,0]-most_likely_ne_value)/most_likely_ne_value+0.1)[0]
									sigma_ne_left = np.flip(temp_2[:most_likely_ne_index+1],axis=0)
									if np.sum(sigma_ne_left)<0.34:
										sigma_ne_left=0
									else:
										sigma_ne_left = np.abs(np.array([sum(sigma_ne_left[:_+1]) for _ in range(len(sigma_ne_left)) ])-0.34)
										sigma_ne_left = sigma_ne_left[1:].argmin()
										sigma_ne_left = ne_values_array[most_likely_ne_index]-ne_values_array[most_likely_ne_index-1-sigma_ne_left]
								except:
									sigma_ne_left=0
								sigma_ne = max(sigma_ne_right,sigma_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nH2p_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nH2p_ne_values)))
								try:
									# sigma_nH2p_ne_right = curve_fit(find_sigma,np.abs(nH2p_ne_values[most_likely_nH2p_ne_index:]-most_likely_nH2p_ne_value),temp[most_likely_nH2p_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nH2p_ne_values[most_likely_nH2p_ne_index:]-most_likely_nH2p_ne_value)/most_likely_nH2p_ne_value+0.1)[0]
									sigma_nH2p_ne_right = temp_2[most_likely_nH2p_nH2_index:]
									if np.sum(sigma_nH2p_ne_right)<0.34:
										sigma_nH2p_ne_right=0
									else:
										sigma_nH2p_ne_right = np.abs(np.array([sum(sigma_nH2p_ne_right[:_+1]) for _ in range(len(sigma_nH2p_ne_right)) ])-0.34)
										sigma_nH2p_ne_right = sigma_nH2p_ne_right[1:].argmin()
										sigma_nH2p_ne_right = -record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2p_nH2_index]+record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2p_nH2_index+1+sigma_nH2p_ne_right]
								except:
									sigma_nH2p_ne_right=0
								try:
									# sigma_nH2p_ne_left = curve_fit(find_sigma,np.abs(nH2p_ne_values[:most_likely_nH2p_ne_index+1]-most_likely_nH2p_ne_value),temp[:most_likely_nH2p_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nH2p_ne_values[:most_likely_nH2p_ne_index+1]-most_likely_nH2p_ne_value)/most_likely_nH2p_ne_value+0.1)[0]
									sigma_nH2p_ne_left = np.flip(temp_2[:most_likely_nH2p_nH2_index+1],axis=0)
									if np.sum(sigma_nH2p_ne_left)<0.34:
										sigma_nH2p_ne_left=0
									else:
										sigma_nH2p_ne_left = np.abs(np.array([sum(sigma_nH2p_ne_left[:_+1]) for _ in range(len(sigma_nH2p_ne_left)) ])-0.34)
										sigma_nH2p_ne_left = sigma_nH2p_ne_left[1:].argmin()
										sigma_nH2p_ne_left = record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2p_nH2_index]-record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2p_nH2_index-1-sigma_nH2p_ne_left]
								except:
									sigma_nH2p_ne_left=0
								sigma_nH2p_ne = max(sigma_nH2p_ne_right,sigma_nH2p_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_ne_index,:,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,:,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nH2_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nH2_ne_values)))
								try:
									# sigma_nH2_ne_right = curve_fit(find_sigma,np.abs(nH2_ne_values[most_likely_nH2_ne_index:]-most_likely_nH2_ne_value),temp[most_likely_nH2_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nH2_ne_values[most_likely_nH2_ne_index:]-most_likely_nH2_ne_value)/most_likely_nH2_ne_value+0.1)[0]
									sigma_nH2_ne_right = temp_2[most_likely_nH2_ne_index:]
									if np.sum(sigma_nH2_ne_right)<0.34:
										sigma_nH2_ne_right=0
									else:
										sigma_nH2_ne_right = np.abs(np.array([sum(sigma_nH2_ne_right[:_+1]) for _ in range(len(sigma_nH2_ne_right)) ])-0.34)
										sigma_nH2_ne_right = sigma_nH2_ne_right[1:].argmin()
										sigma_nH2_ne_right = -record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2_ne_index]+record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2_ne_index+1+sigma_nH2_ne_right]
								except:
									sigma_nH2_ne_right=0
								try:
									# sigma_nH2_ne_left = curve_fit(find_sigma,np.abs(nH2_ne_values[:most_likely_nH2_ne_index+1]-most_likely_nH2_ne_value),temp[:most_likely_nH2_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nH2_ne_values[:most_likely_nH2_ne_index+1]-most_likely_nH2_ne_value)/most_likely_nH2_ne_value+0.1)[0]
									sigma_nH2_ne_left = np.flip(temp_2[:most_likely_nH2_ne_index+1],axis=0)
									if np.sum(sigma_nH2_ne_left)<0.34:
										sigma_nH2_ne_left=0
									else:
										sigma_nH2_ne_left = np.abs(np.array([sum(sigma_nH2_ne_left[:_+1]) for _ in range(len(sigma_nH2_ne_left)) ])-0.34)
										sigma_nH2_ne_left = sigma_nH2_ne_left[1:].argmin()
										sigma_nH2_ne_left = record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2_ne_index]-record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH2_ne_index-1-sigma_nH2_ne_left]
								except:
									sigma_nH2_ne_left=0
								sigma_nH2_ne = max(sigma_nH2_ne_right,sigma_nH2_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nHm_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nHm_ne_values)))
								try:
									# sigma_nHm_ne_right = curve_fit(find_sigma,np.abs(nHm_ne_values[most_likely_nHm_ne_index:]-most_likely_nHm_ne_value),temp[most_likely_nHm_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nHm_ne_values[most_likely_nHm_ne_index:]-most_likely_nHm_ne_value)/most_likely_nHm_ne_value+0.1)[0]
									sigma_nHm_ne_right = temp_2[most_likely_nHm_nH2_index:]
									if np.sum(sigma_nHm_ne_right)<0.34:
										sigma_nHm_ne_right=0
									else:
										sigma_nHm_ne_right = np.abs(np.array([sum(sigma_nHm_ne_right[:_+1]) for _ in range(len(sigma_nHm_ne_right)) ])-0.34)
										sigma_nHm_ne_right = sigma_nHm_ne_right[1:].argmin()
										sigma_nHm_ne_right = -record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nHm_nH2_index]+record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nHm_nH2_index+1+sigma_nHm_ne_right]
								except:
									sigma_nHm_ne_right=0
								try:
									# sigma_nHm_ne_left = curve_fit(find_sigma,np.abs(nHm_ne_values[:most_likely_nHm_ne_index+1]-most_likely_nHm_ne_value),temp[:most_likely_nHm_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nHm_ne_values[:most_likely_nHm_ne_index+1]-most_likely_nHm_ne_value)/most_likely_nHm_ne_value+0.1)[0]
									sigma_nHm_ne_left = np.flip(temp_2[:most_likely_nHm_nH2_index+1],axis=0)
									if np.sum(sigma_nHm_ne_left)<0.34:
										sigma_nHm_ne_left=0
									else:
										sigma_nHm_ne_left = np.abs(np.array([sum(sigma_nHm_ne_left[:_+1]) for _ in range(len(sigma_nHm_ne_left)) ])-0.34)
										sigma_nHm_ne_left = sigma_nHm_ne_left[1:].argmin()
										sigma_nHm_ne_left = record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nHm_nH2_index]-record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nHm_nH2_index-1-sigma_nHm_ne_left]
								except:
									sigma_nHm_ne_left=0
								sigma_nHm_ne = max(sigma_nHm_ne_right,sigma_nHm_ne_left)
								# temp = np.sqrt(-2*(likelihood_log_probs[:,most_likely_nHm_ne_index,most_likely_nH2_ne_index,most_likely_nH2p_ne_index,most_likely_ne_index,most_likely_Te_index]-max_likelihood_log_prob))
								temp_2 = likelihood_log_probs[:,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
								temp_2 = np.exp(temp_2+np.log(d_nH_ne_values)-np.log(np.sum(np.exp(temp_2)*d_nH_ne_values)))
								try:
									# sigma_nH_ne_right = curve_fit(find_sigma,np.abs(nH_ne_values[most_likely_nH_ne_index:]-most_likely_nH_ne_value),temp[most_likely_nH_ne_index:],p0=[1])[0][0]#,sigma=np.abs(nH_ne_values[most_likely_nH_ne_index:]-most_likely_nH_ne_value)/most_likely_nH_ne_value+0.1)[0]
									sigma_nH_ne_right = temp_2[most_likely_nH_ne_index:]
									if np.sum(sigma_nH_ne_right)<0.34:
										sigma_nH_ne_right=0
									else:
										sigma_nH_ne_right = np.abs(np.array([sum(sigma_nH_ne_right[:_+1]) for _ in range(len(sigma_nH_ne_right)) ])-0.34)
										sigma_nH_ne_right = sigma_nH_ne_right[1:].argmin()
										sigma_nH_ne_right = -record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH_ne_index]+record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH_ne_index+1+sigma_nH_ne_right]
								except:
									sigma_nH_ne_right=0
								try:
									# sigma_nH_ne_left = curve_fit(find_sigma,np.abs(nH_ne_values[:most_likely_nH_ne_index+1]-most_likely_nH_ne_value),temp[:most_likely_nH_ne_index+1],p0=[1])[0][0]#,sigma=np.abs(nH_ne_values[:most_likely_nH_ne_index+1]-most_likely_nH_ne_value)/most_likely_nH_ne_value+0.1)[0][0]
									sigma_nH_ne_left = np.flip(temp_2[:most_likely_nH_ne_index+1],axis=0)
									if np.sum(sigma_nH_ne_left)<0.34:
										sigma_nH_ne_left=0
									else:
										sigma_nH_ne_left = np.abs(np.array([sum(sigma_nH_ne_left[:_+1]) for _ in range(len(sigma_nH_ne_left)) ])-0.34)
										sigma_nH_ne_left = sigma_nH_ne_left[1:].argmin()
										sigma_nH_ne_left = record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH_ne_index]-record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][most_likely_nH_ne_index-1-sigma_nH_ne_left]
								except:
									sigma_nH_ne_left=0
								sigma_nH_ne = max(sigma_nH_ne_right,sigma_nH_ne_left)
								sigma_nHp_ne = (1+most_likely_nHm_ne_value-most_likely_nH2p_ne_value-0)*((sigma_nHm_ne)**2+(sigma_nH2p_ne)**2)**0.5
								sigma_nH3p_ne = 0

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											fig, ax = plt.subplots( 4,2,figsize=(25, 40), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0+'\nMarginalised best index: [nH/ne,nH-/ne,nH2+/ne] [%.3g,%.3g,%.3g]' %(most_likely_marginalised_nH_ne_index,most_likely_marginalised_nHm_nH2_index,most_likely_marginalised_nH2p_nH2_index))
											plot_index = 0
											color = ['b', 'r', 'm', 'y', 'g', 'c', 'slategrey', 'darkorange', 'lime', 'pink', 'gainsboro', 'paleturquoise', 'teal', 'olive']
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_excit.tolist()*2)[1:-1],100*np.array([prob_power_rad_excit.tolist()]*2).T.flatten(),color=color[0],label='power_rad_excit');
											im = ax[plot_index,0].plot(actual_values_power_rad_excit,100*prob_power_rad_excit,'+',color=color[0],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_excit,100,color[0]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_rec_bremm.tolist()*2)[1:-1],100*np.array([prob_power_rad_rec_bremm.tolist()]*2).T.flatten(),color=color[1],label='power_rad_rec_bremm');
											im = ax[plot_index,0].plot(actual_values_power_rad_rec_bremm,100*prob_power_rad_rec_bremm,'+',color=color[1],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_rec_bremm,100,color[1]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_mol.tolist()*2)[1:-1],100*np.array([prob_power_rad_mol.tolist()]*2).T.flatten(),color=color[2],label='power_rad_mol');
											im = ax[plot_index,0].plot(actual_values_power_rad_mol,100*prob_power_rad_mol,'+',color=color[2],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_mol,100,color[2]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_via_ionisation.tolist()*2)[1:-1],100*np.array([prob_power_via_ionisation.tolist()]*2).T.flatten(),color=color[3],label='power_via_ionisation');
											im = ax[plot_index,0].plot(actual_values_power_via_ionisation,100*prob_power_via_ionisation,'+',color=color[3],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_via_ionisation,100,color[3]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_via_recombination.tolist()*2)[1:-1],100*np.array([prob_power_via_recombination.tolist()]*2).T.flatten(),color=color[4],label='power_via_recombination');
											im = ax[plot_index,0].plot(actual_values_power_via_recombination,100*prob_power_via_recombination,'+',color=color[4],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_via_recombination,100,color[4]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_tot_rad_power.tolist()*2)[1:-1],100*np.array([prob_tot_rad_power.tolist()]*2).T.flatten(),color=color[5],label='tot_rad_power');
											im = ax[plot_index,0].plot(actual_values_tot_rad_power,100*prob_tot_rad_power,'+',color=color[5],markersize=5);
											im = ax[plot_index,0].plot(most_likely_tot_rad_power,100,color[5]+'o',markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_Hm.tolist()*2)[1:-1],100*np.array([prob_power_rad_Hm.tolist()]*2).T.flatten(),color=color[6],label='power_rad_Hm');
											im = ax[plot_index,0].plot(actual_values_power_rad_Hm,100*prob_power_rad_Hm,'+',color=color[6],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_Hm,100,'o',color=color[6],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_H2.tolist()*2)[1:-1],100*np.array([prob_power_rad_H2.tolist()]*2).T.flatten(),color=color[7],label='power_rad_H2');
											im = ax[plot_index,0].plot(actual_values_power_rad_H2,100*prob_power_rad_H2,'+',color=color[7],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_H2,100,'o',color=color[7],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rad_H2p.tolist()*2)[1:-1],100*np.array([prob_power_rad_H2p.tolist()]*2).T.flatten(),color=color[8],label='power_rad_H2p');
											im = ax[plot_index,0].plot(actual_values_power_rad_H2p,100*prob_power_rad_H2p,'+',color=color[8],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rad_H2p,100,'o',color=color[8],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_heating_rec.tolist()*2)[1:-1],100*np.array([prob_power_heating_rec.tolist()]*2).T.flatten(),color=color[9],label='power_heating_rec');
											im = ax[plot_index,0].plot(actual_values_power_heating_rec,100*prob_power_heating_rec,'+',color=color[9],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_heating_rec,100,'o',color=color[9],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_rec_neutral.tolist()*2)[1:-1],100*np.array([prob_power_rec_neutral.tolist()]*2).T.flatten(),color=color[10],label='power_rec_neutral');
											im = ax[plot_index,0].plot(actual_values_power_rec_neutral,100*prob_power_rec_neutral,'+',color=color[10],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_rec_neutral,100,'o',color=color[10],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_power_via_brem.tolist()*2)[1:-1],100*np.array([prob_power_via_brem.tolist()]*2).T.flatten(),color=color[11],label='power_via_brem');
											im = ax[plot_index,0].plot(actual_values_power_via_brem,100*prob_power_via_brem,'+',color=color[11],markersize=5);
											im = ax[plot_index,0].plot(most_likely_power_via_brem,100,'o',color=color[11],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_total_removed_power.tolist()*2)[1:-1],100*np.array([prob_total_removed_power.tolist()]*2).T.flatten(),color=color[12],label='total_removed_power');
											im = ax[plot_index,0].plot(actual_values_total_removed_power,100*prob_total_removed_power,'+',color=color[12],markersize=5);
											im = ax[plot_index,0].plot(most_likely_total_removed_power,100,'o',color=color[12],markersize=10,fillstyle='none');
											im = ax[plot_index,0].plot(np.sort(intervals_local_CX.tolist()*2)[1:-1],100*np.array([prob_local_CX.tolist()]*2).T.flatten(),color=color[13],label='local_CX');
											im = ax[plot_index,0].plot(actual_values_local_CX,100*prob_local_CX,'+',color=color[13],markersize=5);
											im = ax[plot_index,0].plot(most_likely_local_CX,100,'o',color=color[13],markersize=10,fillstyle='none');
											# im = ax[plot_index,0].plot([interpolated_power_pulse_shape(time_crop[my_time_pos])/source_power_spread/area/length]*2,[0,100],'k--');
											im = ax[plot_index,0].plot([most_likely_total_removable_power_times_volume]*2,[0,100],'k--');
											im = ax[plot_index,0].plot([max_total_removable_power_times_volume]*2,[0,100],'--',color='gray');
											im = ax[plot_index,0].plot([min_total_removable_power_times_volume]*2,[0,100],'--',color='gray');
											ax[plot_index,0].set_title('Power balance PDF, prob times volume below %.3g of peak neglected, O=ML' %(min_fraction_of_prob_considered) + '\nsigma: molecular %.3g%%, atomic %.3g%%, budget %.3g%%' %(power_molecular_precision*100,power_atomic_precision*100,power_budget_precision*100))
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('Power [W/m3]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											# ax[plot_index,0].set_xlim(left=1e-1*np.min([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power]))
											ax[plot_index,0].set_xlim(left=max(1,1e-1*np.min([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power,most_likely_power_heating_rec,most_likely_power_rec_neutral,most_likely_power_via_brem,most_likely_total_removed_power])),right=1e2*np.max([most_likely_power_rad_excit,most_likely_power_rad_rec_bremm,most_likely_power_rad_mol,most_likely_power_via_ionisation,most_likely_power_via_recombination,most_likely_tot_rad_power]))
											ax[plot_index,0].grid()

											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,:]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,1].plot(Te_values_array,100*temp_2);
											im = ax[plot_index,1].plot(most_likely_Te_value,100,'ko',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_Te_prof_multipulse_interp_crop_limited_restrict,100,'kx',markersize=30);
											im = ax[plot_index,1].plot(Te_values_array,100*np.exp(Te_log_probs)/np.sum(np.exp(Te_log_probs)),':');
											im = ax[plot_index,1].plot([most_likely_Te_value-sigma_Te_left,most_likely_Te_value-sigma_Te_left],[0,100],'k--');
											im = ax[plot_index,1].plot([most_likely_Te_value+sigma_Te_right,most_likely_Te_value+sigma_Te_right],[0,100],'k--');
											im = ax[plot_index,1].plot([np.min(Te_values_limits),np.min(Te_values_limits)],[0,100],'y--');
											im = ax[plot_index,1].plot([np.max(Te_values_limits),np.max(Te_values_limits)],[0,100],'y--');
											im = ax[plot_index,1].plot(np.sort(intervals_Te_values.tolist()*2)[1:-1],100*np.array([prob_Te_values.tolist()]*2).T.flatten(),color='m');
											im = ax[plot_index,1].plot(actual_values_Te_values,100*prob_Te_values,'+',color='m',markersize=5);
											ax[plot_index,1].set_title('Te at highest likelihood with precision\n :=prior, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('temperature [eV]')
											# ax[plot_index,0].set_xscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											plot_index += 1
											temp_2 = likelihood_log_probs[:,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],100*temp_2,color[0],label='nH_ne');
											im = ax[plot_index,0].plot(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][record_nH_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index].argmax()],100,color[0]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH_ne_value,100,color[0]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nH_ne_value-sigma_nH_ne_left,most_likely_nH_ne_value-sigma_nH_ne_left],[0,100],color[0]+'--');
											im = ax[plot_index,0].plot([most_likely_nH_ne_value+sigma_nH_ne_right,most_likely_nH_ne_value+sigma_nH_ne_right],[0,100],color[0]+'--');
											im = ax[plot_index,0].plot(record_nH_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],100*np.exp(record_nH_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])/np.sum(np.exp(record_nH_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])),color[0]+':');
											im = ax[plot_index,0].plot(np.sort(intervals_nH_ne_values.tolist()*2)[1:-1],100*np.array([prob_nH_ne_values.tolist()]*2).T.flatten(),color=color[0]);
											im = ax[plot_index,0].plot(actual_values_nH_ne_values,100*prob_nH_ne_values,'+',color=color[0],markersize=5);
											im = ax[plot_index,0].plot(np.sort(intervals_nH_ne_excited_states.tolist()*2)[1:-1],100*np.array([prob_nH_ne_excited_states.tolist()]*2).T.flatten(),'--',color=color[0]);
											im = ax[plot_index,0].plot(actual_values_nH_ne_excited_states,100*prob_nH_ne_excited_states,'+',color=color[0],markersize=5);
											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,:,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(record_nHm_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],100*temp_2,color[1],label='nHm_ne');
											im = ax[plot_index,0].plot(most_likely_nHm_ne_value,100,color[1]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nHm_ne_value-sigma_nHm_ne_left,most_likely_nHm_ne_value-sigma_nHm_ne_left],[0,100],color[1]+'--');
											im = ax[plot_index,0].plot([most_likely_nHm_ne_value+sigma_nHm_ne_right,most_likely_nHm_ne_value+sigma_nHm_ne_right],[0,100],color[1]+'--');
											im = ax[plot_index,0].plot(np.sort(intervals_nHm_ne_values.tolist()*2)[1:-1],100*np.array([prob_nHm_ne_values.tolist()]*2).T.flatten(),color=color[1]);
											im = ax[plot_index,0].plot(actual_values_nHm_ne_values,100*prob_nHm_ne_values,'+',color=color[1],markersize=5);
											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,:,most_likely_nH2p_nH2_index,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],100*temp_2,color[2],label='nH2_ne');
											im = ax[plot_index,0].plot(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index][record_nH2_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index].argmax()],100,color[2]+'x',markersize=30);
											im = ax[plot_index,0].plot(most_likely_nH2_ne_value,100,color[2]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nH2_ne_value-sigma_nH2_ne_left,most_likely_nH2_ne_value-sigma_nH2_ne_left],[0,100],color[2]+'--');
											im = ax[plot_index,0].plot([most_likely_nH2_ne_value+sigma_nH2_ne_right,most_likely_nH2_ne_value+sigma_nH2_ne_right],[0,100],color[2]+'--');
											im = ax[plot_index,0].plot(record_nH2_ne_values[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],100*np.exp(record_nH2_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])/np.sum(np.exp(record_nH2_ne_log_prob[:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index])),color[2]+':');
											im = ax[plot_index,0].plot(np.sort(intervals_nH2_ne_values.tolist()*2)[1:-1],100*np.array([prob_nH2_ne_values.tolist()]*2).T.flatten(),color=color[2]);
											im = ax[plot_index,0].plot(actual_values_nH2_ne_values,100*prob_nH2_ne_values,'+',color=color[2],markersize=5);
											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,:,most_likely_ne_index,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,0].plot(record_nH2p_ne_values[most_likely_nH2_ne_index,:,most_likely_ne_index*TS_Te_steps + most_likely_Te_index],100*temp_2,color[3],label='nH2p_ne');
											im = ax[plot_index,0].plot(most_likely_nH2p_ne_value,100,color[3]+'o',markersize=30,fillstyle='none');
											im = ax[plot_index,0].plot([most_likely_nH2p_ne_value-sigma_nH2p_ne_left,most_likely_nH2p_ne_value-sigma_nH2p_ne_left],[0,100],color[3]+'--');
											im = ax[plot_index,0].plot([most_likely_nH2p_ne_value+sigma_nH2p_ne_right,most_likely_nH2p_ne_value+sigma_nH2p_ne_right],[0,100],color[3]+'--');
											im = ax[plot_index,0].plot(np.sort(intervals_nH2p_ne_values.tolist()*2)[1:-1],100*np.array([prob_nH2p_ne_values.tolist()]*2).T.flatten(),color=color[3]);
											im = ax[plot_index,0].plot(actual_values_nH2p_ne_values,100*prob_nH2p_ne_values,'+',color=color[3],markersize=5);
											ax[plot_index,0].set_title('Relative densities at highest likelihood with precision\n :=prior, O=ML, X=central')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('[au]')
											ax[plot_index,0].set_xscale('log')
											ax[plot_index,0].legend(loc='best', fontsize='x-small')
											ax[plot_index,0].grid()

											temp_2 = likelihood_log_probs[most_likely_nH_ne_index,most_likely_nHm_nH2_index,most_likely_nH2_ne_index,most_likely_nH2p_nH2_index,:,most_likely_Te_index]
											temp_2 = np.exp(temp_2-np.log(np.sum(np.exp(temp_2))))
											im = ax[plot_index,1].plot(ne_values_array,100*temp_2);
											im = ax[plot_index,1].plot(most_likely_ne_value,100,'ko',markersize=30,fillstyle='none');
											im = ax[plot_index,1].plot(merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20,100,'kx',markersize=30);
											im = ax[plot_index,1].plot(ne_values_array,100*np.exp(ne_log_probs)/np.sum(np.exp(ne_log_probs)),':');
											im = ax[plot_index,1].plot([most_likely_ne_value-sigma_ne_left,most_likely_ne_value-sigma_ne_left],[0,100],'k--');
											im = ax[plot_index,1].plot([most_likely_ne_value+sigma_ne_right,most_likely_ne_value+sigma_ne_right],[0,100],'k--');ne_values_limits
											im = ax[plot_index,1].plot([np.min(ne_values_limits),np.min(ne_values_limits)],[0,100],'y--');
											im = ax[plot_index,1].plot([np.max(ne_values_limits),np.max(ne_values_limits)],[0,100],'y--');
											im = ax[plot_index,1].plot(np.sort(intervals_ne_values.tolist()*2)[1:-1],100*np.array([prob_ne_values.tolist()]*2).T.flatten(),color='m');
											im = ax[plot_index,1].plot(actual_values_ne_values,100*prob_ne_values,'+',color='m',markersize=5);
											ax[plot_index,1].set_title('ne at highest likelihood with precision\n :=prior, O=ML, X=TS')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('density [#/m3]')
											# ax[plot_index,0].set_yscale('log')
											# ax[plot_index,1].legend(loc='best', fontsize='x-small')
											ax[plot_index,1].grid()

											if include_particles_limitation:
												plot_index += 1
												if most_likely_net_e_destruction<=0:
													im = ax[plot_index,0].plot(-most_likely_net_e_destruction,100,'go',markersize=30,fillstyle='none');
												else:
													im = ax[plot_index,0].plot(most_likely_net_e_destruction,100,'ro',markersize=30,fillstyle='none');
												# im = ax[plot_index,0].plot(np.sort(intervals_net_e_destruction.tolist()*2)[1:-1],100*np.array([prob_net_e_destruction.tolist()]*2).T.flatten(),color='m');
												# im = ax[plot_index,0].plot(actual_values_net_e_destruction,100*prob_net_e_destruction,'+',color='m',markersize=5);
												im = ax[plot_index,0].plot(np.sort(intervals_net_e_destruction[intervals_net_e_destruction>=0].tolist()*2)[1:-1],100*np.array([prob_net_e_destruction[(intervals_net_e_destruction>0)[1:]].tolist()]*2).T.flatten(),color='r');
												im = ax[plot_index,0].plot(-np.sort(intervals_net_e_destruction[intervals_net_e_destruction<=0].tolist()*2)[1:-1],100*np.array([prob_net_e_destruction[(intervals_net_e_destruction<0)[:-1]].tolist()]*2).T.flatten(),color='g');
												im = ax[plot_index,0].plot(-actual_values_net_e_destruction[actual_values_net_e_destruction<=0],100*prob_net_e_destruction[actual_values_net_e_destruction<=0],'+',color='g',markersize=5);
												im = ax[plot_index,0].plot(actual_values_net_e_destruction[actual_values_net_e_destruction>=0],100*prob_net_e_destruction[actual_values_net_e_destruction>=0],'+',color='r',markersize=5);
												im = ax[plot_index,0].plot([most_likely_total_removable_e]*2,[0,100],'k--');
												im = ax[plot_index,0].plot([total_removable_e[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,0].plot([total_removable_e[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,0].set_title('electrons balance within time and volume step\ngreen=creation, red=destruction\nsigma: molecular %.3g%%, atomic %.3g%%, budget %.3g%%' %(particle_molecular_precision*100,particle_atomic_precision*100,particle_atomic_budget_precision*100))
												ax[plot_index,0].set_ylabel('normalised likelihood')
												ax[plot_index,0].set_xlabel('particles [#*10^20]')
												ax[plot_index,0].set_xscale('log')
												# ax[plot_index,0].legend(loc='best', fontsize='x-small')
												ax[plot_index,0].grid()

												if most_likely_net_Hp_destruction<=0:
													im = ax[plot_index,1].plot(-most_likely_net_Hp_destruction,100,'go',markersize=30,fillstyle='none');
												else:
													im = ax[plot_index,1].plot(most_likely_net_Hp_destruction,100,'ro',markersize=30,fillstyle='none');
												# im = ax[plot_index,1].plot(np.sort(intervals_net_Hp_destruction.tolist()*2)[1:-1],100*np.array([prob_net_Hp_destruction.tolist()]*2).T.flatten(),color='m');
												# im = ax[plot_index,1].plot(actual_values_net_Hp_destruction,100*prob_net_Hp_destruction,'+',color='m',markersize=5);
												im = ax[plot_index,1].plot(np.sort(intervals_net_Hp_destruction[intervals_net_Hp_destruction>=0].tolist()*2)[1:-1],100*np.array([prob_net_Hp_destruction[(intervals_net_Hp_destruction>0)[1:]].tolist()]*2).T.flatten(),color='r');
												im = ax[plot_index,1].plot(-np.sort(intervals_net_Hp_destruction[intervals_net_Hp_destruction<=0].tolist()*2)[1:-1],100*np.array([prob_net_Hp_destruction[(intervals_net_Hp_destruction<0)[:-1]].tolist()]*2).T.flatten(),color='g');
												im = ax[plot_index,1].plot(-actual_values_net_Hp_destruction[actual_values_net_Hp_destruction<=0],100*prob_net_Hp_destruction[actual_values_net_Hp_destruction<=0],'+',color='g',markersize=5);
												im = ax[plot_index,1].plot(actual_values_net_Hp_destruction[actual_values_net_Hp_destruction>=0],100*prob_net_Hp_destruction[actual_values_net_Hp_destruction>=0],'+',color='r',markersize=5);
												im = ax[plot_index,1].plot([most_likely_total_removable_Hp]*2,[0,100],'k--');
												im = ax[plot_index,1].plot([total_removable_Hp[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,1].plot([total_removable_Hp[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,1].set_title('H+ balance within time and volume step\ngreen=creation, red=destruction\nlarge = H+, small = H\nsigma: molecular %.3g%%, atomic %.3g%%, budget %.3g%%' %(particle_molecular_precision*100,particle_atomic_precision*100,particle_atomic_budget_precision*100))
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('particles [#*10^20]')
												ax[plot_index,1].set_xscale('log')
												# ax[plot_index,0].legend(loc='best', fontsize='x-small')
												ax[plot_index,1].grid()

												plot_index += 1
												if most_likely_net_Hm_destruction<=0:
													im = ax[plot_index,0].plot(-most_likely_net_Hm_destruction,100,'go',markersize=30,fillstyle='none');
												else:
													im = ax[plot_index,0].plot(most_likely_net_Hm_destruction,100,'ro',markersize=30,fillstyle='none');
												# im = ax[plot_index,0].plot(np.sort(intervals_net_Hm_destruction.tolist()*2)[1:-1],100*np.array([prob_net_Hm_destruction.tolist()]*2).T.flatten(),color='m');
												# im = ax[plot_index,0].plot(actual_values_net_Hm_destruction,100*prob_net_Hm_destruction,'+',color='m',markersize=5);
												im = ax[plot_index,0].plot(np.sort(intervals_net_Hm_destruction[intervals_net_Hm_destruction>=0].tolist()*2)[1:-1],100*np.array([prob_net_Hm_destruction[(intervals_net_Hm_destruction>0)[1:]].tolist()]*2).T.flatten(),color='r');
												im = ax[plot_index,0].plot(-np.sort(intervals_net_Hm_destruction[intervals_net_Hm_destruction<=0].tolist()*2)[1:-1],100*np.array([prob_net_Hm_destruction[(intervals_net_Hm_destruction<0)[:-1]].tolist()]*2).T.flatten(),color='g');
												im = ax[plot_index,0].plot(-actual_values_net_Hm_destruction[actual_values_net_Hm_destruction<=0],100*prob_net_Hm_destruction[actual_values_net_Hm_destruction<=0],'+',color='g',markersize=5);
												im = ax[plot_index,0].plot(actual_values_net_Hm_destruction[actual_values_net_Hm_destruction>=0],100*prob_net_Hm_destruction[actual_values_net_Hm_destruction>=0],'+',color='r',markersize=5);
												im = ax[plot_index,0].plot([most_likely_total_removable_Hm]*2,[0,100],'k--');
												im = ax[plot_index,0].plot([total_removable_Hm[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,0].plot([total_removable_Hm[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,0].set_title('H- balance within time and volume step\ngreen=creation, red=destruction\nsigma: molecular %.3g%%, atomic %.3g%%, budget %.3g%%' %(particle_molecular_precision*100,particle_atomic_precision*100,particle_molecular_budget_precision*100))
												ax[plot_index,0].set_ylabel('normalised likelihood')
												ax[plot_index,0].set_xlabel('particles [#*10^20]')
												ax[plot_index,0].set_xscale('log')
												# ax[plot_index,0].legend(loc='best', fontsize='x-small')
												ax[plot_index,0].grid()

												if most_likely_net_H2p_destruction<=0:
													im = ax[plot_index,1].plot(-most_likely_net_H2p_destruction,100,'go',markersize=30,fillstyle='none');
												else:
													im = ax[plot_index,1].plot(most_likely_net_H2p_destruction,100,'ro',markersize=30,fillstyle='none');
												# im = ax[plot_index,1].plot(np.sort(intervals_net_H2p_destruction.tolist()*2)[1:-1],100*np.array([prob_net_H2p_destruction.tolist()]*2).T.flatten(),color='m');
												# im = ax[plot_index,1].plot(actual_values_net_H2p_destruction,100*prob_net_H2p_destruction,'+',color='m',markersize=5);
												im = ax[plot_index,1].plot(np.sort(intervals_net_H2p_destruction[intervals_net_H2p_destruction>=0].tolist()*2)[1:-1],100*np.array([prob_net_H2p_destruction[(intervals_net_H2p_destruction>0)[1:]].tolist()]*2).T.flatten(),color='r');
												im = ax[plot_index,1].plot(-np.sort(intervals_net_H2p_destruction[intervals_net_H2p_destruction<=0].tolist()*2)[1:-1],100*np.array([prob_net_H2p_destruction[(intervals_net_H2p_destruction<0)[:-1]].tolist()]*2).T.flatten(),color='g');
												im = ax[plot_index,1].plot(-actual_values_net_H2p_destruction[actual_values_net_H2p_destruction<=0],100*prob_net_H2p_destruction[actual_values_net_H2p_destruction<=0],'+',color='g',markersize=5);
												im = ax[plot_index,1].plot(actual_values_net_H2p_destruction[actual_values_net_H2p_destruction>=0],100*prob_net_H2p_destruction[actual_values_net_H2p_destruction>=0],'+',color='r',markersize=5);
												im = ax[plot_index,1].plot([most_likely_total_removable_H2p]*2,[0,100],'k--');
												im = ax[plot_index,1].plot([total_removable_H2p[non_zero_prob_select].max()]*2,[0,100],'--',color='gray');
												im = ax[plot_index,1].plot([total_removable_H2p[non_zero_prob_select].min()]*2,[0,100],'--',color='gray');
												ax[plot_index,1].set_title('H2+ balance within time and volume step\ngreen=creation, red=destruction\nsigma: molecular %.3g%%, atomic %.3g%%, budget %.3g%%' %(particle_molecular_precision*100,particle_atomic_precision*100,particle_molecular_budget_precision*100))
												ax[plot_index,1].set_ylabel('normalised likelihood')
												ax[plot_index,1].set_xlabel('particles [#*10^20]')
												ax[plot_index,1].set_xscale('log')
												# ax[plot_index,0].legend(loc='best', fontsize='x-small')
												ax[plot_index,1].grid()

											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_fourth.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')

								# I add this because I want to see how Halpha works
								n_list_all_full = np.array([3]+np.array(n_list_all).tolist())
								multiplicative_factor_full = energy_difference_full[n_list_all_full - 2] * einstein_coeff_full[n_list_all_full - 2] / J_to_eV


								excitation_full = []
								for isel in (np.array(n_list_all_full)-2):
									temp = read_adf15(pecfile, isel, most_likely_Te_value,most_likely_ne_value * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									temp[np.isinf(temp)] = 0
									excitation_full.append(temp)
								excitation_full = np.array(excitation_full).flatten()  # in # photons cm^-3 s^-1
								excitation_full = (excitation_full * (10 ** -6) * (energy_difference_full[n_list_all_full - 2] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

								recombination_full = []
								for isel in (np.array(n_list_all_full)+16):
									temp = read_adf15(pecfile, isel, most_likely_Te_value,most_likely_ne_value * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									recombination_full.append(temp)
								recombination_full = np.array(recombination_full).flatten()  # in # photons cm^-3 s^-1 / (# cm^-3)**2
								recombination_full = (recombination_full * (10 ** -6) * (energy_difference_full[n_list_all_full - 2] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2


								def fit_Yacora_pop_coeff(ne,Te,T_Hp,T_Hm,T_H2p,multiplicative_factor,excitation_restrict,recombination_restrict):
									def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
										# I add this because I want to see how Halpha works
										# nHp_ne=1+nHm_ne-nH2p_ne-nH3p_ne
										multiplicative_factor = energy_difference_full[n_list_all - 2] * einstein_coeff_full[n_list_all - 2] / J_to_eV
										total = np.array([(excitation_full[n_list_all - 3] *  nH_ne /multiplicative_factor).astype('float')])
										total += np.array([(recombination_full[n_list_all - 3] * nHp_ne /multiplicative_factor).astype('float')])
										# total = nH_ne*From_H_pop_coeff_full([[Te,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
										# total += nHp_ne*From_Hp_pop_coeff_full([[Te,ne]],n_list_all)
										total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[Te,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full_extra([[Te,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
										total += nH2_ne*From_H2_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total += nH2p_ne*From_H2p_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total += nH3p_ne*From_H3p_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total = total[0]*(ne ** 2)*multiplicative_factor
										# print(total)
										return np.log(total)
									return calculated_emission

								nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = most_likely_nH_ne_value,1+most_likely_nHm_ne_value-most_likely_nH2p_ne_value-0,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value,0
								# nH_ne_sigma, nHp_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = 1,1,1,1,1,1
								# residuals = np.sum(((np.log(inverted_profiles_crop_restrict) - fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, *fit[0]))) ** 2)
								residuals = np.sum(((inverted_profiles_crop_restrict - np.exp(fit_Yacora_pop_coeff(most_likely_ne_value,most_likely_Te_value,T_Hp,T_Hm,T_H2p,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne)))/inverted_profiles_crop_sigma_restrict) ** 2)

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											# tm.sleep(np.random.random()*10)
											plt.figure(figsize=(20, 10))
											# nH_ne, nHp_ne, nH2p_ne = fit[0]
											# nHp_ne = 1 + nHm_ne - nH2p_ne
											plt.errorbar(n_list_all,inverted_profiles_crop_restrict,yerr=inverted_profiles_crop_sigma_restrict,label='OES')
											plt.plot(n_list_all_full,(excitation_full *  nH_ne).astype('float')*(most_likely_ne_value ** 2),label='direct excitation\nH(q) + e-  H(p>q) + e- (ADAS coeff)')
											plt.plot(n_list_all_full,(recombination_full * nHp_ne).astype('float')*(most_likely_ne_value ** 2),label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e- (ADAS coeff)')
											# plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[most_likely_Te_value,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
											# plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[most_likely_Te_value,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
											plt.plot(n_list_all_full,nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[most_likely_Te_value,T_Hp,T_Hm,most_likely_ne_value,nHp_ne*most_likely_ne_value]],n_list_all_full) )[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H+ mutual neutralisation\nH+ + H-  H(p) + H')
											plt.plot(n_list_all_full,nHm_ne*( From_Hn_with_H2p_pop_coeff_full_extra([[most_likely_Te_value,T_H2p,T_Hm,most_likely_ne_value,nH2p_ne*most_likely_ne_value]],n_list_all_full) )[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2+ mutual neutralisation\nH2+ + H-  H(p) + H2')
											plt.plot(n_list_all_full,nH2_ne*From_H2_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
											plt.plot(n_list_all_full,nH2p_ne*From_H2p_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
											plt.plot(n_list_all_full,nH3p_ne*From_H3p_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
											temp = np.exp(fit_Yacora_pop_coeff(most_likely_ne_value,most_likely_Te_value,T_Hp,T_Hm,T_H2p,multiplicative_factor_full,excitation_restrict,recombination_restrict)(n_list_all_full, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne))
											plt.plot(n_list_all_full,temp,'--',label='total fit')
											plt.plot(n_list_all_full,((excitation_full *  nH_ne).astype('float')*(most_likely_ne_value ** 2) + (recombination_full * nHp_ne).astype('float')*(most_likely_ne_value ** 2)),'+',label='excitation + recombination')
											plt.semilogy()
											plt.legend(loc='best', fontsize='x-small')
											plt.ylim(np.min(inverted_profiles_crop_restrict)/2,max(np.max(inverted_profiles_crop_restrict)*2,np.max(temp)))
											plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g+/-%.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value,sigma_Te) + '%.3g(ML %.3g+/-%.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20,sigma_ne*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g+/-%.3g, ' %(nH_ne,sigma_nH_ne) + '%.3g+/-%.3g, ' %(nHp_ne,sigma_nHp_ne)+ '%.3g+/-%.3g, ' %(nHm_ne,sigma_nHm_ne)+ '%.3g+/-%.3g, ' %(nH2_ne,sigma_nH2_ne)+ '%.3g+/-%.3g, ' %(nH2p_ne,sigma_nH2p_ne)+ '%.3g+/-%.3g]' %(nH3p_ne,sigma_nH3p_ne) +'\nH ionization length %.3gm' % ionization_length_H +'\nH2 ionization length %.3gm' % ionization_length_H2)
											plt.xlabel('Exctited state n')
											plt.ylabel('Line emissivity n->2 [W m^-3]')
											# plt.pause(0.01)
											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														plt.savefig(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														tm.sleep(np.random.random()**2)
														# print(path_where_to_save_everything + mod4 + '/merge'+str(merge_ID_target)+'_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')

								end_time = tm.time()
								time_spent = end_time-start_time

								sgna =999 ;print('worker '+str(current_process())+' marker '+str(sgna)+' '+str(domain_index)+' in %.3gmin %.3gsec' %(int(time_spent/60),int(time_spent%60)))
								results = [nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne,residuals,most_likely_Te_value,most_likely_ne_value*1e-20,sigma_Te,sigma_ne,sigma_nH_ne,sigma_nHp_ne,sigma_nHm_ne,sigma_nH2_ne,sigma_nH2p_ne,sigma_nH3p_ne,False,power_balance_data]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
								try:
									del build_log_PDF,find_correlation,find_sigma,fit_Yacora_pop_coeff
								except:
									try:
										del build_log_PDF,find_sigma,fit_Yacora_pop_coeff
									except:
										del find_sigma,fit_Yacora_pop_coeff
							except Exception as e:
								results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
								print(traceback.format_exc())
								print('child multiprocessor terminated with error '+str(e)+'worker '+str(current_process())+' '+str(domain_index)+' t=%.3g, r=%.3g' %(my_time_pos,my_r_pos))
							return output	# here I use flexible priors for H2, H2+, H-

						def abortable_worker(func, *arg):
							timeout = timeout_bayesian_search
							p = ThreadPool(1)
							res = p.apply_async(func, args=[arg])
							print('External starting of ' + str(arg[0]))
							start = tm.time()
							try:
								out = res.get(timeout)  # Wait timeout seconds for func to complete.
								print("Succesful end of " +str(arg[0])+ " in %.3g min" %((tm.time() - start)/60))
								return out
							# except multiprocessing.TimeoutError:
							except Exception as e:
								print("External aborting due to timeout " +str(arg[0])+ " in %.3g min" %((tm.time() - start)/60))
								results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
								my_time_pos = arg[1]
								my_r_pos = arg[2]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
								return output

						if do_only_one_loop==False:
							if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results.npz') ) or recorded_data_override[0] ):

								all_indexes = []
								global_index = 0
								to_print=collect_power_PDF
								for my_time_pos in range(len(time_crop)):
								# for my_time_pos in sample_time_step:
									for my_r_pos in range(len(r_crop)):
									# for my_r_pos in sample_radious:
										if (merge_Te_prof_multipulse_interp_crop_limited[my_time_pos,my_r_pos]> 0.1 and merge_ne_prof_multipulse_interp_crop_limited[my_time_pos,my_r_pos]> 5e-07):
											all_indexes.append([global_index,my_time_pos,my_r_pos,1,guess,ionization_length_H[my_time_pos, my_r_pos],ionization_length_H2[my_time_pos, my_r_pos],to_print])
											# calc_stuff([global_index,my_time_pos,my_r_pos,1,guess,ionization_length_H,ionization_length_Hm,ionization_length_H2,ionization_length_H2p,to_print])
										global_index+=1

								# if __name__ == '__main__':
								if False:	# old loop that doesn't have a timeout
									try:
										# with Pool(number_cpu_available,maxtasksperchild=1) as pool:
											# pool = Pool(number_cpu_available)
										all_results = []
										for fraction in range(int(np.ceil(len(all_indexes)/(number_cpu_available*4)))):
											with Pool(number_cpu_available,maxtasksperchild=1) as pool:
												print('starting set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1)) + ', index ' + str(all_indexes[fraction*(number_cpu_available*4)][0]) + ' to ' + str(all_indexes[(fraction+1)*(number_cpu_available*4)-1][0]))
												temp = pool.map(calc_stuff_2, all_indexes[fraction*(number_cpu_available*4):(fraction+1)*(number_cpu_available*4)])
												pool.close()
												pool.join()
												pool.terminate()
												del pool
												all_results.extend(temp)
												print('set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1))+' done')
											#all_results = [*pool.map(calc_stuff, all_indexes)]
									except Exception as e:
										print('parent multiprocessor terminated with error '+str(e))
										pool.close()
									# pool.close()
										pool.join()
										pool.terminate()
										del pool
								elif True:	# new loop with timeout
									try:
										# with Pool(number_cpu_available,maxtasksperchild=1) as pool:
											# pool = Pool(number_cpu_available)
										all_results = []
										for fraction in range(int(np.ceil(len(all_indexes)/(number_cpu_available*4)))):
											with Pool(number_cpu_available,maxtasksperchild=1) as pool:
												print('starting set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1)) + ', index ' + str(all_indexes[fraction*(number_cpu_available*4)][0]) + ' to ' + str(all_indexes[(fraction+1)*(number_cpu_available*4)-1][0]))
												temp1 = []
												for f in all_indexes[fraction*(number_cpu_available*4):(fraction+1)*(number_cpu_available*4)]:
													abortable_func = partial(abortable_worker, calc_stuff_2)
													temp1.append(pool.apply_async(abortable_func, args=f))
												pool.close()
												pool.join()
												pool.terminate()
												temp = []
												for value in temp1:
													temp.append(value.get())
												del pool
												all_results.extend(temp)
												print('set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1))+' done')
											#all_results = [*pool.map(calc_stuff, all_indexes)]
									except Exception as e:
										print('parent multiprocessor terminated with error '+str(e))
										pool.close()
									# pool.close()
										pool.join()
										pool.terminate()
										del pool

								for i in range(len(all_results)):
									if (all_results[i].results)[17]==False:
										nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
										nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
										nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
										nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
										nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
										nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
										residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]
										Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[7]
										ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[8]
										sigma_Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[9]
										sigma_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[10]
										sigma_nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[11]
										sigma_nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[12]
										sigma_nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[13]
										sigma_nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[14]
										sigma_nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[15]
										sigma_nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[16]
										power_balance_data[int(all_results[i].my_time_pos)*np.shape(nH_ne_all)[1] + int(all_results[i].my_r_pos)] = (all_results[i].results)[18]


								# all_indexes = []
								# global_index = 0
								# to_print=True
								# for my_time_pos in range(len(time_crop)):
								# 	if my_time_pos in sample_time_step:
								# 		for my_r_pos in range(len(r_crop)):
								# 			if my_r_pos in sample_radious:
								# 				calc_stuff([global_index,my_time_pos,my_r_pos,1,guess,ionization_length_H,ionization_length_Hm,ionization_length_H2,ionization_length_H2p,to_print])


								np.savez_compressed(path_where_to_save_everything + mod4 +'/results',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all,Te_all=Te_all,ne_all=ne_all,sigma_Te_all=sigma_Te_all,sigma_ne_all=sigma_ne_all,sigma_nH_ne_all=sigma_nH_ne_all,sigma_nHp_ne_all=sigma_nHp_ne_all,sigma_nHm_ne_all=sigma_nHm_ne_all,sigma_nH2_ne_all=sigma_nH2_ne_all,sigma_nH2p_ne_all=sigma_nH2p_ne_all,sigma_nH3p_ne_all=sigma_nH3p_ne_all)
								if collect_power_PDF:
									with open(path_where_to_save_everything + mod4 +'/power_balance.data', 'wb') as filehandle:
									    pickle.dump(power_balance_data, filehandle)
								else:
									with open(path_where_to_save_everything + mod4 +'/power_balance_no_PDF.data', 'wb') as filehandle:
									    pickle.dump(power_balance_data, filehandle)

							else:
								nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH_ne_all']
								nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nHp_ne_all']
								nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nHm_ne_all']
								nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH2_ne_all']
								nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH2p_ne_all']
								nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['nH3p_ne_all']
								residuals_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['residuals_all']
								try:
									Te_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['Te_all']
									ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['ne_all']
								except:
									print('Bayesian Te, ne not present')
									Te_all = cp.deepcopy(merge_Te_prof_multipulse_interp_crop_limited)
									ne_all = cp.deepcopy(merge_ne_prof_multipulse_interp_crop_limited)
								try:
									sigma_Te_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_Te_all']
									sigma_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_ne_all']
									sigma_nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_nH_ne_all']
									sigma_nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_nHp_ne_all']
									sigma_nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_nHm_ne_all']
									sigma_nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_nH2_ne_all']
									sigma_nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_nH2p_ne_all']
									sigma_nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results.npz')['sigma_nH3p_ne_all']
								except:
									print('sigma not present')
								try:
									with open(path_where_to_save_everything + mod4 +'/power_balance.data', 'rb') as filehandle:
									    power_balance_data = pickle.load(filehandle)
								except:
									print('power_balance_data not present')

							global_pass = 2
							exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())

						# if True: # I don't think now, given the indetermination in how emission profiles fit the measurements, that second passes are useful. 04/06/2020 I do it for the locations with low Te, ne

						if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results2.npz') ) or recorded_data_override[1] ):


							all_indexes = []
							global_index = 0
							to_print=collect_power_PDF
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									if (merge_Te_prof_multipulse_interp_crop[my_time_pos,my_r_pos]> 0 and merge_ne_prof_multipulse_interp_crop[my_time_pos,my_r_pos]> 0):
										if nHm_ne_all[my_time_pos,my_r_pos]==0:
											all_indexes.append([global_index,my_time_pos,my_r_pos,2,guess,ionization_length_H[my_time_pos, my_r_pos],ionization_length_H2[my_time_pos, my_r_pos],to_print])
									global_index+=1

							# if __name__ == '__main__':
							try:
								# with Pool(number_cpu_available,maxtasksperchild=1) as pool:
									# pool = Pool(number_cpu_available)
								all_results = []
								for fraction in range(int(np.ceil(len(all_indexes)/(number_cpu_available*4)))):
									with Pool(number_cpu_available,maxtasksperchild=1) as pool:
										print('starting set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1)))
										temp = pool.map(calc_stuff_2, all_indexes[fraction*(number_cpu_available*4):(fraction+1)*(number_cpu_available*4)])
										pool.close()
										pool.join()
										pool.terminate()
										del pool
										all_results.extend(temp)
										print('set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1))+' done')
									#all_results = [*pool.map(calc_stuff, all_indexes)]
							except Exception as e:
								print('parent multiprocessor terminated with error '+str(e))
								pool.close()
							# pool.close()
								pool.join()
								pool.terminate()
								del pool

							for i in range(len(all_results)):
								if (all_results[i].results)[17]==False:
									nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
									nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
									nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
									nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
									nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
									nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
									residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]
									Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[7]
									ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[8]
									sigma_Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[9]
									sigma_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[10]
									sigma_nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[11]
									sigma_nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[12]
									sigma_nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[13]
									sigma_nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[14]
									sigma_nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[15]
									sigma_nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[16]
									power_balance_data[int(all_results[i].my_time_pos)*np.shape(nH_ne_all)[1] + int(all_results[i].my_r_pos)] = (all_results[i].results)[18]

							np.savez_compressed(path_where_to_save_everything + mod4 +'/results2',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all,Te_all=Te_all,ne_all=ne_all,sigma_Te_all=sigma_Te_all,sigma_ne_all=sigma_ne_all,sigma_nH_ne_all=sigma_nH_ne_all,sigma_nHp_ne_all=sigma_nHp_ne_all,sigma_nHm_ne_all=sigma_nHm_ne_all,sigma_nH2_ne_all=sigma_nH2_ne_all,sigma_nH2p_ne_all=sigma_nH2p_ne_all,sigma_nH3p_ne_all=sigma_nH3p_ne_all)
							if collect_power_PDF:
								with open(path_where_to_save_everything + mod4 +'/power_balance2.data', 'wb') as filehandle:
								    pickle.dump(power_balance_data, filehandle)
							else:
								with open(path_where_to_save_everything + mod4 +'/power_balance2_no_PDF.data', 'wb') as filehandle:
								    pickle.dump(power_balance_data, filehandle)

						else:
							nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['nH_ne_all']
							nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['nHp_ne_all']
							nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['nHm_ne_all']
							nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['nH2_ne_all']
							nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['nH2p_ne_all']
							nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['nH3p_ne_all']
							residuals_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['residuals_all']
							try:
								Te_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['Te_all']
								ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['ne_all']
							except:
								print('Bayesian Te, ne not present')
								Te_all = cp.deepcopy(merge_Te_prof_multipulse_interp_crop_limited)
								ne_all = cp.deepcopy(merge_ne_prof_multipulse_interp_crop_limited)
							try:
								sigma_Te_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_Te_all']
								sigma_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_ne_all']
								sigma_nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_nH_ne_all']
								sigma_nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_nHp_ne_all']
								sigma_nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_nHm_ne_all']
								sigma_nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_nH2_ne_all']
								sigma_nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_nH2p_ne_all']
								sigma_nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results2.npz')['sigma_nH3p_ne_all']
							except:
								print('sigma not present')
							try:
								with open(path_where_to_save_everything + mod4 +'/power_balance2.data', 'rb') as filehandle:
								    power_balance_data = pickle.load(filehandle)
							except:
								print('power_balance_data not present')

						global_pass = 3
						exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())



						# if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results3.npz') ) or recorded_data_override[2] ):
						#
						#
						# 	all_indexes = []
						# 	global_index = 0
						# 	to_print=collect_power_PDF
						# 	for my_time_pos in range(len(time_crop)):
						# 		for my_r_pos in range(len(r_crop)):
						# 			if (merge_Te_prof_multipulse_interp_crop[my_time_pos,my_r_pos]> 0 and merge_ne_prof_multipulse_interp_crop[my_time_pos,my_r_pos]> 0):
						# 				if nHm_ne_all[my_time_pos,my_r_pos]==0:
						# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,guess,ionization_length_H[my_time_pos, my_r_pos],ionization_length_H2[my_time_pos, my_r_pos],to_print])
						# 			global_index+=1
						#
						# 	# if __name__ == '__main__':
						# 	try:
						# 		# with Pool(number_cpu_available,maxtasksperchild=1) as pool:
						# 			# pool = Pool(number_cpu_available)
						# 		all_results = []
						# 		for fraction in range(int(np.ceil(len(all_indexes)/(number_cpu_available*4)))):
						# 			with Pool(number_cpu_available,maxtasksperchild=1) as pool:
						# 				print('starting set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1)))
						# 				temp = pool.map(calc_stuff_2, all_indexes[fraction*(number_cpu_available*4):(fraction+1)*(number_cpu_available*4)])
						# 				pool.close()
						# 				pool.join()
						# 				pool.terminate()
						# 				del pool
						# 				all_results.extend(temp)
						# 				print('set '+str(fraction)+' of '+str(int(np.ceil(len(all_indexes)/(number_cpu_available*4))-1))+' done')
						# 			#all_results = [*pool.map(calc_stuff, all_indexes)]
						# 	except Exception as e:
						# 		print('parent multiprocessor terminated with error '+str(e))
						# 		pool.close()
						# 	# pool.close()
						# 		pool.join()
						# 		pool.terminate()
						# 		del pool
						#
						# 	for i in range(len(all_results)):
						# 		if (all_results[i].results)[17]==False:
						# 			nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
						# 			nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
						# 			nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
						# 			nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
						# 			nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
						# 			nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
						# 			residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]
						# 			Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[7]
						# 			ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[8]
						# 			sigma_Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[9]
						# 			sigma_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[10]
						# 			sigma_nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[11]
						# 			sigma_nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[12]
						# 			sigma_nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[13]
						# 			sigma_nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[14]
						# 			sigma_nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[15]
						# 			sigma_nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[16]
						# 			power_balance_data[int(all_results[i].my_time_pos)*np.shape(nH_ne_all)[1] + int(all_results[i].my_r_pos)] = (all_results[i].results)[18]
						#
						# 	np.savez_compressed(path_where_to_save_everything + mod4 +'/results3',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all,Te_all=Te_all,ne_all=ne_all,sigma_Te_all=sigma_Te_all,sigma_ne_all=sigma_ne_all,sigma_nH_ne_all=sigma_nH_ne_all,sigma_nHp_ne_all=sigma_nHp_ne_all,sigma_nHm_ne_all=sigma_nHm_ne_all,sigma_nH2_ne_all=sigma_nH2_ne_all,sigma_nH2p_ne_all=sigma_nH2p_ne_all,sigma_nH3p_ne_all=sigma_nH3p_ne_all)
						# 	if collect_power_PDF:
						# 		with open(path_where_to_save_everything + mod4 +'/power_balance3.data', 'wb') as filehandle:
						# 		    pickle.dump(power_balance_data, filehandle)
						# 	else:
						# 		with open(path_where_to_save_everything + mod4 +'/power_balance3_no_PDF.data', 'wb') as filehandle:
						# 		    pickle.dump(power_balance_data, filehandle)
						#
						# else:
						# 	nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH_ne_all']
						# 	nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nHp_ne_all']
						# 	nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nHm_ne_all']
						# 	nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH2_ne_all']
						# 	nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH2p_ne_all']
						# 	nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH3p_ne_all']
						# 	residuals_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['residuals_all']
						# 	try:
						# 		Te_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['Te_all']
						# 		ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['ne_all']
						# 	except:
						# 		print('Bayesian Te, ne not present')
						# 		Te_all = cp.deepcopy(merge_Te_prof_multipulse_interp_crop_limited)
						# 		ne_all = cp.deepcopy(merge_ne_prof_multipulse_interp_crop_limited)
						# 	try:
						# 		sigma_Te_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_Te_all']
						# 		sigma_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_ne_all']
						# 		sigma_nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH_ne_all']
						# 		sigma_nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nHp_ne_all']
						# 		sigma_nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nHm_ne_all']
						# 		sigma_nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH2_ne_all']
						# 		sigma_nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH2p_ne_all']
						# 		sigma_nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH3p_ne_all']
						# 	except:
						# 		print('sigma not present')
						# 	try:
						# 		with open(path_where_to_save_everything + mod4 +'/power_balance3.data', 'rb') as filehandle:
						# 		    power_balance_data = pickle.load(filehandle)
						# 	except:
						# 		print('power_balance_data not present')
						#
						# global_pass = 4
						# exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())


						# I don't think this step is usefull, at least at 20/06/2020
						'''
						def calc_stuff_search(arg):
							try:
								index = arg[0]
								sgna = 0;print('marker '+str(sgna)+' '+str(index))
								my_time_pos = arg[1]
								my_r_pos = arg[2]
								pass_index = arg[3]
								# guess = arg[4]
								# ionization_length_H = arg[5]
								# ionization_length_Hm = arg[6]
								# ionization_length_H2 = arg[7]
								# ionization_length_H2p = arg[8]
								to_print = arg[4]

								inverted_profiles_crop_restrict = inverted_profiles_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								inverted_profiles_crop_sigma_restrict = inverted_profiles_sigma_crop[my_time_pos, n_list_all - 4, my_r_pos].flatten()
								merge_ne_prof_multipulse_interp_crop_limited_restrict = merge_ne_prof_multipulse_interp_crop[my_time_pos, my_r_pos]
								merge_dne_prof_multipulse_interp_crop_limited_restrict = max(merge_dne_prof_multipulse_interp_crop[my_time_pos, my_r_pos],0.1)
								merge_Te_prof_multipulse_interp_crop_limited_restrict = merge_Te_prof_multipulse_interp_crop[my_time_pos, my_r_pos]
								merge_dTe_prof_multipulse_interp_crop_limited_restrict = max(merge_dTe_prof_multipulse_interp_crop[my_time_pos, my_r_pos],0.1)
								recombination_restrict = recombination[n_list_all - 4, my_time_pos, my_r_pos].flatten()
								excitation_restrict = excitation[n_list_all - 4, my_time_pos, my_r_pos].flatten()

								if pass_index<=1:
									if (merge_ne_prof_multipulse_interp_crop_limited_restrict < 5e-07 or merge_Te_prof_multipulse_interp_crop_limited_restrict < 0.1):
										print('my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped ne %.3g, Te %.3g' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict))
										results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output
								else:
									if (merge_ne_prof_multipulse_interp_crop_limited_restrict == 0 or merge_Te_prof_multipulse_interp_crop_limited_restrict == 0):
										print('my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped ne %.3g, Te %.3g' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict))
										results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
										output = calc_stuff_output(my_time_pos,my_r_pos, results)
										return output

								# if np.sum(inverted_profiles_crop_restrict == 0)>2:
								# 	continue

								if False:
									T_Hp = 12000	# K
									T_Hm = 12000	# K
									T_H2p = 5000	# K
								else:
									T_Hp = merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K	# K
									T_Hm = np.exp(TH2_fit_from_simulations(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))/eV_to_K	# K
									T_H2p = np.exp(TH2_fit_from_simulations(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))/eV_to_K	# K
								ne = merge_ne_prof_multipulse_interp_crop_limited_restrict * 1e20
								multiplicative_factor = energy_difference[n_list_all - 4] * einstein_coeff[n_list_all - 4] / J_to_eV

								if False:	# pre 21/05/2020
									max_nH2_from_pressure_int = max_nH2_from_pressure_all[my_time_pos]
									if ionization_length_H[my_time_pos, my_r_pos]<=0.5:
										max_nmolecules_ne_low_ionisation_length = 0.05
										max_nH2_from_pressure_int = ne/10
									else:
										max_nmolecules_ne_low_ionisation_length = 0.15
										max_nH2_from_pressure_int = max_nH2_from_pressure*1
								elif False:	# post 21/05/2020
									max_nH2_from_pressure_int = nH2_from_pressure*max((1-np.sum(dr/ionization_length_H[my_time_pos, my_r_pos:])*1e3),1e-6)	# H2 ionisation 3-4 order stronger than H
									max_nmolecules_ne_low_ionisation_length = nH2_from_pressure*ionization_length_H[my_time_pos, my_r_pos]*1e-3*min(np.sum(dr/ionization_length_H[my_time_pos, my_r_pos:])*1e3,1)	# H2 ionisation 3-4 order stronger than H
									# if ionization_length_H[my_time_pos, my_r_pos]<=0.5:
									# 	max_nmolecules_ne_low_ionisation_length = 10*nH2_from_pressure/ne*300/(max(merge_Te_prof_multipulse_interp_crop_limited_restrict/eV_to_K,300))
									# else:
									# 	max_nmolecules_ne_low_ionisation_length = nH2_from_pressure
								elif True:	# this is after analysis of Ray simulations with B2.5-Eunomia
									max_nH2_ne = np.max(nH2_ne_fit_from_simulations([max(merge_Te_prof_multipulse_interp_crop_limited_restrict,0.1),merge_Te_prof_multipulse_interp_crop_limited_restrict]))*20
									min_nH2_ne = np.min(nH2_ne_fit_from_simulations([max(merge_Te_prof_multipulse_interp_crop_limited_restrict,0.1),merge_Te_prof_multipulse_interp_crop_limited_restrict]))/5
									centre_nH2_ne = nH2_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict)
									# limit_H_H2_up = interpolate.interp1d([0.1,0.2,4],[100,20,20],fill_value='extrapolate')
									# limit_H_H2_down = interpolate.interp1d([0.1,2,4],[10,0.03,0.03],fill_value='extrapolate')
									# limit_H_H2_up = np.exp(limit_H_H2_up(np.log(min(merge_Te_prof_multipulse_interp_crop_limited_restrict-merge_dTe_prof_multipulse_interp_crop_limited_restrict,0.1))))
									# limit_H_H2_down = np.exp(limit_H_H2_down(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict+merge_dTe_prof_multipulse_interp_crop_limited_restrict)))
									# max_nH_ne = min(limit_H_H2_up-min_nH2_ne,20)
									# min_nH_ne = max(limit_H_H2_down-max_nH2_ne,3e-2)
									max_nH_ne = np.exp(limit_H_up(np.log(max(merge_Te_prof_multipulse_interp_crop_limited_restrict,0.1))))
									min_nH_ne = np.exp(limit_H_down(np.log(merge_Te_prof_multipulse_interp_crop_limited_restrict)))
									centre_nH_ne = nH_ne_fit_from_simulations(merge_Te_prof_multipulse_interp_crop_limited_restrict)



								# Here I calculate all te log Probabilities
								Te_log_prob_internal = interpolate.interp1d([merge_Te_prof_multipulse_interp_crop_limited_restrict-merge_dTe_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict+merge_dTe_prof_multipulse_interp_crop_limited_restrict], [2,0,2],fill_value='extrapolate')
								get_Te_log_prob = lambda Te: -(0.5*((Te_log_prob_internal(Te))**2))**1 	# super gaussian order 1
								ne_log_prob_internal = interpolate.interp1d([merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20-merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20,merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20,merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20+merge_dne_prof_multipulse_interp_crop_limited_restrict*1e20], [2,0,2],fill_value='extrapolate')
								get_ne_log_prob = lambda ne: -(0.5*((ne_log_prob_internal(ne))**2))**1 	# super gaussian order 1
								nH2_ne_log_prob_internal = interpolate.interp1d(np.log10([min_nH2_ne,centre_nH2_ne,max_nH2_ne]), [2,0,2],fill_value='extrapolate')
								get_nH2_ne_log_prob = lambda nH2_ne: -0.5*((nH2_ne_log_prob_internal(np.log10(nH2_ne)))**2)	# centre-min/max is 2 sigma
								nH_ne_log_prob_internal = interpolate.interp1d(np.log10([min_nH_ne,centre_nH_ne,max_nH_ne]), [3,0,3],fill_value='extrapolate')
								get_nH_ne_log_prob = lambda nH_ne: -(0.5*((nH_ne_log_prob_internal(np.log10(nH_ne)))**2))**2	# super gaussian order 2, centre-min/max is 3 sigma
								get_emission_log_prob = lambda all_emission : np.sum([-0.5*((emission-emission_centre)/sigma_emission)**2 for emission,emission_centre,sigma_emission in zip(all_emission,inverted_profiles_crop_restrict,inverted_profiles_crop_sigma_restrict)])

								def calculated_emission(Te,ne,nH_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
									excitation_internal = []
									for isel in (n_list_all-2):
										temp = read_adf15(pecfile, isel, Te,ne*1e-6)[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										temp[np.isnan(temp)] = 0
										# temp = temp.reshape((np.shape(Te_values)))
										excitation_internal.append(temp)
									excitation_internal = np.array(excitation_internal).flatten()  # in # photons cm^-3 s^-1
									excitation_internal = (excitation_internal * (10 ** -6) * (energy_difference[n_list_all - 4] / J_to_eV))  # in W m^-3 / (# / m^3)**2

									recombination_internal = []
									for isel in (n_list_all+16):
										temp = read_adf15(pecfile, isel, Te,ne*1e-6)[0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
										if np.isnan(temp):
											temp=0
										# temp = temp.reshape((np.shape(Te_values)))
										recombination_internal.append(temp)
									recombination_internal = np.array(recombination_internal).flatten()  # in # photons cm^-3 s^-1 / (# cm^-3)**2
									recombination_internal = (recombination_internal * (10 ** -6) * (energy_difference[n_list_all - 4] / J_to_eV))  # in W m^-3 / (# / m^3)**2

									nHp_ne=1+nHm_ne-nH2p_ne-nH3p_ne
									T_Hm = np.exp(TH2_fit_from_simulations(np.log(Te)))/eV_to_K	# K
									T_H2p = np.exp(TH2_fit_from_simulations(np.log(Te)))/eV_to_K	# K
									T_Hp = Te/eV_to_K	# K
									total = np.array([(excitation_internal *  nH_ne /multiplicative_factor).astype('float')])
									total += np.array([(recombination_internal * nHp_ne /multiplicative_factor).astype('float')])
									# total = nH_ne*From_H_pop_coeff_full([[Te,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
									# total += nHp_ne*From_Hp_pop_coeff_full([[Te,ne]],n_list_all)
									total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[Te,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full_extra([[Te,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
									total += nH2_ne*From_H2_pop_coeff_full_extra([[Te,ne]],n_list_all)
									total += nH2p_ne*From_H2p_pop_coeff_full_extra([[Te,ne]],n_list_all)
									total += nH3p_ne*From_H3p_pop_coeff_full_extra([[Te,ne]],n_list_all)
									total = total[0]*(ne ** 2)*multiplicative_factor
									# print(total)
									return total


								def get_full_log_prob(trash,*arg):
									Te,ne,nH_ne,nHm_ne,nH2_ne,nH2p_ne = arg
									nH3p_ne=1e-10
									all_emission = calculated_emission(Te,ne,nH_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne)
									output = get_Te_log_prob(Te)+get_ne_log_prob(ne)+get_nH2_ne_log_prob(nH2_ne)+get_nH_ne_log_prob(nH_ne)+get_emission_log_prob(all_emission)
									# print(str(arg)+'>>'+str(output))
									return output


								p0 = [Te_all[my_time_pos, my_r_pos],ne_all[my_time_pos, my_r_pos]*1e20,nH_ne_all[my_time_pos, my_r_pos],nHm_ne_all[my_time_pos, my_r_pos],nH2_ne_all[my_time_pos, my_r_pos],nH2p_ne_all[my_time_pos, my_r_pos]]
								if p0[2]==0:
									p0[2]=centre_nH_ne
								if p0[3]==0:
									p0[3]=1e-3
								if p0[4]==0:
									p0[4]=centre_nH2_ne
								if p0[5]==0:
									p0[5]=1e-3
								bds = [[1e-10,1e-10,1e-10,1e-10,1e-10,1e-10], [np.inf,np.inf,np.inf,1,np.inf,1]]
								x_scale=[Te_all[my_time_pos, my_r_pos],ne_all[my_time_pos, my_r_pos]*1e20,nH_ne_all[my_time_pos, my_r_pos],nHm_ne_all[my_time_pos, my_r_pos],nH2_ne_all[my_time_pos, my_r_pos],nH2p_ne_all[my_time_pos, my_r_pos]]
								fit = curve_fit(get_full_log_prob, 0, 0, p0, maxfev=100000, bounds=bds,x_scale=x_scale,verbose=1,gtol=1e-6)#,xtol=1e-5)#,method='dogbox')

								if len(fit[0])<len(p0):
									print('my_time_pos '+str(my_time_pos)+', my_r_pos '+str(my_r_pos)+' skipped because fit failed')
									results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
									output = calc_stuff_output(my_time_pos,my_r_pos, results)
									return output


								most_likely_Te_value = fit[0][0]
								most_likely_ne_value = fit[0][1]
								most_likely_nH_ne_value = fit[0][2]
								most_likely_nHm_ne_value = fit[0][3]
								most_likely_nH2_ne_value = fit[0][4]
								most_likely_nH2p_ne_value = fit[0][5]
								T_Hm = np.exp(TH2_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K
								T_H2p = np.exp(TH2_fit_from_simulations(np.log(most_likely_Te_value)))/eV_to_K	# K
								T_Hp = most_likely_Te_value/eV_to_K	# K

								Te_values = most_likely_Te_value+np.linspace(-3,+3,num=41)
								Te_values[Te_values<np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])]=np.min(merge_Te_prof_multipulse_interp_crop[merge_Te_prof_multipulse_interp_crop>0])
								Te_values = np.unique(Te_values)
								Te_log_probs = [get_full_log_prob(0,value,most_likely_ne_value,most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value) for value in Te_values]
								Te_log_probs = Te_log_probs-np.max(Te_log_probs)-np.log(np.sum(np.exp(Te_log_probs-np.max(Te_log_probs))))	# normalisation for logarithmic probabilities
								Te_probs = np.exp(Te_log_probs)/sum(np.exp(Te_log_probs))
								try:
									sigma_Te_right = Te_probs[np.abs(Te_values-most_likely_Te_value).argmin():]
									if np.sum(sigma_Te_right)<0.34:
										sigma_Te_right=most_likely_Te_value
									else:
										sigma_Te_right = interpolate.interp1d([0]+[np.trapz(sigma_Te_right[:_+2]) for _ in range(len(sigma_Te_right)-1) ],Te_values[np.abs(Te_values-most_likely_Te_value).argmin():], fill_value="extrapolate")
										sigma_Te_right = np.abs(sigma_Te_right(0.3413)-most_likely_Te_value)
								except:
									sigma_Te_right=0
								try:
									sigma_Te_left = np.flip(Te_probs[:np.abs(Te_values-most_likely_Te_value).argmin()+1],axis=0)
									if np.sum(sigma_Te_left)<0.34:
										sigma_Te_left=most_likely_Te_value
									else:
										sigma_Te_left = interpolate.interp1d([0]+[np.trapz(sigma_Te_left[:_+2]) for _ in range(len(sigma_Te_left)-1) ],np.flip(Te_values[:np.abs(Te_values-most_likely_Te_value).argmin()+1],axis=0), fill_value="extrapolate")
										sigma_Te_left = np.abs(sigma_Te_left(0.3413)-most_likely_Te_value)
								except:
									sigma_Te_left=0
								sigma_Te = max(sigma_Te_right,sigma_Te_left)

								ne_values = most_likely_ne_value*np.logspace(np.log10(0.1),np.log10(10),num=41)
								ne_values[ne_values<np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])]=np.min(merge_ne_prof_multipulse_interp_crop[merge_ne_prof_multipulse_interp_crop>0])
								ne_values = np.unique(ne_values)
								ne_log_probs = [get_full_log_prob(0,most_likely_Te_value,value,most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value) for value in ne_values]
								ne_log_probs = ne_log_probs-np.max(ne_log_probs)-np.log(np.sum(np.exp(ne_log_probs-np.max(ne_log_probs))))	# normalisation for logarithmic probabilities
								ne_probs = np.exp(ne_log_probs)/sum(np.exp(ne_log_probs))
								try:
									sigma_ne_right = ne_probs[np.abs(ne_values-most_likely_ne_value).argmin():]
									if np.sum(sigma_ne_right)<0.34:
										sigma_ne_right=most_likely_ne_value
									else:
										sigma_ne_right = interpolate.interp1d([0]+[np.trapz(sigma_ne_right[:_+2]) for _ in range(len(sigma_ne_right)-1) ],ne_values[np.abs(ne_values-most_likely_ne_value).argmin():], fill_value="extrapolate")
										sigma_ne_right = np.abs(sigma_ne_right(0.3413)-most_likely_ne_value)
								except:
									sigma_ne_right=0
								try:
									sigma_ne_left = np.flip(ne_probs[:np.abs(ne_values-most_likely_ne_value).argmin()+1],axis=0)
									if np.sum(sigma_ne_left)<0.34:
										sigma_ne_left=most_likely_ne_value
									else:
										sigma_ne_left = interpolate.interp1d([0]+[np.trapz(sigma_ne_left[:_+2]) for _ in range(len(sigma_ne_left)-1) ],np.flip(ne_values[:np.abs(ne_values-most_likely_ne_value).argmin()+1],axis=0), fill_value="extrapolate")
										sigma_ne_left = np.abs(sigma_ne_left(0.3413)-most_likely_ne_value)
								except:
									sigma_ne_left=0
								sigma_ne = max(sigma_ne_right,sigma_ne_left)

								nH_ne_values = most_likely_nH_ne_value*np.logspace(np.log10(0.01),np.log10(100),num=41)
								nH_ne_log_probs = [get_full_log_prob(0,most_likely_Te_value,most_likely_ne_value,value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value) for value in nH_ne_values]
								nH_ne_log_probs = nH_ne_log_probs-np.max(nH_ne_log_probs)-np.log(np.sum(np.exp(nH_ne_log_probs-np.max(nH_ne_log_probs))))	# normalisation for logarithmic probabilities
								nH_ne_probs = np.exp(nH_ne_log_probs)/sum(np.exp(nH_ne_log_probs))
								try:
									sigma_nH_ne_right = nH_ne_probs[np.abs(nH_ne_values-most_likely_nH_ne_value).argmin():]
									if np.sum(sigma_nH_ne_right)<0.34:
										sigma_nH_ne_right=most_likely_nH_ne_value
									else:
										sigma_nH_ne_right = interpolate.interp1d([0]+[np.trapz(sigma_nH_ne_right[:_+2]) for _ in range(len(sigma_nH_ne_right)-1) ],nH_ne_values[np.abs(nH_ne_values-most_likely_nH_ne_value).argmin():], fill_value="extrapolate")
										sigma_nH_ne_right = np.abs(sigma_nH_ne_right(0.3413)-most_likely_nH_ne_value)
								except:
									sigma_nH_ne_right=0
								try:
									sigma_nH_ne_left = np.flip(nH_ne_probs[:np.abs(nH_ne_values-most_likely_nH_ne_value).argmin()+1],axis=0)
									if np.sum(sigma_nH_ne_left)<0.34:
										sigma_nH_ne_left=most_likely_nH_ne_value
									else:
										sigma_nH_ne_left = interpolate.interp1d([0]+[np.trapz(sigma_nH_ne_left[:_+2]) for _ in range(len(sigma_nH_ne_left)-1) ],np.flip(nH_ne_values[:np.abs(nH_ne_values-most_likely_nH_ne_value).argmin()+1],axis=0), fill_value="extrapolate")
										sigma_nH_ne_left = np.abs(sigma_nH_ne_left(0.3413)-most_likely_nH_ne_value)
								except:
									sigma_nH_ne_left=0
								sigma_nH_ne = max(sigma_nH_ne_right,sigma_nH_ne_left)

								nHm_ne_values = most_likely_nHm_ne_value*np.logspace(np.log10(0.01),np.log10(100),num=41)
								nHm_ne_values = nHm_ne_values[nHm_ne_values<1]
								nHm_ne_log_probs = [get_full_log_prob(0,most_likely_Te_value,most_likely_ne_value,most_likely_nH_ne_value,value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value) for value in nHm_ne_values]
								nHm_ne_log_probs = nHm_ne_log_probs-np.max(nHm_ne_log_probs)-np.log(np.sum(np.exp(nHm_ne_log_probs-np.max(nHm_ne_log_probs))))	# normalisation for logarithmic probabilities
								nHm_ne_probs = np.exp(nHm_ne_log_probs)/sum(np.exp(nHm_ne_log_probs))
								try:
									sigma_nHm_ne_right = nHm_ne_probs[np.abs(nHm_ne_values-most_likely_nHm_ne_value).argmin():]
									if np.sum(sigma_nHm_ne_right)<0.34:
										sigma_nHm_ne_right=most_likely_nHm_ne_value
									else:
										sigma_nHm_ne_right = interpolate.interp1d([0]+[np.trapz(sigma_nHm_ne_right[:_+2]) for _ in range(len(sigma_nHm_ne_right)-1) ],nHm_ne_values[np.abs(nHm_ne_values-most_likely_nHm_ne_value).argmin():], fill_value="extrapolate")
										sigma_nHm_ne_right = np.abs(sigma_nHm_ne_right(0.3413)-most_likely_nHm_ne_value)
								except:
									sigma_nHm_ne_right=0
								try:
									sigma_nHm_ne_left = np.flip(nHm_ne_probs[:np.abs(nHm_ne_values-most_likely_nHm_ne_value).argmin()+1],axis=0)
									if np.sum(sigma_nHm_ne_left)<0.34:
										sigma_nHm_ne_left=most_likely_nHm_ne_value
									else:
										sigma_nHm_ne_left = interpolate.interp1d([0]+[np.trapz(sigma_nHm_ne_left[:_+2]) for _ in range(len(sigma_nHm_ne_left)-1) ],np.flip(nHm_ne_values[:np.abs(nHm_ne_values-most_likely_nHm_ne_value).argmin()+1],axis=0), fill_value="extrapolate")
										sigma_nHm_ne_left = np.abs(sigma_nHm_ne_left(0.3413)-most_likely_nHm_ne_value)
								except:
									sigma_nHm_ne_left=0
								sigma_nHm_ne = max(sigma_nHm_ne_right,sigma_nHm_ne_left)

								nH2_ne_values = most_likely_nH2_ne_value*np.logspace(np.log10(0.01),np.log10(100),num=41)
								nH2_ne_log_probs = [get_full_log_prob(0,most_likely_Te_value,most_likely_ne_value,most_likely_nH_ne_value,most_likely_nHm_ne_value,value,most_likely_nH2p_ne_value) for value in nH2_ne_values]
								nH2_ne_log_probs = nH2_ne_log_probs-np.max(nH2_ne_log_probs)-np.log(np.sum(np.exp(nH2_ne_log_probs-np.max(nH2_ne_log_probs))))	# normalisation for logarithmic probabilities
								nH2_ne_probs = np.exp(nH2_ne_log_probs)/sum(np.exp(nH2_ne_log_probs))
								try:
									sigma_nH2_ne_right = nH2_ne_probs[np.abs(nH2_ne_values-most_likely_nH2_ne_value).argmin():]
									if np.sum(sigma_nH2_ne_right)<0.34:
										sigma_nH2_ne_right=most_likely_nH2_ne_value
									else:
										sigma_nH2_ne_right = interpolate.interp1d([0]+[np.trapz(sigma_nH2_ne_right[:_+2]) for _ in range(len(sigma_nH2_ne_right)-1) ],nH2_ne_values[np.abs(nH2_ne_values-most_likely_nH2_ne_value).argmin():], fill_value="extrapolate")
										sigma_nH2_ne_right = np.abs(sigma_nH2_ne_right(0.3413)-most_likely_nH2_ne_value)
								except:
									sigma_nH2_ne_right=0
								try:
									sigma_nH2_ne_left = np.flip(nH2_ne_probs[:np.abs(nH2_ne_values-most_likely_nH2_ne_value).argmin()+1],axis=0)
									if np.sum(sigma_nH2_ne_left)<0.34:
										sigma_nH2_ne_left=most_likely_nH2_ne_value
									else:
										sigma_nH2_ne_left = interpolate.interp1d([0]+[np.trapz(sigma_nH2_ne_left[:_+2]) for _ in range(len(sigma_nH2_ne_left)-1) ],np.flip(nH2_ne_values[:np.abs(nH2_ne_values-most_likely_nH2_ne_value).argmin()+1],axis=0), fill_value="extrapolate")
										sigma_nH2_ne_left = np.abs(sigma_nH2_ne_left(0.3413)-most_likely_nH2_ne_value)
								except:
									sigma_nH2_ne_left=0
								sigma_nH2_ne = max(sigma_nH2_ne_right,sigma_nH2_ne_left)

								nH2p_ne_values = most_likely_nH2p_ne_value*np.logspace(np.log10(0.01),np.log10(100),num=41)
								nH2p_ne_values = nH2p_ne_values[nH2p_ne_values<1]
								nH2p_ne_log_probs = [get_full_log_prob(0,most_likely_Te_value,most_likely_ne_value,most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,value) for value in nH2p_ne_values]
								nH2p_ne_log_probs = nH2p_ne_log_probs-np.max(nH2p_ne_log_probs)-np.log(np.sum(np.exp(nH2p_ne_log_probs-np.max(nH2p_ne_log_probs))))	# normalisation for logarithmic probabilities
								nH2p_ne_probs = np.exp(nH2p_ne_log_probs)/sum(np.exp(nH2p_ne_log_probs))
								try:
									sigma_nH2p_ne_right = nH2p_ne_probs[np.abs(nH2p_ne_values-most_likely_nH2p_ne_value).argmin():]
									if np.sum(sigma_nH2p_ne_right)<0.34:
										sigma_nH2p_ne_right=most_likely_nH2p_ne_value
									else:
										sigma_nH2p_ne_right = interpolate.interp1d([0]+[np.trapz(sigma_nH2p_ne_right[:_+2]) for _ in range(len(sigma_nH2p_ne_right)-1) ],nH2p_ne_values[np.abs(nH2p_ne_values-most_likely_nH2p_ne_value).argmin():], fill_value="extrapolate")
										sigma_nH2p_ne_right = np.abs(sigma_nH2p_ne_right(0.3413)-most_likely_nH2p_ne_value)
								except:
									sigma_nH2p_ne_right=0
								try:
									sigma_nH2p_ne_left = np.flip(nH2p_ne_probs[:np.abs(nH2p_ne_values-most_likely_nH2p_ne_value).argmin()+1],axis=0)
									if np.sum(sigma_nH2p_ne_left)<0.34:
										sigma_nH2p_ne_left=most_likely_nH2p_ne_value
									else:
										sigma_nH2p_ne_left = interpolate.interp1d([0]+[np.trapz(sigma_nH2p_ne_left[:_+2]) for _ in range(len(sigma_nH2p_ne_left)-1) ],np.flip(nH2p_ne_values[:np.abs(nH2p_ne_values-most_likely_nH2p_ne_value).argmin()+1],axis=0), fill_value="extrapolate")
										sigma_nH2p_ne_left = np.abs(sigma_nH2p_ne_left(0.3413)-most_likely_nH2p_ne_value)
								except:
									sigma_nH2p_ne_left=0
								sigma_nH2p_ne = max(sigma_nH2p_ne_right,sigma_nH2p_ne_left)
								sigma_nH_ne = max(sigma_nH_ne_right,sigma_nH_ne_left)
								sigma_nHp_ne = (1+most_likely_nHm_ne_value-most_likely_nH2p_ne_value-0)*((sigma_nHm_ne)**2+(sigma_nH2p_ne)**2)**0.5
								sigma_nH3p_ne = 0

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											print('first scan best_fit_nH_ne_index %.3g,best_fit_nHm_ne_value %.3g,best_fit_nH2_ne_value %.3g,best_fit_nH2p_ne_value %.3g' %(most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value))
											tm.sleep(np.random.random()*10)
											print('First scan\nmost_likely_nH_ne_index %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g,most_likely_Te_value %.3g,most_likely_ne_value %.3g' %(most_likely_nH_ne_value,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value,most_likely_Te_value,most_likely_ne_value))
											fig, ax = plt.subplots( 3,2,figsize=(20, 35), squeeze=False)
											fig.suptitle('first scan\nmost_likely_nH_ne_value %.3g,most_likely_nHm_ne_value %.3g,most_likely_nH2_ne_value %.3g,most_likely_nH2p_ne_value %.3g' %(most_likely_nH_ne_value*most_likely_ne_value,most_likely_nHm_ne_value*most_likely_ne_value,most_likely_nH2_ne_value*most_likely_ne_value,most_likely_nH2p_ne_value*most_likely_ne_value) +'\nlines '+str(n_list_all)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value) + '%.3g(ML %.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g, ' % most_likely_nH_ne_value + '%.3g, ' %(1 - most_likely_nH2p_ne_value + most_likely_nHm_ne_value)+ '%.3g, ' % most_likely_nHm_ne_value+ '%.3g, ' % most_likely_nH2_ne_value+ '%.3g, ' % most_likely_nH2p_ne_value+ '%.3g]' % 0)
											plot_index = 0
											im = ax[plot_index,0].plot(Te_values[Te_probs>0],Te_probs[Te_probs>0]);
											im = ax[plot_index,0].plot([most_likely_Te_value,most_likely_Te_value],[np.max(Te_probs),np.min(Te_probs)],'k--',label='best');
											im = ax[plot_index,0].plot([Te_all[my_time_pos, my_r_pos],Te_all[my_time_pos, my_r_pos]],[np.max(Te_probs),np.min(Te_probs)],'r--',label='initial');
											im = ax[plot_index,0].plot([merge_Te_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict],[np.max(Te_probs),np.min(Te_probs)],'b--',label='TS');
											ax[plot_index,0].set_title('Te Likelihood around the best')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('Te [eV]')
											ax[plot_index,0].legend(loc='best')

											im = ax[plot_index,1].plot(ne_values[ne_probs>0],ne_probs[ne_probs>0]);
											im = ax[plot_index,1].plot([most_likely_ne_value,most_likely_ne_value],[np.max(ne_probs),np.min(ne_probs)],'k--',label='best');
											im = ax[plot_index,1].plot([ne_all[my_time_pos, my_r_pos]*1e20,ne_all[my_time_pos, my_r_pos]*1e20],[np.max(ne_probs),np.min(ne_probs)],'r--',label='initial');
											im = ax[plot_index,1].plot([merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20,merge_ne_prof_multipulse_interp_crop_limited_restrict*1e20],[np.max(ne_probs),np.min(ne_probs)],'b--',label='TS');
											ax[plot_index,1].set_title('ne Likelihood around the best')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('ne [#/m^3]')
											ax[plot_index,1].legend(loc='best')

											plot_index += 1
											im = ax[plot_index,0].plot(nH_ne_values[nH_ne_probs>0],nH_ne_probs[nH_ne_probs>0]);
											im = ax[plot_index,0].plot([most_likely_nH_ne_value,most_likely_nH_ne_value],[np.max(nH_ne_probs),np.min(nH_ne_probs)],'k--',label='best');
											im = ax[plot_index,0].plot([nH_ne_all[my_time_pos, my_r_pos],nH_ne_all[my_time_pos, my_r_pos]],[np.max(nH_ne_probs),np.min(nH_ne_probs)],'r--',label='initial');
											im = ax[plot_index,0].plot([centre_nH_ne,centre_nH_ne],[np.max(nH_ne_probs),np.min(nH_ne_probs)],'b--',label='simul');
											ax[plot_index,0].set_title('nH/ne Likelihood around the best')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('nH/ne')
											ax[plot_index,0].legend(loc='best')

											im = ax[plot_index,1].plot(nHm_ne_values[nHm_ne_probs>0],nHm_ne_probs[nHm_ne_probs>0]);
											im = ax[plot_index,1].plot([most_likely_nHm_ne_value,most_likely_nHm_ne_value],[np.max(nHm_ne_probs),np.min(nHm_ne_probs)],'k--',label='best');
											im = ax[plot_index,1].plot([nHm_ne_all[my_time_pos, my_r_pos],nHm_ne_all[my_time_pos, my_r_pos]],[np.max(nHm_ne_probs),np.min(nHm_ne_probs)],'r--',label='initial');
											ax[plot_index,1].set_title('nH-/ne Likelihood around the best')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('nH-/ne')
											ax[plot_index,1].legend(loc='best')

											plot_index += 1
											im = ax[plot_index,0].plot(nH2_ne_values[nH2_ne_probs>0],nH2_ne_probs[nH2_ne_probs>0]);
											im = ax[plot_index,0].plot([most_likely_nH2_ne_value,most_likely_nH2_ne_value],[np.max(nH2_ne_probs),np.min(nH2_ne_probs)],'k--',label='best');
											im = ax[plot_index,0].plot([nH2_ne_all[my_time_pos, my_r_pos],nH2_ne_all[my_time_pos, my_r_pos]],[np.max(nH2_ne_probs),np.min(nH2_ne_probs)],'r--',label='initial');
											im = ax[plot_index,0].plot([centre_nH2_ne,centre_nH2_ne],[np.max(nH2_ne_probs),np.min(nH2_ne_probs)],'b--',label='simul');
											ax[plot_index,0].set_title('nH2/ne Likelihood around the best')
											ax[plot_index,0].set_ylabel('normalised likelihood')
											ax[plot_index,0].set_xlabel('nH2/ne')
											ax[plot_index,0].legend(loc='best')

											im = ax[plot_index,1].plot(nH2p_ne_values[nH2p_ne_probs>0],nH2p_ne_probs[nH2p_ne_probs>0]);
											im = ax[plot_index,1].plot([most_likely_nH2p_ne_value,most_likely_nH2p_ne_value],[np.max(nH2p_ne_probs),np.min(nH2p_ne_probs)],'k--',label='best');
											im = ax[plot_index,1].plot([nH2p_ne_all[my_time_pos, my_r_pos],nH2p_ne_all[my_time_pos, my_r_pos]],[np.max(nH2p_ne_probs),np.min(nH2p_ne_probs)],'r--',label='initial');
											ax[plot_index,1].set_title('nH2p/ne Likelihood around the best')
											ax[plot_index,1].set_ylabel('normalised likelihood')
											ax[plot_index,1].set_xlabel('nH2+/ne')
											ax[plot_index,1].legend(loc='best')

											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														tm.sleep(np.random.random()**2)
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_Bayesian_search_' + str(my_time_pos)+'_'+str(my_r_pos)+ '_first.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')


								# I add this because I want to see how Halpha works
								n_list_all_full = np.array([3]+np.array(n_list_all).tolist())
								multiplicative_factor_full = energy_difference_full[n_list_all_full - 2] * einstein_coeff_full[n_list_all_full - 2] / J_to_eV


								excitation_full = []
								for isel in (np.array(n_list_all_full)-2):
									temp = read_adf15(pecfile, isel, most_likely_Te_value,most_likely_ne_value * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									excitation_full.append(temp)
								excitation_full = np.array(excitation_full).flatten()  # in # photons cm^-3 s^-1
								excitation_full = (excitation_full * (10 ** -6) * (energy_difference_full[n_list_all_full - 2] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2

								recombination_full = []
								for isel in (np.array(n_list_all_full)+16):
									temp = read_adf15(pecfile, isel, most_likely_Te_value,most_likely_ne_value * 10 ** (0 - 6)) [0]  # ADAS database is in cm^3   # photons s^-1 cm^-3
									recombination_full.append(temp)
								recombination_full = np.array(recombination_full).flatten()  # in # photons cm^-3 s^-1 / (# cm^-3)**2
								recombination_full = (recombination_full * (10 ** -6) * (energy_difference_full[n_list_all_full - 2] / J_to_eV)).T  # in W m^-3 / (# / m^3)**2


								def fit_Yacora_pop_coeff(ne,Te,T_Hp,T_Hm,T_H2p,multiplicative_factor,excitation_restrict,recombination_restrict):
									def calculated_emission(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne):
										# I add this because I want to see how Halpha works
										# nHp_ne=1+nHm_ne-nH2p_ne-nH3p_ne
										multiplicative_factor = energy_difference_full[n_list_all - 2] * einstein_coeff_full[n_list_all - 2] / J_to_eV
										total = np.array([(excitation_full[n_list_all - 3] *  nH_ne /multiplicative_factor).astype('float')])
										total += np.array([(recombination_full[n_list_all - 3] * nHp_ne /multiplicative_factor).astype('float')])
										# total = nH_ne*From_H_pop_coeff_full([[Te,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)
										# total += nHp_ne*From_Hp_pop_coeff_full([[Te,ne]],n_list_all)
										total += nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[Te,T_Hp,T_Hm,ne,nHp_ne*ne]],n_list_all) + From_Hn_with_H2p_pop_coeff_full_extra([[Te,T_H2p,T_Hm,ne,nH2p_ne*ne]],n_list_all) )
										total += nH2_ne*From_H2_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total += nH2p_ne*From_H2p_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total += nH3p_ne*From_H3p_pop_coeff_full_extra([[Te,ne]],n_list_all)
										total = total[0]*(ne ** 2)*multiplicative_factor
										# print(total)
										return np.log(total)
									return calculated_emission

								nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne = most_likely_nH_ne_value,1+most_likely_nHm_ne_value-most_likely_nH2p_ne_value-0,most_likely_nHm_ne_value,most_likely_nH2_ne_value,most_likely_nH2p_ne_value,0
								# nH_ne_sigma, nHp_ne_sigma, nHm_ne_sigma, nH2_ne_sigma, nH2p_ne_sigma, nH3p_ne_sigma = 1,1,1,1,1,1
								# residuals = np.sum(((np.log(inverted_profiles_crop_restrict) - fit_Yacora_pop_coeff(merge_ne_prof_multipulse_interp_crop_limited_restrict,merge_Te_prof_multipulse_interp_crop_limited_restrict,T_Hp,T_Hm,T_H2p,ne,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, *fit[0]))) ** 2)
								residuals = np.sum(((inverted_profiles_crop_restrict - np.exp(fit_Yacora_pop_coeff(most_likely_ne_value,most_likely_Te_value,T_Hp,T_Hm,T_H2p,multiplicative_factor,excitation_restrict,recombination_restrict)(n_list_all, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne)))/inverted_profiles_crop_sigma_restrict) ** 2)

								if my_time_pos in sample_time_step:
									if my_r_pos in sample_radious:
										if to_print:
											tm.sleep(np.random.random()*10)
											plt.figure(figsize=(20, 10))
											# nH_ne, nHp_ne, nH2p_ne = fit[0]
											# nHp_ne = 1 + nHm_ne - nH2p_ne
											plt.errorbar(n_list_all,inverted_profiles_crop_restrict,yerr=inverted_profiles_crop_sigma_restrict,label='OES')
											plt.plot(n_list_all_full,(excitation_full *  nH_ne).astype('float')*(most_likely_ne_value ** 2),label='direct excitation\nH(q) + e-  H(p>q) + e- (ADAS coeff)')
											plt.plot(n_list_all_full,(recombination_full * nHp_ne).astype('float')*(most_likely_ne_value ** 2),label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e- (ADAS coeff)')
											# plt.plot(n_list_all,nH_ne*From_H_pop_coeff_full([[most_likely_Te_value,ne,nHp_ne*ne,nH_ne*ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='direct excitation\nH(q) + e-  H(p>q) + e-')
											# plt.plot(n_list_all,nHp_ne*From_Hp_pop_coeff_full([[most_likely_Te_value,ne]],n_list_all)[0]*(ne ** 2)*multiplicative_factor,label='recombination\nH+ + e-  H(p) + h\nH+ + 2e-  H(p) + e-')
											plt.plot(n_list_all_full,nHm_ne*( From_Hn_with_Hp_pop_coeff_full_extra([[most_likely_Te_value,T_Hp,T_Hm,most_likely_ne_value,nHp_ne*most_likely_ne_value]],n_list_all_full) )[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H+ mutual neutralisation\nH+ + H-  H(p) + H')
											plt.plot(n_list_all_full,nHm_ne*( From_Hn_with_H2p_pop_coeff_full_extra([[most_likely_Te_value,T_H2p,T_Hm,most_likely_ne_value,nH2p_ne*most_likely_ne_value]],n_list_all_full) )[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2+ mutual neutralisation\nH2+ + H-  H(p) + H2')
											plt.plot(n_list_all_full,nH2_ne*From_H2_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2 dissociation\nH2 + e-  H(p) + H(1) + e-')
											plt.plot(n_list_all_full,nH2p_ne*From_H2p_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H2+ dissociation\nH2+ + e-  H(p) + H+ + e-')
											plt.plot(n_list_all_full,nH3p_ne*From_H3p_pop_coeff_full_extra([[most_likely_Te_value,most_likely_ne_value]],n_list_all_full)[0]*(most_likely_ne_value ** 2)*multiplicative_factor_full,label='H3+ dissociation\nH3+ + e-  H(p) + H2')
											temp = np.exp(fit_Yacora_pop_coeff(most_likely_ne_value,most_likely_Te_value,T_Hp,T_Hm,T_H2p,multiplicative_factor_full,excitation_restrict,recombination_restrict)(n_list_all_full, nH_ne,nHp_ne,nHm_ne,nH2_ne,nH2p_ne,nH3p_ne))
											plt.plot(n_list_all_full,temp,'--',label='total fit')
											plt.plot(n_list_all_full,((excitation_full *  nH_ne).astype('float')*(most_likely_ne_value ** 2) + (recombination_full * nHp_ne).astype('float')*(most_likely_ne_value ** 2)),'+',label='excitation + recombination')
											plt.semilogy()
											plt.legend(loc='best', fontsize='x-small')
											plt.ylim(np.min(inverted_profiles_crop_restrict)/2,max(np.max(inverted_profiles_crop_restrict)*2,np.max(temp)))
											plt.title('lines '+str(n_list_all)+' weights '+str(n_weights)+'\nlocation [time, r]'+ ' [%.3g ms, ' % time_crop[my_time_pos] + ' %.3g mm]' % (1000*r_crop[my_r_pos]) +' , [TS Te, TS ne] '+ ' [%.3g(ML %.3g+/-%.3g) eV, ' %(merge_Te_prof_multipulse_interp_crop_limited_restrict,most_likely_Te_value,sigma_Te) + '%.3g(ML %.3g+/-%.3g) #10^20/m^3]' %(merge_ne_prof_multipulse_interp_crop_limited_restrict,most_likely_ne_value*1e-20,sigma_ne*1e-20) +'\nfit [nH/ne, nH+/ne, nH-/ne, nH2/ne, nH2+/ne, nH3+/ne] , '+ '[%.3g+/-%.3g, ' %(nH_ne,sigma_nH_ne) + '%.3g+/-%.3g, ' %(nHp_ne,sigma_nHp_ne)+ '%.3g+/-%.3g, ' %(nHm_ne,sigma_nHm_ne)+ '%.3g+/-%.3g, ' %(nH2_ne,sigma_nH2_ne)+ '%.3g+/-%.3g, ' %(nH2p_ne,sigma_nH2p_ne)+ '%.3g+/-%.3g]' %(nH3p_ne,sigma_nH3p_ne))
											plt.xlabel('Exctited state n')
											plt.ylabel('Line emissivity n->2 [W m^-3]')
											# plt.pause(0.01)
											save_done = 0
											save_index=1
											try:	# All this trie are because of a known issues when saving lots of figure inside of multiprocessor
												plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
											except Exception as e:
												print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(1)+' failed. Reason %s' % e)
												while save_done==0 and save_index<100:
													try:
														tm.sleep(np.random.random()**2)
														plt.savefig(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps', bbox_inches='tight')
														print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' successfull')
														save_done=1
													except Exception as e:
														# print(path_where_to_save_everything + mod4 + '/post_process_mega_global_fit_pass'+str(pass_index)+'_' + str(my_time_pos)+'_'+str(my_r_pos)+ '.eps save try number '+str(save_index+1)+' failed. Reason %s' % e)
														save_index+=1
											plt.close('all')

								sgna =999 ;print('marker '+str(sgna)+' '+str(index))
								results = [nH_ne, nHp_ne, nHm_ne, nH2_ne, nH2p_ne, nH3p_ne,residuals,most_likely_Te_value,most_likely_ne_value*1e-20,sigma_Te,sigma_ne,sigma_nH_ne,sigma_nHp_ne,sigma_nHm_ne,sigma_nH2_ne,sigma_nH2p_ne,sigma_nH3p_ne,False]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
							except Exception as e:
								results = [0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,True]
								output = calc_stuff_output(my_time_pos,my_r_pos, results)
								print('child multiprocessor terminated with error '+str(e)+' t=%.3g, r=%.3g' %(my_time_pos,my_r_pos))
							return output

						if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results3.npz') ) or recorded_data_override[2] ):

							all_indexes = []
							global_index = 0
							to_print=True
							for my_time_pos in range(len(time_crop)):
								for my_r_pos in range(len(r_crop)):
									all_indexes.append([global_index,my_time_pos,my_r_pos,3,to_print])
									global_index+=1

							pool = Pool(number_cpu_available)
							all_results = [*pool.map(calc_stuff_search, all_indexes)]
							pool.close()
							pool.join()
							pool.terminate()
							del pool

							for i in range(len(all_results)):
								if (all_results[i].results)[17]==False:
									nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
									nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
									nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
									nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
									nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
									nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
									residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]
									Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[7]
									ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[8]
									sigma_Te_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[9]
									sigma_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[10]
									sigma_nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[11]
									sigma_nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[12]
									sigma_nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[13]
									sigma_nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[14]
									sigma_nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[15]
									sigma_nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[16]

							np.savez_compressed(path_where_to_save_everything + mod4 +'/results3',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all,Te_all=Te_all,ne_all=ne_all,sigma_Te_all=sigma_Te_all,sigma_ne_all=sigma_ne_all,sigma_nH_ne_all=sigma_nH_ne_all,sigma_nHp_ne_all=sigma_nHp_ne_all,sigma_nHm_ne_all=sigma_nHm_ne_all,sigma_nH2_ne_all=sigma_nH2_ne_all,sigma_nH2p_ne_all=sigma_nH2p_ne_all,sigma_nH3p_ne_all=sigma_nH3p_ne_all)
						else:
							nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH_ne_all']
							nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nHp_ne_all']
							nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nHm_ne_all']
							nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH2_ne_all']
							nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH2p_ne_all']
							nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['nH3p_ne_all']
							residuals_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['residuals_all']
							try:
								Te_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['Te_all']
								ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['ne_all']
							except:
								print('Bayesian Te, ne not present')
								Te_all = cp.deepcopy(merge_Te_prof_multipulse_interp_crop_limited)
								ne_all = cp.deepcopy(merge_ne_prof_multipulse_interp_crop_limited)
							try:
								sigma_Te_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_Te_all']
								sigma_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_ne_all']
								sigma_nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH_ne_all']
								sigma_nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nHp_ne_all']
								sigma_nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nHm_ne_all']
								sigma_nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH2_ne_all']
								sigma_nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH2p_ne_all']
								sigma_nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results3.npz')['sigma_nH3p_ne_all']
							except:
								print('sigma not present')

						global_pass = 4
						exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())
						'''


					# 	if ( (not os.path.exists(path_where_to_save_everything + mod4 +'/results_2.npz') ) or recorded_data_override[1] ):
					#
					# 		if False:
					# 			nH_ne_all = medfilt(nH_ne_all,[3,15])
					# 			nHp_ne_all = medfilt(nHp_ne_all,[3,7])
					# 			nHm_ne_all = medfilt(nHm_ne_all,[3,5])
					# 			nH2_ne_all = medfilt(nH2_ne_all,[3,7])
					# 			nH2p_ne_all = medfilt(nH2p_ne_all,[3,5])
					# 			nH3p_ne_all = medfilt(nH3p_ne_all,[3,5])
					# 		else:
					# 			nH_ne_all = convolve(nH_ne_all,np.ones((3,15))/np.sum(np.ones((3,15))),mode='constant', cval=0.0)
					# 			nHp_ne_all = convolve(nHp_ne_all,np.ones((3,15))/np.sum(np.ones((3,15))),mode='constant', cval=0.0)
					# 			nHm_ne_all = convolve(nHm_ne_all,np.ones((3,3))/np.sum(np.ones((3,3))),mode='constant', cval=0.0)
					# 			nH2_ne_all = medfilt(nH2_ne_all,[3,7])
					# 			nH2p_ne_all = convolve(nH2p_ne_all,np.ones((3,3))/np.sum(np.ones((3,3))),mode='constant', cval=0.0)
					# 			nH3p_ne_all = convolve(nH3p_ne_all,np.ones((3,3))/np.sum(np.ones((3,3))),mode='constant', cval=0.0)
					#
					# 		global_pass = 2
					# 		exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())
					#
					#
					# 		all_indexes = []
					# 		global_index = 0
					# 		for my_time_pos in range(len(time_crop)):
					# 			for my_r_pos in range(len(r_crop)):
					# 				if max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				if max_nHm_ne == 1 and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == min_multiplier and max_nH2_ne == min_multiplier and max_nH2p_ne == min_multiplier and max_nH3p_ne == 1:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH3p_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == min_multiplier and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == min_multiplier and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == min_multiplier:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					# 				elif max_nHm_ne == 1 and max_nH2_ne == 1 and max_nH2p_ne == 1 and max_nH3p_ne == 1:
					# 					all_indexes.append([global_index,my_time_pos,my_r_pos,2,[nH_ne_all[my_time_pos,my_r_pos], nHp_ne_all[my_time_pos,my_r_pos],nHm_ne_all[my_time_pos,my_r_pos],nH2_ne_all[my_time_pos,my_r_pos],nH2p_ne_all[my_time_pos,my_r_pos],nH3p_ne_all[my_time_pos,my_r_pos]]])
					# 					global_index+=1
					#
					# 		pool = Pool(number_cpu_available)
					# 		all_results = [*pool.map(calc_stuff, all_indexes)]
					# 		pool.close()
					# 		pool.join()
					#
					# 		for i in range(len(all_results)):
					# 			nH_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[0]
					# 			nHp_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[1]
					# 			nHm_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[2]
					# 			nH2_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[3]
					# 			nH2p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[4]
					# 			nH3p_ne_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[5]
					# 			residuals_all[int(all_results[i].my_time_pos), int(all_results[i].my_r_pos)] = (all_results[i].results)[6]
					#
					#
					# 		np.savez_compressed(path_where_to_save_everything + mod4 +'/results_2',nH_ne_all=nH_ne_all,nHp_ne_all=nHp_ne_all,nHm_ne_all=nHm_ne_all,nH2_ne_all=nH2_ne_all,nH2p_ne_all=nH2p_ne_all,nH3p_ne_all=nH3p_ne_all,residuals_all=residuals_all)
					# 	else:
					# 		nH_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH_ne_all']
					# 		nHp_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nHp_ne_all']
					# 		nHm_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nHm_ne_all']
					# 		nH2_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH2_ne_all']
					# 		nH2p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH2p_ne_all']
					# 		nH3p_ne_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['nH3p_ne_all']
					# 		residuals_all = np.load(path_where_to_save_everything + mod4 +'/results_2.npz')['residuals_all']
					#
					#
					# # plt.figure()
					# # plt.title('ne,Te,nH_ne,h_atomic_density,OES_multiplier\n'+str([*merge_ne_prof_multipulse_interp_crop_limited_restrict,*merge_Te_prof_multipulse_interp_crop_limited_restrict,*fit[0],OES_multiplier]))
					# # plt.plot(n_list,inverted_profiles_crop_restrict*OES_multiplier)
					# # plt.plot(n_list,fit_nH_ne_h_atomic_density(recombination_restrict,merge_ne_prof_multipulse_interp_crop_limited_restrict,excitation_restrict)(n_list,*fit[0]))
					# # plt.pause(0.01)
					#
					# global_pass = 3
					# exec(open("/home/ffederic/work/Collaboratory/test/experimental_data/post_process_PSI_parameter_search_1_Yacora_plots.py").read())
